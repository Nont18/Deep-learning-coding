{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2041,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import mediapipe as mp \n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2042,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holist = mp.solutions.holistic \n",
    "mp_draw = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2043,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_detection(img, model):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img.flags.writeable = False                 \n",
    "    result = model.process(img)                 # Make prediction\n",
    "    img.flags.writeable = True                   \n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR) \n",
    "    return img, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2044,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_landmarks(img, result):\n",
    "    mp_draw.draw_landmarks(img, result.face_landmarks, mp_holist.FACEMESH_CONTOURS) # Draw face connections\n",
    "    mp_draw.draw_landmarks(img, result.pose_landmarks, mp_holist.POSE_CONNECTIONS) # Draw pose connections\n",
    "    mp_draw.draw_landmarks(img, result.left_hand_landmarks, mp_holist.HAND_CONNECTIONS) # Draw left hand connections\n",
    "    mp_draw.draw_landmarks(img, result.right_hand_landmarks, mp_holist.HAND_CONNECTIONS) # Draw right hand connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2045,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_styled_landmarks(img, result):\n",
    "    mp_draw.draw_landmarks(img, result.face_landmarks, mp_holist.FACEMESH_CONTOURS, \n",
    "                             mp_draw.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1), # color the joint \n",
    "                             mp_draw.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1) #color the connection\n",
    "                             ) \n",
    "    # mp_draw.draw_landmarks(img, result.face_landmarks, mp_holist.FACEMESH_CONTOURS, \n",
    "    #                          mp_draw.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1), # color the joint \n",
    "    #                          mp_draw.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1) #color the connection\n",
    "    #                          ) \n",
    "    \n",
    "    mp_draw.draw_landmarks(img, result.pose_landmarks, mp_holist.POSE_CONNECTIONS,\n",
    "                             mp_draw.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4), \n",
    "                             mp_draw.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                             ) \n",
    "    mp_draw.draw_landmarks(img, result.left_hand_landmarks, mp_holist.HAND_CONNECTIONS, \n",
    "                             mp_draw.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4), \n",
    "                             mp_draw.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                             ) \n",
    "    mp_draw.draw_landmarks(img, result.right_hand_landmarks, mp_holist.HAND_CONNECTIONS, \n",
    "                             mp_draw.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4), \n",
    "                             mp_draw.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                             ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2046,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frozenset({(0, 1),\n",
       "           (0, 4),\n",
       "           (1, 2),\n",
       "           (2, 3),\n",
       "           (3, 7),\n",
       "           (4, 5),\n",
       "           (5, 6),\n",
       "           (6, 8),\n",
       "           (9, 10),\n",
       "           (11, 12),\n",
       "           (11, 13),\n",
       "           (11, 23),\n",
       "           (12, 14),\n",
       "           (12, 24),\n",
       "           (13, 15),\n",
       "           (14, 16),\n",
       "           (15, 17),\n",
       "           (15, 19),\n",
       "           (15, 21),\n",
       "           (16, 18),\n",
       "           (16, 20),\n",
       "           (16, 22),\n",
       "           (17, 19),\n",
       "           (18, 20),\n",
       "           (23, 24),\n",
       "           (23, 25),\n",
       "           (24, 26),\n",
       "           (25, 27),\n",
       "           (26, 28),\n",
       "           (27, 29),\n",
       "           (27, 31),\n",
       "           (28, 30),\n",
       "           (28, 32),\n",
       "           (29, 31),\n",
       "           (30, 32)})"
      ]
     },
     "execution_count": 2046,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp_holist.POSE_CONNECTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2047,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keypoints(results):\n",
    "    pose=np.array([[res.x,res.y,res.z,res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*4)\n",
    "    left_hnd=np.array([[res.x,res.y,res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "    right_hnd=np.array([[res.x,res.y,res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "    face=np.array([[res.x,res.y,res.z] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(468*3)\n",
    "    return np.concatenate([pose,left_hnd,right_hnd,face])\n",
    "# concatenating for the model to detect the sign language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2048,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 2048,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "video_dir = \"C:/Users/araya/Desktop/keypoints/video_extract\"\n",
    "video_list = []\n",
    "video_list = os.listdir(video_dir)\n",
    "\n",
    "len(video_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2049,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['กฎกระทรวง.mp4',\n",
       " 'กฎหมายรัฐธรรมนูญ.mp4',\n",
       " 'กรมอนามัย.mp4',\n",
       " 'กรรม.mp4',\n",
       " 'กรรมสิทธิ์.mp4',\n",
       " 'กระโดด.mp4',\n",
       " 'กล้วยบวชชี.mp4',\n",
       " 'กล้วยเชื่อม.mp4',\n",
       " 'กังวล.mp4',\n",
       " 'กีฬา.mp4',\n",
       " 'น้อง.mp4',\n",
       " 'เขิน.mp4',\n",
       " 'เขื่อนดิน.mp4',\n",
       " 'เขื่อนสิริกิติ์.mp4',\n",
       " 'เข้าใจผิด.mp4',\n",
       " 'เคย.mp4',\n",
       " 'เครียด.mp4',\n",
       " 'เครื่องปั่นดิน.mp4',\n",
       " 'เครื่องหมายการค้า.mp4',\n",
       " 'เจอ.mp4',\n",
       " 'เจ้าหนี้.mp4',\n",
       " 'เช่าซื้อ.mp4',\n",
       " 'เช่าทรัพย์.mp4',\n",
       " 'เซอร์เบีย.mp4',\n",
       " 'เซเนกัล.mp4',\n",
       " 'เซ็ง.mp4',\n",
       " 'เดิน.mp4',\n",
       " 'เดิมพัน.mp4',\n",
       " 'เพลีย.mp4',\n",
       " 'เมื่อย.mp4',\n",
       " 'เม็กซิโก.mp4',\n",
       " 'เฮโรอีน.mp4',\n",
       " 'แกมเบีย.mp4',\n",
       " 'แซมเบีย.mp4',\n",
       " 'โกหก.mp4',\n",
       " 'โจทก์.mp4',\n",
       " 'โชจู.mp4',\n",
       " 'ใกล้.mp4',\n",
       " 'ไดโนเสาร์.mp4',\n",
       " 'ไอซ์.mp4']"
      ]
     },
     "execution_count": 2049,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2050,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for exported data, numpy arrays\n",
    "Model_Data=os.path.join('Data for different actions')\n",
    "\n",
    "actions = np.array(video_list)\n",
    "\n",
    "no_of_seqs = 1\n",
    "\n",
    "# 30 frames in length\n",
    "seq_length = 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2051,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['กฎกระทรวง.mp4', 'กฎหมายรัฐธรรมนูญ.mp4', 'กรมอนามัย.mp4',\n",
       "       'กรรม.mp4', 'กรรมสิทธิ์.mp4', 'กระโดด.mp4', 'กล้วยบวชชี.mp4',\n",
       "       'กล้วยเชื่อม.mp4', 'กังวล.mp4', 'กีฬา.mp4', 'น้อง.mp4', 'เขิน.mp4',\n",
       "       'เขื่อนดิน.mp4', 'เขื่อนสิริกิติ์.mp4', 'เข้าใจผิด.mp4', 'เคย.mp4',\n",
       "       'เครียด.mp4', 'เครื่องปั่นดิน.mp4', 'เครื่องหมายการค้า.mp4',\n",
       "       'เจอ.mp4', 'เจ้าหนี้.mp4', 'เช่าซื้อ.mp4', 'เช่าทรัพย์.mp4',\n",
       "       'เซอร์เบีย.mp4', 'เซเนกัล.mp4', 'เซ็ง.mp4', 'เดิน.mp4',\n",
       "       'เดิมพัน.mp4', 'เพลีย.mp4', 'เมื่อย.mp4', 'เม็กซิโก.mp4',\n",
       "       'เฮโรอีน.mp4', 'แกมเบีย.mp4', 'แซมเบีย.mp4', 'โกหก.mp4',\n",
       "       'โจทก์.mp4', 'โชจู.mp4', 'ใกล้.mp4', 'ไดโนเสาร์.mp4', 'ไอซ์.mp4'],\n",
       "      dtype='<U21')"
      ]
     },
     "execution_count": 2051,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collecting keypoint values for Training nd Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2052,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory where your videos are stored\n",
    "directory = \"C:/Users/araya/Desktop/keypoints/video_extract\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2053,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/araya/Desktop/keypoints/video_extract'"
      ]
     },
     "execution_count": 2053,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2054,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/araya/Desktop/keypoints/video_extract/กฎกระทรวง.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/กฎหมายรัฐธรรมนูญ.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/กรมอนามัย.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/กรรม.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/กรรมสิทธิ์.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/กระโดด.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/กล้วยบวชชี.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/กล้วยเชื่อม.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/กังวล.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/กีฬา.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/น้อง.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เขิน.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เขื่อนดิน.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เขื่อนสิริกิติ์.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เข้าใจผิด.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เคย.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เครียด.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เครื่องปั่นดิน.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เครื่องหมายการค้า.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เจอ.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เจ้าหนี้.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เช่าซื้อ.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เช่าทรัพย์.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เซอร์เบีย.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เซเนกัล.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เซ็ง.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เดิน.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เดิมพัน.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เพลีย.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เมื่อย.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เม็กซิโก.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เฮโรอีน.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/แกมเบีย.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/แซมเบีย.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/โกหก.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/โจทก์.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/โชจู.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/ใกล้.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/ไดโนเสาร์.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/ไอซ์.mp4\n"
     ]
    }
   ],
   "source": [
    "for filename in actions:\n",
    "    print(directory + '/' + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2055,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Data for different actions/กฎกระทรวง.mp4/กฎกระทรวง.npy', 'Data for different actions/กฎหมายรัฐธรรมนูญ.mp4/กฎหมายรัฐธรรมนูญ.npy', 'Data for different actions/กรมอนามัย.mp4/กรมอนามัย.npy', 'Data for different actions/กรรม.mp4/กรรม.npy', 'Data for different actions/กรรมสิทธิ์.mp4/กรรมสิทธิ์.npy', 'Data for different actions/กระโดด.mp4/กระโดด.npy', 'Data for different actions/กล้วยบวชชี.mp4/กล้วยบวชชี.npy', 'Data for different actions/กล้วยเชื่อม.mp4/กล้วยเชื่อม.npy', 'Data for different actions/กังวล.mp4/กังวล.npy', 'Data for different actions/กีฬา.mp4/กีฬา.npy', 'Data for different actions/น้อง.mp4/น้อง.npy', 'Data for different actions/เขิน.mp4/เขิน.npy', 'Data for different actions/เขื่อนดิน.mp4/เขื่อนดิน.npy', 'Data for different actions/เขื่อนสิริกิติ์.mp4/เขื่อนสิริกิติ์.npy', 'Data for different actions/เข้าใจผิด.mp4/เข้าใจผิด.npy', 'Data for different actions/เคย.mp4/เคย.npy', 'Data for different actions/เครียด.mp4/เครียด.npy', 'Data for different actions/เครื่องปั่นดิน.mp4/เครื่องปั่นดิน.npy', 'Data for different actions/เครื่องหมายการค้า.mp4/เครื่องหมายการค้า.npy', 'Data for different actions/เจอ.mp4/เจอ.npy', 'Data for different actions/เจ้าหนี้.mp4/เจ้าหนี้.npy', 'Data for different actions/เช่าซื้อ.mp4/เช่าซื้อ.npy', 'Data for different actions/เช่าทรัพย์.mp4/เช่าทรัพย์.npy', 'Data for different actions/เซอร์เบีย.mp4/เซอร์เบีย.npy', 'Data for different actions/เซเนกัล.mp4/เซเนกัล.npy', 'Data for different actions/เซ็ง.mp4/เซ็ง.npy', 'Data for different actions/เดิน.mp4/เดิน.npy', 'Data for different actions/เดิมพัน.mp4/เดิมพัน.npy', 'Data for different actions/เพลีย.mp4/เพลีย.npy', 'Data for different actions/เมื่อย.mp4/เมื่อย.npy', 'Data for different actions/เม็กซิโก.mp4/เม็กซิโก.npy', 'Data for different actions/เฮโรอีน.mp4/เฮโรอีน.npy', 'Data for different actions/แกมเบีย.mp4/แกมเบีย.npy', 'Data for different actions/แซมเบีย.mp4/แซมเบีย.npy', 'Data for different actions/โกหก.mp4/โกหก.npy', 'Data for different actions/โจทก์.mp4/โจทก์.npy', 'Data for different actions/โชจู.mp4/โชจู.npy', 'Data for different actions/ใกล้.mp4/ใกล้.npy', 'Data for different actions/ไดโนเสาร์.mp4/ไดโนเสาร์.npy', 'Data for different actions/ไอซ์.mp4/ไอซ์.npy']\n"
     ]
    }
   ],
   "source": [
    "file_paths = []\n",
    "for action in actions:\n",
    "    video_path = os.path.join('Data for different actions/', action)\n",
    "    # print(video_path)\n",
    "    # print(action)\n",
    "    file_paths.append(video_path + '/' + action.split(\".\")[0] + \".npy\")\n",
    "print(file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2056,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_keypoint_sequences(file_paths):\n",
    "    keypoint_sequences = []\n",
    "    for file_path in file_paths:\n",
    "        keypoints = np.load(file_path)\n",
    "        keypoint_sequences.append(torch.tensor(keypoints, dtype=torch.float32))\n",
    "    return keypoint_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2057,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 0.5013,  0.2452, -1.2167,  ...,  0.5663,  0.2188,  0.0098],\n",
       "         [ 0.4997,  0.2482, -1.4690,  ...,  0.5652,  0.2181,  0.0106],\n",
       "         [ 0.4984,  0.2500, -1.4853,  ...,  0.5654,  0.2185,  0.0112],\n",
       "         ...,\n",
       "         [ 0.4861,  0.2513, -1.3416,  ...,  0.5572,  0.2177,  0.0091],\n",
       "         [ 0.4873,  0.2514, -1.3574,  ...,  0.5575,  0.2172,  0.0097],\n",
       "         [ 0.4883,  0.2516, -1.3579,  ...,  0.5577,  0.2170,  0.0101]]),\n",
       " tensor([[ 0.4922,  0.2382, -1.2850,  ...,  0.5578,  0.2124,  0.0094],\n",
       "         [ 0.4920,  0.2405, -1.4288,  ...,  0.5571,  0.2116,  0.0099],\n",
       "         [ 0.4920,  0.2409, -1.4093,  ...,  0.5567,  0.2122,  0.0098],\n",
       "         ...,\n",
       "         [ 0.4814,  0.2260, -1.3318,  ...,  0.5503,  0.1923,  0.0123],\n",
       "         [ 0.4815,  0.2257, -1.3351,  ...,  0.5503,  0.1921,  0.0122],\n",
       "         [ 0.4815,  0.2255, -1.3497,  ...,  0.5501,  0.1919,  0.0124]]),\n",
       " tensor([[ 0.5049,  0.2371, -1.2115,  ...,  0.5643,  0.2082,  0.0088],\n",
       "         [ 0.5045,  0.2381, -1.1896,  ...,  0.5643,  0.2081,  0.0085],\n",
       "         [ 0.5041,  0.2385, -1.1915,  ...,  0.5643,  0.2080,  0.0089],\n",
       "         ...,\n",
       "         [ 0.4963,  0.2307, -1.3096,  ...,  0.5624,  0.2043,  0.0127],\n",
       "         [ 0.4965,  0.2308, -1.3085,  ...,  0.5625,  0.2045,  0.0126],\n",
       "         [ 0.4972,  0.2312, -1.3053,  ...,  0.5633,  0.2045,  0.0128]]),\n",
       " tensor([[ 0.5134,  0.2614, -1.4426,  ...,  0.5818,  0.2272,  0.0153],\n",
       "         [ 0.5130,  0.2604, -1.4262,  ...,  0.5810,  0.2273,  0.0147],\n",
       "         [ 0.5126,  0.2599, -1.4278,  ...,  0.5810,  0.2276,  0.0150],\n",
       "         ...,\n",
       "         [ 0.5079,  0.2693, -1.4999,  ...,  0.5780,  0.2349,  0.0115],\n",
       "         [ 0.5090,  0.2688, -1.4936,  ...,  0.5782,  0.2346,  0.0116],\n",
       "         [ 0.5092,  0.2683, -1.4518,  ...,  0.5786,  0.2341,  0.0116]]),\n",
       " tensor([[ 0.4883,  0.2402, -1.1024,  ...,  0.5482,  0.2132,  0.0081],\n",
       "         [ 0.4878,  0.2402, -1.1906,  ...,  0.5469,  0.2135,  0.0083],\n",
       "         [ 0.4863,  0.2402, -1.1774,  ...,  0.5477,  0.2141,  0.0087],\n",
       "         ...,\n",
       "         [ 0.4788,  0.3129, -1.6072,  ...,  0.5349,  0.2531,  0.0022],\n",
       "         [ 0.4782,  0.3129, -1.6350,  ...,  0.5344,  0.2525,  0.0022],\n",
       "         [ 0.4771,  0.3131, -1.6312,  ...,  0.5339,  0.2515,  0.0022]]),\n",
       " tensor([[ 0.4992,  0.1994, -1.1906,  ...,  0.5657,  0.1731,  0.0116],\n",
       "         [ 0.4988,  0.2047, -1.3590,  ...,  0.5663,  0.1723,  0.0123],\n",
       "         [ 0.4982,  0.2082, -1.3140,  ...,  0.5671,  0.1730,  0.0129],\n",
       "         ...,\n",
       "         [ 0.4743,  0.1974, -1.3230,  ...,  0.5475,  0.1620,  0.0155],\n",
       "         [ 0.4732,  0.1974, -1.3174,  ...,  0.5461,  0.1615,  0.0151],\n",
       "         [ 0.4720,  0.1974, -1.3149,  ...,  0.5453,  0.1614,  0.0149]]),\n",
       " tensor([[ 0.5023,  0.2809, -1.6242,  ...,  0.5847,  0.2321,  0.0112],\n",
       "         [ 0.5023,  0.2806, -1.6631,  ...,  0.5840,  0.2322,  0.0130],\n",
       "         [ 0.5022,  0.2805, -1.6912,  ...,  0.5837,  0.2322,  0.0122],\n",
       "         ...,\n",
       "         [ 0.5037,  0.2791, -1.5789,  ...,  0.5834,  0.2224,  0.0129],\n",
       "         [ 0.5044,  0.2774, -1.5686,  ...,  0.5831,  0.2220,  0.0130],\n",
       "         [ 0.5052,  0.2722, -1.5527,  ...,  0.5827,  0.2216,  0.0132]]),\n",
       " tensor([[ 0.4868,  0.2821, -1.4668,  ...,  0.5711,  0.2335,  0.0116],\n",
       "         [ 0.4861,  0.2786, -1.5812,  ...,  0.5702,  0.2334,  0.0129],\n",
       "         [ 0.4856,  0.2769, -1.6059,  ...,  0.5699,  0.2333,  0.0131],\n",
       "         ...,\n",
       "         [ 0.4826,  0.2583, -1.6140,  ...,  0.5606,  0.2261,  0.0154],\n",
       "         [ 0.4820,  0.2583, -1.5231,  ...,  0.5603,  0.2261,  0.0156],\n",
       "         [ 0.4818,  0.2580, -1.5255,  ...,  0.5600,  0.2263,  0.0156]]),\n",
       " tensor([[ 0.5016,  0.2321, -1.1859,  ...,  0.5647,  0.2139,  0.0072],\n",
       "         [ 0.5015,  0.2340, -1.1996,  ...,  0.5645,  0.2135,  0.0076],\n",
       "         [ 0.5016,  0.2346, -1.2272,  ...,  0.5644,  0.2137,  0.0082],\n",
       "         ...,\n",
       "         [ 0.4743,  0.2622, -1.4181,  ...,  0.5499,  0.2133,  0.0080],\n",
       "         [ 0.4763,  0.2599, -1.4742,  ...,  0.5519,  0.2118,  0.0090],\n",
       "         [ 0.4787,  0.2522, -1.6440,  ...,  0.5537,  0.2110,  0.0093]]),\n",
       " tensor([[ 0.4926,  0.1945, -1.2354,  ...,  0.5488,  0.1581,  0.0085],\n",
       "         [ 0.4942,  0.1949, -1.4254,  ...,  0.5481,  0.1576,  0.0085],\n",
       "         [ 0.4948,  0.1960, -1.4483,  ...,  0.5479,  0.1581,  0.0084],\n",
       "         ...,\n",
       "         [ 0.4917,  0.1882, -1.3355,  ...,  0.5458,  0.1536,  0.0126],\n",
       "         [ 0.4918,  0.1885, -1.3154,  ...,  0.5456,  0.1536,  0.0125],\n",
       "         [ 0.4918,  0.1886, -1.3147,  ...,  0.5453,  0.1537,  0.0124]]),\n",
       " tensor([[ 0.4956,  0.2681, -1.1361,  ...,  0.5554,  0.2332,  0.0147],\n",
       "         [ 0.4948,  0.2681, -1.3768,  ...,  0.5540,  0.2333,  0.0116],\n",
       "         [ 0.4943,  0.2681, -1.3754,  ...,  0.5538,  0.2332,  0.0116],\n",
       "         ...,\n",
       "         [ 0.4895,  0.2689, -1.2187,  ...,  0.5513,  0.2276,  0.0135],\n",
       "         [ 0.4889,  0.2688, -1.2198,  ...,  0.5508,  0.2276,  0.0134],\n",
       "         [ 0.4882,  0.2688, -1.2172,  ...,  0.5507,  0.2276,  0.0134]]),\n",
       " tensor([[ 0.5032,  0.2228, -1.1998,  ...,  0.5663,  0.1971,  0.0106],\n",
       "         [ 0.5035,  0.2228, -1.2072,  ...,  0.5662,  0.1969,  0.0106],\n",
       "         [ 0.5035,  0.2230, -1.2082,  ...,  0.5664,  0.1963,  0.0108],\n",
       "         ...,\n",
       "         [ 0.4982,  0.2206, -1.2743,  ...,  0.5578,  0.1892,  0.0092],\n",
       "         [ 0.4983,  0.2178, -1.2380,  ...,  0.5581,  0.1883,  0.0091],\n",
       "         [ 0.4979,  0.2173, -1.2264,  ...,  0.5578,  0.1877,  0.0096]]),\n",
       " tensor([[ 0.5442,  0.2507, -1.4443,  ...,  0.6105,  0.2203,  0.0123],\n",
       "         [ 0.5444,  0.2508, -1.6574,  ...,  0.6094,  0.2198,  0.0134],\n",
       "         [ 0.5445,  0.2510, -1.7250,  ...,  0.6093,  0.2195,  0.0144],\n",
       "         ...,\n",
       "         [ 0.5324,  0.2577, -1.6704,  ...,  0.5975,  0.2210,  0.0145],\n",
       "         [ 0.5323,  0.2560, -1.6673,  ...,  0.5966,  0.2206,  0.0148],\n",
       "         [ 0.5323,  0.2553, -1.6826,  ...,  0.5957,  0.2201,  0.0146]]),\n",
       " tensor([[ 0.5402,  0.2562, -1.5458,  ...,  0.6041,  0.2257,  0.0125],\n",
       "         [ 0.5389,  0.2596, -1.7020,  ...,  0.6031,  0.2264,  0.0130],\n",
       "         [ 0.5379,  0.2616, -1.7134,  ...,  0.6027,  0.2258,  0.0139],\n",
       "         ...,\n",
       "         [ 0.5153,  0.2631, -1.6030,  ...,  0.5956,  0.2125,  0.0142],\n",
       "         [ 0.5176,  0.2626, -1.6101,  ...,  0.5985,  0.2126,  0.0139],\n",
       "         [ 0.5197,  0.2624, -1.5662,  ...,  0.6011,  0.2119,  0.0145]]),\n",
       " tensor([[ 0.5030,  0.2553, -1.1988,  ...,  0.5699,  0.2265,  0.0097],\n",
       "         [ 0.5028,  0.2582, -1.2761,  ...,  0.5689,  0.2266,  0.0109],\n",
       "         [ 0.5028,  0.2605, -1.3315,  ...,  0.5690,  0.2269,  0.0105],\n",
       "         ...,\n",
       "         [ 0.5028,  0.2675, -1.4499,  ...,  0.5672,  0.2323,  0.0110],\n",
       "         [ 0.5007,  0.2672, -1.4234,  ...,  0.5668,  0.2317,  0.0115],\n",
       "         [ 0.4988,  0.2671, -1.4308,  ...,  0.5670,  0.2312,  0.0118]]),\n",
       " tensor([[ 0.5069,  0.2355, -1.3384,  ...,  0.5700,  0.2051,  0.0053],\n",
       "         [ 0.5045,  0.2395, -1.5097,  ...,  0.5699,  0.2043,  0.0064],\n",
       "         [ 0.5028,  0.2420, -1.5081,  ...,  0.5699,  0.2045,  0.0069],\n",
       "         ...,\n",
       "         [ 0.4952,  0.2462, -1.4319,  ...,  0.5658,  0.2015,  0.0122],\n",
       "         [ 0.4952,  0.2448, -1.4781,  ...,  0.5661,  0.2014,  0.0123],\n",
       "         [ 0.4953,  0.2436, -1.4689,  ...,  0.5662,  0.2013,  0.0124]]),\n",
       " tensor([[ 0.5035,  0.2282, -1.1379,  ...,  0.5710,  0.1953,  0.0120],\n",
       "         [ 0.5033,  0.2284, -1.2771,  ...,  0.5713,  0.1954,  0.0123],\n",
       "         [ 0.5032,  0.2286, -1.2743,  ...,  0.5715,  0.1957,  0.0122],\n",
       "         ...,\n",
       "         [ 0.4810,  0.2296, -1.4129,  ...,  0.5542,  0.1897,  0.0133],\n",
       "         [ 0.4812,  0.2296, -1.4275,  ...,  0.5549,  0.1900,  0.0130],\n",
       "         [ 0.4816,  0.2299, -1.4337,  ...,  0.5557,  0.1903,  0.0133]]),\n",
       " tensor([[ 0.5108,  0.2425, -1.1053,  ...,  0.5724,  0.2176,  0.0127],\n",
       "         [ 0.5091,  0.2430, -1.3007,  ...,  0.5713,  0.2177,  0.0129],\n",
       "         [ 0.5080,  0.2432, -1.3035,  ...,  0.5714,  0.2179,  0.0130],\n",
       "         ...,\n",
       "         [ 0.4966,  0.2620, -1.5367,  ...,  0.5653,  0.2259,  0.0082],\n",
       "         [ 0.4968,  0.2621, -1.5419,  ...,  0.5656,  0.2262,  0.0083],\n",
       "         [ 0.4971,  0.2623, -1.5482,  ...,  0.5658,  0.2263,  0.0086]]),\n",
       " tensor([[ 0.4878,  0.2235, -1.2515,  ...,  0.5511,  0.1981,  0.0114],\n",
       "         [ 0.4870,  0.2286, -1.4279,  ...,  0.5506,  0.1977,  0.0105],\n",
       "         [ 0.4865,  0.2315, -1.4431,  ...,  0.5508,  0.1984,  0.0110],\n",
       "         ...,\n",
       "         [ 0.4901,  0.2217, -1.3449,  ...,  0.5576,  0.1888,  0.0156],\n",
       "         [ 0.4898,  0.2224, -1.3780,  ...,  0.5575,  0.1892,  0.0157],\n",
       "         [ 0.4896,  0.2232, -1.4140,  ...,  0.5572,  0.1897,  0.0156]]),\n",
       " tensor([[ 0.5194,  0.2227, -1.3410,  ...,  0.5911,  0.1970,  0.0142],\n",
       "         [ 0.5200,  0.2228, -1.3298,  ...,  0.5912,  0.1965,  0.0131],\n",
       "         [ 0.5202,  0.2230, -1.3074,  ...,  0.5909,  0.1970,  0.0149],\n",
       "         ...,\n",
       "         [ 0.5146,  0.2198, -1.3267,  ...,  0.5821,  0.1907,  0.0159],\n",
       "         [ 0.5141,  0.2205, -1.3207,  ...,  0.5816,  0.1911,  0.0154],\n",
       "         [ 0.5137,  0.2209, -1.3223,  ...,  0.5812,  0.1917,  0.0161]]),\n",
       " tensor([[ 0.5103,  0.2428, -1.1660,  ...,  0.5757,  0.2179,  0.0081],\n",
       "         [ 0.5106,  0.2437, -1.2850,  ...,  0.5751,  0.2183,  0.0099],\n",
       "         [ 0.5112,  0.2443, -1.2880,  ...,  0.5748,  0.2189,  0.0108],\n",
       "         ...,\n",
       "         [ 0.4800,  0.2603, -1.3086,  ...,  0.5532,  0.2237,  0.0069],\n",
       "         [ 0.4807,  0.2604, -1.2544,  ...,  0.5539,  0.2238,  0.0067],\n",
       "         [ 0.4813,  0.2604, -1.2161,  ...,  0.5548,  0.2238,  0.0065]]),\n",
       " tensor([[ 0.4945,  0.2362, -1.1227,  ...,  0.5529,  0.2086,  0.0088],\n",
       "         [ 0.4947,  0.2363, -1.1264,  ...,  0.5528,  0.2094,  0.0088],\n",
       "         [ 0.4951,  0.2364, -1.1371,  ...,  0.5531,  0.2099,  0.0089],\n",
       "         ...,\n",
       "         [ 0.4933,  0.2480, -1.2424,  ...,  0.5563,  0.2184,  0.0091],\n",
       "         [ 0.4933,  0.2480, -1.2443,  ...,  0.5565,  0.2185,  0.0093],\n",
       "         [ 0.4932,  0.2480, -1.2944,  ...,  0.5564,  0.2185,  0.0095]]),\n",
       " tensor([[ 0.5038,  0.2425, -1.1550,  ...,  0.5665,  0.2136,  0.0080],\n",
       "         [ 0.5027,  0.2423, -1.2423,  ...,  0.5653,  0.2133,  0.0092],\n",
       "         [ 0.5018,  0.2423, -1.2565,  ...,  0.5649,  0.2130,  0.0094],\n",
       "         ...,\n",
       "         [ 0.4950,  0.2412, -1.1727,  ...,  0.5624,  0.2175,  0.0087],\n",
       "         [ 0.4951,  0.2412, -1.1690,  ...,  0.5625,  0.2177,  0.0082],\n",
       "         [ 0.4951,  0.2412, -1.1910,  ...,  0.5626,  0.2180,  0.0079]]),\n",
       " tensor([[ 0.4916,  0.2518, -1.3187,  ...,  0.5597,  0.2202,  0.0108],\n",
       "         [ 0.4907,  0.2519, -1.3672,  ...,  0.5580,  0.2209,  0.0105],\n",
       "         [ 0.4896,  0.2520, -1.4026,  ...,  0.5580,  0.2210,  0.0110],\n",
       "         ...,\n",
       "         [ 0.4850,  0.2552, -1.4312,  ...,  0.5509,  0.2199,  0.0138],\n",
       "         [ 0.4839,  0.2550, -1.4298,  ...,  0.5505,  0.2199,  0.0138],\n",
       "         [ 0.4831,  0.2549, -1.4164,  ...,  0.5501,  0.2200,  0.0137]]),\n",
       " tensor([[ 0.5051,  0.2347, -1.4390,  ...,  0.5717,  0.2094,  0.0091],\n",
       "         [ 0.5024,  0.2389, -1.5627,  ...,  0.5707,  0.2087,  0.0090],\n",
       "         [ 0.5005,  0.2417, -1.5896,  ...,  0.5704,  0.2090,  0.0098],\n",
       "         ...,\n",
       "         [ 0.4950,  0.2365, -1.4622,  ...,  0.5663,  0.2072,  0.0114],\n",
       "         [ 0.4950,  0.2366, -1.4772,  ...,  0.5667,  0.2075,  0.0115],\n",
       "         [ 0.4949,  0.2366, -1.4725,  ...,  0.5671,  0.2078,  0.0120]]),\n",
       " tensor([[ 0.5064,  0.2529, -1.3080,  ...,  0.5751,  0.2261,  0.0114],\n",
       "         [ 0.5055,  0.2550, -1.3556,  ...,  0.5752,  0.2257,  0.0106],\n",
       "         [ 0.5048,  0.2568, -1.3925,  ...,  0.5751,  0.2260,  0.0110],\n",
       "         ...,\n",
       "         [ 0.4960,  0.2624, -1.3587,  ...,  0.5642,  0.2311,  0.0101],\n",
       "         [ 0.4961,  0.2619, -1.3373,  ...,  0.5652,  0.2307,  0.0104],\n",
       "         [ 0.4961,  0.2615, -1.3405,  ...,  0.5653,  0.2302,  0.0102]]),\n",
       " tensor([[ 0.5267,  0.2322, -1.2986,  ...,  0.5921,  0.1996,  0.0123],\n",
       "         [ 0.5267,  0.2305, -1.3156,  ...,  0.5925,  0.1999,  0.0112],\n",
       "         [ 0.5266,  0.2296, -1.3147,  ...,  0.5928,  0.1997,  0.0121],\n",
       "         ...,\n",
       "         [ 0.5122,  0.2243, -1.2697,  ...,  0.5819,  0.1855,  0.0147],\n",
       "         [ 0.5114,  0.2239, -1.2687,  ...,  0.5817,  0.1857,  0.0145],\n",
       "         [ 0.5110,  0.2235, -1.2585,  ...,  0.5815,  0.1858,  0.0145]]),\n",
       " tensor([[ 0.5050,  0.2164, -1.1575,  ...,  0.5700,  0.1959,  0.0103],\n",
       "         [ 0.5041,  0.2187, -1.3621,  ...,  0.5689,  0.1959,  0.0100],\n",
       "         [ 0.5031,  0.2218, -1.3920,  ...,  0.5693,  0.1959,  0.0109],\n",
       "         ...,\n",
       "         [ 0.4987,  0.2252, -1.2609,  ...,  0.5655,  0.1932,  0.0101],\n",
       "         [ 0.4982,  0.2238, -1.2657,  ...,  0.5653,  0.1926,  0.0103],\n",
       "         [ 0.4969,  0.2230, -1.2967,  ...,  0.5649,  0.1919,  0.0105]]),\n",
       " tensor([[ 0.5097,  0.2301, -1.2305,  ...,  0.5773,  0.2070,  0.0135],\n",
       "         [ 0.5098,  0.2316, -1.4094,  ...,  0.5762,  0.2072,  0.0130],\n",
       "         [ 0.5099,  0.2328, -1.4219,  ...,  0.5754,  0.2074,  0.0134],\n",
       "         ...,\n",
       "         [ 0.5106,  0.2519, -1.1800,  ...,  0.5731,  0.2204,  0.0132],\n",
       "         [ 0.5082,  0.2514, -1.1958,  ...,  0.5717,  0.2193,  0.0134],\n",
       "         [ 0.5074,  0.2516, -1.2210,  ...,  0.5703,  0.2182,  0.0128]]),\n",
       " tensor([[ 0.5410,  0.2495, -1.3908,  ...,  0.6085,  0.2224,  0.0099],\n",
       "         [ 0.5399,  0.2502, -1.3960,  ...,  0.6066,  0.2219,  0.0111],\n",
       "         [ 0.5390,  0.2511, -1.3861,  ...,  0.6062,  0.2215,  0.0105],\n",
       "         ...,\n",
       "         [ 0.5131,  0.2461, -1.3199,  ...,  0.5857,  0.2158,  0.0118],\n",
       "         [ 0.5137,  0.2459, -1.3370,  ...,  0.5858,  0.2153,  0.0118],\n",
       "         [ 0.5141,  0.2456, -1.3376,  ...,  0.5860,  0.2150,  0.0116]]),\n",
       " tensor([[ 0.4813,  0.2267, -1.2462,  ...,  0.5499,  0.2013,  0.0123],\n",
       "         [ 0.4796,  0.2283, -1.4595,  ...,  0.5479,  0.2026,  0.0127],\n",
       "         [ 0.4786,  0.2300, -1.5108,  ...,  0.5480,  0.2025,  0.0122],\n",
       "         ...,\n",
       "         [ 0.4782,  0.2297, -1.2598,  ...,  0.5464,  0.1965,  0.0150],\n",
       "         [ 0.4781,  0.2300, -1.2686,  ...,  0.5459,  0.1960,  0.0147],\n",
       "         [ 0.4780,  0.2304, -1.2444,  ...,  0.5461,  0.1953,  0.0154]]),\n",
       " tensor([[ 0.5051,  0.2433, -1.3371,  ...,  0.5701,  0.2185,  0.0094],\n",
       "         [ 0.5042,  0.2464, -1.4811,  ...,  0.5696,  0.2193,  0.0109],\n",
       "         [ 0.5039,  0.2479, -1.4928,  ...,  0.5700,  0.2201,  0.0112],\n",
       "         ...,\n",
       "         [ 0.4965,  0.2517, -1.4369,  ...,  0.5645,  0.2217,  0.0130],\n",
       "         [ 0.4956,  0.2516, -1.4394,  ...,  0.5637,  0.2215,  0.0129],\n",
       "         [ 0.4943,  0.2514, -1.4394,  ...,  0.5628,  0.2207,  0.0124]]),\n",
       " tensor([[ 0.5269,  0.2488, -1.5232,  ...,  0.5929,  0.2181,  0.0118],\n",
       "         [ 0.5260,  0.2493, -1.4445,  ...,  0.5918,  0.2172,  0.0111],\n",
       "         [ 0.5250,  0.2497, -1.4588,  ...,  0.5916,  0.2171,  0.0113],\n",
       "         ...,\n",
       "         [ 0.5126,  0.2514, -1.5292,  ...,  0.5827,  0.2212,  0.0138],\n",
       "         [ 0.5125,  0.2512, -1.5273,  ...,  0.5813,  0.2204,  0.0136],\n",
       "         [ 0.5123,  0.2512, -1.5221,  ...,  0.5795,  0.2200,  0.0137]]),\n",
       " tensor([[ 0.5103,  0.2330, -1.4731,  ...,  0.5745,  0.2056,  0.0102],\n",
       "         [ 0.5071,  0.2360, -1.5453,  ...,  0.5731,  0.2055,  0.0103],\n",
       "         [ 0.5052,  0.2381, -1.5650,  ...,  0.5733,  0.2056,  0.0100],\n",
       "         ...,\n",
       "         [ 0.4875,  0.2316, -1.5252,  ...,  0.5606,  0.1993,  0.0132],\n",
       "         [ 0.4872,  0.2318, -1.5227,  ...,  0.5604,  0.1997,  0.0129],\n",
       "         [ 0.4870,  0.2318, -1.5220,  ...,  0.5604,  0.2000,  0.0129]]),\n",
       " tensor([[ 0.4952,  0.2338, -1.3905,  ...,  0.5593,  0.2078,  0.0128],\n",
       "         [ 0.4926,  0.2435, -1.4861,  ...,  0.5600,  0.2072,  0.0117],\n",
       "         [ 0.4916,  0.2483, -1.4905,  ...,  0.5596,  0.2079,  0.0126],\n",
       "         ...,\n",
       "         [ 0.4846,  0.2462, -1.4163,  ...,  0.5649,  0.2045,  0.0151],\n",
       "         [ 0.4852,  0.2450, -1.4038,  ...,  0.5648,  0.2038,  0.0156],\n",
       "         [ 0.4857,  0.2436, -1.3897,  ...,  0.5648,  0.2033,  0.0155]]),\n",
       " tensor([[ 0.4828,  0.2604, -1.2334,  ...,  0.5483,  0.2258,  0.0073],\n",
       "         [ 0.4816,  0.2606, -1.4555,  ...,  0.5474,  0.2267,  0.0087],\n",
       "         [ 0.4809,  0.2608, -1.4653,  ...,  0.5475,  0.2266,  0.0088],\n",
       "         ...,\n",
       "         [ 0.4832,  0.2490, -1.4275,  ...,  0.5557,  0.2156,  0.0123],\n",
       "         [ 0.4845,  0.2491, -1.4277,  ...,  0.5566,  0.2158,  0.0124],\n",
       "         [ 0.4855,  0.2492, -1.4367,  ...,  0.5573,  0.2163,  0.0122]]),\n",
       " tensor([[ 0.5122,  0.2456, -1.3706,  ...,  0.5836,  0.2207,  0.0125],\n",
       "         [ 0.5121,  0.2461, -1.4417,  ...,  0.5818,  0.2208,  0.0118],\n",
       "         [ 0.5121,  0.2465, -1.4591,  ...,  0.5815,  0.2204,  0.0118],\n",
       "         ...,\n",
       "         [ 0.5017,  0.2434, -1.4740,  ...,  0.5812,  0.2105,  0.0155],\n",
       "         [ 0.5022,  0.2433, -1.4619,  ...,  0.5818,  0.2102,  0.0157],\n",
       "         [ 0.5032,  0.2431, -1.4609,  ...,  0.5821,  0.2097,  0.0163]]),\n",
       " tensor([[ 0.4849,  0.2484, -1.3873,  ...,  0.5543,  0.2162,  0.0108],\n",
       "         [ 0.4846,  0.2500, -1.4881,  ...,  0.5539,  0.2157,  0.0111],\n",
       "         [ 0.4844,  0.2507, -1.4935,  ...,  0.5537,  0.2161,  0.0111],\n",
       "         ...,\n",
       "         [ 0.4589,  0.2435, -1.4798,  ...,  0.5299,  0.2058,  0.0120],\n",
       "         [ 0.4586,  0.2436, -1.4788,  ...,  0.5293,  0.2056,  0.0122],\n",
       "         [ 0.4583,  0.2437, -1.4790,  ...,  0.5289,  0.2052,  0.0123]]),\n",
       " tensor([[ 0.5199,  0.2290, -1.2810,  ...,  0.5876,  0.2058,  0.0103],\n",
       "         [ 0.5195,  0.2307, -1.3821,  ...,  0.5873,  0.2059,  0.0106],\n",
       "         [ 0.5193,  0.2327, -1.4100,  ...,  0.5877,  0.2059,  0.0109],\n",
       "         ...,\n",
       "         [ 0.5108,  0.2431, -1.3919,  ...,  0.5781,  0.2077,  0.0105],\n",
       "         [ 0.5093,  0.2422, -1.3894,  ...,  0.5768,  0.2068,  0.0103],\n",
       "         [ 0.5079,  0.2405, -1.3818,  ...,  0.5751,  0.2053,  0.0102]]),\n",
       " tensor([[ 0.5005,  0.2439, -1.3629,  ...,  0.5694,  0.2139,  0.0154],\n",
       "         [ 0.5002,  0.2448, -1.5049,  ...,  0.5688,  0.2128,  0.0146],\n",
       "         [ 0.4999,  0.2457, -1.5287,  ...,  0.5683,  0.2134,  0.0148],\n",
       "         ...,\n",
       "         [ 0.4965,  0.2433, -1.3673,  ...,  0.5670,  0.2114,  0.0169],\n",
       "         [ 0.4960,  0.2433, -1.3676,  ...,  0.5660,  0.2107,  0.0168],\n",
       "         [ 0.4950,  0.2433, -1.3637,  ...,  0.5651,  0.2100,  0.0170]])]"
      ]
     },
     "execution_count": 2057,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the sequences\n",
    "import torch\n",
    "sequences = load_keypoint_sequences(file_paths)\n",
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2058,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40, 160, 1662])\n"
     ]
    }
   ],
   "source": [
    "# Pad the sequences to the same length\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "padded_sequences = pad_sequence(sequences, batch_first=True)\n",
    "pad_sequence\n",
    "print(padded_sequences.shape) # (batch_size, max_sequence_length, num_keypoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2059,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['กฎกระทรวง',\n",
       " 'กฎหมายรัฐธรรมนูญ',\n",
       " 'กรมอนามัย',\n",
       " 'กรรม',\n",
       " 'กรรมสิทธิ์',\n",
       " 'กระโดด',\n",
       " 'กล้วยบวชชี',\n",
       " 'กล้วยเชื่อม',\n",
       " 'กังวล',\n",
       " 'กีฬา',\n",
       " 'น้อง',\n",
       " 'เขิน',\n",
       " 'เขื่อนดิน',\n",
       " 'เขื่อนสิริกิติ์',\n",
       " 'เข้าใจผิด',\n",
       " 'เคย',\n",
       " 'เครียด',\n",
       " 'เครื่องปั่นดิน',\n",
       " 'เครื่องหมายการค้า',\n",
       " 'เจอ',\n",
       " 'เจ้าหนี้',\n",
       " 'เช่าซื้อ',\n",
       " 'เช่าทรัพย์',\n",
       " 'เซอร์เบีย',\n",
       " 'เซเนกัล',\n",
       " 'เซ็ง',\n",
       " 'เดิน',\n",
       " 'เดิมพัน',\n",
       " 'เพลีย',\n",
       " 'เมื่อย',\n",
       " 'เม็กซิโก',\n",
       " 'เฮโรอีน',\n",
       " 'แกมเบีย',\n",
       " 'แซมเบีย',\n",
       " 'โกหก',\n",
       " 'โจทก์',\n",
       " 'โชจู',\n",
       " 'ใกล้',\n",
       " 'ไดโนเสาร์',\n",
       " 'ไอซ์']"
      ]
     },
     "execution_count": 2059,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [action.split(\".\")[0] for action in actions]\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2060,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "       34, 35, 36, 37, 38, 39], dtype=int64)"
      ]
     },
     "execution_count": 2060,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "labels = le.fit_transform(labels)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2061,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# y = pd.read_csv(\"script.csv\")\n",
    "# y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2062,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y[\"label\"] = y[\"label\"].astype(int)\n",
    "# labels = y.label\n",
    "# labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2063,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# Create a custom dataset\n",
    "class KeypointDataset(Dataset):\n",
    "    def __init__(self, file_paths, labels):\n",
    "        self.file_paths = file_paths\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        keypoints = np.load(self.file_paths[idx])\n",
    "        label = self.labels[idx]\n",
    "        return torch.tensor(keypoints, dtype=torch.float32), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2064,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset\n",
    "dataset = KeypointDataset(file_paths, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2065,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Data for different actions/กฎกระทรวง.mp4/กฎกระทรวง.npy', 'Data for different actions/กฎหมายรัฐธรรมนูญ.mp4/กฎหมายรัฐธรรมนูญ.npy', 'Data for different actions/กรมอนามัย.mp4/กรมอนามัย.npy', 'Data for different actions/กรรม.mp4/กรรม.npy', 'Data for different actions/กรรมสิทธิ์.mp4/กรรมสิทธิ์.npy', 'Data for different actions/กระโดด.mp4/กระโดด.npy', 'Data for different actions/กล้วยบวชชี.mp4/กล้วยบวชชี.npy', 'Data for different actions/กล้วยเชื่อม.mp4/กล้วยเชื่อม.npy', 'Data for different actions/กังวล.mp4/กังวล.npy', 'Data for different actions/กีฬา.mp4/กีฬา.npy', 'Data for different actions/น้อง.mp4/น้อง.npy', 'Data for different actions/เขิน.mp4/เขิน.npy', 'Data for different actions/เขื่อนดิน.mp4/เขื่อนดิน.npy', 'Data for different actions/เขื่อนสิริกิติ์.mp4/เขื่อนสิริกิติ์.npy', 'Data for different actions/เข้าใจผิด.mp4/เข้าใจผิด.npy', 'Data for different actions/เคย.mp4/เคย.npy', 'Data for different actions/เครียด.mp4/เครียด.npy', 'Data for different actions/เครื่องปั่นดิน.mp4/เครื่องปั่นดิน.npy', 'Data for different actions/เครื่องหมายการค้า.mp4/เครื่องหมายการค้า.npy', 'Data for different actions/เจอ.mp4/เจอ.npy', 'Data for different actions/เจ้าหนี้.mp4/เจ้าหนี้.npy', 'Data for different actions/เช่าซื้อ.mp4/เช่าซื้อ.npy', 'Data for different actions/เช่าทรัพย์.mp4/เช่าทรัพย์.npy', 'Data for different actions/เซอร์เบีย.mp4/เซอร์เบีย.npy', 'Data for different actions/เซเนกัล.mp4/เซเนกัล.npy', 'Data for different actions/เซ็ง.mp4/เซ็ง.npy', 'Data for different actions/เดิน.mp4/เดิน.npy', 'Data for different actions/เดิมพัน.mp4/เดิมพัน.npy', 'Data for different actions/เพลีย.mp4/เพลีย.npy', 'Data for different actions/เมื่อย.mp4/เมื่อย.npy', 'Data for different actions/เม็กซิโก.mp4/เม็กซิโก.npy', 'Data for different actions/เฮโรอีน.mp4/เฮโรอีน.npy', 'Data for different actions/แกมเบีย.mp4/แกมเบีย.npy', 'Data for different actions/แซมเบีย.mp4/แซมเบีย.npy', 'Data for different actions/โกหก.mp4/โกหก.npy', 'Data for different actions/โจทก์.mp4/โจทก์.npy', 'Data for different actions/โชจู.mp4/โชจู.npy', 'Data for different actions/ใกล้.mp4/ใกล้.npy', 'Data for different actions/ไดโนเสาร์.mp4/ไดโนเสาร์.npy', 'Data for different actions/ไอซ์.mp4/ไอซ์.npy']\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]\n"
     ]
    }
   ],
   "source": [
    "print(dataset.file_paths)\n",
    "print(dataset.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2066,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collate function for padding\n",
    "def collate_fn(batch):\n",
    "    sequences, labels = zip(*batch)\n",
    "    padded_sequences = pad_sequence(sequences, batch_first=True)\n",
    "    return padded_sequences, torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2067,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x26bf277d130>"
      ]
     },
     "execution_count": 2067,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the DataLoader\n",
    "batch_size = 4\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2068,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2068,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set device (use GPU if available)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2069,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes,dropout):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc1 = nn.Linear(hidden_size, 256)\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        # c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        \n",
    "        # Forward propagate the LSTM\n",
    "        out, _ = self.lstm(self.dropout(x))\n",
    "        \n",
    "        # Use the last time step's output for classification\n",
    "        out = out[:, -1, :]\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2070,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model, loss function, and optimizer\n",
    "model = LSTMModel(input_size=1662, hidden_size=256, num_layers=2, num_classes=40, dropout=0.5).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2071,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()  # For multi-class classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2072,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1200], Loss: 3.8274 , Accuracy : 0.00%\n",
      "Epoch [2/1200], Loss: 3.7084 , Accuracy : 0.00%\n",
      "Epoch [3/1200], Loss: 3.8006 , Accuracy : 2.50%\n",
      "Epoch [4/1200], Loss: 3.9958 , Accuracy : 5.00%\n",
      "Epoch [5/1200], Loss: 4.1444 , Accuracy : 2.50%\n",
      "Epoch [6/1200], Loss: 3.4215 , Accuracy : 0.00%\n",
      "Epoch [7/1200], Loss: 3.1291 , Accuracy : 0.00%\n",
      "Epoch [8/1200], Loss: 3.9719 , Accuracy : 0.00%\n",
      "Epoch [9/1200], Loss: 3.5613 , Accuracy : 2.50%\n",
      "Epoch [10/1200], Loss: 3.4013 , Accuracy : 2.50%\n",
      "Epoch [11/1200], Loss: 3.1113 , Accuracy : 5.00%\n",
      "Epoch [12/1200], Loss: 3.5069 , Accuracy : 0.00%\n",
      "Epoch [13/1200], Loss: 3.6848 , Accuracy : 2.50%\n",
      "Epoch [14/1200], Loss: 4.0323 , Accuracy : 5.00%\n",
      "Epoch [15/1200], Loss: 2.8784 , Accuracy : 7.50%\n",
      "Epoch [16/1200], Loss: 2.5826 , Accuracy : 2.50%\n",
      "Epoch [17/1200], Loss: 3.6187 , Accuracy : 5.00%\n",
      "Epoch [18/1200], Loss: 3.2916 , Accuracy : 0.00%\n",
      "Epoch [19/1200], Loss: 3.4451 , Accuracy : 2.50%\n",
      "Epoch [20/1200], Loss: 3.1288 , Accuracy : 2.50%\n",
      "Epoch [21/1200], Loss: 2.8888 , Accuracy : 5.00%\n",
      "Epoch [22/1200], Loss: 3.4950 , Accuracy : 2.50%\n",
      "Epoch [23/1200], Loss: 3.4776 , Accuracy : 2.50%\n",
      "Epoch [24/1200], Loss: 3.9811 , Accuracy : 2.50%\n",
      "Epoch [25/1200], Loss: 3.4936 , Accuracy : 5.00%\n",
      "Epoch [26/1200], Loss: 3.2615 , Accuracy : 2.50%\n",
      "Epoch [27/1200], Loss: 3.4303 , Accuracy : 7.50%\n",
      "Epoch [28/1200], Loss: 2.4418 , Accuracy : 7.50%\n",
      "Epoch [29/1200], Loss: 3.3299 , Accuracy : 7.50%\n",
      "Epoch [30/1200], Loss: 3.8022 , Accuracy : 0.00%\n",
      "Epoch [31/1200], Loss: 3.0597 , Accuracy : 7.50%\n",
      "Epoch [32/1200], Loss: 2.9033 , Accuracy : 10.00%\n",
      "Epoch [33/1200], Loss: 2.4786 , Accuracy : 7.50%\n",
      "Epoch [34/1200], Loss: 3.0024 , Accuracy : 7.50%\n",
      "Epoch [35/1200], Loss: 2.5590 , Accuracy : 10.00%\n",
      "Epoch [36/1200], Loss: 2.9121 , Accuracy : 7.50%\n",
      "Epoch [37/1200], Loss: 2.4610 , Accuracy : 2.50%\n",
      "Epoch [38/1200], Loss: 3.4057 , Accuracy : 10.00%\n",
      "Epoch [39/1200], Loss: 3.5403 , Accuracy : 7.50%\n",
      "Epoch [40/1200], Loss: 2.8438 , Accuracy : 10.00%\n",
      "Epoch [41/1200], Loss: 3.5960 , Accuracy : 10.00%\n",
      "Epoch [42/1200], Loss: 2.9566 , Accuracy : 10.00%\n",
      "Epoch [43/1200], Loss: 3.3547 , Accuracy : 10.00%\n",
      "Epoch [44/1200], Loss: 2.8062 , Accuracy : 12.50%\n",
      "Epoch [45/1200], Loss: 2.8357 , Accuracy : 12.50%\n",
      "Epoch [46/1200], Loss: 3.3193 , Accuracy : 5.00%\n",
      "Epoch [47/1200], Loss: 2.7129 , Accuracy : 10.00%\n",
      "Epoch [48/1200], Loss: 2.1711 , Accuracy : 12.50%\n",
      "Epoch [49/1200], Loss: 2.6510 , Accuracy : 15.00%\n",
      "Epoch [50/1200], Loss: 2.8252 , Accuracy : 20.00%\n",
      "Epoch [51/1200], Loss: 3.3787 , Accuracy : 17.50%\n",
      "Epoch [52/1200], Loss: 2.6179 , Accuracy : 12.50%\n",
      "Epoch [53/1200], Loss: 1.9137 , Accuracy : 10.00%\n",
      "Epoch [54/1200], Loss: 2.8199 , Accuracy : 12.50%\n",
      "Epoch [55/1200], Loss: 3.6962 , Accuracy : 15.00%\n",
      "Epoch [56/1200], Loss: 2.7519 , Accuracy : 10.00%\n",
      "Epoch [57/1200], Loss: 3.9399 , Accuracy : 17.50%\n",
      "Epoch [58/1200], Loss: 3.6296 , Accuracy : 10.00%\n",
      "Epoch [59/1200], Loss: 2.7846 , Accuracy : 15.00%\n",
      "Epoch [60/1200], Loss: 3.4658 , Accuracy : 12.50%\n",
      "Epoch [61/1200], Loss: 3.0476 , Accuracy : 15.00%\n",
      "Epoch [62/1200], Loss: 4.9867 , Accuracy : 17.50%\n",
      "Epoch [63/1200], Loss: 2.3261 , Accuracy : 15.00%\n",
      "Epoch [64/1200], Loss: 2.6704 , Accuracy : 17.50%\n",
      "Epoch [65/1200], Loss: 3.1158 , Accuracy : 27.50%\n",
      "Epoch [66/1200], Loss: 2.8230 , Accuracy : 22.50%\n",
      "Epoch [67/1200], Loss: 2.8704 , Accuracy : 20.00%\n",
      "Epoch [68/1200], Loss: 2.1553 , Accuracy : 15.00%\n",
      "Epoch [69/1200], Loss: 3.2369 , Accuracy : 22.50%\n",
      "Epoch [70/1200], Loss: 3.0509 , Accuracy : 22.50%\n",
      "Epoch [71/1200], Loss: 2.6084 , Accuracy : 17.50%\n",
      "Epoch [72/1200], Loss: 2.6727 , Accuracy : 17.50%\n",
      "Epoch [73/1200], Loss: 2.6554 , Accuracy : 20.00%\n",
      "Epoch [74/1200], Loss: 2.4332 , Accuracy : 17.50%\n",
      "Epoch [75/1200], Loss: 3.7945 , Accuracy : 22.50%\n",
      "Epoch [76/1200], Loss: 2.6401 , Accuracy : 20.00%\n",
      "Epoch [77/1200], Loss: 3.9985 , Accuracy : 22.50%\n",
      "Epoch [78/1200], Loss: 2.7793 , Accuracy : 17.50%\n",
      "Epoch [79/1200], Loss: 2.9776 , Accuracy : 25.00%\n",
      "Epoch [80/1200], Loss: 2.8690 , Accuracy : 15.00%\n",
      "Epoch [81/1200], Loss: 1.7924 , Accuracy : 22.50%\n",
      "Epoch [82/1200], Loss: 3.3100 , Accuracy : 20.00%\n",
      "Epoch [83/1200], Loss: 3.2202 , Accuracy : 20.00%\n",
      "Epoch [84/1200], Loss: 2.5580 , Accuracy : 10.00%\n",
      "Epoch [85/1200], Loss: 2.8492 , Accuracy : 20.00%\n",
      "Epoch [86/1200], Loss: 2.9567 , Accuracy : 12.50%\n",
      "Epoch [87/1200], Loss: 2.7923 , Accuracy : 17.50%\n",
      "Epoch [88/1200], Loss: 2.3026 , Accuracy : 27.50%\n",
      "Epoch [89/1200], Loss: 2.4818 , Accuracy : 30.00%\n",
      "Epoch [90/1200], Loss: 3.1315 , Accuracy : 17.50%\n",
      "Epoch [91/1200], Loss: 3.4101 , Accuracy : 22.50%\n",
      "Epoch [92/1200], Loss: 2.4416 , Accuracy : 25.00%\n",
      "Epoch [93/1200], Loss: 3.0581 , Accuracy : 17.50%\n",
      "Epoch [94/1200], Loss: 1.9358 , Accuracy : 20.00%\n",
      "Epoch [95/1200], Loss: 2.1657 , Accuracy : 17.50%\n",
      "Epoch [96/1200], Loss: 2.1050 , Accuracy : 25.00%\n",
      "Epoch [97/1200], Loss: 1.7022 , Accuracy : 22.50%\n",
      "Epoch [98/1200], Loss: 2.4647 , Accuracy : 25.00%\n",
      "Epoch [99/1200], Loss: 2.7912 , Accuracy : 15.00%\n",
      "Epoch [100/1200], Loss: 1.6938 , Accuracy : 20.00%\n",
      "Epoch [101/1200], Loss: 1.7506 , Accuracy : 22.50%\n",
      "Epoch [102/1200], Loss: 7.8506 , Accuracy : 7.50%\n",
      "Epoch [103/1200], Loss: 3.7932 , Accuracy : 15.00%\n",
      "Epoch [104/1200], Loss: 2.6478 , Accuracy : 15.00%\n",
      "Epoch [105/1200], Loss: 3.9424 , Accuracy : 12.50%\n",
      "Epoch [106/1200], Loss: 2.3818 , Accuracy : 15.00%\n",
      "Epoch [107/1200], Loss: 3.1261 , Accuracy : 17.50%\n",
      "Epoch [108/1200], Loss: 2.3509 , Accuracy : 17.50%\n",
      "Epoch [109/1200], Loss: 2.3010 , Accuracy : 15.00%\n",
      "Epoch [110/1200], Loss: 3.7181 , Accuracy : 22.50%\n",
      "Epoch [111/1200], Loss: 3.5694 , Accuracy : 27.50%\n",
      "Epoch [112/1200], Loss: 2.3414 , Accuracy : 32.50%\n",
      "Epoch [113/1200], Loss: 1.7212 , Accuracy : 22.50%\n",
      "Epoch [114/1200], Loss: 1.2893 , Accuracy : 25.00%\n",
      "Epoch [115/1200], Loss: 2.5969 , Accuracy : 32.50%\n",
      "Epoch [116/1200], Loss: 1.4501 , Accuracy : 32.50%\n",
      "Epoch [117/1200], Loss: 2.1787 , Accuracy : 25.00%\n",
      "Epoch [118/1200], Loss: 2.2002 , Accuracy : 22.50%\n",
      "Epoch [119/1200], Loss: 2.0333 , Accuracy : 35.00%\n",
      "Epoch [120/1200], Loss: 1.8234 , Accuracy : 30.00%\n",
      "Epoch [121/1200], Loss: 2.5419 , Accuracy : 30.00%\n",
      "Epoch [122/1200], Loss: 1.9309 , Accuracy : 27.50%\n",
      "Epoch [123/1200], Loss: 1.2026 , Accuracy : 22.50%\n",
      "Epoch [124/1200], Loss: 1.7541 , Accuracy : 27.50%\n",
      "Epoch [125/1200], Loss: 1.8008 , Accuracy : 30.00%\n",
      "Epoch [126/1200], Loss: 1.8936 , Accuracy : 25.00%\n",
      "Epoch [127/1200], Loss: 1.9972 , Accuracy : 30.00%\n",
      "Epoch [128/1200], Loss: 2.0710 , Accuracy : 25.00%\n",
      "Epoch [129/1200], Loss: 2.8140 , Accuracy : 22.50%\n",
      "Epoch [130/1200], Loss: 2.0960 , Accuracy : 25.00%\n",
      "Epoch [131/1200], Loss: 2.0791 , Accuracy : 30.00%\n",
      "Epoch [132/1200], Loss: 2.7390 , Accuracy : 27.50%\n",
      "Epoch [133/1200], Loss: 2.7081 , Accuracy : 22.50%\n",
      "Epoch [134/1200], Loss: 1.3346 , Accuracy : 27.50%\n",
      "Epoch [135/1200], Loss: 1.5132 , Accuracy : 20.00%\n",
      "Epoch [136/1200], Loss: 2.4320 , Accuracy : 25.00%\n",
      "Epoch [137/1200], Loss: 1.5192 , Accuracy : 27.50%\n",
      "Epoch [138/1200], Loss: 2.5277 , Accuracy : 32.50%\n",
      "Epoch [139/1200], Loss: 1.6730 , Accuracy : 35.00%\n",
      "Epoch [140/1200], Loss: 1.0174 , Accuracy : 32.50%\n",
      "Epoch [141/1200], Loss: 2.0156 , Accuracy : 22.50%\n",
      "Epoch [142/1200], Loss: 1.8817 , Accuracy : 35.00%\n",
      "Epoch [143/1200], Loss: 1.5604 , Accuracy : 32.50%\n",
      "Epoch [144/1200], Loss: 1.4738 , Accuracy : 32.50%\n",
      "Epoch [145/1200], Loss: 1.1540 , Accuracy : 40.00%\n",
      "Epoch [146/1200], Loss: 1.5454 , Accuracy : 37.50%\n",
      "Epoch [147/1200], Loss: 2.1166 , Accuracy : 35.00%\n",
      "Epoch [148/1200], Loss: 2.4650 , Accuracy : 30.00%\n",
      "Epoch [149/1200], Loss: 1.6585 , Accuracy : 35.00%\n",
      "Epoch [150/1200], Loss: 2.2028 , Accuracy : 27.50%\n",
      "Epoch [151/1200], Loss: 2.3282 , Accuracy : 37.50%\n",
      "Epoch [152/1200], Loss: 1.2061 , Accuracy : 30.00%\n",
      "Epoch [153/1200], Loss: 1.7041 , Accuracy : 35.00%\n",
      "Epoch [154/1200], Loss: 1.5552 , Accuracy : 35.00%\n",
      "Epoch [155/1200], Loss: 2.7119 , Accuracy : 32.50%\n",
      "Epoch [156/1200], Loss: 0.9265 , Accuracy : 27.50%\n",
      "Epoch [157/1200], Loss: 4.9102 , Accuracy : 37.50%\n",
      "Epoch [158/1200], Loss: 2.8984 , Accuracy : 30.00%\n",
      "Epoch [159/1200], Loss: 1.7205 , Accuracy : 40.00%\n",
      "Epoch [160/1200], Loss: 1.5894 , Accuracy : 22.50%\n",
      "Epoch [161/1200], Loss: 2.9694 , Accuracy : 37.50%\n",
      "Epoch [162/1200], Loss: 2.4391 , Accuracy : 37.50%\n",
      "Epoch [163/1200], Loss: 1.6922 , Accuracy : 32.50%\n",
      "Epoch [164/1200], Loss: 2.1338 , Accuracy : 22.50%\n",
      "Epoch [165/1200], Loss: 1.6132 , Accuracy : 25.00%\n",
      "Epoch [166/1200], Loss: 3.2197 , Accuracy : 35.00%\n",
      "Epoch [167/1200], Loss: 2.5129 , Accuracy : 30.00%\n",
      "Epoch [168/1200], Loss: 1.6989 , Accuracy : 30.00%\n",
      "Epoch [169/1200], Loss: 1.5454 , Accuracy : 45.00%\n",
      "Epoch [170/1200], Loss: 1.4588 , Accuracy : 40.00%\n",
      "Epoch [171/1200], Loss: 1.1561 , Accuracy : 45.00%\n",
      "Epoch [172/1200], Loss: 2.9717 , Accuracy : 22.50%\n",
      "Epoch [173/1200], Loss: 0.7204 , Accuracy : 40.00%\n",
      "Epoch [174/1200], Loss: 2.5530 , Accuracy : 37.50%\n",
      "Epoch [175/1200], Loss: 0.8590 , Accuracy : 40.00%\n",
      "Epoch [176/1200], Loss: 0.8797 , Accuracy : 32.50%\n",
      "Epoch [177/1200], Loss: 1.4981 , Accuracy : 45.00%\n",
      "Epoch [178/1200], Loss: 0.9935 , Accuracy : 45.00%\n",
      "Epoch [179/1200], Loss: 1.1852 , Accuracy : 50.00%\n",
      "Epoch [180/1200], Loss: 1.4459 , Accuracy : 45.00%\n",
      "Epoch [181/1200], Loss: 1.6289 , Accuracy : 47.50%\n",
      "Epoch [182/1200], Loss: 0.9476 , Accuracy : 45.00%\n",
      "Epoch [183/1200], Loss: 0.6503 , Accuracy : 37.50%\n",
      "Epoch [184/1200], Loss: 1.6899 , Accuracy : 37.50%\n",
      "Epoch [185/1200], Loss: 1.9839 , Accuracy : 42.50%\n",
      "Epoch [186/1200], Loss: 1.2657 , Accuracy : 42.50%\n",
      "Epoch [187/1200], Loss: 2.1465 , Accuracy : 42.50%\n",
      "Epoch [188/1200], Loss: 2.2266 , Accuracy : 32.50%\n",
      "Epoch [189/1200], Loss: 1.8016 , Accuracy : 52.50%\n",
      "Epoch [190/1200], Loss: 1.3381 , Accuracy : 42.50%\n",
      "Epoch [191/1200], Loss: 1.3421 , Accuracy : 45.00%\n",
      "Epoch [192/1200], Loss: 1.0809 , Accuracy : 45.00%\n",
      "Epoch [193/1200], Loss: 1.7743 , Accuracy : 40.00%\n",
      "Epoch [194/1200], Loss: 1.1844 , Accuracy : 47.50%\n",
      "Epoch [195/1200], Loss: 1.3188 , Accuracy : 52.50%\n",
      "Epoch [196/1200], Loss: 1.9347 , Accuracy : 55.00%\n",
      "Epoch [197/1200], Loss: 2.8537 , Accuracy : 52.50%\n",
      "Epoch [198/1200], Loss: 3.4566 , Accuracy : 35.00%\n",
      "Epoch [199/1200], Loss: 1.1598 , Accuracy : 42.50%\n",
      "Epoch [200/1200], Loss: 1.2868 , Accuracy : 30.00%\n",
      "Epoch [201/1200], Loss: 2.1353 , Accuracy : 27.50%\n",
      "Epoch [202/1200], Loss: 0.6209 , Accuracy : 45.00%\n",
      "Epoch [203/1200], Loss: 2.6575 , Accuracy : 30.00%\n",
      "Epoch [204/1200], Loss: 0.9362 , Accuracy : 45.00%\n",
      "Epoch [205/1200], Loss: 1.0811 , Accuracy : 37.50%\n",
      "Epoch [206/1200], Loss: 1.2721 , Accuracy : 42.50%\n",
      "Epoch [207/1200], Loss: 3.0082 , Accuracy : 37.50%\n",
      "Epoch [208/1200], Loss: 1.9841 , Accuracy : 47.50%\n",
      "Epoch [209/1200], Loss: 1.0382 , Accuracy : 50.00%\n",
      "Epoch [210/1200], Loss: 0.7471 , Accuracy : 55.00%\n",
      "Epoch [211/1200], Loss: 1.2008 , Accuracy : 40.00%\n",
      "Epoch [212/1200], Loss: 0.5525 , Accuracy : 47.50%\n",
      "Epoch [213/1200], Loss: 2.7425 , Accuracy : 40.00%\n",
      "Epoch [214/1200], Loss: 0.9063 , Accuracy : 45.00%\n",
      "Epoch [215/1200], Loss: 1.1758 , Accuracy : 55.00%\n",
      "Epoch [216/1200], Loss: 1.2100 , Accuracy : 50.00%\n",
      "Epoch [217/1200], Loss: 1.7364 , Accuracy : 60.00%\n",
      "Epoch [218/1200], Loss: 0.8464 , Accuracy : 55.00%\n",
      "Epoch [219/1200], Loss: 1.6280 , Accuracy : 45.00%\n",
      "Epoch [220/1200], Loss: 1.6795 , Accuracy : 52.50%\n",
      "Epoch [221/1200], Loss: 1.4571 , Accuracy : 55.00%\n",
      "Epoch [222/1200], Loss: 0.4791 , Accuracy : 47.50%\n",
      "Epoch [223/1200], Loss: 2.2436 , Accuracy : 47.50%\n",
      "Epoch [224/1200], Loss: 1.1044 , Accuracy : 60.00%\n",
      "Epoch [225/1200], Loss: 0.8628 , Accuracy : 57.50%\n",
      "Epoch [226/1200], Loss: 1.4459 , Accuracy : 65.00%\n",
      "Epoch [227/1200], Loss: 0.7767 , Accuracy : 47.50%\n",
      "Epoch [228/1200], Loss: 1.8484 , Accuracy : 52.50%\n",
      "Epoch [229/1200], Loss: 1.7009 , Accuracy : 50.00%\n",
      "Epoch [230/1200], Loss: 3.3042 , Accuracy : 52.50%\n",
      "Epoch [231/1200], Loss: 0.7710 , Accuracy : 60.00%\n",
      "Epoch [232/1200], Loss: 1.4258 , Accuracy : 45.00%\n",
      "Epoch [233/1200], Loss: 2.1604 , Accuracy : 47.50%\n",
      "Epoch [234/1200], Loss: 1.6455 , Accuracy : 45.00%\n",
      "Epoch [235/1200], Loss: 0.6671 , Accuracy : 55.00%\n",
      "Epoch [236/1200], Loss: 0.3971 , Accuracy : 60.00%\n",
      "Epoch [237/1200], Loss: 1.9643 , Accuracy : 55.00%\n",
      "Epoch [238/1200], Loss: 0.8713 , Accuracy : 52.50%\n",
      "Epoch [239/1200], Loss: 1.5745 , Accuracy : 60.00%\n",
      "Epoch [240/1200], Loss: 0.4668 , Accuracy : 67.50%\n",
      "Epoch [241/1200], Loss: 0.7194 , Accuracy : 52.50%\n",
      "Epoch [242/1200], Loss: 0.4990 , Accuracy : 50.00%\n",
      "Epoch [243/1200], Loss: 1.3692 , Accuracy : 57.50%\n",
      "Epoch [244/1200], Loss: 0.9243 , Accuracy : 60.00%\n",
      "Epoch [245/1200], Loss: 1.4871 , Accuracy : 47.50%\n",
      "Epoch [246/1200], Loss: 0.9389 , Accuracy : 55.00%\n",
      "Epoch [247/1200], Loss: 1.1520 , Accuracy : 57.50%\n",
      "Epoch [248/1200], Loss: 0.4434 , Accuracy : 50.00%\n",
      "Epoch [249/1200], Loss: 1.8880 , Accuracy : 60.00%\n",
      "Epoch [250/1200], Loss: 1.1269 , Accuracy : 47.50%\n",
      "Epoch [251/1200], Loss: 0.9393 , Accuracy : 60.00%\n",
      "Epoch [252/1200], Loss: 0.5088 , Accuracy : 52.50%\n",
      "Epoch [253/1200], Loss: 1.6544 , Accuracy : 47.50%\n",
      "Epoch [254/1200], Loss: 0.6231 , Accuracy : 45.00%\n",
      "Epoch [255/1200], Loss: 1.8953 , Accuracy : 62.50%\n",
      "Epoch [256/1200], Loss: 0.8815 , Accuracy : 60.00%\n",
      "Epoch [257/1200], Loss: 1.2548 , Accuracy : 52.50%\n",
      "Epoch [258/1200], Loss: 1.3704 , Accuracy : 40.00%\n",
      "Epoch [259/1200], Loss: 0.8748 , Accuracy : 45.00%\n",
      "Epoch [260/1200], Loss: 1.8170 , Accuracy : 47.50%\n",
      "Epoch [261/1200], Loss: 0.4573 , Accuracy : 47.50%\n",
      "Epoch [262/1200], Loss: 0.8055 , Accuracy : 45.00%\n",
      "Epoch [263/1200], Loss: 1.1749 , Accuracy : 50.00%\n",
      "Epoch [264/1200], Loss: 2.0432 , Accuracy : 52.50%\n",
      "Epoch [265/1200], Loss: 0.9832 , Accuracy : 50.00%\n",
      "Epoch [266/1200], Loss: 0.6072 , Accuracy : 62.50%\n",
      "Epoch [267/1200], Loss: 1.3709 , Accuracy : 62.50%\n",
      "Epoch [268/1200], Loss: 1.3528 , Accuracy : 45.00%\n",
      "Epoch [269/1200], Loss: 0.3871 , Accuracy : 55.00%\n",
      "Epoch [270/1200], Loss: 0.2809 , Accuracy : 55.00%\n",
      "Epoch [271/1200], Loss: 1.0718 , Accuracy : 57.50%\n",
      "Epoch [272/1200], Loss: 0.7202 , Accuracy : 52.50%\n",
      "Epoch [273/1200], Loss: 0.6706 , Accuracy : 72.50%\n",
      "Epoch [274/1200], Loss: 1.5932 , Accuracy : 60.00%\n",
      "Epoch [275/1200], Loss: 1.3460 , Accuracy : 60.00%\n",
      "Epoch [276/1200], Loss: 0.8872 , Accuracy : 57.50%\n",
      "Epoch [277/1200], Loss: 1.5732 , Accuracy : 60.00%\n",
      "Epoch [278/1200], Loss: 1.3014 , Accuracy : 55.00%\n",
      "Epoch [279/1200], Loss: 1.0954 , Accuracy : 62.50%\n",
      "Epoch [280/1200], Loss: 1.6672 , Accuracy : 50.00%\n",
      "Epoch [281/1200], Loss: 0.7119 , Accuracy : 45.00%\n",
      "Epoch [282/1200], Loss: 4.0599 , Accuracy : 55.00%\n",
      "Epoch [283/1200], Loss: 1.4478 , Accuracy : 55.00%\n",
      "Epoch [284/1200], Loss: 1.6788 , Accuracy : 45.00%\n",
      "Epoch [285/1200], Loss: 0.6824 , Accuracy : 50.00%\n",
      "Epoch [286/1200], Loss: 1.1439 , Accuracy : 50.00%\n",
      "Epoch [287/1200], Loss: 0.8867 , Accuracy : 57.50%\n",
      "Epoch [288/1200], Loss: 1.9550 , Accuracy : 62.50%\n",
      "Epoch [289/1200], Loss: 1.1004 , Accuracy : 52.50%\n",
      "Epoch [290/1200], Loss: 1.1859 , Accuracy : 62.50%\n",
      "Epoch [291/1200], Loss: 0.6446 , Accuracy : 70.00%\n",
      "Epoch [292/1200], Loss: 2.2622 , Accuracy : 45.00%\n",
      "Epoch [293/1200], Loss: 1.3187 , Accuracy : 55.00%\n",
      "Epoch [294/1200], Loss: 2.3282 , Accuracy : 57.50%\n",
      "Epoch [295/1200], Loss: 0.6189 , Accuracy : 67.50%\n",
      "Epoch [296/1200], Loss: 0.3468 , Accuracy : 75.00%\n",
      "Epoch [297/1200], Loss: 2.0921 , Accuracy : 67.50%\n",
      "Epoch [298/1200], Loss: 0.9149 , Accuracy : 55.00%\n",
      "Epoch [299/1200], Loss: 1.8237 , Accuracy : 60.00%\n",
      "Epoch [300/1200], Loss: 0.2729 , Accuracy : 50.00%\n",
      "Epoch [301/1200], Loss: 0.9355 , Accuracy : 50.00%\n",
      "Epoch [302/1200], Loss: 1.1121 , Accuracy : 62.50%\n",
      "Epoch [303/1200], Loss: 0.8069 , Accuracy : 55.00%\n",
      "Epoch [304/1200], Loss: 1.3759 , Accuracy : 60.00%\n",
      "Epoch [305/1200], Loss: 0.7239 , Accuracy : 67.50%\n",
      "Epoch [306/1200], Loss: 1.4288 , Accuracy : 75.00%\n",
      "Epoch [307/1200], Loss: 0.3196 , Accuracy : 65.00%\n",
      "Epoch [308/1200], Loss: 0.4354 , Accuracy : 55.00%\n",
      "Epoch [309/1200], Loss: 2.0936 , Accuracy : 57.50%\n",
      "Epoch [310/1200], Loss: 1.4111 , Accuracy : 65.00%\n",
      "Epoch [311/1200], Loss: 0.2744 , Accuracy : 57.50%\n",
      "Epoch [312/1200], Loss: 0.8835 , Accuracy : 62.50%\n",
      "Epoch [313/1200], Loss: 1.3186 , Accuracy : 65.00%\n",
      "Epoch [314/1200], Loss: 0.8537 , Accuracy : 62.50%\n",
      "Epoch [315/1200], Loss: 1.1141 , Accuracy : 55.00%\n",
      "Epoch [316/1200], Loss: 1.5938 , Accuracy : 50.00%\n",
      "Epoch [317/1200], Loss: 1.4287 , Accuracy : 47.50%\n",
      "Epoch [318/1200], Loss: 1.3894 , Accuracy : 47.50%\n",
      "Epoch [319/1200], Loss: 1.9994 , Accuracy : 57.50%\n",
      "Epoch [320/1200], Loss: 0.9614 , Accuracy : 67.50%\n",
      "Epoch [321/1200], Loss: 0.8805 , Accuracy : 55.00%\n",
      "Epoch [322/1200], Loss: 0.8075 , Accuracy : 65.00%\n",
      "Epoch [323/1200], Loss: 2.1393 , Accuracy : 62.50%\n",
      "Epoch [324/1200], Loss: 2.0638 , Accuracy : 72.50%\n",
      "Epoch [325/1200], Loss: 0.5794 , Accuracy : 70.00%\n",
      "Epoch [326/1200], Loss: 0.5425 , Accuracy : 57.50%\n",
      "Epoch [327/1200], Loss: 0.3128 , Accuracy : 67.50%\n",
      "Epoch [328/1200], Loss: 1.0120 , Accuracy : 75.00%\n",
      "Epoch [329/1200], Loss: 0.1962 , Accuracy : 62.50%\n",
      "Epoch [330/1200], Loss: 1.7290 , Accuracy : 65.00%\n",
      "Epoch [331/1200], Loss: 1.3197 , Accuracy : 60.00%\n",
      "Epoch [332/1200], Loss: 0.4459 , Accuracy : 45.00%\n",
      "Epoch [333/1200], Loss: 1.5106 , Accuracy : 42.50%\n",
      "Epoch [334/1200], Loss: 0.9431 , Accuracy : 50.00%\n",
      "Epoch [335/1200], Loss: 0.9515 , Accuracy : 57.50%\n",
      "Epoch [336/1200], Loss: 1.0503 , Accuracy : 50.00%\n",
      "Epoch [337/1200], Loss: 1.0311 , Accuracy : 57.50%\n",
      "Epoch [338/1200], Loss: 1.0590 , Accuracy : 60.00%\n",
      "Epoch [339/1200], Loss: 0.6710 , Accuracy : 57.50%\n",
      "Epoch [340/1200], Loss: 1.3466 , Accuracy : 65.00%\n",
      "Epoch [341/1200], Loss: 2.1330 , Accuracy : 55.00%\n",
      "Epoch [342/1200], Loss: 2.2891 , Accuracy : 45.00%\n",
      "Epoch [343/1200], Loss: 0.7022 , Accuracy : 47.50%\n",
      "Epoch [344/1200], Loss: 0.5771 , Accuracy : 55.00%\n",
      "Epoch [345/1200], Loss: 1.4777 , Accuracy : 65.00%\n",
      "Epoch [346/1200], Loss: 1.5291 , Accuracy : 60.00%\n",
      "Epoch [347/1200], Loss: 0.4327 , Accuracy : 60.00%\n",
      "Epoch [348/1200], Loss: 0.8181 , Accuracy : 72.50%\n",
      "Epoch [349/1200], Loss: 0.5612 , Accuracy : 70.00%\n",
      "Epoch [350/1200], Loss: 0.8671 , Accuracy : 65.00%\n",
      "Epoch [351/1200], Loss: 0.3839 , Accuracy : 70.00%\n",
      "Epoch [352/1200], Loss: 0.4497 , Accuracy : 67.50%\n",
      "Epoch [353/1200], Loss: 1.0979 , Accuracy : 57.50%\n",
      "Epoch [354/1200], Loss: 0.5360 , Accuracy : 80.00%\n",
      "Epoch [355/1200], Loss: 1.3093 , Accuracy : 70.00%\n",
      "Epoch [356/1200], Loss: 0.3186 , Accuracy : 67.50%\n",
      "Epoch [357/1200], Loss: 2.3817 , Accuracy : 62.50%\n",
      "Epoch [358/1200], Loss: 1.7055 , Accuracy : 62.50%\n",
      "Epoch [359/1200], Loss: 0.0603 , Accuracy : 75.00%\n",
      "Epoch [360/1200], Loss: 1.8681 , Accuracy : 65.00%\n",
      "Epoch [361/1200], Loss: 0.8509 , Accuracy : 67.50%\n",
      "Epoch [362/1200], Loss: 0.7156 , Accuracy : 62.50%\n",
      "Epoch [363/1200], Loss: 1.3599 , Accuracy : 67.50%\n",
      "Epoch [364/1200], Loss: 1.2779 , Accuracy : 62.50%\n",
      "Epoch [365/1200], Loss: 1.1745 , Accuracy : 60.00%\n",
      "Epoch [366/1200], Loss: 0.7248 , Accuracy : 60.00%\n",
      "Epoch [367/1200], Loss: 0.7856 , Accuracy : 67.50%\n",
      "Epoch [368/1200], Loss: 0.3230 , Accuracy : 65.00%\n",
      "Epoch [369/1200], Loss: 0.8627 , Accuracy : 65.00%\n",
      "Epoch [370/1200], Loss: 0.8042 , Accuracy : 80.00%\n",
      "Epoch [371/1200], Loss: 1.3717 , Accuracy : 77.50%\n",
      "Epoch [372/1200], Loss: 2.0948 , Accuracy : 67.50%\n",
      "Epoch [373/1200], Loss: 1.4390 , Accuracy : 70.00%\n",
      "Epoch [374/1200], Loss: 0.0232 , Accuracy : 70.00%\n",
      "Epoch [375/1200], Loss: 0.6088 , Accuracy : 70.00%\n",
      "Epoch [376/1200], Loss: 0.3388 , Accuracy : 67.50%\n",
      "Epoch [377/1200], Loss: 0.4496 , Accuracy : 70.00%\n",
      "Epoch [378/1200], Loss: 0.8778 , Accuracy : 70.00%\n",
      "Epoch [379/1200], Loss: 1.2649 , Accuracy : 80.00%\n",
      "Epoch [380/1200], Loss: 0.6584 , Accuracy : 85.00%\n",
      "Epoch [381/1200], Loss: 0.2915 , Accuracy : 75.00%\n",
      "Epoch [382/1200], Loss: 1.2007 , Accuracy : 77.50%\n",
      "Epoch [383/1200], Loss: 0.6456 , Accuracy : 82.50%\n",
      "Epoch [384/1200], Loss: 0.4153 , Accuracy : 62.50%\n",
      "Epoch [385/1200], Loss: 0.8320 , Accuracy : 72.50%\n",
      "Epoch [386/1200], Loss: 0.6100 , Accuracy : 67.50%\n",
      "Epoch [387/1200], Loss: 0.3785 , Accuracy : 85.00%\n",
      "Epoch [388/1200], Loss: 0.5171 , Accuracy : 77.50%\n",
      "Epoch [389/1200], Loss: 0.8275 , Accuracy : 75.00%\n",
      "Epoch [390/1200], Loss: 0.5075 , Accuracy : 72.50%\n",
      "Epoch [391/1200], Loss: 0.6715 , Accuracy : 70.00%\n",
      "Epoch [392/1200], Loss: 0.4780 , Accuracy : 77.50%\n",
      "Epoch [393/1200], Loss: 0.4435 , Accuracy : 67.50%\n",
      "Epoch [394/1200], Loss: 0.6634 , Accuracy : 77.50%\n",
      "Epoch [395/1200], Loss: 1.0243 , Accuracy : 65.00%\n",
      "Epoch [396/1200], Loss: 0.1761 , Accuracy : 72.50%\n",
      "Epoch [397/1200], Loss: 0.3036 , Accuracy : 70.00%\n",
      "Epoch [398/1200], Loss: 0.5511 , Accuracy : 80.00%\n",
      "Epoch [399/1200], Loss: 0.5118 , Accuracy : 77.50%\n",
      "Epoch [400/1200], Loss: 0.7659 , Accuracy : 70.00%\n",
      "Epoch [401/1200], Loss: 0.4778 , Accuracy : 80.00%\n",
      "Epoch [402/1200], Loss: 1.0517 , Accuracy : 72.50%\n",
      "Epoch [403/1200], Loss: 1.1371 , Accuracy : 67.50%\n",
      "Epoch [404/1200], Loss: 0.6579 , Accuracy : 70.00%\n",
      "Epoch [405/1200], Loss: 0.7398 , Accuracy : 72.50%\n",
      "Epoch [406/1200], Loss: 0.7329 , Accuracy : 55.00%\n",
      "Epoch [407/1200], Loss: 1.0480 , Accuracy : 67.50%\n",
      "Epoch [408/1200], Loss: 1.2793 , Accuracy : 52.50%\n",
      "Epoch [409/1200], Loss: 1.5319 , Accuracy : 65.00%\n",
      "Epoch [410/1200], Loss: 0.3925 , Accuracy : 60.00%\n",
      "Epoch [411/1200], Loss: 0.5552 , Accuracy : 65.00%\n",
      "Epoch [412/1200], Loss: 0.5703 , Accuracy : 72.50%\n",
      "Epoch [413/1200], Loss: 1.5568 , Accuracy : 75.00%\n",
      "Epoch [414/1200], Loss: 0.5030 , Accuracy : 75.00%\n",
      "Epoch [415/1200], Loss: 0.1230 , Accuracy : 82.50%\n",
      "Epoch [416/1200], Loss: 0.4077 , Accuracy : 85.00%\n",
      "Epoch [417/1200], Loss: 1.2339 , Accuracy : 80.00%\n",
      "Epoch [418/1200], Loss: 0.5492 , Accuracy : 77.50%\n",
      "Epoch [419/1200], Loss: 0.1893 , Accuracy : 70.00%\n",
      "Epoch [420/1200], Loss: 0.0218 , Accuracy : 82.50%\n",
      "Epoch [421/1200], Loss: 0.6306 , Accuracy : 72.50%\n",
      "Epoch [422/1200], Loss: 0.0106 , Accuracy : 70.00%\n",
      "Epoch [423/1200], Loss: 0.3733 , Accuracy : 72.50%\n",
      "Epoch [424/1200], Loss: 0.4415 , Accuracy : 67.50%\n",
      "Epoch [425/1200], Loss: 1.3256 , Accuracy : 60.00%\n",
      "Epoch [426/1200], Loss: 0.3191 , Accuracy : 67.50%\n",
      "Epoch [427/1200], Loss: 0.5002 , Accuracy : 75.00%\n",
      "Epoch [428/1200], Loss: 1.3385 , Accuracy : 75.00%\n",
      "Epoch [429/1200], Loss: 1.3496 , Accuracy : 67.50%\n",
      "Epoch [430/1200], Loss: 0.0795 , Accuracy : 80.00%\n",
      "Epoch [431/1200], Loss: 0.1989 , Accuracy : 72.50%\n",
      "Epoch [432/1200], Loss: 0.3405 , Accuracy : 85.00%\n",
      "Epoch [433/1200], Loss: 0.7162 , Accuracy : 70.00%\n",
      "Epoch [434/1200], Loss: 0.7090 , Accuracy : 75.00%\n",
      "Epoch [435/1200], Loss: 0.2515 , Accuracy : 80.00%\n",
      "Epoch [436/1200], Loss: 0.3789 , Accuracy : 72.50%\n",
      "Epoch [437/1200], Loss: 0.0988 , Accuracy : 80.00%\n",
      "Epoch [438/1200], Loss: 1.3521 , Accuracy : 85.00%\n",
      "Epoch [439/1200], Loss: 0.1374 , Accuracy : 80.00%\n",
      "Epoch [440/1200], Loss: 0.3020 , Accuracy : 90.00%\n",
      "Epoch [441/1200], Loss: 0.4369 , Accuracy : 80.00%\n",
      "Epoch [442/1200], Loss: 0.2725 , Accuracy : 87.50%\n",
      "Epoch [443/1200], Loss: 0.7546 , Accuracy : 82.50%\n",
      "Epoch [444/1200], Loss: 0.3235 , Accuracy : 77.50%\n",
      "Epoch [445/1200], Loss: 0.5817 , Accuracy : 87.50%\n",
      "Epoch [446/1200], Loss: 0.1317 , Accuracy : 80.00%\n",
      "Epoch [447/1200], Loss: 0.3425 , Accuracy : 75.00%\n",
      "Epoch [448/1200], Loss: 1.2961 , Accuracy : 67.50%\n",
      "Epoch [449/1200], Loss: 0.9912 , Accuracy : 72.50%\n",
      "Epoch [450/1200], Loss: 0.8716 , Accuracy : 70.00%\n",
      "Epoch [451/1200], Loss: 0.0455 , Accuracy : 82.50%\n",
      "Epoch [452/1200], Loss: 0.3569 , Accuracy : 65.00%\n",
      "Epoch [453/1200], Loss: 0.5667 , Accuracy : 60.00%\n",
      "Epoch [454/1200], Loss: 1.3095 , Accuracy : 65.00%\n",
      "Epoch [455/1200], Loss: 1.0107 , Accuracy : 70.00%\n",
      "Epoch [456/1200], Loss: 0.3650 , Accuracy : 62.50%\n",
      "Epoch [457/1200], Loss: 0.6814 , Accuracy : 57.50%\n",
      "Epoch [458/1200], Loss: 0.3476 , Accuracy : 65.00%\n",
      "Epoch [459/1200], Loss: 0.7902 , Accuracy : 70.00%\n",
      "Epoch [460/1200], Loss: 0.4145 , Accuracy : 77.50%\n",
      "Epoch [461/1200], Loss: 0.1661 , Accuracy : 82.50%\n",
      "Epoch [462/1200], Loss: 0.4955 , Accuracy : 75.00%\n",
      "Epoch [463/1200], Loss: 0.8876 , Accuracy : 80.00%\n",
      "Epoch [464/1200], Loss: 0.9530 , Accuracy : 77.50%\n",
      "Epoch [465/1200], Loss: 0.3470 , Accuracy : 75.00%\n",
      "Epoch [466/1200], Loss: 0.8183 , Accuracy : 80.00%\n",
      "Epoch [467/1200], Loss: 0.5731 , Accuracy : 75.00%\n",
      "Epoch [468/1200], Loss: 0.3270 , Accuracy : 77.50%\n",
      "Epoch [469/1200], Loss: 0.5611 , Accuracy : 77.50%\n",
      "Epoch [470/1200], Loss: 0.5656 , Accuracy : 82.50%\n",
      "Epoch [471/1200], Loss: 0.3464 , Accuracy : 80.00%\n",
      "Epoch [472/1200], Loss: 0.4316 , Accuracy : 80.00%\n",
      "Epoch [473/1200], Loss: 0.0418 , Accuracy : 82.50%\n",
      "Epoch [474/1200], Loss: 0.5076 , Accuracy : 80.00%\n",
      "Epoch [475/1200], Loss: 0.0983 , Accuracy : 80.00%\n",
      "Epoch [476/1200], Loss: 0.1570 , Accuracy : 82.50%\n",
      "Epoch [477/1200], Loss: 0.2118 , Accuracy : 80.00%\n",
      "Epoch [478/1200], Loss: 0.2255 , Accuracy : 85.00%\n",
      "Epoch [479/1200], Loss: 0.6281 , Accuracy : 80.00%\n",
      "Epoch [480/1200], Loss: 0.2033 , Accuracy : 80.00%\n",
      "Epoch [481/1200], Loss: 1.8512 , Accuracy : 77.50%\n",
      "Epoch [482/1200], Loss: 0.8139 , Accuracy : 75.00%\n",
      "Epoch [483/1200], Loss: 0.3411 , Accuracy : 77.50%\n",
      "Epoch [484/1200], Loss: 1.6456 , Accuracy : 60.00%\n",
      "Epoch [485/1200], Loss: 0.2045 , Accuracy : 70.00%\n",
      "Epoch [486/1200], Loss: 0.3223 , Accuracy : 75.00%\n",
      "Epoch [487/1200], Loss: 0.0304 , Accuracy : 77.50%\n",
      "Epoch [488/1200], Loss: 0.2008 , Accuracy : 77.50%\n",
      "Epoch [489/1200], Loss: 1.5261 , Accuracy : 75.00%\n",
      "Epoch [490/1200], Loss: 0.4672 , Accuracy : 77.50%\n",
      "Epoch [491/1200], Loss: 0.5146 , Accuracy : 75.00%\n",
      "Epoch [492/1200], Loss: 0.0045 , Accuracy : 80.00%\n",
      "Epoch [493/1200], Loss: 0.2218 , Accuracy : 85.00%\n",
      "Epoch [494/1200], Loss: 0.2782 , Accuracy : 85.00%\n",
      "Epoch [495/1200], Loss: 0.0069 , Accuracy : 90.00%\n",
      "Epoch [496/1200], Loss: 0.2465 , Accuracy : 72.50%\n",
      "Epoch [497/1200], Loss: 0.5747 , Accuracy : 85.00%\n",
      "Epoch [498/1200], Loss: 1.3434 , Accuracy : 72.50%\n",
      "Epoch [499/1200], Loss: 1.0372 , Accuracy : 82.50%\n",
      "Epoch [500/1200], Loss: 0.3767 , Accuracy : 90.00%\n",
      "Epoch [501/1200], Loss: 0.0301 , Accuracy : 95.00%\n",
      "Epoch [502/1200], Loss: 0.5240 , Accuracy : 87.50%\n",
      "Epoch [503/1200], Loss: 0.2415 , Accuracy : 85.00%\n",
      "Epoch [504/1200], Loss: 0.3279 , Accuracy : 85.00%\n",
      "Epoch [505/1200], Loss: 0.0793 , Accuracy : 90.00%\n",
      "Epoch [506/1200], Loss: 0.1408 , Accuracy : 82.50%\n",
      "Epoch [507/1200], Loss: 0.6821 , Accuracy : 80.00%\n",
      "Epoch [508/1200], Loss: 0.2615 , Accuracy : 82.50%\n",
      "Epoch [509/1200], Loss: 0.7047 , Accuracy : 85.00%\n",
      "Epoch [510/1200], Loss: 0.9877 , Accuracy : 75.00%\n",
      "Epoch [511/1200], Loss: 0.2466 , Accuracy : 85.00%\n",
      "Epoch [512/1200], Loss: 0.1437 , Accuracy : 82.50%\n",
      "Epoch [513/1200], Loss: 0.4274 , Accuracy : 80.00%\n",
      "Epoch [514/1200], Loss: 0.4388 , Accuracy : 82.50%\n",
      "Epoch [515/1200], Loss: 0.3072 , Accuracy : 82.50%\n",
      "Epoch [516/1200], Loss: 0.9282 , Accuracy : 85.00%\n",
      "Epoch [517/1200], Loss: 0.2503 , Accuracy : 77.50%\n",
      "Epoch [518/1200], Loss: 0.6125 , Accuracy : 82.50%\n",
      "Epoch [519/1200], Loss: 0.7128 , Accuracy : 87.50%\n",
      "Epoch [520/1200], Loss: 0.1820 , Accuracy : 82.50%\n",
      "Epoch [521/1200], Loss: 0.0655 , Accuracy : 85.00%\n",
      "Epoch [522/1200], Loss: 0.3351 , Accuracy : 82.50%\n",
      "Epoch [523/1200], Loss: 1.3900 , Accuracy : 90.00%\n",
      "Epoch [524/1200], Loss: 0.6127 , Accuracy : 95.00%\n",
      "Epoch [525/1200], Loss: 0.4580 , Accuracy : 77.50%\n",
      "Epoch [526/1200], Loss: 0.2808 , Accuracy : 82.50%\n",
      "Epoch [527/1200], Loss: 0.2536 , Accuracy : 72.50%\n",
      "Epoch [528/1200], Loss: 0.3422 , Accuracy : 77.50%\n",
      "Epoch [529/1200], Loss: 0.9516 , Accuracy : 77.50%\n",
      "Epoch [530/1200], Loss: 0.8254 , Accuracy : 87.50%\n",
      "Epoch [531/1200], Loss: 0.0176 , Accuracy : 87.50%\n",
      "Epoch [532/1200], Loss: 0.8064 , Accuracy : 85.00%\n",
      "Epoch [533/1200], Loss: 0.0057 , Accuracy : 85.00%\n",
      "Epoch [534/1200], Loss: 0.1472 , Accuracy : 77.50%\n",
      "Epoch [535/1200], Loss: 0.1185 , Accuracy : 75.00%\n",
      "Epoch [536/1200], Loss: 0.4025 , Accuracy : 62.50%\n",
      "Epoch [537/1200], Loss: 0.3468 , Accuracy : 80.00%\n",
      "Epoch [538/1200], Loss: 0.3134 , Accuracy : 87.50%\n",
      "Epoch [539/1200], Loss: 0.1310 , Accuracy : 82.50%\n",
      "Epoch [540/1200], Loss: 0.0022 , Accuracy : 82.50%\n",
      "Epoch [541/1200], Loss: 0.0319 , Accuracy : 85.00%\n",
      "Epoch [542/1200], Loss: 0.8194 , Accuracy : 77.50%\n",
      "Epoch [543/1200], Loss: 0.7558 , Accuracy : 85.00%\n",
      "Epoch [544/1200], Loss: 0.0986 , Accuracy : 85.00%\n",
      "Epoch [545/1200], Loss: 0.9321 , Accuracy : 82.50%\n",
      "Epoch [546/1200], Loss: 0.6904 , Accuracy : 85.00%\n",
      "Epoch [547/1200], Loss: 0.2201 , Accuracy : 92.50%\n",
      "Epoch [548/1200], Loss: 0.2990 , Accuracy : 85.00%\n",
      "Epoch [549/1200], Loss: 0.1429 , Accuracy : 87.50%\n",
      "Epoch [550/1200], Loss: 0.0072 , Accuracy : 97.50%\n",
      "Epoch [551/1200], Loss: 0.2296 , Accuracy : 92.50%\n",
      "Epoch [552/1200], Loss: 0.2427 , Accuracy : 92.50%\n",
      "Epoch [553/1200], Loss: 0.0142 , Accuracy : 90.00%\n",
      "Epoch [554/1200], Loss: 0.1997 , Accuracy : 92.50%\n",
      "Epoch [555/1200], Loss: 0.0230 , Accuracy : 87.50%\n",
      "Epoch [556/1200], Loss: 0.0569 , Accuracy : 92.50%\n",
      "Epoch [557/1200], Loss: 0.7446 , Accuracy : 87.50%\n",
      "Epoch [558/1200], Loss: 0.0373 , Accuracy : 85.00%\n",
      "Epoch [559/1200], Loss: 0.3718 , Accuracy : 77.50%\n",
      "Epoch [560/1200], Loss: 0.0882 , Accuracy : 80.00%\n",
      "Epoch [561/1200], Loss: 0.8120 , Accuracy : 87.50%\n",
      "Epoch [562/1200], Loss: 0.3877 , Accuracy : 90.00%\n",
      "Epoch [563/1200], Loss: 0.2129 , Accuracy : 95.00%\n",
      "Epoch [564/1200], Loss: 0.2428 , Accuracy : 90.00%\n",
      "Epoch [565/1200], Loss: 0.2337 , Accuracy : 87.50%\n",
      "Epoch [566/1200], Loss: 0.5745 , Accuracy : 85.00%\n",
      "Epoch [567/1200], Loss: 0.0215 , Accuracy : 87.50%\n",
      "Epoch [568/1200], Loss: 0.2697 , Accuracy : 92.50%\n",
      "Epoch [569/1200], Loss: 0.1262 , Accuracy : 85.00%\n",
      "Epoch [570/1200], Loss: 0.2527 , Accuracy : 85.00%\n",
      "Epoch [571/1200], Loss: 0.2813 , Accuracy : 85.00%\n",
      "Epoch [572/1200], Loss: 0.5888 , Accuracy : 90.00%\n",
      "Epoch [573/1200], Loss: 0.6132 , Accuracy : 80.00%\n",
      "Epoch [574/1200], Loss: 0.3425 , Accuracy : 87.50%\n",
      "Epoch [575/1200], Loss: 1.2236 , Accuracy : 75.00%\n",
      "Epoch [576/1200], Loss: 0.1649 , Accuracy : 90.00%\n",
      "Epoch [577/1200], Loss: 0.0039 , Accuracy : 90.00%\n",
      "Epoch [578/1200], Loss: 0.0895 , Accuracy : 82.50%\n",
      "Epoch [579/1200], Loss: 0.0335 , Accuracy : 90.00%\n",
      "Epoch [580/1200], Loss: 0.0573 , Accuracy : 90.00%\n",
      "Epoch [581/1200], Loss: 0.0850 , Accuracy : 87.50%\n",
      "Epoch [582/1200], Loss: 0.7076 , Accuracy : 67.50%\n",
      "Epoch [583/1200], Loss: 4.1087 , Accuracy : 72.50%\n",
      "Epoch [584/1200], Loss: 0.5587 , Accuracy : 70.00%\n",
      "Epoch [585/1200], Loss: 4.0814 , Accuracy : 60.00%\n",
      "Epoch [586/1200], Loss: 0.2855 , Accuracy : 75.00%\n",
      "Epoch [587/1200], Loss: 2.5692 , Accuracy : 42.50%\n",
      "Epoch [588/1200], Loss: 2.0594 , Accuracy : 62.50%\n",
      "Epoch [589/1200], Loss: 0.6539 , Accuracy : 60.00%\n",
      "Epoch [590/1200], Loss: 1.3284 , Accuracy : 52.50%\n",
      "Epoch [591/1200], Loss: 0.9791 , Accuracy : 65.00%\n",
      "Epoch [592/1200], Loss: 0.1946 , Accuracy : 85.00%\n",
      "Epoch [593/1200], Loss: 0.1805 , Accuracy : 80.00%\n",
      "Epoch [594/1200], Loss: 0.4421 , Accuracy : 75.00%\n",
      "Epoch [595/1200], Loss: 0.0573 , Accuracy : 80.00%\n",
      "Epoch [596/1200], Loss: 0.3022 , Accuracy : 87.50%\n",
      "Epoch [597/1200], Loss: 0.1891 , Accuracy : 87.50%\n",
      "Epoch [598/1200], Loss: 0.2503 , Accuracy : 87.50%\n",
      "Epoch [599/1200], Loss: 0.7577 , Accuracy : 87.50%\n",
      "Epoch [600/1200], Loss: 1.3910 , Accuracy : 77.50%\n",
      "Epoch [601/1200], Loss: 0.0482 , Accuracy : 87.50%\n",
      "Epoch [602/1200], Loss: 0.6412 , Accuracy : 85.00%\n",
      "Epoch [603/1200], Loss: 0.2956 , Accuracy : 85.00%\n",
      "Epoch [604/1200], Loss: 0.0749 , Accuracy : 92.50%\n",
      "Epoch [605/1200], Loss: 0.0519 , Accuracy : 87.50%\n",
      "Epoch [606/1200], Loss: 0.3612 , Accuracy : 85.00%\n",
      "Epoch [607/1200], Loss: 0.1141 , Accuracy : 95.00%\n",
      "Epoch [608/1200], Loss: 0.2323 , Accuracy : 87.50%\n",
      "Epoch [609/1200], Loss: 0.5738 , Accuracy : 87.50%\n",
      "Epoch [610/1200], Loss: 0.2696 , Accuracy : 95.00%\n",
      "Epoch [611/1200], Loss: 0.2141 , Accuracy : 87.50%\n",
      "Epoch [612/1200], Loss: 0.1241 , Accuracy : 90.00%\n",
      "Epoch [613/1200], Loss: 0.0168 , Accuracy : 80.00%\n",
      "Epoch [614/1200], Loss: 0.0466 , Accuracy : 87.50%\n",
      "Epoch [615/1200], Loss: 0.8371 , Accuracy : 80.00%\n",
      "Epoch [616/1200], Loss: 0.0086 , Accuracy : 82.50%\n",
      "Epoch [617/1200], Loss: 0.1492 , Accuracy : 90.00%\n",
      "Epoch [618/1200], Loss: 0.0789 , Accuracy : 92.50%\n",
      "Epoch [619/1200], Loss: 0.1666 , Accuracy : 97.50%\n",
      "Epoch [620/1200], Loss: 0.2309 , Accuracy : 95.00%\n",
      "Epoch [621/1200], Loss: 0.8549 , Accuracy : 92.50%\n",
      "Epoch [622/1200], Loss: 0.0479 , Accuracy : 95.00%\n",
      "Epoch [623/1200], Loss: 0.5916 , Accuracy : 92.50%\n",
      "Epoch [624/1200], Loss: 0.3280 , Accuracy : 92.50%\n",
      "Epoch [625/1200], Loss: 0.0432 , Accuracy : 92.50%\n",
      "Epoch [626/1200], Loss: 0.0112 , Accuracy : 92.50%\n",
      "Epoch [627/1200], Loss: 0.0577 , Accuracy : 95.00%\n",
      "Epoch [628/1200], Loss: 0.0080 , Accuracy : 92.50%\n",
      "Epoch [629/1200], Loss: 0.0094 , Accuracy : 92.50%\n",
      "Epoch [630/1200], Loss: 0.0454 , Accuracy : 92.50%\n",
      "Epoch [631/1200], Loss: 0.0580 , Accuracy : 97.50%\n",
      "Epoch [632/1200], Loss: 0.4702 , Accuracy : 92.50%\n",
      "Epoch [633/1200], Loss: 0.0065 , Accuracy : 95.00%\n",
      "Epoch [634/1200], Loss: 0.2526 , Accuracy : 80.00%\n",
      "Epoch [635/1200], Loss: 0.0108 , Accuracy : 80.00%\n",
      "Epoch [636/1200], Loss: 0.1617 , Accuracy : 82.50%\n",
      "Epoch [637/1200], Loss: 0.5345 , Accuracy : 87.50%\n",
      "Epoch [638/1200], Loss: 0.0428 , Accuracy : 85.00%\n",
      "Epoch [639/1200], Loss: 0.0159 , Accuracy : 82.50%\n",
      "Epoch [640/1200], Loss: 0.1807 , Accuracy : 87.50%\n",
      "Epoch [641/1200], Loss: 0.4266 , Accuracy : 85.00%\n",
      "Epoch [642/1200], Loss: 0.5079 , Accuracy : 85.00%\n",
      "Epoch [643/1200], Loss: 0.3637 , Accuracy : 85.00%\n",
      "Epoch [644/1200], Loss: 0.2539 , Accuracy : 87.50%\n",
      "Epoch [645/1200], Loss: 0.0638 , Accuracy : 82.50%\n",
      "Epoch [646/1200], Loss: 0.1051 , Accuracy : 85.00%\n",
      "Epoch [647/1200], Loss: 0.4118 , Accuracy : 92.50%\n",
      "Epoch [648/1200], Loss: 0.0837 , Accuracy : 85.00%\n",
      "Epoch [649/1200], Loss: 0.0212 , Accuracy : 90.00%\n",
      "Epoch [650/1200], Loss: 0.0133 , Accuracy : 90.00%\n",
      "Epoch [651/1200], Loss: 0.2699 , Accuracy : 90.00%\n",
      "Epoch [652/1200], Loss: 0.2892 , Accuracy : 92.50%\n",
      "Epoch [653/1200], Loss: 0.3136 , Accuracy : 95.00%\n",
      "Epoch [654/1200], Loss: 0.0130 , Accuracy : 95.00%\n",
      "Epoch [655/1200], Loss: 0.0064 , Accuracy : 92.50%\n",
      "Epoch [656/1200], Loss: 0.2788 , Accuracy : 87.50%\n",
      "Epoch [657/1200], Loss: 0.0608 , Accuracy : 90.00%\n",
      "Epoch [658/1200], Loss: 0.1600 , Accuracy : 92.50%\n",
      "Epoch [659/1200], Loss: 0.0072 , Accuracy : 95.00%\n",
      "Epoch [660/1200], Loss: 0.2223 , Accuracy : 92.50%\n",
      "Epoch [661/1200], Loss: 0.2946 , Accuracy : 92.50%\n",
      "Epoch [662/1200], Loss: 0.0090 , Accuracy : 97.50%\n",
      "Epoch [663/1200], Loss: 0.0036 , Accuracy : 95.00%\n",
      "Epoch [664/1200], Loss: 0.0408 , Accuracy : 92.50%\n",
      "Epoch [665/1200], Loss: 0.2110 , Accuracy : 92.50%\n",
      "Epoch [666/1200], Loss: 0.0100 , Accuracy : 90.00%\n",
      "Epoch [667/1200], Loss: 0.0098 , Accuracy : 95.00%\n",
      "Epoch [668/1200], Loss: 0.2664 , Accuracy : 97.50%\n",
      "Epoch [669/1200], Loss: 0.0054 , Accuracy : 95.00%\n",
      "Epoch [670/1200], Loss: 0.1819 , Accuracy : 95.00%\n",
      "Epoch [671/1200], Loss: 0.0055 , Accuracy : 90.00%\n",
      "Epoch [672/1200], Loss: 0.0122 , Accuracy : 97.50%\n",
      "Epoch [673/1200], Loss: 0.0058 , Accuracy : 95.00%\n",
      "Epoch [674/1200], Loss: 0.0414 , Accuracy : 87.50%\n",
      "Epoch [675/1200], Loss: 0.0024 , Accuracy : 90.00%\n",
      "Epoch [676/1200], Loss: 0.2315 , Accuracy : 90.00%\n",
      "Epoch [677/1200], Loss: 0.0062 , Accuracy : 90.00%\n",
      "Epoch [678/1200], Loss: 2.1072 , Accuracy : 85.00%\n",
      "Epoch [679/1200], Loss: 1.0019 , Accuracy : 90.00%\n",
      "Epoch [680/1200], Loss: 0.2117 , Accuracy : 92.50%\n",
      "Epoch [681/1200], Loss: 0.7192 , Accuracy : 87.50%\n",
      "Epoch [682/1200], Loss: 0.3075 , Accuracy : 85.00%\n",
      "Epoch [683/1200], Loss: 0.2156 , Accuracy : 90.00%\n",
      "Epoch [684/1200], Loss: 0.2618 , Accuracy : 85.00%\n",
      "Epoch [685/1200], Loss: 0.0211 , Accuracy : 77.50%\n",
      "Epoch [686/1200], Loss: 0.8288 , Accuracy : 82.50%\n",
      "Epoch [687/1200], Loss: 0.2940 , Accuracy : 87.50%\n",
      "Epoch [688/1200], Loss: 2.3077 , Accuracy : 82.50%\n",
      "Epoch [689/1200], Loss: 0.3321 , Accuracy : 80.00%\n",
      "Epoch [690/1200], Loss: 0.1481 , Accuracy : 87.50%\n",
      "Epoch [691/1200], Loss: 0.5253 , Accuracy : 82.50%\n",
      "Epoch [692/1200], Loss: 0.3012 , Accuracy : 85.00%\n",
      "Epoch [693/1200], Loss: 0.1795 , Accuracy : 87.50%\n",
      "Epoch [694/1200], Loss: 0.4756 , Accuracy : 85.00%\n",
      "Epoch [695/1200], Loss: 0.6761 , Accuracy : 82.50%\n",
      "Epoch [696/1200], Loss: 2.6536 , Accuracy : 65.00%\n",
      "Epoch [697/1200], Loss: 0.0598 , Accuracy : 80.00%\n",
      "Epoch [698/1200], Loss: 0.0091 , Accuracy : 80.00%\n",
      "Epoch [699/1200], Loss: 0.0082 , Accuracy : 80.00%\n",
      "Epoch [700/1200], Loss: 0.3932 , Accuracy : 80.00%\n",
      "Epoch [701/1200], Loss: 0.3838 , Accuracy : 85.00%\n",
      "Epoch [702/1200], Loss: 0.3434 , Accuracy : 87.50%\n",
      "Epoch [703/1200], Loss: 0.5630 , Accuracy : 87.50%\n",
      "Epoch [704/1200], Loss: 0.1569 , Accuracy : 97.50%\n",
      "Epoch [705/1200], Loss: 0.2447 , Accuracy : 90.00%\n",
      "Epoch [706/1200], Loss: 1.0531 , Accuracy : 82.50%\n",
      "Epoch [707/1200], Loss: 0.3380 , Accuracy : 90.00%\n",
      "Epoch [708/1200], Loss: 1.0516 , Accuracy : 82.50%\n",
      "Epoch [709/1200], Loss: 0.6557 , Accuracy : 85.00%\n",
      "Epoch [710/1200], Loss: 0.1514 , Accuracy : 92.50%\n",
      "Epoch [711/1200], Loss: 0.7382 , Accuracy : 92.50%\n",
      "Epoch [712/1200], Loss: 0.0063 , Accuracy : 90.00%\n",
      "Epoch [713/1200], Loss: 0.0174 , Accuracy : 97.50%\n",
      "Epoch [714/1200], Loss: 0.2721 , Accuracy : 92.50%\n",
      "Epoch [715/1200], Loss: 0.0490 , Accuracy : 92.50%\n",
      "Epoch [716/1200], Loss: 0.2310 , Accuracy : 82.50%\n",
      "Epoch [717/1200], Loss: 0.2771 , Accuracy : 97.50%\n",
      "Epoch [718/1200], Loss: 0.2155 , Accuracy : 92.50%\n",
      "Epoch [719/1200], Loss: 0.0392 , Accuracy : 92.50%\n",
      "Epoch [720/1200], Loss: 0.4904 , Accuracy : 95.00%\n",
      "Epoch [721/1200], Loss: 0.4389 , Accuracy : 92.50%\n",
      "Epoch [722/1200], Loss: 0.7348 , Accuracy : 92.50%\n",
      "Epoch [723/1200], Loss: 0.0056 , Accuracy : 90.00%\n",
      "Epoch [724/1200], Loss: 0.0060 , Accuracy : 92.50%\n",
      "Epoch [725/1200], Loss: 0.0131 , Accuracy : 95.00%\n",
      "Epoch [726/1200], Loss: 0.0645 , Accuracy : 95.00%\n",
      "Epoch [727/1200], Loss: 0.0011 , Accuracy : 85.00%\n",
      "Epoch [728/1200], Loss: 0.0117 , Accuracy : 92.50%\n",
      "Epoch [729/1200], Loss: 0.1468 , Accuracy : 97.50%\n",
      "Epoch [730/1200], Loss: 0.2629 , Accuracy : 95.00%\n",
      "Epoch [731/1200], Loss: 0.0145 , Accuracy : 92.50%\n",
      "Epoch [732/1200], Loss: 0.0164 , Accuracy : 95.00%\n",
      "Epoch [733/1200], Loss: 0.6332 , Accuracy : 82.50%\n",
      "Epoch [734/1200], Loss: 0.0125 , Accuracy : 95.00%\n",
      "Epoch [735/1200], Loss: 0.3840 , Accuracy : 87.50%\n",
      "Epoch [736/1200], Loss: 0.9514 , Accuracy : 87.50%\n",
      "Epoch [737/1200], Loss: 0.3491 , Accuracy : 97.50%\n",
      "Epoch [738/1200], Loss: 0.1992 , Accuracy : 92.50%\n",
      "Epoch [739/1200], Loss: 0.5100 , Accuracy : 90.00%\n",
      "Epoch [740/1200], Loss: 0.0052 , Accuracy : 92.50%\n",
      "Epoch [741/1200], Loss: 0.0175 , Accuracy : 95.00%\n",
      "Epoch [742/1200], Loss: 0.9397 , Accuracy : 85.00%\n",
      "Epoch [743/1200], Loss: 0.1866 , Accuracy : 95.00%\n",
      "Epoch [744/1200], Loss: 0.6414 , Accuracy : 87.50%\n",
      "Epoch [745/1200], Loss: 1.2169 , Accuracy : 82.50%\n",
      "Epoch [746/1200], Loss: 1.0202 , Accuracy : 85.00%\n",
      "Epoch [747/1200], Loss: 0.2022 , Accuracy : 80.00%\n",
      "Epoch [748/1200], Loss: 0.0167 , Accuracy : 80.00%\n",
      "Epoch [749/1200], Loss: 0.1037 , Accuracy : 87.50%\n",
      "Epoch [750/1200], Loss: 0.3601 , Accuracy : 90.00%\n",
      "Epoch [751/1200], Loss: 0.9078 , Accuracy : 92.50%\n",
      "Epoch [752/1200], Loss: 0.0404 , Accuracy : 92.50%\n",
      "Epoch [753/1200], Loss: 0.0237 , Accuracy : 87.50%\n",
      "Epoch [754/1200], Loss: 0.1541 , Accuracy : 87.50%\n",
      "Epoch [755/1200], Loss: 0.0142 , Accuracy : 92.50%\n",
      "Epoch [756/1200], Loss: 0.3759 , Accuracy : 90.00%\n",
      "Epoch [757/1200], Loss: 0.0241 , Accuracy : 95.00%\n",
      "Epoch [758/1200], Loss: 0.0412 , Accuracy : 92.50%\n",
      "Epoch [759/1200], Loss: 0.3354 , Accuracy : 92.50%\n",
      "Epoch [760/1200], Loss: 0.3114 , Accuracy : 92.50%\n",
      "Epoch [761/1200], Loss: 0.0087 , Accuracy : 92.50%\n",
      "Epoch [762/1200], Loss: 0.2620 , Accuracy : 95.00%\n",
      "Epoch [763/1200], Loss: 0.7039 , Accuracy : 90.00%\n",
      "Epoch [764/1200], Loss: 0.0041 , Accuracy : 92.50%\n",
      "Epoch [765/1200], Loss: 0.1177 , Accuracy : 90.00%\n",
      "Epoch [766/1200], Loss: 0.0137 , Accuracy : 85.00%\n",
      "Epoch [767/1200], Loss: 0.0134 , Accuracy : 95.00%\n",
      "Epoch [768/1200], Loss: 0.0087 , Accuracy : 90.00%\n",
      "Epoch [769/1200], Loss: 0.0088 , Accuracy : 92.50%\n",
      "Epoch [770/1200], Loss: 0.2230 , Accuracy : 97.50%\n",
      "Epoch [771/1200], Loss: 0.0078 , Accuracy : 95.00%\n",
      "Epoch [772/1200], Loss: 0.0329 , Accuracy : 97.50%\n",
      "Epoch [773/1200], Loss: 0.0349 , Accuracy : 95.00%\n",
      "Epoch [774/1200], Loss: 0.4415 , Accuracy : 92.50%\n",
      "Epoch [775/1200], Loss: 0.0264 , Accuracy : 95.00%\n",
      "Epoch [776/1200], Loss: 0.0029 , Accuracy : 92.50%\n",
      "Epoch [777/1200], Loss: 0.0034 , Accuracy : 92.50%\n",
      "Epoch [778/1200], Loss: 0.9682 , Accuracy : 85.00%\n",
      "Epoch [779/1200], Loss: 0.3574 , Accuracy : 85.00%\n",
      "Epoch [780/1200], Loss: 0.0075 , Accuracy : 85.00%\n",
      "Epoch [781/1200], Loss: 0.0088 , Accuracy : 87.50%\n",
      "Epoch [782/1200], Loss: 0.2912 , Accuracy : 82.50%\n",
      "Epoch [783/1200], Loss: 0.4422 , Accuracy : 85.00%\n",
      "Epoch [784/1200], Loss: 0.0046 , Accuracy : 95.00%\n",
      "Epoch [785/1200], Loss: 0.0710 , Accuracy : 95.00%\n",
      "Epoch [786/1200], Loss: 0.0336 , Accuracy : 95.00%\n",
      "Epoch [787/1200], Loss: 0.0747 , Accuracy : 92.50%\n",
      "Epoch [788/1200], Loss: 0.0244 , Accuracy : 95.00%\n",
      "Epoch [789/1200], Loss: 0.0180 , Accuracy : 97.50%\n",
      "Epoch [790/1200], Loss: 0.0727 , Accuracy : 95.00%\n",
      "Epoch [791/1200], Loss: 0.0191 , Accuracy : 92.50%\n",
      "Epoch [792/1200], Loss: 0.3219 , Accuracy : 95.00%\n",
      "Epoch [793/1200], Loss: 0.2179 , Accuracy : 95.00%\n",
      "Epoch [794/1200], Loss: 0.0083 , Accuracy : 92.50%\n",
      "Epoch [795/1200], Loss: 0.1813 , Accuracy : 97.50%\n",
      "Epoch [796/1200], Loss: 0.0072 , Accuracy : 97.50%\n",
      "Epoch [797/1200], Loss: 0.2104 , Accuracy : 95.00%\n",
      "Epoch [798/1200], Loss: 0.0050 , Accuracy : 97.50%\n",
      "Epoch [799/1200], Loss: 0.5002 , Accuracy : 90.00%\n",
      "Epoch [800/1200], Loss: 0.0150 , Accuracy : 92.50%\n",
      "Epoch [801/1200], Loss: 0.0854 , Accuracy : 92.50%\n",
      "Epoch [802/1200], Loss: 0.0046 , Accuracy : 92.50%\n",
      "Epoch [803/1200], Loss: 0.2060 , Accuracy : 95.00%\n",
      "Epoch [804/1200], Loss: 0.0012 , Accuracy : 90.00%\n",
      "Epoch [805/1200], Loss: 0.0040 , Accuracy : 95.00%\n",
      "Epoch [806/1200], Loss: 0.0069 , Accuracy : 95.00%\n",
      "Epoch [807/1200], Loss: 0.0119 , Accuracy : 95.00%\n",
      "Epoch [808/1200], Loss: 0.2795 , Accuracy : 95.00%\n",
      "Epoch [809/1200], Loss: 0.0011 , Accuracy : 90.00%\n",
      "Epoch [810/1200], Loss: 0.0240 , Accuracy : 95.00%\n",
      "Epoch [811/1200], Loss: 0.0051 , Accuracy : 95.00%\n",
      "Epoch [812/1200], Loss: 0.0016 , Accuracy : 95.00%\n",
      "Epoch [813/1200], Loss: 0.0351 , Accuracy : 92.50%\n",
      "Epoch [814/1200], Loss: 0.0008 , Accuracy : 97.50%\n",
      "Epoch [815/1200], Loss: 0.0582 , Accuracy : 92.50%\n",
      "Epoch [816/1200], Loss: 0.1758 , Accuracy : 82.50%\n",
      "Epoch [817/1200], Loss: 0.0014 , Accuracy : 82.50%\n",
      "Epoch [818/1200], Loss: 0.0672 , Accuracy : 90.00%\n",
      "Epoch [819/1200], Loss: 0.3380 , Accuracy : 87.50%\n",
      "Epoch [820/1200], Loss: 0.4519 , Accuracy : 90.00%\n",
      "Epoch [821/1200], Loss: 0.0568 , Accuracy : 97.50%\n",
      "Epoch [822/1200], Loss: 0.0012 , Accuracy : 92.50%\n",
      "Epoch [823/1200], Loss: 0.0017 , Accuracy : 92.50%\n",
      "Epoch [824/1200], Loss: 0.0451 , Accuracy : 90.00%\n",
      "Epoch [825/1200], Loss: 0.3609 , Accuracy : 95.00%\n",
      "Epoch [826/1200], Loss: 0.3502 , Accuracy : 90.00%\n",
      "Epoch [827/1200], Loss: 0.0009 , Accuracy : 95.00%\n",
      "Epoch [828/1200], Loss: 0.3515 , Accuracy : 90.00%\n",
      "Epoch [829/1200], Loss: 0.0009 , Accuracy : 92.50%\n",
      "Epoch [830/1200], Loss: 0.0011 , Accuracy : 92.50%\n",
      "Epoch [831/1200], Loss: 0.2963 , Accuracy : 97.50%\n",
      "Epoch [832/1200], Loss: 0.0719 , Accuracy : 97.50%\n",
      "Epoch [833/1200], Loss: 0.0281 , Accuracy : 97.50%\n",
      "Epoch [834/1200], Loss: 0.0057 , Accuracy : 95.00%\n",
      "Epoch [835/1200], Loss: 0.3117 , Accuracy : 90.00%\n",
      "Epoch [836/1200], Loss: 0.1928 , Accuracy : 92.50%\n",
      "Epoch [837/1200], Loss: 0.0150 , Accuracy : 95.00%\n",
      "Epoch [838/1200], Loss: 0.0135 , Accuracy : 97.50%\n",
      "Epoch [839/1200], Loss: 0.0033 , Accuracy : 97.50%\n",
      "Epoch [840/1200], Loss: 0.0095 , Accuracy : 95.00%\n",
      "Epoch [841/1200], Loss: 0.0010 , Accuracy : 92.50%\n",
      "Epoch [842/1200], Loss: 0.0011 , Accuracy : 97.50%\n",
      "Epoch [843/1200], Loss: 0.0025 , Accuracy : 97.50%\n",
      "Epoch [844/1200], Loss: 0.1959 , Accuracy : 97.50%\n",
      "Epoch [845/1200], Loss: 0.0149 , Accuracy : 92.50%\n",
      "Epoch [846/1200], Loss: 0.3483 , Accuracy : 85.00%\n",
      "Epoch [847/1200], Loss: 0.0542 , Accuracy : 85.00%\n",
      "Epoch [848/1200], Loss: 0.1589 , Accuracy : 80.00%\n",
      "Epoch [849/1200], Loss: 0.2346 , Accuracy : 80.00%\n",
      "Epoch [850/1200], Loss: 0.0400 , Accuracy : 82.50%\n",
      "Epoch [851/1200], Loss: 0.0085 , Accuracy : 82.50%\n",
      "Epoch [852/1200], Loss: 0.0125 , Accuracy : 92.50%\n",
      "Epoch [853/1200], Loss: 0.0282 , Accuracy : 90.00%\n",
      "Epoch [854/1200], Loss: 0.2302 , Accuracy : 90.00%\n",
      "Epoch [855/1200], Loss: 0.0099 , Accuracy : 92.50%\n",
      "Epoch [856/1200], Loss: 0.4063 , Accuracy : 90.00%\n",
      "Epoch [857/1200], Loss: 0.0699 , Accuracy : 95.00%\n",
      "Epoch [858/1200], Loss: 0.1012 , Accuracy : 92.50%\n",
      "Epoch [859/1200], Loss: 0.1396 , Accuracy : 92.50%\n",
      "Epoch [860/1200], Loss: 0.0759 , Accuracy : 92.50%\n",
      "Epoch [861/1200], Loss: 0.0024 , Accuracy : 90.00%\n",
      "Epoch [862/1200], Loss: 0.0060 , Accuracy : 90.00%\n",
      "Epoch [863/1200], Loss: 0.1126 , Accuracy : 92.50%\n",
      "Epoch [864/1200], Loss: 0.0208 , Accuracy : 97.50%\n",
      "Epoch [865/1200], Loss: 0.1960 , Accuracy : 95.00%\n",
      "Epoch [866/1200], Loss: 0.3533 , Accuracy : 97.50%\n",
      "Epoch [867/1200], Loss: 0.0101 , Accuracy : 97.50%\n",
      "Epoch [868/1200], Loss: 0.0261 , Accuracy : 95.00%\n",
      "Epoch [869/1200], Loss: 0.0695 , Accuracy : 95.00%\n",
      "Epoch [870/1200], Loss: 0.3943 , Accuracy : 95.00%\n",
      "Epoch [871/1200], Loss: 0.0523 , Accuracy : 97.50%\n",
      "Epoch [872/1200], Loss: 0.0201 , Accuracy : 95.00%\n",
      "Epoch [873/1200], Loss: 0.0125 , Accuracy : 97.50%\n",
      "Epoch [874/1200], Loss: 0.0141 , Accuracy : 97.50%\n",
      "Epoch [875/1200], Loss: 0.0146 , Accuracy : 95.00%\n",
      "Epoch [876/1200], Loss: 0.2320 , Accuracy : 92.50%\n",
      "Epoch [877/1200], Loss: 0.0075 , Accuracy : 97.50%\n",
      "Epoch [878/1200], Loss: 0.0063 , Accuracy : 92.50%\n",
      "Epoch [879/1200], Loss: 0.0031 , Accuracy : 92.50%\n",
      "Epoch [880/1200], Loss: 0.1779 , Accuracy : 92.50%\n",
      "Epoch [881/1200], Loss: 0.2215 , Accuracy : 97.50%\n",
      "Epoch [882/1200], Loss: 0.0025 , Accuracy : 97.50%\n",
      "Epoch [883/1200], Loss: 0.1956 , Accuracy : 95.00%\n",
      "Epoch [884/1200], Loss: 0.0091 , Accuracy : 97.50%\n",
      "Epoch [885/1200], Loss: 0.1855 , Accuracy : 95.00%\n",
      "Epoch [886/1200], Loss: 0.0017 , Accuracy : 95.00%\n",
      "Epoch [887/1200], Loss: 0.2171 , Accuracy : 95.00%\n",
      "Epoch [888/1200], Loss: 0.0025 , Accuracy : 97.50%\n",
      "Epoch [889/1200], Loss: 0.0206 , Accuracy : 97.50%\n",
      "Epoch [890/1200], Loss: 0.0107 , Accuracy : 97.50%\n",
      "Epoch [891/1200], Loss: 0.1995 , Accuracy : 95.00%\n",
      "Epoch [892/1200], Loss: 0.0659 , Accuracy : 97.50%\n",
      "Epoch [893/1200], Loss: 0.1957 , Accuracy : 90.00%\n",
      "Epoch [894/1200], Loss: 0.0019 , Accuracy : 97.50%\n",
      "Epoch [895/1200], Loss: 0.2075 , Accuracy : 95.00%\n",
      "Epoch [896/1200], Loss: 0.0489 , Accuracy : 92.50%\n",
      "Epoch [897/1200], Loss: 0.3271 , Accuracy : 92.50%\n",
      "Epoch [898/1200], Loss: 0.1734 , Accuracy : 97.50%\n",
      "Epoch [899/1200], Loss: 0.2058 , Accuracy : 95.00%\n",
      "Epoch [900/1200], Loss: 0.1832 , Accuracy : 90.00%\n",
      "Epoch [901/1200], Loss: 0.3443 , Accuracy : 82.50%\n",
      "Epoch [902/1200], Loss: 0.2075 , Accuracy : 85.00%\n",
      "Epoch [903/1200], Loss: 0.7283 , Accuracy : 85.00%\n",
      "Epoch [904/1200], Loss: 0.5536 , Accuracy : 80.00%\n",
      "Epoch [905/1200], Loss: 0.0387 , Accuracy : 80.00%\n",
      "Epoch [906/1200], Loss: 5.3847 , Accuracy : 75.00%\n",
      "Epoch [907/1200], Loss: 0.3745 , Accuracy : 77.50%\n",
      "Epoch [908/1200], Loss: 0.2408 , Accuracy : 80.00%\n",
      "Epoch [909/1200], Loss: 0.2735 , Accuracy : 75.00%\n",
      "Epoch [910/1200], Loss: 1.3740 , Accuracy : 87.50%\n",
      "Epoch [911/1200], Loss: 0.0269 , Accuracy : 87.50%\n",
      "Epoch [912/1200], Loss: 0.2227 , Accuracy : 92.50%\n",
      "Epoch [913/1200], Loss: 0.1820 , Accuracy : 95.00%\n",
      "Epoch [914/1200], Loss: 0.1087 , Accuracy : 97.50%\n",
      "Epoch [915/1200], Loss: 0.0321 , Accuracy : 97.50%\n",
      "Epoch [916/1200], Loss: 0.1249 , Accuracy : 97.50%\n",
      "Epoch [917/1200], Loss: 0.4403 , Accuracy : 95.00%\n",
      "Epoch [918/1200], Loss: 0.2427 , Accuracy : 87.50%\n",
      "Epoch [919/1200], Loss: 0.0591 , Accuracy : 97.50%\n",
      "Epoch [920/1200], Loss: 0.0038 , Accuracy : 97.50%\n",
      "Epoch [921/1200], Loss: 0.1923 , Accuracy : 95.00%\n",
      "Epoch [922/1200], Loss: 0.0019 , Accuracy : 97.50%\n",
      "Epoch [923/1200], Loss: 0.0418 , Accuracy : 97.50%\n",
      "Epoch [924/1200], Loss: 0.2276 , Accuracy : 95.00%\n",
      "Epoch [925/1200], Loss: 0.0023 , Accuracy : 97.50%\n",
      "Epoch [926/1200], Loss: 0.0004 , Accuracy : 95.00%\n",
      "Epoch [927/1200], Loss: 0.0185 , Accuracy : 95.00%\n",
      "Epoch [928/1200], Loss: 0.0055 , Accuracy : 97.50%\n",
      "Epoch [929/1200], Loss: 0.4115 , Accuracy : 95.00%\n",
      "Epoch [930/1200], Loss: 0.1855 , Accuracy : 95.00%\n",
      "Epoch [931/1200], Loss: 0.4974 , Accuracy : 92.50%\n",
      "Epoch [932/1200], Loss: 0.1892 , Accuracy : 92.50%\n",
      "Epoch [933/1200], Loss: 0.0512 , Accuracy : 95.00%\n",
      "Epoch [934/1200], Loss: 0.4028 , Accuracy : 92.50%\n",
      "Epoch [935/1200], Loss: 0.1919 , Accuracy : 97.50%\n",
      "Epoch [936/1200], Loss: 0.0072 , Accuracy : 97.50%\n",
      "Epoch [937/1200], Loss: 0.0014 , Accuracy : 95.00%\n",
      "Epoch [938/1200], Loss: 0.0076 , Accuracy : 92.50%\n",
      "Epoch [939/1200], Loss: 0.0446 , Accuracy : 95.00%\n",
      "Epoch [940/1200], Loss: 0.0064 , Accuracy : 97.50%\n",
      "Epoch [941/1200], Loss: 0.0173 , Accuracy : 97.50%\n",
      "Epoch [942/1200], Loss: 0.1978 , Accuracy : 97.50%\n",
      "Epoch [943/1200], Loss: 0.0079 , Accuracy : 95.00%\n",
      "Epoch [944/1200], Loss: 0.0012 , Accuracy : 97.50%\n",
      "Epoch [945/1200], Loss: 0.0280 , Accuracy : 97.50%\n",
      "Epoch [946/1200], Loss: 0.2082 , Accuracy : 92.50%\n",
      "Epoch [947/1200], Loss: 0.0082 , Accuracy : 97.50%\n",
      "Epoch [948/1200], Loss: 0.0043 , Accuracy : 97.50%\n",
      "Epoch [949/1200], Loss: 0.2388 , Accuracy : 97.50%\n",
      "Epoch [950/1200], Loss: 0.0237 , Accuracy : 97.50%\n",
      "Epoch [951/1200], Loss: 0.2055 , Accuracy : 95.00%\n",
      "Epoch [952/1200], Loss: 0.0011 , Accuracy : 97.50%\n",
      "Epoch [953/1200], Loss: 0.0131 , Accuracy : 95.00%\n",
      "Epoch [954/1200], Loss: 0.0625 , Accuracy : 97.50%\n",
      "Epoch [955/1200], Loss: 0.0178 , Accuracy : 95.00%\n",
      "Epoch [956/1200], Loss: 0.0013 , Accuracy : 97.50%\n",
      "Epoch [957/1200], Loss: 0.1989 , Accuracy : 95.00%\n",
      "Epoch [958/1200], Loss: 0.0030 , Accuracy : 95.00%\n",
      "Epoch [959/1200], Loss: 0.0041 , Accuracy : 97.50%\n",
      "Epoch [960/1200], Loss: 0.0130 , Accuracy : 97.50%\n",
      "Epoch [961/1200], Loss: 0.2100 , Accuracy : 97.50%\n",
      "Epoch [962/1200], Loss: 0.0058 , Accuracy : 95.00%\n",
      "Epoch [963/1200], Loss: 0.2041 , Accuracy : 97.50%\n",
      "Epoch [964/1200], Loss: 0.0052 , Accuracy : 95.00%\n",
      "Epoch [965/1200], Loss: 0.0031 , Accuracy : 95.00%\n",
      "Epoch [966/1200], Loss: 0.1996 , Accuracy : 97.50%\n",
      "Epoch [967/1200], Loss: 0.0104 , Accuracy : 95.00%\n",
      "Epoch [968/1200], Loss: 0.0070 , Accuracy : 97.50%\n",
      "Epoch [969/1200], Loss: 0.0003 , Accuracy : 97.50%\n",
      "Epoch [970/1200], Loss: 0.0017 , Accuracy : 95.00%\n",
      "Epoch [971/1200], Loss: 0.1939 , Accuracy : 97.50%\n",
      "Epoch [972/1200], Loss: 0.0153 , Accuracy : 97.50%\n",
      "Epoch [973/1200], Loss: 0.0168 , Accuracy : 97.50%\n",
      "Epoch [974/1200], Loss: 0.0022 , Accuracy : 97.50%\n",
      "Epoch [975/1200], Loss: 0.0050 , Accuracy : 95.00%\n",
      "Epoch [976/1200], Loss: 0.1863 , Accuracy : 95.00%\n",
      "Epoch [977/1200], Loss: 0.0108 , Accuracy : 85.00%\n",
      "Epoch [978/1200], Loss: 0.2540 , Accuracy : 92.50%\n",
      "Epoch [979/1200], Loss: 0.0067 , Accuracy : 87.50%\n",
      "Epoch [980/1200], Loss: 0.0068 , Accuracy : 77.50%\n",
      "Epoch [981/1200], Loss: 1.5206 , Accuracy : 82.50%\n",
      "Epoch [982/1200], Loss: 0.8931 , Accuracy : 75.00%\n",
      "Epoch [983/1200], Loss: 1.0891 , Accuracy : 77.50%\n",
      "Epoch [984/1200], Loss: 0.3859 , Accuracy : 77.50%\n",
      "Epoch [985/1200], Loss: 0.7396 , Accuracy : 87.50%\n",
      "Epoch [986/1200], Loss: 0.0389 , Accuracy : 85.00%\n",
      "Epoch [987/1200], Loss: 0.3091 , Accuracy : 90.00%\n",
      "Epoch [988/1200], Loss: 0.0041 , Accuracy : 90.00%\n",
      "Epoch [989/1200], Loss: 0.2025 , Accuracy : 90.00%\n",
      "Epoch [990/1200], Loss: 0.0952 , Accuracy : 90.00%\n",
      "Epoch [991/1200], Loss: 0.5283 , Accuracy : 92.50%\n",
      "Epoch [992/1200], Loss: 0.0036 , Accuracy : 92.50%\n",
      "Epoch [993/1200], Loss: 0.0037 , Accuracy : 92.50%\n",
      "Epoch [994/1200], Loss: 0.0006 , Accuracy : 95.00%\n",
      "Epoch [995/1200], Loss: 0.0013 , Accuracy : 97.50%\n",
      "Epoch [996/1200], Loss: 0.2125 , Accuracy : 97.50%\n",
      "Epoch [997/1200], Loss: 0.0741 , Accuracy : 97.50%\n",
      "Epoch [998/1200], Loss: 0.3162 , Accuracy : 95.00%\n",
      "Epoch [999/1200], Loss: 0.0600 , Accuracy : 92.50%\n",
      "Epoch [1000/1200], Loss: 0.6933 , Accuracy : 90.00%\n",
      "Epoch [1001/1200], Loss: 0.2327 , Accuracy : 87.50%\n",
      "Epoch [1002/1200], Loss: 0.0139 , Accuracy : 95.00%\n",
      "Epoch [1003/1200], Loss: 0.0806 , Accuracy : 95.00%\n",
      "Epoch [1004/1200], Loss: 0.0072 , Accuracy : 97.50%\n",
      "Epoch [1005/1200], Loss: 0.0233 , Accuracy : 97.50%\n",
      "Epoch [1006/1200], Loss: 0.0349 , Accuracy : 95.00%\n",
      "Epoch [1007/1200], Loss: 0.0100 , Accuracy : 97.50%\n",
      "Epoch [1008/1200], Loss: 0.2120 , Accuracy : 97.50%\n",
      "Epoch [1009/1200], Loss: 0.1821 , Accuracy : 95.00%\n",
      "Epoch [1010/1200], Loss: 0.6268 , Accuracy : 90.00%\n",
      "Epoch [1011/1200], Loss: 0.9874 , Accuracy : 95.00%\n",
      "Epoch [1012/1200], Loss: 0.0608 , Accuracy : 90.00%\n",
      "Epoch [1013/1200], Loss: 0.0029 , Accuracy : 92.50%\n",
      "Epoch [1014/1200], Loss: 0.0062 , Accuracy : 90.00%\n",
      "Epoch [1015/1200], Loss: 0.0008 , Accuracy : 92.50%\n",
      "Epoch [1016/1200], Loss: 0.9834 , Accuracy : 87.50%\n",
      "Epoch [1017/1200], Loss: 0.0024 , Accuracy : 92.50%\n",
      "Epoch [1018/1200], Loss: 0.0257 , Accuracy : 92.50%\n",
      "Epoch [1019/1200], Loss: 0.0015 , Accuracy : 97.50%\n",
      "Epoch [1020/1200], Loss: 0.0022 , Accuracy : 92.50%\n",
      "Epoch [1021/1200], Loss: 0.2199 , Accuracy : 97.50%\n",
      "Epoch [1022/1200], Loss: 0.0058 , Accuracy : 92.50%\n",
      "Epoch [1023/1200], Loss: 0.0043 , Accuracy : 95.00%\n",
      "Epoch [1024/1200], Loss: 0.0879 , Accuracy : 97.50%\n",
      "Epoch [1025/1200], Loss: 0.0804 , Accuracy : 95.00%\n",
      "Epoch [1026/1200], Loss: 0.0418 , Accuracy : 97.50%\n",
      "Epoch [1027/1200], Loss: 0.0032 , Accuracy : 97.50%\n",
      "Epoch [1028/1200], Loss: 0.2026 , Accuracy : 95.00%\n",
      "Epoch [1029/1200], Loss: 0.0059 , Accuracy : 90.00%\n",
      "Epoch [1030/1200], Loss: 0.0182 , Accuracy : 95.00%\n",
      "Epoch [1031/1200], Loss: 0.1233 , Accuracy : 92.50%\n",
      "Epoch [1032/1200], Loss: 0.0017 , Accuracy : 95.00%\n",
      "Epoch [1033/1200], Loss: 0.0217 , Accuracy : 92.50%\n",
      "Epoch [1034/1200], Loss: 1.0938 , Accuracy : 92.50%\n",
      "Epoch [1035/1200], Loss: 0.0034 , Accuracy : 97.50%\n",
      "Epoch [1036/1200], Loss: 0.0064 , Accuracy : 95.00%\n",
      "Epoch [1037/1200], Loss: 0.0169 , Accuracy : 92.50%\n",
      "Epoch [1038/1200], Loss: 0.0031 , Accuracy : 95.00%\n",
      "Epoch [1039/1200], Loss: 0.0119 , Accuracy : 97.50%\n",
      "Epoch [1040/1200], Loss: 0.0175 , Accuracy : 95.00%\n",
      "Epoch [1041/1200], Loss: 0.2828 , Accuracy : 90.00%\n",
      "Epoch [1042/1200], Loss: 0.0056 , Accuracy : 95.00%\n",
      "Epoch [1043/1200], Loss: 0.0140 , Accuracy : 97.50%\n",
      "Epoch [1044/1200], Loss: 0.0245 , Accuracy : 92.50%\n",
      "Epoch [1045/1200], Loss: 0.0026 , Accuracy : 97.50%\n",
      "Epoch [1046/1200], Loss: 0.0804 , Accuracy : 95.00%\n",
      "Epoch [1047/1200], Loss: 0.0366 , Accuracy : 95.00%\n",
      "Epoch [1048/1200], Loss: 0.0096 , Accuracy : 92.50%\n",
      "Epoch [1049/1200], Loss: 0.2088 , Accuracy : 95.00%\n",
      "Epoch [1050/1200], Loss: 0.0042 , Accuracy : 90.00%\n",
      "Epoch [1051/1200], Loss: 0.0037 , Accuracy : 92.50%\n",
      "Epoch [1052/1200], Loss: 0.0067 , Accuracy : 95.00%\n",
      "Epoch [1053/1200], Loss: 0.0081 , Accuracy : 92.50%\n",
      "Epoch [1054/1200], Loss: 0.0602 , Accuracy : 95.00%\n",
      "Epoch [1055/1200], Loss: 0.0020 , Accuracy : 97.50%\n",
      "Epoch [1056/1200], Loss: 0.0602 , Accuracy : 95.00%\n",
      "Epoch [1057/1200], Loss: 0.2001 , Accuracy : 95.00%\n",
      "Epoch [1058/1200], Loss: 0.2141 , Accuracy : 97.50%\n",
      "Epoch [1059/1200], Loss: 0.1975 , Accuracy : 97.50%\n",
      "Epoch [1060/1200], Loss: 0.0313 , Accuracy : 97.50%\n",
      "Epoch [1061/1200], Loss: 0.0083 , Accuracy : 97.50%\n",
      "Epoch [1062/1200], Loss: 0.3486 , Accuracy : 95.00%\n",
      "Epoch [1063/1200], Loss: 0.0135 , Accuracy : 97.50%\n",
      "Epoch [1064/1200], Loss: 0.0061 , Accuracy : 97.50%\n",
      "Epoch [1065/1200], Loss: 0.0168 , Accuracy : 95.00%\n",
      "Epoch [1066/1200], Loss: 0.0016 , Accuracy : 97.50%\n",
      "Epoch [1067/1200], Loss: 0.0197 , Accuracy : 95.00%\n",
      "Epoch [1068/1200], Loss: 0.8039 , Accuracy : 92.50%\n",
      "Epoch [1069/1200], Loss: 0.1772 , Accuracy : 95.00%\n",
      "Epoch [1070/1200], Loss: 0.1953 , Accuracy : 87.50%\n",
      "Epoch [1071/1200], Loss: 0.0014 , Accuracy : 92.50%\n",
      "Epoch [1072/1200], Loss: 0.0145 , Accuracy : 92.50%\n",
      "Epoch [1073/1200], Loss: 0.0629 , Accuracy : 92.50%\n",
      "Epoch [1074/1200], Loss: 0.0020 , Accuracy : 92.50%\n",
      "Epoch [1075/1200], Loss: 0.0314 , Accuracy : 97.50%\n",
      "Epoch [1076/1200], Loss: 0.2234 , Accuracy : 95.00%\n",
      "Epoch [1077/1200], Loss: 0.2303 , Accuracy : 97.50%\n",
      "Epoch [1078/1200], Loss: 0.0015 , Accuracy : 95.00%\n",
      "Epoch [1079/1200], Loss: 0.1842 , Accuracy : 95.00%\n",
      "Epoch [1080/1200], Loss: 0.0316 , Accuracy : 97.50%\n",
      "Epoch [1081/1200], Loss: 0.2229 , Accuracy : 97.50%\n",
      "Epoch [1082/1200], Loss: 0.1939 , Accuracy : 95.00%\n",
      "Epoch [1083/1200], Loss: 0.2154 , Accuracy : 97.50%\n",
      "Epoch [1084/1200], Loss: 0.0022 , Accuracy : 95.00%\n",
      "Epoch [1085/1200], Loss: 0.1963 , Accuracy : 97.50%\n",
      "Epoch [1086/1200], Loss: 0.0048 , Accuracy : 97.50%\n",
      "Epoch [1087/1200], Loss: 0.0011 , Accuracy : 95.00%\n",
      "Epoch [1088/1200], Loss: 0.0090 , Accuracy : 95.00%\n",
      "Epoch [1089/1200], Loss: 0.0012 , Accuracy : 97.50%\n",
      "Epoch [1090/1200], Loss: 0.0035 , Accuracy : 97.50%\n",
      "Epoch [1091/1200], Loss: 0.0060 , Accuracy : 97.50%\n",
      "Epoch [1092/1200], Loss: 0.0040 , Accuracy : 95.00%\n",
      "Epoch [1093/1200], Loss: 0.0126 , Accuracy : 95.00%\n",
      "Epoch [1094/1200], Loss: 0.0023 , Accuracy : 95.00%\n",
      "Epoch [1095/1200], Loss: 0.0353 , Accuracy : 95.00%\n",
      "Epoch [1096/1200], Loss: 0.0230 , Accuracy : 95.00%\n",
      "Epoch [1097/1200], Loss: 0.0567 , Accuracy : 97.50%\n",
      "Epoch [1098/1200], Loss: 0.0073 , Accuracy : 97.50%\n",
      "Epoch [1099/1200], Loss: 0.0078 , Accuracy : 95.00%\n",
      "Epoch [1100/1200], Loss: 0.1782 , Accuracy : 97.50%\n",
      "Epoch [1101/1200], Loss: 0.0074 , Accuracy : 95.00%\n",
      "Epoch [1102/1200], Loss: 0.0012 , Accuracy : 95.00%\n",
      "Epoch [1103/1200], Loss: 0.0026 , Accuracy : 95.00%\n",
      "Epoch [1104/1200], Loss: 0.0136 , Accuracy : 97.50%\n",
      "Epoch [1105/1200], Loss: 0.0097 , Accuracy : 97.50%\n",
      "Epoch [1106/1200], Loss: 0.0011 , Accuracy : 97.50%\n",
      "Epoch [1107/1200], Loss: 0.0068 , Accuracy : 97.50%\n",
      "Epoch [1108/1200], Loss: 0.0265 , Accuracy : 97.50%\n",
      "Epoch [1109/1200], Loss: 0.1798 , Accuracy : 95.00%\n",
      "Epoch [1110/1200], Loss: 2.4832 , Accuracy : 80.00%\n",
      "Epoch [1111/1200], Loss: 0.3802 , Accuracy : 90.00%\n",
      "Epoch [1112/1200], Loss: 0.1823 , Accuracy : 85.00%\n",
      "Epoch [1113/1200], Loss: 0.0002 , Accuracy : 80.00%\n",
      "Epoch [1114/1200], Loss: 0.0126 , Accuracy : 87.50%\n",
      "Epoch [1115/1200], Loss: 2.5955 , Accuracy : 82.50%\n",
      "Epoch [1116/1200], Loss: 0.1201 , Accuracy : 90.00%\n",
      "Epoch [1117/1200], Loss: 0.0991 , Accuracy : 95.00%\n",
      "Epoch [1118/1200], Loss: 0.0784 , Accuracy : 95.00%\n",
      "Epoch [1119/1200], Loss: 0.0096 , Accuracy : 95.00%\n",
      "Epoch [1120/1200], Loss: 0.0017 , Accuracy : 92.50%\n",
      "Epoch [1121/1200], Loss: 0.0097 , Accuracy : 97.50%\n",
      "Epoch [1122/1200], Loss: 0.0075 , Accuracy : 95.00%\n",
      "Epoch [1123/1200], Loss: 0.0063 , Accuracy : 97.50%\n",
      "Epoch [1124/1200], Loss: 0.0037 , Accuracy : 97.50%\n",
      "Epoch [1125/1200], Loss: 0.0061 , Accuracy : 97.50%\n",
      "Epoch [1126/1200], Loss: 0.0069 , Accuracy : 97.50%\n",
      "Epoch [1127/1200], Loss: 0.0021 , Accuracy : 95.00%\n",
      "Epoch [1128/1200], Loss: 0.0354 , Accuracy : 97.50%\n",
      "Epoch [1129/1200], Loss: 0.0165 , Accuracy : 97.50%\n",
      "Epoch [1130/1200], Loss: 0.0020 , Accuracy : 92.50%\n",
      "Epoch [1131/1200], Loss: 0.0171 , Accuracy : 97.50%\n",
      "Epoch [1132/1200], Loss: 0.0028 , Accuracy : 97.50%\n",
      "Epoch [1133/1200], Loss: 0.0066 , Accuracy : 97.50%\n",
      "Epoch [1134/1200], Loss: 0.2021 , Accuracy : 95.00%\n",
      "Epoch [1135/1200], Loss: 0.0106 , Accuracy : 97.50%\n",
      "Epoch [1136/1200], Loss: 0.0174 , Accuracy : 97.50%\n",
      "Epoch [1137/1200], Loss: 0.0026 , Accuracy : 97.50%\n",
      "Epoch [1138/1200], Loss: 0.0151 , Accuracy : 97.50%\n",
      "Epoch [1139/1200], Loss: 0.0022 , Accuracy : 97.50%\n",
      "Epoch [1140/1200], Loss: 0.0016 , Accuracy : 97.50%\n",
      "Epoch [1141/1200], Loss: 0.0089 , Accuracy : 97.50%\n",
      "Epoch [1142/1200], Loss: 0.0025 , Accuracy : 97.50%\n",
      "Epoch [1143/1200], Loss: 0.1988 , Accuracy : 97.50%\n",
      "Epoch [1144/1200], Loss: 0.2129 , Accuracy : 97.50%\n",
      "Epoch [1145/1200], Loss: 0.0022 , Accuracy : 97.50%\n",
      "Epoch [1146/1200], Loss: 0.0013 , Accuracy : 97.50%\n",
      "Epoch [1147/1200], Loss: 0.0033 , Accuracy : 97.50%\n",
      "Epoch [1148/1200], Loss: 0.0031 , Accuracy : 97.50%\n",
      "Epoch [1149/1200], Loss: 0.0036 , Accuracy : 95.00%\n",
      "Epoch [1150/1200], Loss: 0.1855 , Accuracy : 97.50%\n",
      "Epoch [1151/1200], Loss: 0.0075 , Accuracy : 95.00%\n",
      "Epoch [1152/1200], Loss: 0.1973 , Accuracy : 97.50%\n",
      "Epoch [1153/1200], Loss: 0.0005 , Accuracy : 95.00%\n",
      "Epoch [1154/1200], Loss: 0.0084 , Accuracy : 95.00%\n",
      "Epoch [1155/1200], Loss: 0.0005 , Accuracy : 95.00%\n",
      "Epoch [1156/1200], Loss: 0.0003 , Accuracy : 97.50%\n",
      "Epoch [1157/1200], Loss: 0.2154 , Accuracy : 95.00%\n",
      "Epoch [1158/1200], Loss: 0.0043 , Accuracy : 97.50%\n",
      "Epoch [1159/1200], Loss: 0.0166 , Accuracy : 97.50%\n",
      "Epoch [1160/1200], Loss: 0.3517 , Accuracy : 97.50%\n",
      "Epoch [1161/1200], Loss: 0.0128 , Accuracy : 95.00%\n",
      "Epoch [1162/1200], Loss: 0.0058 , Accuracy : 95.00%\n",
      "Epoch [1163/1200], Loss: 0.0173 , Accuracy : 97.50%\n",
      "Epoch [1164/1200], Loss: 0.0046 , Accuracy : 95.00%\n",
      "Epoch [1165/1200], Loss: 0.0028 , Accuracy : 97.50%\n",
      "Epoch [1166/1200], Loss: 0.2075 , Accuracy : 97.50%\n",
      "Epoch [1167/1200], Loss: 0.0053 , Accuracy : 97.50%\n",
      "Epoch [1168/1200], Loss: 0.0034 , Accuracy : 97.50%\n",
      "Epoch [1169/1200], Loss: 0.0083 , Accuracy : 97.50%\n",
      "Epoch [1170/1200], Loss: 0.0015 , Accuracy : 97.50%\n",
      "Epoch [1171/1200], Loss: 0.0057 , Accuracy : 95.00%\n",
      "Epoch [1172/1200], Loss: 0.2131 , Accuracy : 97.50%\n",
      "Epoch [1173/1200], Loss: 0.0070 , Accuracy : 95.00%\n",
      "Epoch [1174/1200], Loss: 0.0043 , Accuracy : 95.00%\n",
      "Epoch [1175/1200], Loss: 0.0209 , Accuracy : 95.00%\n",
      "Epoch [1176/1200], Loss: 0.0275 , Accuracy : 92.50%\n",
      "Epoch [1177/1200], Loss: 0.0784 , Accuracy : 92.50%\n",
      "Epoch [1178/1200], Loss: 0.4552 , Accuracy : 80.00%\n",
      "Epoch [1179/1200], Loss: 0.0133 , Accuracy : 85.00%\n",
      "Epoch [1180/1200], Loss: 0.7683 , Accuracy : 72.50%\n",
      "Epoch [1181/1200], Loss: 1.9088 , Accuracy : 67.50%\n",
      "Epoch [1182/1200], Loss: 6.0301 , Accuracy : 65.00%\n",
      "Epoch [1183/1200], Loss: 0.2209 , Accuracy : 67.50%\n",
      "Epoch [1184/1200], Loss: 4.7932 , Accuracy : 60.00%\n",
      "Epoch [1185/1200], Loss: 1.1210 , Accuracy : 67.50%\n",
      "Epoch [1186/1200], Loss: 0.8775 , Accuracy : 82.50%\n",
      "Epoch [1187/1200], Loss: 0.0834 , Accuracy : 95.00%\n",
      "Epoch [1188/1200], Loss: 0.2599 , Accuracy : 87.50%\n",
      "Epoch [1189/1200], Loss: 0.2104 , Accuracy : 95.00%\n",
      "Epoch [1190/1200], Loss: 0.0071 , Accuracy : 95.00%\n",
      "Epoch [1191/1200], Loss: 0.0320 , Accuracy : 95.00%\n",
      "Epoch [1192/1200], Loss: 0.2210 , Accuracy : 95.00%\n",
      "Epoch [1193/1200], Loss: 0.0090 , Accuracy : 95.00%\n",
      "Epoch [1194/1200], Loss: 0.0876 , Accuracy : 95.00%\n",
      "Epoch [1195/1200], Loss: 0.0337 , Accuracy : 97.50%\n",
      "Epoch [1196/1200], Loss: 0.0092 , Accuracy : 95.00%\n",
      "Epoch [1197/1200], Loss: 0.0485 , Accuracy : 97.50%\n",
      "Epoch [1198/1200], Loss: 0.0219 , Accuracy : 95.00%\n",
      "Epoch [1199/1200], Loss: 0.2380 , Accuracy : 97.50%\n",
      "Epoch [1200/1200], Loss: 0.0045 , Accuracy : 97.50%\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "# References : https://saturncloud.io/blog/calculating-the-accuracy-of-pytorch-models-every-epoch/#:~:text=In%20order%20to%20calculate%20the,tensor%20along%20a%20specified%20dimension\n",
    "num_epochs = 1200\n",
    "loss_logger = []\n",
    "accuracy_logger = []\n",
    "# n_epochs = []\n",
    "for epoch in range(num_epochs):\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    model.train()\n",
    "    for i, (sequences, labels) in enumerate(data_loader):\n",
    "        # Move data to the device\n",
    "        # labels = labels.type(torch.LongTensor)   # casting to long\n",
    "        sequences = sequences.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(sequences)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        total_correct += (predicted == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # loss_logger.append(loss.item())\n",
    "    loss_logger.append(loss.item())\n",
    "    accuracy = 100 * total_correct /total_samples\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f} , Accuracy : {accuracy:.2f}%')\n",
    "    accuracy_logger.append(accuracy)\n",
    "    # n_epochs.append(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2073,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.8273825645446777,\n",
       " 3.7083983421325684,\n",
       " 3.800642728805542,\n",
       " 3.995840072631836,\n",
       " 4.1443657875061035,\n",
       " 3.4214909076690674,\n",
       " 3.129099130630493,\n",
       " 3.971860885620117,\n",
       " 3.5612785816192627,\n",
       " 3.401299476623535,\n",
       " 3.1112802028656006,\n",
       " 3.5069472789764404,\n",
       " 3.6847753524780273,\n",
       " 4.032256126403809,\n",
       " 2.8784098625183105,\n",
       " 2.5825812816619873,\n",
       " 3.6186819076538086,\n",
       " 3.2915992736816406,\n",
       " 3.445080518722534,\n",
       " 3.1287965774536133,\n",
       " 2.888828754425049,\n",
       " 3.4949917793273926,\n",
       " 3.4775853157043457,\n",
       " 3.981126308441162,\n",
       " 3.493602991104126,\n",
       " 3.261467456817627,\n",
       " 3.430319309234619,\n",
       " 2.4418141841888428,\n",
       " 3.3298707008361816,\n",
       " 3.802168846130371,\n",
       " 3.059731960296631,\n",
       " 2.9032704830169678,\n",
       " 2.478595733642578,\n",
       " 3.002411127090454,\n",
       " 2.558986186981201,\n",
       " 2.9121012687683105,\n",
       " 2.461008071899414,\n",
       " 3.405729293823242,\n",
       " 3.5402793884277344,\n",
       " 2.8437588214874268,\n",
       " 3.5960419178009033,\n",
       " 2.9565932750701904,\n",
       " 3.354661464691162,\n",
       " 2.8062002658843994,\n",
       " 2.835690498352051,\n",
       " 3.319319725036621,\n",
       " 2.7129437923431396,\n",
       " 2.171107769012451,\n",
       " 2.6509592533111572,\n",
       " 2.8252432346343994,\n",
       " 3.3787271976470947,\n",
       " 2.617863655090332,\n",
       " 1.9136948585510254,\n",
       " 2.819880962371826,\n",
       " 3.6961798667907715,\n",
       " 2.751906394958496,\n",
       " 3.9399118423461914,\n",
       " 3.629598379135132,\n",
       " 2.7846269607543945,\n",
       " 3.4657881259918213,\n",
       " 3.0476279258728027,\n",
       " 4.986703872680664,\n",
       " 2.326127529144287,\n",
       " 2.670403480529785,\n",
       " 3.115839719772339,\n",
       " 2.8230090141296387,\n",
       " 2.870394229888916,\n",
       " 2.1553077697753906,\n",
       " 3.236936569213867,\n",
       " 3.0509157180786133,\n",
       " 2.6084117889404297,\n",
       " 2.6726813316345215,\n",
       " 2.655449628829956,\n",
       " 2.433213233947754,\n",
       " 3.7945406436920166,\n",
       " 2.6401445865631104,\n",
       " 3.9984500408172607,\n",
       " 2.7792646884918213,\n",
       " 2.9775893688201904,\n",
       " 2.8689537048339844,\n",
       " 1.7924001216888428,\n",
       " 3.3099780082702637,\n",
       " 3.220180034637451,\n",
       " 2.5579946041107178,\n",
       " 2.849247694015503,\n",
       " 2.9567301273345947,\n",
       " 2.7922592163085938,\n",
       " 2.3025803565979004,\n",
       " 2.4818148612976074,\n",
       " 3.131500720977783,\n",
       " 3.410094738006592,\n",
       " 2.441584348678589,\n",
       " 3.058103561401367,\n",
       " 1.935807704925537,\n",
       " 2.165724754333496,\n",
       " 2.1050262451171875,\n",
       " 1.7021911144256592,\n",
       " 2.4646708965301514,\n",
       " 2.7912371158599854,\n",
       " 1.6937681436538696,\n",
       " 1.7505841255187988,\n",
       " 7.850563049316406,\n",
       " 3.7931575775146484,\n",
       " 2.6477959156036377,\n",
       " 3.9424335956573486,\n",
       " 2.381789207458496,\n",
       " 3.1261403560638428,\n",
       " 2.350905418395996,\n",
       " 2.300992965698242,\n",
       " 3.7180607318878174,\n",
       " 3.5694098472595215,\n",
       " 2.3414456844329834,\n",
       " 1.7211651802062988,\n",
       " 1.2892742156982422,\n",
       " 2.5969245433807373,\n",
       " 1.4501252174377441,\n",
       " 2.1787209510803223,\n",
       " 2.200150966644287,\n",
       " 2.03330659866333,\n",
       " 1.823376178741455,\n",
       " 2.541867733001709,\n",
       " 1.930908441543579,\n",
       " 1.2025988101959229,\n",
       " 1.7540602684020996,\n",
       " 1.8008151054382324,\n",
       " 1.893649935722351,\n",
       " 1.9971575736999512,\n",
       " 2.0709621906280518,\n",
       " 2.813966751098633,\n",
       " 2.0960047245025635,\n",
       " 2.0791008472442627,\n",
       " 2.7389960289001465,\n",
       " 2.708142042160034,\n",
       " 1.3345997333526611,\n",
       " 1.5131994485855103,\n",
       " 2.43196964263916,\n",
       " 1.5191562175750732,\n",
       " 2.5276827812194824,\n",
       " 1.6730005741119385,\n",
       " 1.0173594951629639,\n",
       " 2.0155584812164307,\n",
       " 1.8817157745361328,\n",
       " 1.560410737991333,\n",
       " 1.4737672805786133,\n",
       " 1.1539530754089355,\n",
       " 1.5454463958740234,\n",
       " 2.1166107654571533,\n",
       " 2.4650330543518066,\n",
       " 1.6585075855255127,\n",
       " 2.202780246734619,\n",
       " 2.3281843662261963,\n",
       " 1.206088662147522,\n",
       " 1.7040961980819702,\n",
       " 1.5551661252975464,\n",
       " 2.711855411529541,\n",
       " 0.9265044927597046,\n",
       " 4.910192966461182,\n",
       " 2.8983805179595947,\n",
       " 1.7205305099487305,\n",
       " 1.5894142389297485,\n",
       " 2.9693586826324463,\n",
       " 2.4390804767608643,\n",
       " 1.692172884941101,\n",
       " 2.1337976455688477,\n",
       " 1.613244891166687,\n",
       " 3.2197468280792236,\n",
       " 2.5128531455993652,\n",
       " 1.6988939046859741,\n",
       " 1.5454444885253906,\n",
       " 1.458838701248169,\n",
       " 1.1560630798339844,\n",
       " 2.9716668128967285,\n",
       " 0.7204082608222961,\n",
       " 2.553010940551758,\n",
       " 0.858967125415802,\n",
       " 0.8796613812446594,\n",
       " 1.498122215270996,\n",
       " 0.9934697151184082,\n",
       " 1.185231328010559,\n",
       " 1.4458844661712646,\n",
       " 1.6289052963256836,\n",
       " 0.9476227164268494,\n",
       " 0.6503375768661499,\n",
       " 1.6899052858352661,\n",
       " 1.983855128288269,\n",
       " 1.2656668424606323,\n",
       " 2.146495819091797,\n",
       " 2.2265703678131104,\n",
       " 1.801647424697876,\n",
       " 1.3381083011627197,\n",
       " 1.3420571088790894,\n",
       " 1.08092200756073,\n",
       " 1.7742750644683838,\n",
       " 1.1843876838684082,\n",
       " 1.3187830448150635,\n",
       " 1.934696912765503,\n",
       " 2.853663444519043,\n",
       " 3.4565954208374023,\n",
       " 1.1598291397094727,\n",
       " 1.2868340015411377,\n",
       " 2.135310173034668,\n",
       " 0.6209049820899963,\n",
       " 2.657534599304199,\n",
       " 0.9361936450004578,\n",
       " 1.081068992614746,\n",
       " 1.2720898389816284,\n",
       " 3.0082006454467773,\n",
       " 1.9841229915618896,\n",
       " 1.038240671157837,\n",
       " 0.7470628023147583,\n",
       " 1.200810432434082,\n",
       " 0.552462100982666,\n",
       " 2.74247407913208,\n",
       " 0.9063084125518799,\n",
       " 1.1757532358169556,\n",
       " 1.2099758386611938,\n",
       " 1.7364132404327393,\n",
       " 0.8464080095291138,\n",
       " 1.6279624700546265,\n",
       " 1.679455041885376,\n",
       " 1.4570951461791992,\n",
       " 0.479099303483963,\n",
       " 2.2436106204986572,\n",
       " 1.1044342517852783,\n",
       " 0.8628081679344177,\n",
       " 1.4459155797958374,\n",
       " 0.7767252922058105,\n",
       " 1.8484041690826416,\n",
       " 1.7008914947509766,\n",
       " 3.304159164428711,\n",
       " 0.7710232734680176,\n",
       " 1.4257783889770508,\n",
       " 2.1603691577911377,\n",
       " 1.645538568496704,\n",
       " 0.6670919060707092,\n",
       " 0.39708152413368225,\n",
       " 1.9643222093582153,\n",
       " 0.8713085651397705,\n",
       " 1.5745353698730469,\n",
       " 0.4667949676513672,\n",
       " 0.7193688750267029,\n",
       " 0.4990118145942688,\n",
       " 1.369215726852417,\n",
       " 0.924315333366394,\n",
       " 1.4871426820755005,\n",
       " 0.9388918876647949,\n",
       " 1.1520066261291504,\n",
       " 0.44336867332458496,\n",
       " 1.8880316019058228,\n",
       " 1.1269069910049438,\n",
       " 0.9392533898353577,\n",
       " 0.50876384973526,\n",
       " 1.6543731689453125,\n",
       " 0.6230537295341492,\n",
       " 1.8953362703323364,\n",
       " 0.8815351724624634,\n",
       " 1.254815936088562,\n",
       " 1.370374083518982,\n",
       " 0.8748002052307129,\n",
       " 1.8169981241226196,\n",
       " 0.45728832483291626,\n",
       " 0.8054862022399902,\n",
       " 1.1749300956726074,\n",
       " 2.043198823928833,\n",
       " 0.9831770658493042,\n",
       " 0.6072046160697937,\n",
       " 1.3708746433258057,\n",
       " 1.3527864217758179,\n",
       " 0.3870534896850586,\n",
       " 0.28091341257095337,\n",
       " 1.0717650651931763,\n",
       " 0.7202228903770447,\n",
       " 0.6705507636070251,\n",
       " 1.5931613445281982,\n",
       " 1.3460310697555542,\n",
       " 0.8872263431549072,\n",
       " 1.5732474327087402,\n",
       " 1.3014146089553833,\n",
       " 1.0954368114471436,\n",
       " 1.6672377586364746,\n",
       " 0.7118748426437378,\n",
       " 4.059893608093262,\n",
       " 1.4477715492248535,\n",
       " 1.6787889003753662,\n",
       " 0.6823896169662476,\n",
       " 1.1438710689544678,\n",
       " 0.8866719603538513,\n",
       " 1.9549609422683716,\n",
       " 1.1004279851913452,\n",
       " 1.1859008073806763,\n",
       " 0.6445584893226624,\n",
       " 2.262226104736328,\n",
       " 1.3187448978424072,\n",
       " 2.328157663345337,\n",
       " 0.6189436316490173,\n",
       " 0.34680137038230896,\n",
       " 2.0920512676239014,\n",
       " 0.91485595703125,\n",
       " 1.8237016201019287,\n",
       " 0.27294036746025085,\n",
       " 0.9355344772338867,\n",
       " 1.1120636463165283,\n",
       " 0.8068842887878418,\n",
       " 1.375885009765625,\n",
       " 0.7238568663597107,\n",
       " 1.4288384914398193,\n",
       " 0.319642573595047,\n",
       " 0.4353818893432617,\n",
       " 2.09358549118042,\n",
       " 1.4111233949661255,\n",
       " 0.27441278100013733,\n",
       " 0.883522629737854,\n",
       " 1.31862211227417,\n",
       " 0.8537222146987915,\n",
       " 1.1141139268875122,\n",
       " 1.5937556028366089,\n",
       " 1.428655743598938,\n",
       " 1.3893976211547852,\n",
       " 1.9994425773620605,\n",
       " 0.961410641670227,\n",
       " 0.8805351853370667,\n",
       " 0.8074814081192017,\n",
       " 2.1393439769744873,\n",
       " 2.0638086795806885,\n",
       " 0.5793998837471008,\n",
       " 0.5424544811248779,\n",
       " 0.3127650022506714,\n",
       " 1.0119659900665283,\n",
       " 0.1961653083562851,\n",
       " 1.7289910316467285,\n",
       " 1.3197113275527954,\n",
       " 0.4458872079849243,\n",
       " 1.5105524063110352,\n",
       " 0.9430918097496033,\n",
       " 0.9514616131782532,\n",
       " 1.0502958297729492,\n",
       " 1.0311120748519897,\n",
       " 1.058980941772461,\n",
       " 0.6710036993026733,\n",
       " 1.346571683883667,\n",
       " 2.1329727172851562,\n",
       " 2.2891080379486084,\n",
       " 0.7022251486778259,\n",
       " 0.5770660638809204,\n",
       " 1.477674961090088,\n",
       " 1.5290827751159668,\n",
       " 0.43269187211990356,\n",
       " 0.8180650472640991,\n",
       " 0.5611671805381775,\n",
       " 0.8671241998672485,\n",
       " 0.38389280438423157,\n",
       " 0.44974157214164734,\n",
       " 1.0979069471359253,\n",
       " 0.5360381603240967,\n",
       " 1.30928635597229,\n",
       " 0.3186454474925995,\n",
       " 2.381743907928467,\n",
       " 1.7054855823516846,\n",
       " 0.06032472103834152,\n",
       " 1.8681284189224243,\n",
       " 0.8509035110473633,\n",
       " 0.7155749797821045,\n",
       " 1.35991370677948,\n",
       " 1.2778884172439575,\n",
       " 1.1745492219924927,\n",
       " 0.7247568964958191,\n",
       " 0.785561203956604,\n",
       " 0.3230360150337219,\n",
       " 0.8627153635025024,\n",
       " 0.8041701316833496,\n",
       " 1.371675968170166,\n",
       " 2.0947587490081787,\n",
       " 1.438988208770752,\n",
       " 0.023160602897405624,\n",
       " 0.6088389158248901,\n",
       " 0.338844895362854,\n",
       " 0.4496195316314697,\n",
       " 0.8778417706489563,\n",
       " 1.2648621797561646,\n",
       " 0.6583527326583862,\n",
       " 0.29149898886680603,\n",
       " 1.2007172107696533,\n",
       " 0.6455662846565247,\n",
       " 0.4153316020965576,\n",
       " 0.8320142030715942,\n",
       " 0.6100074648857117,\n",
       " 0.37848517298698425,\n",
       " 0.5171016454696655,\n",
       " 0.827508807182312,\n",
       " 0.5075101852416992,\n",
       " 0.6715347170829773,\n",
       " 0.47795620560646057,\n",
       " 0.44348636269569397,\n",
       " 0.6633594036102295,\n",
       " 1.024340271949768,\n",
       " 0.17613182961940765,\n",
       " 0.3036437928676605,\n",
       " 0.5511474609375,\n",
       " 0.5118000507354736,\n",
       " 0.7658923864364624,\n",
       " 0.4778233766555786,\n",
       " 1.0516782999038696,\n",
       " 1.1370759010314941,\n",
       " 0.6579322814941406,\n",
       " 0.7397655844688416,\n",
       " 0.7329356670379639,\n",
       " 1.04800546169281,\n",
       " 1.2792651653289795,\n",
       " 1.5318752527236938,\n",
       " 0.39253872632980347,\n",
       " 0.5551937222480774,\n",
       " 0.5703067779541016,\n",
       " 1.5567710399627686,\n",
       " 0.5030232071876526,\n",
       " 0.12296290695667267,\n",
       " 0.40767887234687805,\n",
       " 1.2338590621948242,\n",
       " 0.5491718053817749,\n",
       " 0.18934659659862518,\n",
       " 0.021826766431331635,\n",
       " 0.6306184530258179,\n",
       " 0.010642657056450844,\n",
       " 0.3733363151550293,\n",
       " 0.44149041175842285,\n",
       " 1.3255841732025146,\n",
       " 0.31913894414901733,\n",
       " 0.5002378225326538,\n",
       " 1.3384697437286377,\n",
       " 1.349578857421875,\n",
       " 0.07950317114591599,\n",
       " 0.19887420535087585,\n",
       " 0.3404744267463684,\n",
       " 0.7161502242088318,\n",
       " 0.7089703679084778,\n",
       " 0.2515051066875458,\n",
       " 0.3789178729057312,\n",
       " 0.09875752031803131,\n",
       " 1.3520784378051758,\n",
       " 0.13743562996387482,\n",
       " 0.30201777815818787,\n",
       " 0.4368664026260376,\n",
       " 0.27246326208114624,\n",
       " 0.7545531988143921,\n",
       " 0.32345548272132874,\n",
       " 0.5817440748214722,\n",
       " 0.1317499428987503,\n",
       " 0.34254002571105957,\n",
       " 1.2960641384124756,\n",
       " 0.9912235140800476,\n",
       " 0.8715918064117432,\n",
       " 0.0454849936068058,\n",
       " 0.35693424940109253,\n",
       " 0.5666945576667786,\n",
       " 1.309517741203308,\n",
       " 1.0106849670410156,\n",
       " 0.36500269174575806,\n",
       " 0.6814125180244446,\n",
       " 0.3475860059261322,\n",
       " 0.7901890277862549,\n",
       " 0.41448861360549927,\n",
       " 0.16612178087234497,\n",
       " 0.4955228269100189,\n",
       " 0.8876270055770874,\n",
       " 0.9529778957366943,\n",
       " 0.34697437286376953,\n",
       " 0.8182560205459595,\n",
       " 0.5731421113014221,\n",
       " 0.32700076699256897,\n",
       " 0.5611063838005066,\n",
       " 0.5656356811523438,\n",
       " 0.3464282155036926,\n",
       " 0.4316067397594452,\n",
       " 0.0417708195745945,\n",
       " 0.5075790882110596,\n",
       " 0.09826833754777908,\n",
       " 0.15696102380752563,\n",
       " 0.21182584762573242,\n",
       " 0.2255222201347351,\n",
       " 0.6281196475028992,\n",
       " 0.20334991812705994,\n",
       " 1.851214051246643,\n",
       " 0.8138608932495117,\n",
       " 0.34108906984329224,\n",
       " 1.6456353664398193,\n",
       " 0.20453065633773804,\n",
       " 0.32225164771080017,\n",
       " 0.030449744313955307,\n",
       " 0.2008112668991089,\n",
       " 1.5261151790618896,\n",
       " 0.46718138456344604,\n",
       " 0.5145884156227112,\n",
       " 0.004504487384110689,\n",
       " 0.2218247503042221,\n",
       " 0.27822935581207275,\n",
       " 0.006867865100502968,\n",
       " 0.246532142162323,\n",
       " 0.5746844410896301,\n",
       " 1.3433701992034912,\n",
       " 1.0372283458709717,\n",
       " 0.37672173976898193,\n",
       " 0.03010343201458454,\n",
       " 0.5240488052368164,\n",
       " 0.24152663350105286,\n",
       " 0.3279287815093994,\n",
       " 0.07926978915929794,\n",
       " 0.14083291590213776,\n",
       " 0.6821168661117554,\n",
       " 0.2614571750164032,\n",
       " 0.7047179341316223,\n",
       " 0.9877396821975708,\n",
       " 0.2465684711933136,\n",
       " 0.14367231726646423,\n",
       " 0.42737793922424316,\n",
       " 0.43876004219055176,\n",
       " 0.30715474486351013,\n",
       " 0.9281585216522217,\n",
       " 0.25034573674201965,\n",
       " 0.612456202507019,\n",
       " 0.7128462195396423,\n",
       " 0.18202415108680725,\n",
       " 0.06549172103404999,\n",
       " 0.3350616991519928,\n",
       " 1.3899998664855957,\n",
       " 0.6127117872238159,\n",
       " 0.4580118656158447,\n",
       " 0.2808327078819275,\n",
       " 0.2535998821258545,\n",
       " 0.3422014117240906,\n",
       " 0.9516434669494629,\n",
       " 0.8254361152648926,\n",
       " 0.017632078379392624,\n",
       " 0.8064122200012207,\n",
       " 0.005689313169568777,\n",
       " 0.1472133994102478,\n",
       " 0.11852264404296875,\n",
       " 0.40250688791275024,\n",
       " 0.3468049168586731,\n",
       " 0.31337523460388184,\n",
       " 0.13101506233215332,\n",
       " 0.0021995557472109795,\n",
       " 0.03188726305961609,\n",
       " 0.8194214105606079,\n",
       " 0.7557624578475952,\n",
       " 0.09858633577823639,\n",
       " 0.9320612549781799,\n",
       " 0.6903653144836426,\n",
       " 0.22008828818798065,\n",
       " 0.29904431104660034,\n",
       " 0.14288902282714844,\n",
       " 0.007175516802817583,\n",
       " 0.22961540520191193,\n",
       " 0.242669939994812,\n",
       " 0.01421851385384798,\n",
       " 0.1997227668762207,\n",
       " 0.02302207425236702,\n",
       " 0.056949682533741,\n",
       " 0.7446275353431702,\n",
       " 0.037347324192523956,\n",
       " 0.3718433976173401,\n",
       " 0.08815176784992218,\n",
       " 0.8120466470718384,\n",
       " 0.3877115547657013,\n",
       " 0.21293041110038757,\n",
       " 0.24282823503017426,\n",
       " 0.2337067574262619,\n",
       " 0.5744751691818237,\n",
       " 0.02152312733232975,\n",
       " 0.2697288990020752,\n",
       " 0.1262422800064087,\n",
       " 0.25266033411026,\n",
       " 0.28132158517837524,\n",
       " 0.5888106226921082,\n",
       " 0.613189697265625,\n",
       " 0.34247440099716187,\n",
       " 1.223634958267212,\n",
       " 0.16489842534065247,\n",
       " 0.0038759075105190277,\n",
       " 0.08952540159225464,\n",
       " 0.033479318022727966,\n",
       " 0.0573008731007576,\n",
       " 0.08495987951755524,\n",
       " 0.7075767517089844,\n",
       " 4.108724117279053,\n",
       " 0.5586533546447754,\n",
       " 4.081427574157715,\n",
       " 0.28545114398002625,\n",
       " 2.5692124366760254,\n",
       " 2.05938458442688,\n",
       " 0.6538724303245544,\n",
       " 1.3283743858337402,\n",
       " 0.9791077375411987,\n",
       " 0.19459331035614014,\n",
       " 0.18048708140850067,\n",
       " 0.44205692410469055,\n",
       " 0.057303376495838165,\n",
       " 0.3021791875362396,\n",
       " 0.1891247183084488,\n",
       " 0.2502824068069458,\n",
       " 0.7577317953109741,\n",
       " 1.390982985496521,\n",
       " 0.04818137735128403,\n",
       " 0.6412090063095093,\n",
       " 0.2955899238586426,\n",
       " 0.07486997544765472,\n",
       " 0.051900725811719894,\n",
       " 0.3612419664859772,\n",
       " 0.11407393217086792,\n",
       " 0.23227296769618988,\n",
       " 0.5737934708595276,\n",
       " 0.26958411931991577,\n",
       " 0.21406979858875275,\n",
       " 0.12410412728786469,\n",
       " 0.01679694466292858,\n",
       " 0.04664609581232071,\n",
       " 0.8371222019195557,\n",
       " 0.008568402379751205,\n",
       " 0.14922937750816345,\n",
       " 0.07888241112232208,\n",
       " 0.16659829020500183,\n",
       " 0.23088416457176208,\n",
       " 0.854949951171875,\n",
       " 0.04786033183336258,\n",
       " 0.5916357636451721,\n",
       " 0.3279857635498047,\n",
       " 0.043185509741306305,\n",
       " 0.0112126050516963,\n",
       " 0.05770277604460716,\n",
       " 0.00795065425336361,\n",
       " 0.009360160678625107,\n",
       " 0.045378427952528,\n",
       " 0.05802610516548157,\n",
       " 0.4701991677284241,\n",
       " 0.006498424336314201,\n",
       " 0.252564936876297,\n",
       " 0.010796939954161644,\n",
       " 0.16171687841415405,\n",
       " 0.5345085859298706,\n",
       " 0.04284164682030678,\n",
       " 0.015894722193479538,\n",
       " 0.1807342916727066,\n",
       " 0.4266180396080017,\n",
       " 0.5078685283660889,\n",
       " 0.36369308829307556,\n",
       " 0.25393930077552795,\n",
       " 0.06375338137149811,\n",
       " 0.10514377057552338,\n",
       " 0.41183972358703613,\n",
       " 0.08365308493375778,\n",
       " 0.021155670285224915,\n",
       " 0.013253758661448956,\n",
       " 0.2698785364627838,\n",
       " 0.2892225384712219,\n",
       " 0.31358930468559265,\n",
       " 0.012992550618946552,\n",
       " 0.006411802489310503,\n",
       " 0.27875879406929016,\n",
       " 0.06083960831165314,\n",
       " 0.15998999774456024,\n",
       " 0.007170926779508591,\n",
       " 0.22227156162261963,\n",
       " 0.2945539951324463,\n",
       " 0.008997873403131962,\n",
       " 0.00356936058960855,\n",
       " 0.040765512734651566,\n",
       " 0.21099193394184113,\n",
       " 0.010004384443163872,\n",
       " 0.00977630540728569,\n",
       " 0.2664446532726288,\n",
       " 0.005411425605416298,\n",
       " 0.1819133460521698,\n",
       " 0.005507073365151882,\n",
       " 0.012248791754245758,\n",
       " 0.005831069778650999,\n",
       " 0.04139213263988495,\n",
       " 0.0023986981250345707,\n",
       " 0.23153547942638397,\n",
       " 0.006190953776240349,\n",
       " 2.1071722507476807,\n",
       " 1.0018973350524902,\n",
       " 0.21170233190059662,\n",
       " 0.7191686630249023,\n",
       " 0.3075315058231354,\n",
       " 0.21555115282535553,\n",
       " 0.26181429624557495,\n",
       " 0.02114260569214821,\n",
       " 0.8288069367408752,\n",
       " 0.2940043807029724,\n",
       " 2.307734489440918,\n",
       " 0.332067608833313,\n",
       " 0.14812278747558594,\n",
       " 0.5252774357795715,\n",
       " 0.30115950107574463,\n",
       " 0.1795339435338974,\n",
       " 0.47558146715164185,\n",
       " 0.6760814785957336,\n",
       " 2.6535589694976807,\n",
       " 0.0598459467291832,\n",
       " 0.009061342105269432,\n",
       " 0.008173997513949871,\n",
       " 0.39320385456085205,\n",
       " 0.38382893800735474,\n",
       " 0.34335461258888245,\n",
       " 0.5629779100418091,\n",
       " 0.1569196581840515,\n",
       " 0.24474617838859558,\n",
       " 1.0531325340270996,\n",
       " 0.33796626329421997,\n",
       " 1.0515801906585693,\n",
       " 0.6557247638702393,\n",
       " 0.15137113630771637,\n",
       " 0.7382398247718811,\n",
       " 0.006300545297563076,\n",
       " 0.01741687022149563,\n",
       " 0.27214351296424866,\n",
       " 0.04901791363954544,\n",
       " 0.23104077577590942,\n",
       " 0.27705568075180054,\n",
       " 0.21552778780460358,\n",
       " 0.039248839020729065,\n",
       " 0.49038657546043396,\n",
       " 0.4389151334762573,\n",
       " 0.7348426580429077,\n",
       " 0.005649693310260773,\n",
       " 0.0060297418385744095,\n",
       " 0.013110345229506493,\n",
       " 0.06453798711299896,\n",
       " 0.0010961645748466253,\n",
       " 0.011733532883226871,\n",
       " 0.1467873603105545,\n",
       " 0.2628597617149353,\n",
       " 0.014450844377279282,\n",
       " 0.01637043058872223,\n",
       " 0.6331620812416077,\n",
       " 0.012475804425776005,\n",
       " 0.38404375314712524,\n",
       " 0.9514333009719849,\n",
       " 0.3491072356700897,\n",
       " 0.1991787850856781,\n",
       " 0.5099981427192688,\n",
       " 0.0052176653407514095,\n",
       " 0.017525603994727135,\n",
       " 0.93966144323349,\n",
       " 0.18657974898815155,\n",
       " 0.6414470672607422,\n",
       " 1.2168853282928467,\n",
       " 1.0202285051345825,\n",
       " 0.2021903246641159,\n",
       " 0.016674594953656197,\n",
       " 0.10370883345603943,\n",
       " 0.36009925603866577,\n",
       " 0.9077942371368408,\n",
       " 0.04038102552294731,\n",
       " 0.02371850237250328,\n",
       " 0.1540742665529251,\n",
       " 0.014228611253201962,\n",
       " 0.3759140074253082,\n",
       " 0.024123016744852066,\n",
       " 0.04123159870505333,\n",
       " 0.33538293838500977,\n",
       " 0.3114077150821686,\n",
       " 0.008671405725181103,\n",
       " 0.2620360553264618,\n",
       " 0.7038681507110596,\n",
       " 0.004105845466256142,\n",
       " 0.11767803877592087,\n",
       " 0.013727035373449326,\n",
       " 0.013356035575270653,\n",
       " 0.008729974739253521,\n",
       " 0.00875033438205719,\n",
       " 0.22303014993667603,\n",
       " 0.0077949813567101955,\n",
       " 0.03288273140788078,\n",
       " 0.03492453694343567,\n",
       " 0.4414723515510559,\n",
       " 0.026427829638123512,\n",
       " 0.0028533493168652058,\n",
       " 0.0033988384529948235,\n",
       " 0.9682324528694153,\n",
       " 0.35744509100914,\n",
       " 0.007479421328753233,\n",
       " 0.008780124597251415,\n",
       " 0.29117101430892944,\n",
       " 0.44220244884490967,\n",
       " 0.004570059012621641,\n",
       " 0.07099531590938568,\n",
       " 0.033574070781469345,\n",
       " 0.0746985450387001,\n",
       " 0.024413317441940308,\n",
       " 0.017988352105021477,\n",
       " 0.07274117320775986,\n",
       " 0.01912948302924633,\n",
       " 0.32187598943710327,\n",
       " 0.21789805591106415,\n",
       " 0.008302303962409496,\n",
       " 0.18134474754333496,\n",
       " 0.007239638827741146,\n",
       " 0.21040129661560059,\n",
       " 0.005021031480282545,\n",
       " 0.5002360939979553,\n",
       " 0.015036637894809246,\n",
       " 0.08542443066835403,\n",
       " 0.00455616507679224,\n",
       " 0.20604293048381805,\n",
       " 0.0012433230876922607,\n",
       " 0.0040102750062942505,\n",
       " 0.006868790369480848,\n",
       " 0.011879464611411095,\n",
       " 0.2795233130455017,\n",
       " 0.0011486037401482463,\n",
       " 0.023997122421860695,\n",
       " 0.005058759823441505,\n",
       " 0.0016456645680591464,\n",
       " 0.03505564481019974,\n",
       " 0.0008148802444338799,\n",
       " 0.05823973938822746,\n",
       " 0.17577987909317017,\n",
       " 0.0013587337452918291,\n",
       " 0.06716699153184891,\n",
       " 0.33798748254776,\n",
       " 0.4519297480583191,\n",
       " 0.056848227977752686,\n",
       " 0.0011621966259554029,\n",
       " 0.0017296490259468555,\n",
       " 0.04505603387951851,\n",
       " 0.36094242334365845,\n",
       " 0.35023191571235657,\n",
       " 0.0009350732434540987,\n",
       " 0.35145139694213867,\n",
       " 0.0009117663139477372,\n",
       " 0.0010812547989189625,\n",
       " 0.2963414490222931,\n",
       " 0.07187163829803467,\n",
       " 0.02808757685124874,\n",
       " 0.00572671415284276,\n",
       " 0.31173741817474365,\n",
       " 0.19281406700611115,\n",
       " 0.014986966736614704,\n",
       " 0.013517570681869984,\n",
       " 0.003267283085733652,\n",
       " 0.009478604421019554,\n",
       " 0.0009659689385443926,\n",
       " 0.001103013171814382,\n",
       " 0.0025233400519937277,\n",
       " 0.1958562284708023,\n",
       " 0.01488527376204729,\n",
       " 0.34832435846328735,\n",
       " 0.05423206090927124,\n",
       " 0.15890561044216156,\n",
       " 0.2346363663673401,\n",
       " 0.03998152166604996,\n",
       " 0.00848353374749422,\n",
       " 0.012540709227323532,\n",
       " 0.028167877346277237,\n",
       " 0.23016460239887238,\n",
       " 0.009903311729431152,\n",
       " 0.40626946091651917,\n",
       " 0.0698651596903801,\n",
       " 0.101212278008461,\n",
       " 0.13962501287460327,\n",
       " 0.07590211927890778,\n",
       " 0.0023501941468566656,\n",
       " 0.00599023699760437,\n",
       " 0.11260879039764404,\n",
       " 0.020839255303144455,\n",
       " 0.19600076973438263,\n",
       " 0.35328996181488037,\n",
       " 0.01011289656162262,\n",
       " 0.02611873671412468,\n",
       " 0.0695461556315422,\n",
       " 0.3942973017692566,\n",
       " 0.05228148028254509,\n",
       " 0.0201276745647192,\n",
       " 0.0125432088971138,\n",
       " 0.014083086512982845,\n",
       " 0.014574478380382061,\n",
       " 0.232017382979393,\n",
       " 0.007481713313609362,\n",
       " 0.0062705641612410545,\n",
       " 0.0030836137011647224,\n",
       " 0.1779245287179947,\n",
       " 0.22151030600070953,\n",
       " 0.002483049873262644,\n",
       " 0.19563208520412445,\n",
       " 0.00914826337248087,\n",
       " 0.18549536168575287,\n",
       " 0.001662219874560833,\n",
       " 0.21709103882312775,\n",
       " 0.0025067676324397326,\n",
       " 0.020581848919391632,\n",
       " 0.010695050470530987,\n",
       " 0.19953979551792145,\n",
       " 0.06590554863214493,\n",
       " 0.19569861888885498,\n",
       " 0.0018878561677411199,\n",
       " 0.2074960619211197,\n",
       " 0.04890213906764984,\n",
       " 0.32709139585494995,\n",
       " 0.1734052300453186,\n",
       " 0.20582568645477295,\n",
       " 0.1832464188337326,\n",
       " 0.34432652592658997,\n",
       " 0.20748159289360046,\n",
       " 0.7282764911651611,\n",
       " 0.5535790920257568,\n",
       " 0.03870542347431183,\n",
       " 5.384726524353027,\n",
       " 0.37449371814727783,\n",
       " 0.24078640341758728,\n",
       " 0.27353695034980774,\n",
       " 1.3739677667617798,\n",
       " 0.02685249224305153,\n",
       " 0.22270165383815765,\n",
       " 0.18200194835662842,\n",
       " 0.10865636169910431,\n",
       " 0.032131265848875046,\n",
       " 0.12488868832588196,\n",
       " 0.44029897451400757,\n",
       " 0.24269890785217285,\n",
       " 0.05911025404930115,\n",
       " 0.003762055654078722,\n",
       " 0.19232875108718872,\n",
       " 0.0018934246618300676,\n",
       " 0.0418187715113163,\n",
       " 0.22757618129253387,\n",
       " 0.0023168649058789015,\n",
       " 0.0003837691911030561,\n",
       " 0.018524710088968277,\n",
       " 0.005537012591958046,\n",
       " 0.4114619493484497,\n",
       " 0.18554547429084778,\n",
       " 0.4974057078361511,\n",
       " 0.1891547292470932,\n",
       " 0.05124660208821297,\n",
       " 0.40283387899398804,\n",
       " 0.1918700486421585,\n",
       " 0.0072299279272556305,\n",
       " 0.0014106936287134886,\n",
       " 0.007618388626724482,\n",
       " 0.044630490243434906,\n",
       " 0.006376109551638365,\n",
       " 0.01725958101451397,\n",
       " 0.19778844714164734,\n",
       " 0.007887122221291065,\n",
       " 0.0011836475459858775,\n",
       " 0.027979183942079544,\n",
       " 0.208152636885643,\n",
       " 0.00815060455352068,\n",
       " 0.004339050967246294,\n",
       " 0.23878172039985657,\n",
       " 0.023681476712226868,\n",
       " 0.20548397302627563,\n",
       " 0.0010730683570727706,\n",
       " 0.013138527050614357,\n",
       " 0.062477823346853256,\n",
       " 0.017756035551428795,\n",
       " 0.0013139871880412102,\n",
       " 0.19889836013317108,\n",
       " 0.0029853021260350943,\n",
       " 0.004055624827742577,\n",
       " 0.013014069758355618,\n",
       " 0.21001091599464417,\n",
       " 0.005785798188298941,\n",
       " 0.20412616431713104,\n",
       " 0.005248625762760639,\n",
       " 0.0030748615972697735,\n",
       " 0.19957077503204346,\n",
       " 0.010410448536276817,\n",
       " 0.007043228019028902,\n",
       " 0.00031435766140930355,\n",
       " 0.001725002657622099,\n",
       " 0.19394265115261078,\n",
       " 0.015306549146771431,\n",
       " 0.016833709552884102,\n",
       " 0.0021594332065433264,\n",
       " 0.005000376608222723,\n",
       " 0.18634414672851562,\n",
       " 0.010800870135426521,\n",
       " 0.25397393107414246,\n",
       " 0.006724779028445482,\n",
       " 0.006806036923080683,\n",
       " 1.5205726623535156,\n",
       " 0.8931046724319458,\n",
       " 1.0890592336654663,\n",
       " 0.3859238028526306,\n",
       " 0.7395756244659424,\n",
       " 0.038899604231119156,\n",
       " 0.30910947918891907,\n",
       " 0.004056604579091072,\n",
       " 0.20249338448047638,\n",
       " 0.09517802298069,\n",
       " 0.5283300280570984,\n",
       " 0.003595166839659214,\n",
       " 0.0036940178833901882,\n",
       " 0.0006004181341268122,\n",
       " 0.0012820966076105833,\n",
       " 0.21254636347293854,\n",
       " 0.07410034537315369,\n",
       " 0.31618157029151917,\n",
       " 0.05999346822500229,\n",
       " 0.6933389902114868,\n",
       " ...]"
      ]
     },
     "execution_count": 2073,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.title(\"Loss Curve\")\n",
    "plt.plot(loss_logger, label='train_loss')\n",
    "# plt.plot(accuracy_logger,label='accuracy')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save and Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2075,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.5049,  0.2371, -1.2115,  ...,  0.5643,  0.2082,  0.0088],\n",
       "         [ 0.5045,  0.2381, -1.1896,  ...,  0.5643,  0.2081,  0.0085],\n",
       "         [ 0.5041,  0.2385, -1.1915,  ...,  0.5643,  0.2080,  0.0089],\n",
       "         ...,\n",
       "         [ 0.4963,  0.2307, -1.3096,  ...,  0.5624,  0.2043,  0.0127],\n",
       "         [ 0.4965,  0.2308, -1.3085,  ...,  0.5625,  0.2045,  0.0126],\n",
       "         [ 0.4972,  0.2312, -1.3053,  ...,  0.5633,  0.2045,  0.0128]],\n",
       "\n",
       "        [[ 0.5103,  0.2330, -1.4731,  ...,  0.5745,  0.2056,  0.0102],\n",
       "         [ 0.5071,  0.2360, -1.5453,  ...,  0.5731,  0.2055,  0.0103],\n",
       "         [ 0.5052,  0.2381, -1.5650,  ...,  0.5733,  0.2056,  0.0100],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.5122,  0.2456, -1.3706,  ...,  0.5836,  0.2207,  0.0125],\n",
       "         [ 0.5121,  0.2461, -1.4417,  ...,  0.5818,  0.2208,  0.0118],\n",
       "         [ 0.5121,  0.2465, -1.4591,  ...,  0.5815,  0.2204,  0.0118],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.5051,  0.2347, -1.4390,  ...,  0.5717,  0.2094,  0.0091],\n",
       "         [ 0.5024,  0.2389, -1.5627,  ...,  0.5707,  0.2087,  0.0090],\n",
       "         [ 0.5005,  0.2417, -1.5896,  ...,  0.5704,  0.2090,  0.0098],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 2075,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_sequence(sequences, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2076,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 19.3016, -11.7313,   8.0267,  ..., -16.0590,   8.6910,  11.2458],\n",
       "        [-10.1414,  16.0537,   2.3802,  ...,  12.0405,   0.9564, -13.0069],\n",
       "        [  3.2742,   1.6396,  16.0763,  ...,   0.9442, -13.1241,  -5.2576],\n",
       "        ...,\n",
       "        [-22.1028,  10.2167,  -7.1462,  ...,  19.4835,  -5.3908, -10.5055],\n",
       "        [ 12.7865,  -9.3807,  -1.0302,  ..., -15.0377,  23.3777,  13.0176],\n",
       "        [  0.7202, -14.1109,   0.1277,  ...,  -8.1715,   4.8056,  19.1611]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 2076,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Put the model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# No need to track gradients during inference\n",
    "with torch.no_grad():\n",
    "    # Get the model's output (logits)\n",
    "    outputs = model(padded_sequences.to(device))\n",
    "\n",
    "# outputs = torch.softmax(outputs, dim=1)\n",
    "# outputs = torch.max(outputs,1)\n",
    "\n",
    "outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2077,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.5013,  0.2452, -1.2167,  ...,  0.5663,  0.2188,  0.0098],\n",
       "         [ 0.4997,  0.2482, -1.4690,  ...,  0.5652,  0.2181,  0.0106],\n",
       "         [ 0.4984,  0.2500, -1.4853,  ...,  0.5654,  0.2185,  0.0112],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.4922,  0.2382, -1.2850,  ...,  0.5578,  0.2124,  0.0094],\n",
       "         [ 0.4920,  0.2405, -1.4288,  ...,  0.5571,  0.2116,  0.0099],\n",
       "         [ 0.4920,  0.2409, -1.4093,  ...,  0.5567,  0.2122,  0.0098],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.5049,  0.2371, -1.2115,  ...,  0.5643,  0.2082,  0.0088],\n",
       "         [ 0.5045,  0.2381, -1.1896,  ...,  0.5643,  0.2081,  0.0085],\n",
       "         [ 0.5041,  0.2385, -1.1915,  ...,  0.5643,  0.2080,  0.0089],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.4849,  0.2484, -1.3873,  ...,  0.5543,  0.2162,  0.0108],\n",
       "         [ 0.4846,  0.2500, -1.4881,  ...,  0.5539,  0.2157,  0.0111],\n",
       "         [ 0.4844,  0.2507, -1.4935,  ...,  0.5537,  0.2161,  0.0111],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.5199,  0.2290, -1.2810,  ...,  0.5876,  0.2058,  0.0103],\n",
       "         [ 0.5195,  0.2307, -1.3821,  ...,  0.5873,  0.2059,  0.0106],\n",
       "         [ 0.5193,  0.2327, -1.4100,  ...,  0.5877,  0.2059,  0.0109],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.5005,  0.2439, -1.3629,  ...,  0.5694,  0.2139,  0.0154],\n",
       "         [ 0.5002,  0.2448, -1.5049,  ...,  0.5688,  0.2128,  0.0146],\n",
       "         [ 0.4999,  0.2457, -1.5287,  ...,  0.5683,  0.2134,  0.0148],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]])"
      ]
     },
     "execution_count": 2077,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2174,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = [\"Data for different actions/เครียด.mp4/เครียด.npy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.5035,  0.2282, -1.1379,  ...,  0.5710,  0.1953,  0.0120],\n",
       "         [ 0.5033,  0.2284, -1.2771,  ...,  0.5713,  0.1954,  0.0123],\n",
       "         [ 0.5032,  0.2286, -1.2743,  ...,  0.5715,  0.1957,  0.0122],\n",
       "         ...,\n",
       "         [ 0.4810,  0.2296, -1.4129,  ...,  0.5542,  0.1897,  0.0133],\n",
       "         [ 0.4812,  0.2296, -1.4275,  ...,  0.5549,  0.1900,  0.0130],\n",
       "         [ 0.4816,  0.2299, -1.4337,  ...,  0.5557,  0.1903,  0.0133]]])"
      ]
     },
     "execution_count": 2175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the sequences\n",
    "import torch\n",
    "sequences = load_keypoint_sequences(file_paths)\n",
    "# Change list to numpy array \n",
    "sequences = np.array(sequences)\n",
    "# Change numpy array to tensor\n",
    "sequences = torch.FloatTensor(sequences)\n",
    "sequences = pad_sequence(sequences, batch_first=True)\n",
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -5.1466,   4.0204,  -1.4557,  -7.1868,  -6.1722,   8.8426, -18.9277,\n",
       "         -12.3658,  -4.3702, -11.2152, -15.0070,  10.3700,   9.1169, -13.6548,\n",
       "          -5.5266,  -4.3046,  22.2073,  -6.4832,   8.8697,  13.1637,  11.6898,\n",
       "          -6.7590, -20.8999, -21.4657,  16.2000,   5.0745, -15.5841,  11.5555,\n",
       "         -12.0262,  14.0015,  -4.0613,  -9.5173,  -3.4437,   2.3315,  -0.8544,\n",
       "           3.8168, -18.7799,   1.4940,   5.7776,   1.9881]], device='cuda:0',\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 2176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model(sequences.to(device))\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['กฎกระทรวง',\n",
       " 'กฎหมายรัฐธรรมนูญ',\n",
       " 'กรมอนามัย',\n",
       " 'กรรม',\n",
       " 'กรรมสิทธิ์',\n",
       " 'กระโดด',\n",
       " 'กล้วยบวชชี',\n",
       " 'กล้วยเชื่อม',\n",
       " 'กังวล',\n",
       " 'กีฬา',\n",
       " 'น้อง',\n",
       " 'เขิน',\n",
       " 'เขื่อนดิน',\n",
       " 'เขื่อนสิริกิติ์',\n",
       " 'เข้าใจผิด',\n",
       " 'เคย',\n",
       " 'เครียด',\n",
       " 'เครื่องปั่นดิน',\n",
       " 'เครื่องหมายการค้า',\n",
       " 'เจอ',\n",
       " 'เจ้าหนี้',\n",
       " 'เช่าซื้อ',\n",
       " 'เช่าทรัพย์',\n",
       " 'เซอร์เบีย',\n",
       " 'เซเนกัล',\n",
       " 'เซ็ง',\n",
       " 'เดิน',\n",
       " 'เดิมพัน',\n",
       " 'เพลีย',\n",
       " 'เมื่อย',\n",
       " 'เม็กซิโก',\n",
       " 'เฮโรอีน',\n",
       " 'แกมเบีย',\n",
       " 'แซมเบีย',\n",
       " 'โกหก',\n",
       " 'โจทก์',\n",
       " 'โชจู',\n",
       " 'ใกล้',\n",
       " 'ไดโนเสาร์',\n",
       " 'ไอซ์']"
      ]
     },
     "execution_count": 2177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [action.split(\".\")[0] for action in actions]\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change from tensor to numpy arrat\n",
    "outputs = outputs.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -5.146622 ,   4.020432 ,  -1.4557331,  -7.1867733,  -6.172166 ,\n",
       "          8.842602 , -18.927666 , -12.365821 ,  -4.3702393, -11.215222 ,\n",
       "        -15.007039 ,  10.370003 ,   9.116949 , -13.654799 ,  -5.5265737,\n",
       "         -4.3046174,  22.20729  ,  -6.483237 ,   8.869665 ,  13.16366  ,\n",
       "         11.689849 ,  -6.759024 , -20.899908 , -21.46572  ,  16.199951 ,\n",
       "          5.0744896, -15.584129 ,  11.5554905, -12.026156 ,  14.001523 ,\n",
       "         -4.0612717,  -9.517303 ,  -3.4436789,   2.3314533,  -0.8543768,\n",
       "          3.816834 , -18.779905 ,   1.4940379,   5.7775984,   1.9880894]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 2179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -5.146622    4.020432   -1.4557331  -7.1867733  -6.172166    8.842602\n",
      " -18.927666  -12.365821   -4.3702393 -11.215222  -15.007039   10.370003\n",
      "   9.116949  -13.654799   -5.5265737  -4.3046174  22.20729    -6.483237\n",
      "   8.869665   13.16366    11.689849   -6.759024  -20.899908  -21.46572\n",
      "  16.199951    5.0744896 -15.584129   11.5554905 -12.026156   14.001523\n",
      "  -4.0612717  -9.517303   -3.4436789   2.3314533  -0.8543768   3.816834\n",
      " -18.779905    1.4940379   5.7775984   1.9880894]\n"
     ]
    }
   ],
   "source": [
    "for idx, word in enumerate(outputs):\n",
    "    # max_value = torch.max(outputs)\n",
    "    list_outputs = max(outputs)\n",
    "    print(list_outputs)\n",
    "    # print(max_value)\n",
    "    # print(max_value.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 2181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_max = max(range(len(list_outputs)), key=list_outputs.__getitem__)\n",
    "index_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "เครียด\n"
     ]
    }
   ],
   "source": [
    "print(labels[index_max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2087,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input : กฎกระทรวง Predicted : กฎกระทรวง\n",
      "Input : กฎหมายรัฐธรรมนูญ Predicted : กฎหมายรัฐธรรมนูญ\n",
      "Input : กรมอนามัย Predicted : กรมอนามัย\n",
      "Input : กรรม Predicted : กรรม\n",
      "Input : กรรมสิทธิ์ Predicted : เครื่องปั่นดิน\n",
      "Input : กระโดด Predicted : กระโดด\n",
      "Input : กล้วยบวชชี Predicted : กล้วยบวชชี\n",
      "Input : กล้วยเชื่อม Predicted : กล้วยเชื่อม\n",
      "Input : กังวล Predicted : กังวล\n",
      "Input : กีฬา Predicted : กีฬา\n",
      "Input : น้อง Predicted : น้อง\n",
      "Input : เขิน Predicted : เขิน\n",
      "Input : เขื่อนดิน Predicted : เขื่อนดิน\n",
      "Input : เขื่อนสิริกิติ์ Predicted : เขื่อนสิริกิติ์\n",
      "Input : เข้าใจผิด Predicted : เข้าใจผิด\n",
      "Input : เคย Predicted : กล้วยเชื่อม\n",
      "Input : เครียด Predicted : เครียด\n",
      "Input : เครื่องปั่นดิน Predicted : เครื่องปั่นดิน\n",
      "Input : เครื่องหมายการค้า Predicted : เครื่องหมายการค้า\n",
      "Input : เจอ Predicted : เขื่อนดิน\n",
      "Input : เจ้าหนี้ Predicted : เจ้าหนี้\n",
      "Input : เช่าซื้อ Predicted : เช่าซื้อ\n",
      "Input : เช่าทรัพย์ Predicted : เช่าทรัพย์\n",
      "Input : เซอร์เบีย Predicted : เซอร์เบีย\n",
      "Input : เซเนกัล Predicted : เซเนกัล\n",
      "Input : เซ็ง Predicted : เขิน\n",
      "Input : เดิน Predicted : เดิน\n",
      "Input : เดิมพัน Predicted : โจทก์\n",
      "Input : เพลีย Predicted : เช่าทรัพย์\n",
      "Input : เมื่อย Predicted : เมื่อย\n",
      "Input : เม็กซิโก Predicted : เม็กซิโก\n",
      "Input : เฮโรอีน Predicted : เฮโรอีน\n",
      "Input : แกมเบีย Predicted : แกมเบีย\n",
      "Input : แซมเบีย Predicted : แซมเบีย\n",
      "Input : โกหก Predicted : โกหก\n",
      "Input : โจทก์ Predicted : โจทก์\n",
      "Input : โชจู Predicted : โชจู\n",
      "Input : ใกล้ Predicted : กล้วยเชื่อม\n",
      "Input : ไดโนเสาร์ Predicted : ไดโนเสาร์\n",
      "Input : ไอซ์ Predicted : ไอซ์\n",
      "Correct Predicted on Training set : 33 Corrct percentage : 82.5%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "num_clip = 0\n",
    "for clip in labels:\n",
    "    # print(clip)\n",
    "    file_paths = [f\"Data for different actions/{clip}.mp4/{clip}.npy\"]\n",
    "    # print(file_paths)\n",
    "\n",
    "    sequences = load_keypoint_sequences(file_paths)\n",
    "    # Change list to numpy array \n",
    "    sequences = np.array(sequences)\n",
    "    # Change numpy array to tensor\n",
    "    sequences = torch.FloatTensor(sequences)\n",
    "    sequences = pad_sequence(sequences, batch_first=True)\n",
    "\n",
    "    outputs = model(sequences.to(device))\n",
    "\n",
    "    for idx, word in enumerate(outputs):\n",
    "        # max_value = torch.max(outputs)\n",
    "        list_outputs = max(outputs)\n",
    "\n",
    "    index_max = max(range(len(list_outputs)), key=list_outputs.__getitem__)\n",
    "\n",
    "    print(f\"Input : {clip} Predicted : {labels[index_max]}\")\n",
    "\n",
    "    if clip == labels[index_max]:\n",
    "        correct = correct+1\n",
    "    \n",
    "    num_clip = num_clip + 1 \n",
    "\n",
    "print(f\"Correct Predicted on Training set : {correct} Corrct percentage : {correct*100/num_clip}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['กฎกระทรวง', 'กฎหมายรัฐธรรมนูญ', 'กรมอนามัย', 'กรรม', 'กรรมสิทธิ์', 'กระโดด', 'กล้วยบวชชี', 'กล้วยเชื่อม', 'กังวล', 'กีฬา', 'น้อง', 'เขิน', 'เขื่อนดิน', 'เขื่อนสิริกิติ์', 'เข้าใจผิด', 'เคย', 'เครียด', 'เครื่องปั่นดิน', 'เครื่องหมายการค้า', 'เจอ', 'เจ้าหนี้', 'เช่าซื้อ', 'เช่าทรัพย์', 'เซอร์เบีย', 'เซเนกัล', 'เซ็ง', 'เดิน', 'เดิมพัน', 'เพลีย', 'เมื่อย', 'เม็กซิโก', 'เฮโรอีน', 'แกมเบีย', 'แซมเบีย', 'โกหก', 'โจทก์', 'โชจู', 'ใกล้', 'ไดโนเสาร์', 'ไอซ์']\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -------------------------------------------------------------------------------------------------------------------------------------------- ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"word\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(video_list, columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ชื่อไฟลล์ที่รวม Augment มาด้วย"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "onlyfiles = [f for f in listdir(\"Data for different actions\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onlyfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(onlyfiles, columns=columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('script.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.read_csv(\"script.csv\")\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[\"label\"] = y[\"label\"].astype(int)\n",
    "labels = y.label\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
