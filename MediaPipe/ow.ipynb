{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import mediapipe as mp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holist = mp.solutions.holistic \n",
    "mp_draw = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_detection(img, model):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img.flags.writeable = False                 \n",
    "    result = model.process(img)                 # Make prediction\n",
    "    img.flags.writeable = True                   \n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR) \n",
    "    return img, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_landmarks(img, result):\n",
    "    mp_draw.draw_landmarks(img, result.face_landmarks, mp_holist.FACEMESH_CONTOURS) # Draw face connections\n",
    "    mp_draw.draw_landmarks(img, result.pose_landmarks, mp_holist.POSE_CONNECTIONS) # Draw pose connections\n",
    "    mp_draw.draw_landmarks(img, result.left_hand_landmarks, mp_holist.HAND_CONNECTIONS) # Draw left hand connections\n",
    "    mp_draw.draw_landmarks(img, result.right_hand_landmarks, mp_holist.HAND_CONNECTIONS) # Draw right hand connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_styled_landmarks(img, result):\n",
    "    mp_draw.draw_landmarks(img, result.face_landmarks, mp_holist.FACEMESH_CONTOURS, \n",
    "                             mp_draw.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1), # color the joint \n",
    "                             mp_draw.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1) #color the connection\n",
    "                             ) \n",
    "    # mp_draw.draw_landmarks(img, result.face_landmarks, mp_holist.FACEMESH_CONTOURS, \n",
    "    #                          mp_draw.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1), # color the joint \n",
    "    #                          mp_draw.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1) #color the connection\n",
    "    #                          ) \n",
    "    \n",
    "    mp_draw.draw_landmarks(img, result.pose_landmarks, mp_holist.POSE_CONNECTIONS,\n",
    "                             mp_draw.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4), \n",
    "                             mp_draw.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                             ) \n",
    "    mp_draw.draw_landmarks(img, result.left_hand_landmarks, mp_holist.HAND_CONNECTIONS, \n",
    "                             mp_draw.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4), \n",
    "                             mp_draw.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                             ) \n",
    "    mp_draw.draw_landmarks(img, result.right_hand_landmarks, mp_holist.HAND_CONNECTIONS, \n",
    "                             mp_draw.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4), \n",
    "                             mp_draw.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                             ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frozenset({(0, 1),\n",
       "           (0, 4),\n",
       "           (1, 2),\n",
       "           (2, 3),\n",
       "           (3, 7),\n",
       "           (4, 5),\n",
       "           (5, 6),\n",
       "           (6, 8),\n",
       "           (9, 10),\n",
       "           (11, 12),\n",
       "           (11, 13),\n",
       "           (11, 23),\n",
       "           (12, 14),\n",
       "           (12, 24),\n",
       "           (13, 15),\n",
       "           (14, 16),\n",
       "           (15, 17),\n",
       "           (15, 19),\n",
       "           (15, 21),\n",
       "           (16, 18),\n",
       "           (16, 20),\n",
       "           (16, 22),\n",
       "           (17, 19),\n",
       "           (18, 20),\n",
       "           (23, 24),\n",
       "           (23, 25),\n",
       "           (24, 26),\n",
       "           (25, 27),\n",
       "           (26, 28),\n",
       "           (27, 29),\n",
       "           (27, 31),\n",
       "           (28, 30),\n",
       "           (28, 32),\n",
       "           (29, 31),\n",
       "           (30, 32)})"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp_holist.POSE_CONNECTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\araya\\AppData\\Roaming\\Python\\Python312\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "# Set mediapipe model \n",
    "with mp_holist.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        image, results = mediapipe_detection(frame, holistic)\n",
    "        print(results)\n",
    "        \n",
    "        draw_styled_landmarks(image, results)\n",
    "\n",
    "        cv2.imshow('OpenCV Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.997908890247345"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.pose_landmarks.landmark[0].visibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results.pose_landmarks.landmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keypoints(results):\n",
    "    pose=np.array([[res.x,res.y,res.z,res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*4)\n",
    "    left_hnd=np.array([[res.x,res.y,res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "    right_hnd=np.array([[res.x,res.y,res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "    face=np.array([[res.x,res.y,res.z] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(468*3)\n",
    "    return np.concatenate([pose,left_hnd,right_hnd,face])\n",
    "# concatenating for the model to detect the sign language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1662,)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_keypoints(results).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "video_dir = \"C:/Users/araya/Desktop/keypoints/video_extract\"\n",
    "video_list = []\n",
    "video_list = os.listdir(video_dir)\n",
    "\n",
    "len(video_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['กฎกระทรวง.mp4',\n",
       " 'กฎหมายรัฐธรรมนูญ.mp4',\n",
       " 'กรมอนามัย.mp4',\n",
       " 'กรรม.mp4',\n",
       " 'กรรมสิทธิ์.mp4',\n",
       " 'กระโดด.mp4',\n",
       " 'กล้วยบวชชี.mp4',\n",
       " 'กล้วยเชื่อม.mp4',\n",
       " 'กังวล.mp4',\n",
       " 'กีฬา.mp4',\n",
       " 'น้อง.mp4',\n",
       " 'เขิน.mp4',\n",
       " 'เขื่อนดิน.mp4',\n",
       " 'เขื่อนสิริกิติ์.mp4',\n",
       " 'เข้าใจผิด.mp4',\n",
       " 'เคย.mp4',\n",
       " 'เครียด.mp4',\n",
       " 'เครื่องปั่นดิน.mp4',\n",
       " 'เครื่องหมายการค้า.mp4',\n",
       " 'เจอ.mp4',\n",
       " 'เจ้าหนี้.mp4',\n",
       " 'เช่าซื้อ.mp4',\n",
       " 'เช่าทรัพย์.mp4',\n",
       " 'เซอร์เบีย.mp4',\n",
       " 'เซเนกัล.mp4',\n",
       " 'เซ็ง.mp4',\n",
       " 'เดิน.mp4',\n",
       " 'เดิมพัน.mp4',\n",
       " 'เพลีย.mp4',\n",
       " 'เมื่อย.mp4',\n",
       " 'เม็กซิโก.mp4',\n",
       " 'เฮโรอีน.mp4',\n",
       " 'แกมเบีย.mp4',\n",
       " 'แซมเบีย.mp4',\n",
       " 'โกหก.mp4',\n",
       " 'โจทก์.mp4',\n",
       " 'โชจู.mp4',\n",
       " 'ใกล้.mp4',\n",
       " 'ไดโนเสาร์.mp4',\n",
       " 'ไอซ์.mp4']"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for exported data, numpy arrays\n",
    "Model_Data=os.path.join('Data for different actions')\n",
    "\n",
    "actions = np.array(video_list)\n",
    "\n",
    "no_of_seqs = 1\n",
    "\n",
    "# 30 frames in length\n",
    "seq_length = 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['กฎกระทรวง.mp4', 'กฎหมายรัฐธรรมนูญ.mp4', 'กรมอนามัย.mp4',\n",
       "       'กรรม.mp4', 'กรรมสิทธิ์.mp4', 'กระโดด.mp4', 'กล้วยบวชชี.mp4',\n",
       "       'กล้วยเชื่อม.mp4', 'กังวล.mp4', 'กีฬา.mp4', 'น้อง.mp4', 'เขิน.mp4',\n",
       "       'เขื่อนดิน.mp4', 'เขื่อนสิริกิติ์.mp4', 'เข้าใจผิด.mp4', 'เคย.mp4',\n",
       "       'เครียด.mp4', 'เครื่องปั่นดิน.mp4', 'เครื่องหมายการค้า.mp4',\n",
       "       'เจอ.mp4', 'เจ้าหนี้.mp4', 'เช่าซื้อ.mp4', 'เช่าทรัพย์.mp4',\n",
       "       'เซอร์เบีย.mp4', 'เซเนกัล.mp4', 'เซ็ง.mp4', 'เดิน.mp4',\n",
       "       'เดิมพัน.mp4', 'เพลีย.mp4', 'เมื่อย.mp4', 'เม็กซิโก.mp4',\n",
       "       'เฮโรอีน.mp4', 'แกมเบีย.mp4', 'แซมเบีย.mp4', 'โกหก.mp4',\n",
       "       'โจทก์.mp4', 'โชจู.mp4', 'ใกล้.mp4', 'ไดโนเสาร์.mp4', 'ไอซ์.mp4'],\n",
       "      dtype='<U21')"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just creating the folders and sub folders\n",
    "\n",
    "for action in actions: \n",
    "    try: \n",
    "        os.makedirs(os.path.join(Model_Data, action))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# augment_dir = \"C:/Users/araya/Desktop/augments\"\n",
    "\n",
    "# augment_list = []\n",
    "# augment_list = os.listdir(augment_dir)\n",
    "# augment_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actions = list(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in augment_list:\n",
    "#     # print(x)\n",
    "#     actions.append(x)\n",
    "# actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actions = np.array(actions)\n",
    "# actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collecting keypoint values for Training nd Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory where your videos are stored\n",
    "directory = \"C:/Users/araya/Desktop/keypoints/video_extract\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/araya/Desktop/keypoints/video_extract'"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/araya/Desktop/keypoints/video_extract/กฎกระทรวง.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/กฎหมายรัฐธรรมนูญ.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/กรมอนามัย.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/กรรม.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/กรรมสิทธิ์.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/กระโดด.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/กล้วยบวชชี.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/กล้วยเชื่อม.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/กังวล.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/กีฬา.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/น้อง.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เขิน.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เขื่อนดิน.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เขื่อนสิริกิติ์.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เข้าใจผิด.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เคย.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เครียด.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เครื่องปั่นดิน.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เครื่องหมายการค้า.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เจอ.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เจ้าหนี้.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เช่าซื้อ.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เช่าทรัพย์.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เซอร์เบีย.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เซเนกัล.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เซ็ง.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เดิน.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เดิมพัน.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เพลีย.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เมื่อย.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เม็กซิโก.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เฮโรอีน.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/แกมเบีย.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/แซมเบีย.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/โกหก.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/โจทก์.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/โชจู.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/ใกล้.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/ไดโนเสาร์.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/ไอซ์.mp4\n"
     ]
    }
   ],
   "source": [
    "for filename in actions:\n",
    "    print(directory + '/' + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set mediapipe model \n",
    "# for action in actions:\n",
    "#     video_path = os.path.join(\"C:/Users/araya/Desktop/keypoints/video_extract\", action)\n",
    "#     cap = cv2.VideoCapture(video_path)\n",
    "#     cap.set(cv2.CAP_PROP_FPS, 60)\n",
    "#     length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "#     print(\"LENGTH:\" + str(length))\n",
    "#     # keypoints = []\n",
    "\n",
    "#     if not cap.isOpened():\n",
    "#         print(f\"Error opening video file: {video_path}\")\n",
    "#         continue\n",
    "\n",
    "#     with mp_holist.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "#         for seq in range(no_of_seqs):\n",
    "#             for frame_num in range(seq_length):\n",
    "\n",
    "#                 ret, frame = cap.read()\n",
    "#                 if not ret:\n",
    "#                     print(f\"End of video {video_path}\")\n",
    "#                     break\n",
    "                \n",
    "#                 img, results = mediapipe_detection(frame, holistic)\n",
    "#                 draw_styled_landmarks(img, results)\n",
    "\n",
    "#                 # print(frame_num)\n",
    "\n",
    "#                 if frame_num == 0: \n",
    "#                     cv2.putText(img, 'DATA COLLECTION STARTED', (120,200), \n",
    "#                                 cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255, 0), 4, cv2.LINE_AA)\n",
    "#                     cv2.putText(img, f'Collecting frames for - {action} Sequence Number - {seq}', (15,12), \n",
    "#                                 cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "#                     cv2.imshow('OpenCV Window', img)\n",
    "#                     cv2.waitKey(2000)  # 2 seconds delay for setup\n",
    "#                 else: \n",
    "#                     cv2.putText(img, f'Collecting frames for - {action} Sequence Number - {seq}', (15,12), \n",
    "#                                 cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "#                     cv2.imshow('OpenCV Window', img)\n",
    "\n",
    "#                 keypoints = extract_keypoints(results)\n",
    "#                 # keypoints.append(results)\n",
    "#                 npy_path = os.path.join(Model_Data, action, f\"frame_{frame_num}.npy\")\n",
    "#                 os.makedirs(os.path.dirname(npy_path), exist_ok=True)\n",
    "#                 np.save(npy_path, keypoints)\n",
    "\n",
    "#                 if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#                     break\n",
    "\n",
    "#             if not ret:\n",
    "#                 break\n",
    "\n",
    "#     cap.release()\n",
    "#     cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np \n",
    "\n",
    "# X = [[1,2,3]]\n",
    "# X.append([6,8,10])\n",
    "# X.append([20,9,4])\n",
    "# X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set mediapipe model \n",
    "for action in actions:\n",
    "    video_path = os.path.join(\"C:/Users/araya/Desktop/keypoints/video_extract\", action)\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    cap.set(cv2.CAP_PROP_FPS, 60)\n",
    "    length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    print(\"LENGTH:\" + str(length))\n",
    "    keypoints = []\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error opening video file: {video_path}\")\n",
    "        continue\n",
    "\n",
    "    with mp_holist.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "        for seq in range(no_of_seqs):\n",
    "            for frame_num in range(seq_length):\n",
    "\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    print(f\"End of video {video_path}\")\n",
    "                    break\n",
    "                \n",
    "                img, results = mediapipe_detection(frame, holistic)\n",
    "                draw_styled_landmarks(img, results)\n",
    "\n",
    "                # print(frame_num)\n",
    "\n",
    "                if frame_num == 0: \n",
    "                    cv2.putText(img, 'DATA COLLECTION STARTED', (120,200), \n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255, 0), 4, cv2.LINE_AA)\n",
    "                    cv2.putText(img, f'Collecting frames for - {action} Sequence Number - {seq}', (15,12), \n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "                    cv2.imshow('OpenCV Window', img)\n",
    "                    cv2.waitKey(2000)  # 2 seconds delay for setup\n",
    "                else: \n",
    "                    cv2.putText(img, f'Collecting frames for - {action} Sequence Number - {seq}', (15,12), \n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "                    cv2.imshow('OpenCV Window', img)\n",
    "\n",
    "                x = extract_keypoints(results)\n",
    "                keypoints.append(x)\n",
    "                npy_path = os.path.join(Model_Data, action, f\"{action.split(\".\")[0]}.npy\")\n",
    "                os.makedirs(os.path.dirname(npy_path), exist_ok=True)\n",
    "                np.save(npy_path, keypoints)\n",
    "\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Data for different actions/กฎกระทรวง.mp4/กฎกระทรวง.npy', 'Data for different actions/กฎหมายรัฐธรรมนูญ.mp4/กฎหมายรัฐธรรมนูญ.npy', 'Data for different actions/กรมอนามัย.mp4/กรมอนามัย.npy', 'Data for different actions/กรรม.mp4/กรรม.npy', 'Data for different actions/กรรมสิทธิ์.mp4/กรรมสิทธิ์.npy', 'Data for different actions/กระโดด.mp4/กระโดด.npy', 'Data for different actions/กล้วยบวชชี.mp4/กล้วยบวชชี.npy', 'Data for different actions/กล้วยเชื่อม.mp4/กล้วยเชื่อม.npy', 'Data for different actions/กังวล.mp4/กังวล.npy', 'Data for different actions/กีฬา.mp4/กีฬา.npy', 'Data for different actions/น้อง.mp4/น้อง.npy', 'Data for different actions/เขิน.mp4/เขิน.npy', 'Data for different actions/เขื่อนดิน.mp4/เขื่อนดิน.npy', 'Data for different actions/เขื่อนสิริกิติ์.mp4/เขื่อนสิริกิติ์.npy', 'Data for different actions/เข้าใจผิด.mp4/เข้าใจผิด.npy', 'Data for different actions/เคย.mp4/เคย.npy', 'Data for different actions/เครียด.mp4/เครียด.npy', 'Data for different actions/เครื่องปั่นดิน.mp4/เครื่องปั่นดิน.npy', 'Data for different actions/เครื่องหมายการค้า.mp4/เครื่องหมายการค้า.npy', 'Data for different actions/เจอ.mp4/เจอ.npy', 'Data for different actions/เจ้าหนี้.mp4/เจ้าหนี้.npy', 'Data for different actions/เช่าซื้อ.mp4/เช่าซื้อ.npy', 'Data for different actions/เช่าทรัพย์.mp4/เช่าทรัพย์.npy', 'Data for different actions/เซอร์เบีย.mp4/เซอร์เบีย.npy', 'Data for different actions/เซเนกัล.mp4/เซเนกัล.npy', 'Data for different actions/เซ็ง.mp4/เซ็ง.npy', 'Data for different actions/เดิน.mp4/เดิน.npy', 'Data for different actions/เดิมพัน.mp4/เดิมพัน.npy', 'Data for different actions/เพลีย.mp4/เพลีย.npy', 'Data for different actions/เมื่อย.mp4/เมื่อย.npy', 'Data for different actions/เม็กซิโก.mp4/เม็กซิโก.npy', 'Data for different actions/เฮโรอีน.mp4/เฮโรอีน.npy', 'Data for different actions/แกมเบีย.mp4/แกมเบีย.npy', 'Data for different actions/แซมเบีย.mp4/แซมเบีย.npy', 'Data for different actions/โกหก.mp4/โกหก.npy', 'Data for different actions/โจทก์.mp4/โจทก์.npy', 'Data for different actions/โชจู.mp4/โชจู.npy', 'Data for different actions/ใกล้.mp4/ใกล้.npy', 'Data for different actions/ไดโนเสาร์.mp4/ไดโนเสาร์.npy', 'Data for different actions/ไอซ์.mp4/ไอซ์.npy']\n"
     ]
    }
   ],
   "source": [
    "file_paths = []\n",
    "for action in actions:\n",
    "    video_path = os.path.join('Data for different actions/', action)\n",
    "    # print(video_path)\n",
    "    # print(action)\n",
    "    file_paths.append(video_path + '/' + action.split(\".\")[0] + \".npy\")\n",
    "print(file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_keypoint_sequences(file_paths):\n",
    "    keypoint_sequences = []\n",
    "    for file_path in file_paths:\n",
    "        keypoints = np.load(file_path)\n",
    "        keypoint_sequences.append(torch.tensor(keypoints, dtype=torch.float32))\n",
    "    return keypoint_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 0.5013,  0.2452, -1.2167,  ...,  0.5663,  0.2188,  0.0098],\n",
       "         [ 0.4997,  0.2482, -1.4690,  ...,  0.5652,  0.2181,  0.0106],\n",
       "         [ 0.4984,  0.2500, -1.4853,  ...,  0.5654,  0.2185,  0.0112],\n",
       "         ...,\n",
       "         [ 0.4861,  0.2513, -1.3416,  ...,  0.5572,  0.2177,  0.0091],\n",
       "         [ 0.4873,  0.2514, -1.3574,  ...,  0.5575,  0.2172,  0.0097],\n",
       "         [ 0.4883,  0.2516, -1.3579,  ...,  0.5577,  0.2170,  0.0101]]),\n",
       " tensor([[ 0.4922,  0.2382, -1.2850,  ...,  0.5578,  0.2124,  0.0094],\n",
       "         [ 0.4920,  0.2405, -1.4288,  ...,  0.5571,  0.2116,  0.0099],\n",
       "         [ 0.4920,  0.2409, -1.4093,  ...,  0.5567,  0.2122,  0.0098],\n",
       "         ...,\n",
       "         [ 0.4814,  0.2260, -1.3318,  ...,  0.5503,  0.1923,  0.0123],\n",
       "         [ 0.4815,  0.2257, -1.3351,  ...,  0.5503,  0.1921,  0.0122],\n",
       "         [ 0.4815,  0.2255, -1.3497,  ...,  0.5501,  0.1919,  0.0124]]),\n",
       " tensor([[ 0.5049,  0.2371, -1.2115,  ...,  0.5643,  0.2082,  0.0088],\n",
       "         [ 0.5045,  0.2381, -1.1896,  ...,  0.5643,  0.2081,  0.0085],\n",
       "         [ 0.5041,  0.2385, -1.1915,  ...,  0.5643,  0.2080,  0.0089],\n",
       "         ...,\n",
       "         [ 0.4963,  0.2307, -1.3096,  ...,  0.5624,  0.2043,  0.0127],\n",
       "         [ 0.4965,  0.2308, -1.3085,  ...,  0.5625,  0.2045,  0.0126],\n",
       "         [ 0.4972,  0.2312, -1.3053,  ...,  0.5633,  0.2045,  0.0128]]),\n",
       " tensor([[ 0.5134,  0.2614, -1.4426,  ...,  0.5818,  0.2272,  0.0153],\n",
       "         [ 0.5130,  0.2604, -1.4262,  ...,  0.5810,  0.2273,  0.0147],\n",
       "         [ 0.5126,  0.2599, -1.4278,  ...,  0.5810,  0.2276,  0.0150],\n",
       "         ...,\n",
       "         [ 0.5079,  0.2693, -1.4999,  ...,  0.5780,  0.2349,  0.0115],\n",
       "         [ 0.5090,  0.2688, -1.4936,  ...,  0.5782,  0.2346,  0.0116],\n",
       "         [ 0.5092,  0.2683, -1.4518,  ...,  0.5786,  0.2341,  0.0116]]),\n",
       " tensor([[ 0.4883,  0.2402, -1.1024,  ...,  0.5482,  0.2132,  0.0081],\n",
       "         [ 0.4878,  0.2402, -1.1906,  ...,  0.5469,  0.2135,  0.0083],\n",
       "         [ 0.4863,  0.2402, -1.1774,  ...,  0.5477,  0.2141,  0.0087],\n",
       "         ...,\n",
       "         [ 0.4788,  0.3129, -1.6072,  ...,  0.5349,  0.2531,  0.0022],\n",
       "         [ 0.4782,  0.3129, -1.6350,  ...,  0.5344,  0.2525,  0.0022],\n",
       "         [ 0.4771,  0.3131, -1.6312,  ...,  0.5339,  0.2515,  0.0022]]),\n",
       " tensor([[ 0.4992,  0.1994, -1.1906,  ...,  0.5657,  0.1731,  0.0116],\n",
       "         [ 0.4988,  0.2047, -1.3590,  ...,  0.5663,  0.1723,  0.0123],\n",
       "         [ 0.4982,  0.2082, -1.3140,  ...,  0.5671,  0.1730,  0.0129],\n",
       "         ...,\n",
       "         [ 0.4743,  0.1974, -1.3230,  ...,  0.5475,  0.1620,  0.0155],\n",
       "         [ 0.4732,  0.1974, -1.3174,  ...,  0.5461,  0.1615,  0.0151],\n",
       "         [ 0.4720,  0.1974, -1.3149,  ...,  0.5453,  0.1614,  0.0149]]),\n",
       " tensor([[ 0.5023,  0.2809, -1.6242,  ...,  0.5847,  0.2321,  0.0112],\n",
       "         [ 0.5023,  0.2806, -1.6631,  ...,  0.5840,  0.2322,  0.0130],\n",
       "         [ 0.5022,  0.2805, -1.6912,  ...,  0.5837,  0.2322,  0.0122],\n",
       "         ...,\n",
       "         [ 0.5037,  0.2791, -1.5789,  ...,  0.5834,  0.2224,  0.0129],\n",
       "         [ 0.5044,  0.2774, -1.5686,  ...,  0.5831,  0.2220,  0.0130],\n",
       "         [ 0.5052,  0.2722, -1.5527,  ...,  0.5827,  0.2216,  0.0132]]),\n",
       " tensor([[ 0.4868,  0.2821, -1.4668,  ...,  0.5711,  0.2335,  0.0116],\n",
       "         [ 0.4861,  0.2786, -1.5812,  ...,  0.5702,  0.2334,  0.0129],\n",
       "         [ 0.4856,  0.2769, -1.6059,  ...,  0.5699,  0.2333,  0.0131],\n",
       "         ...,\n",
       "         [ 0.4826,  0.2583, -1.6140,  ...,  0.5606,  0.2261,  0.0154],\n",
       "         [ 0.4820,  0.2583, -1.5231,  ...,  0.5603,  0.2261,  0.0156],\n",
       "         [ 0.4818,  0.2580, -1.5255,  ...,  0.5600,  0.2263,  0.0156]]),\n",
       " tensor([[ 0.5016,  0.2321, -1.1859,  ...,  0.5647,  0.2139,  0.0072],\n",
       "         [ 0.5015,  0.2340, -1.1996,  ...,  0.5645,  0.2135,  0.0076],\n",
       "         [ 0.5016,  0.2346, -1.2272,  ...,  0.5644,  0.2137,  0.0082],\n",
       "         ...,\n",
       "         [ 0.4743,  0.2622, -1.4181,  ...,  0.5499,  0.2133,  0.0080],\n",
       "         [ 0.4763,  0.2599, -1.4742,  ...,  0.5519,  0.2118,  0.0090],\n",
       "         [ 0.4787,  0.2522, -1.6440,  ...,  0.5537,  0.2110,  0.0093]]),\n",
       " tensor([[ 0.4926,  0.1945, -1.2354,  ...,  0.5488,  0.1581,  0.0085],\n",
       "         [ 0.4942,  0.1949, -1.4254,  ...,  0.5481,  0.1576,  0.0085],\n",
       "         [ 0.4948,  0.1960, -1.4483,  ...,  0.5479,  0.1581,  0.0084],\n",
       "         ...,\n",
       "         [ 0.4917,  0.1882, -1.3355,  ...,  0.5458,  0.1536,  0.0126],\n",
       "         [ 0.4918,  0.1885, -1.3154,  ...,  0.5456,  0.1536,  0.0125],\n",
       "         [ 0.4918,  0.1886, -1.3147,  ...,  0.5453,  0.1537,  0.0124]]),\n",
       " tensor([[ 0.4956,  0.2681, -1.1361,  ...,  0.5554,  0.2332,  0.0147],\n",
       "         [ 0.4948,  0.2681, -1.3768,  ...,  0.5540,  0.2333,  0.0116],\n",
       "         [ 0.4943,  0.2681, -1.3754,  ...,  0.5538,  0.2332,  0.0116],\n",
       "         ...,\n",
       "         [ 0.4895,  0.2689, -1.2187,  ...,  0.5513,  0.2276,  0.0135],\n",
       "         [ 0.4889,  0.2688, -1.2198,  ...,  0.5508,  0.2276,  0.0134],\n",
       "         [ 0.4882,  0.2688, -1.2172,  ...,  0.5507,  0.2276,  0.0134]]),\n",
       " tensor([[ 0.5032,  0.2228, -1.1998,  ...,  0.5663,  0.1971,  0.0106],\n",
       "         [ 0.5035,  0.2228, -1.2072,  ...,  0.5662,  0.1969,  0.0106],\n",
       "         [ 0.5035,  0.2230, -1.2082,  ...,  0.5664,  0.1963,  0.0108],\n",
       "         ...,\n",
       "         [ 0.4982,  0.2206, -1.2743,  ...,  0.5578,  0.1892,  0.0092],\n",
       "         [ 0.4983,  0.2178, -1.2380,  ...,  0.5581,  0.1883,  0.0091],\n",
       "         [ 0.4979,  0.2173, -1.2264,  ...,  0.5578,  0.1877,  0.0096]]),\n",
       " tensor([[ 0.5442,  0.2507, -1.4443,  ...,  0.6105,  0.2203,  0.0123],\n",
       "         [ 0.5444,  0.2508, -1.6574,  ...,  0.6094,  0.2198,  0.0134],\n",
       "         [ 0.5445,  0.2510, -1.7250,  ...,  0.6093,  0.2195,  0.0144],\n",
       "         ...,\n",
       "         [ 0.5324,  0.2577, -1.6704,  ...,  0.5975,  0.2210,  0.0145],\n",
       "         [ 0.5323,  0.2560, -1.6673,  ...,  0.5966,  0.2206,  0.0148],\n",
       "         [ 0.5323,  0.2553, -1.6826,  ...,  0.5957,  0.2201,  0.0146]]),\n",
       " tensor([[ 0.5402,  0.2562, -1.5458,  ...,  0.6041,  0.2257,  0.0125],\n",
       "         [ 0.5389,  0.2596, -1.7020,  ...,  0.6031,  0.2264,  0.0130],\n",
       "         [ 0.5379,  0.2616, -1.7134,  ...,  0.6027,  0.2258,  0.0139],\n",
       "         ...,\n",
       "         [ 0.5153,  0.2631, -1.6030,  ...,  0.5956,  0.2125,  0.0142],\n",
       "         [ 0.5176,  0.2626, -1.6101,  ...,  0.5985,  0.2126,  0.0139],\n",
       "         [ 0.5197,  0.2624, -1.5662,  ...,  0.6011,  0.2119,  0.0145]]),\n",
       " tensor([[ 0.5030,  0.2553, -1.1988,  ...,  0.5699,  0.2265,  0.0097],\n",
       "         [ 0.5028,  0.2582, -1.2761,  ...,  0.5689,  0.2266,  0.0109],\n",
       "         [ 0.5028,  0.2605, -1.3315,  ...,  0.5690,  0.2269,  0.0105],\n",
       "         ...,\n",
       "         [ 0.5028,  0.2675, -1.4499,  ...,  0.5672,  0.2323,  0.0110],\n",
       "         [ 0.5007,  0.2672, -1.4234,  ...,  0.5668,  0.2317,  0.0115],\n",
       "         [ 0.4988,  0.2671, -1.4308,  ...,  0.5670,  0.2312,  0.0118]]),\n",
       " tensor([[ 0.5069,  0.2355, -1.3384,  ...,  0.5700,  0.2051,  0.0053],\n",
       "         [ 0.5045,  0.2395, -1.5097,  ...,  0.5699,  0.2043,  0.0064],\n",
       "         [ 0.5028,  0.2420, -1.5081,  ...,  0.5699,  0.2045,  0.0069],\n",
       "         ...,\n",
       "         [ 0.4952,  0.2462, -1.4319,  ...,  0.5658,  0.2015,  0.0122],\n",
       "         [ 0.4952,  0.2448, -1.4781,  ...,  0.5661,  0.2014,  0.0123],\n",
       "         [ 0.4953,  0.2436, -1.4689,  ...,  0.5662,  0.2013,  0.0124]]),\n",
       " tensor([[ 0.5035,  0.2282, -1.1379,  ...,  0.5710,  0.1953,  0.0120],\n",
       "         [ 0.5033,  0.2284, -1.2771,  ...,  0.5713,  0.1954,  0.0123],\n",
       "         [ 0.5032,  0.2286, -1.2743,  ...,  0.5715,  0.1957,  0.0122],\n",
       "         ...,\n",
       "         [ 0.4810,  0.2296, -1.4129,  ...,  0.5542,  0.1897,  0.0133],\n",
       "         [ 0.4812,  0.2296, -1.4275,  ...,  0.5549,  0.1900,  0.0130],\n",
       "         [ 0.4816,  0.2299, -1.4337,  ...,  0.5557,  0.1903,  0.0133]]),\n",
       " tensor([[ 0.5108,  0.2425, -1.1053,  ...,  0.5724,  0.2176,  0.0127],\n",
       "         [ 0.5091,  0.2430, -1.3007,  ...,  0.5713,  0.2177,  0.0129],\n",
       "         [ 0.5080,  0.2432, -1.3035,  ...,  0.5714,  0.2179,  0.0130],\n",
       "         ...,\n",
       "         [ 0.4966,  0.2620, -1.5367,  ...,  0.5653,  0.2259,  0.0082],\n",
       "         [ 0.4968,  0.2621, -1.5419,  ...,  0.5656,  0.2262,  0.0083],\n",
       "         [ 0.4971,  0.2623, -1.5482,  ...,  0.5658,  0.2263,  0.0086]]),\n",
       " tensor([[ 0.4878,  0.2235, -1.2515,  ...,  0.5511,  0.1981,  0.0114],\n",
       "         [ 0.4870,  0.2286, -1.4279,  ...,  0.5506,  0.1977,  0.0105],\n",
       "         [ 0.4865,  0.2315, -1.4431,  ...,  0.5508,  0.1984,  0.0110],\n",
       "         ...,\n",
       "         [ 0.4901,  0.2217, -1.3449,  ...,  0.5576,  0.1888,  0.0156],\n",
       "         [ 0.4898,  0.2224, -1.3780,  ...,  0.5575,  0.1892,  0.0157],\n",
       "         [ 0.4896,  0.2232, -1.4140,  ...,  0.5572,  0.1897,  0.0156]]),\n",
       " tensor([[ 0.5194,  0.2227, -1.3410,  ...,  0.5911,  0.1970,  0.0142],\n",
       "         [ 0.5200,  0.2228, -1.3298,  ...,  0.5912,  0.1965,  0.0131],\n",
       "         [ 0.5202,  0.2230, -1.3074,  ...,  0.5909,  0.1970,  0.0149],\n",
       "         ...,\n",
       "         [ 0.5146,  0.2198, -1.3267,  ...,  0.5821,  0.1907,  0.0159],\n",
       "         [ 0.5141,  0.2205, -1.3207,  ...,  0.5816,  0.1911,  0.0154],\n",
       "         [ 0.5137,  0.2209, -1.3223,  ...,  0.5812,  0.1917,  0.0161]]),\n",
       " tensor([[ 0.5103,  0.2428, -1.1660,  ...,  0.5757,  0.2179,  0.0081],\n",
       "         [ 0.5106,  0.2437, -1.2850,  ...,  0.5751,  0.2183,  0.0099],\n",
       "         [ 0.5112,  0.2443, -1.2880,  ...,  0.5748,  0.2189,  0.0108],\n",
       "         ...,\n",
       "         [ 0.4800,  0.2603, -1.3086,  ...,  0.5532,  0.2237,  0.0069],\n",
       "         [ 0.4807,  0.2604, -1.2544,  ...,  0.5539,  0.2238,  0.0067],\n",
       "         [ 0.4813,  0.2604, -1.2161,  ...,  0.5548,  0.2238,  0.0065]]),\n",
       " tensor([[ 0.4945,  0.2362, -1.1227,  ...,  0.5529,  0.2086,  0.0088],\n",
       "         [ 0.4947,  0.2363, -1.1264,  ...,  0.5528,  0.2094,  0.0088],\n",
       "         [ 0.4951,  0.2364, -1.1371,  ...,  0.5531,  0.2099,  0.0089],\n",
       "         ...,\n",
       "         [ 0.4933,  0.2480, -1.2424,  ...,  0.5563,  0.2184,  0.0091],\n",
       "         [ 0.4933,  0.2480, -1.2443,  ...,  0.5565,  0.2185,  0.0093],\n",
       "         [ 0.4932,  0.2480, -1.2944,  ...,  0.5564,  0.2185,  0.0095]]),\n",
       " tensor([[ 0.5038,  0.2425, -1.1550,  ...,  0.5665,  0.2136,  0.0080],\n",
       "         [ 0.5027,  0.2423, -1.2423,  ...,  0.5653,  0.2133,  0.0092],\n",
       "         [ 0.5018,  0.2423, -1.2565,  ...,  0.5649,  0.2130,  0.0094],\n",
       "         ...,\n",
       "         [ 0.4950,  0.2412, -1.1727,  ...,  0.5624,  0.2175,  0.0087],\n",
       "         [ 0.4951,  0.2412, -1.1690,  ...,  0.5625,  0.2177,  0.0082],\n",
       "         [ 0.4951,  0.2412, -1.1910,  ...,  0.5626,  0.2180,  0.0079]]),\n",
       " tensor([[ 0.4916,  0.2518, -1.3187,  ...,  0.5597,  0.2202,  0.0108],\n",
       "         [ 0.4907,  0.2519, -1.3672,  ...,  0.5580,  0.2209,  0.0105],\n",
       "         [ 0.4896,  0.2520, -1.4026,  ...,  0.5580,  0.2210,  0.0110],\n",
       "         ...,\n",
       "         [ 0.4850,  0.2552, -1.4312,  ...,  0.5509,  0.2199,  0.0138],\n",
       "         [ 0.4839,  0.2550, -1.4298,  ...,  0.5505,  0.2199,  0.0138],\n",
       "         [ 0.4831,  0.2549, -1.4164,  ...,  0.5501,  0.2200,  0.0137]]),\n",
       " tensor([[ 0.5051,  0.2347, -1.4390,  ...,  0.5717,  0.2094,  0.0091],\n",
       "         [ 0.5024,  0.2389, -1.5627,  ...,  0.5707,  0.2087,  0.0090],\n",
       "         [ 0.5005,  0.2417, -1.5896,  ...,  0.5704,  0.2090,  0.0098],\n",
       "         ...,\n",
       "         [ 0.4950,  0.2365, -1.4622,  ...,  0.5663,  0.2072,  0.0114],\n",
       "         [ 0.4950,  0.2366, -1.4772,  ...,  0.5667,  0.2075,  0.0115],\n",
       "         [ 0.4949,  0.2366, -1.4725,  ...,  0.5671,  0.2078,  0.0120]]),\n",
       " tensor([[ 0.5064,  0.2529, -1.3080,  ...,  0.5751,  0.2261,  0.0114],\n",
       "         [ 0.5055,  0.2550, -1.3556,  ...,  0.5752,  0.2257,  0.0106],\n",
       "         [ 0.5048,  0.2568, -1.3925,  ...,  0.5751,  0.2260,  0.0110],\n",
       "         ...,\n",
       "         [ 0.4960,  0.2624, -1.3587,  ...,  0.5642,  0.2311,  0.0101],\n",
       "         [ 0.4961,  0.2619, -1.3373,  ...,  0.5652,  0.2307,  0.0104],\n",
       "         [ 0.4961,  0.2615, -1.3405,  ...,  0.5653,  0.2302,  0.0102]]),\n",
       " tensor([[ 0.5267,  0.2322, -1.2986,  ...,  0.5921,  0.1996,  0.0123],\n",
       "         [ 0.5267,  0.2305, -1.3156,  ...,  0.5925,  0.1999,  0.0112],\n",
       "         [ 0.5266,  0.2296, -1.3147,  ...,  0.5928,  0.1997,  0.0121],\n",
       "         ...,\n",
       "         [ 0.5122,  0.2243, -1.2697,  ...,  0.5819,  0.1855,  0.0147],\n",
       "         [ 0.5114,  0.2239, -1.2687,  ...,  0.5817,  0.1857,  0.0145],\n",
       "         [ 0.5110,  0.2235, -1.2585,  ...,  0.5815,  0.1858,  0.0145]]),\n",
       " tensor([[ 0.5050,  0.2164, -1.1575,  ...,  0.5700,  0.1959,  0.0103],\n",
       "         [ 0.5041,  0.2187, -1.3621,  ...,  0.5689,  0.1959,  0.0100],\n",
       "         [ 0.5031,  0.2218, -1.3920,  ...,  0.5693,  0.1959,  0.0109],\n",
       "         ...,\n",
       "         [ 0.4987,  0.2252, -1.2609,  ...,  0.5655,  0.1932,  0.0101],\n",
       "         [ 0.4982,  0.2238, -1.2657,  ...,  0.5653,  0.1926,  0.0103],\n",
       "         [ 0.4969,  0.2230, -1.2967,  ...,  0.5649,  0.1919,  0.0105]]),\n",
       " tensor([[ 0.5097,  0.2301, -1.2305,  ...,  0.5773,  0.2070,  0.0135],\n",
       "         [ 0.5098,  0.2316, -1.4094,  ...,  0.5762,  0.2072,  0.0130],\n",
       "         [ 0.5099,  0.2328, -1.4219,  ...,  0.5754,  0.2074,  0.0134],\n",
       "         ...,\n",
       "         [ 0.5106,  0.2519, -1.1800,  ...,  0.5731,  0.2204,  0.0132],\n",
       "         [ 0.5082,  0.2514, -1.1958,  ...,  0.5717,  0.2193,  0.0134],\n",
       "         [ 0.5074,  0.2516, -1.2210,  ...,  0.5703,  0.2182,  0.0128]]),\n",
       " tensor([[ 0.5410,  0.2495, -1.3908,  ...,  0.6085,  0.2224,  0.0099],\n",
       "         [ 0.5399,  0.2502, -1.3960,  ...,  0.6066,  0.2219,  0.0111],\n",
       "         [ 0.5390,  0.2511, -1.3861,  ...,  0.6062,  0.2215,  0.0105],\n",
       "         ...,\n",
       "         [ 0.5131,  0.2461, -1.3199,  ...,  0.5857,  0.2158,  0.0118],\n",
       "         [ 0.5137,  0.2459, -1.3370,  ...,  0.5858,  0.2153,  0.0118],\n",
       "         [ 0.5141,  0.2456, -1.3376,  ...,  0.5860,  0.2150,  0.0116]]),\n",
       " tensor([[ 0.4813,  0.2267, -1.2462,  ...,  0.5499,  0.2013,  0.0123],\n",
       "         [ 0.4796,  0.2283, -1.4595,  ...,  0.5479,  0.2026,  0.0127],\n",
       "         [ 0.4786,  0.2300, -1.5108,  ...,  0.5480,  0.2025,  0.0122],\n",
       "         ...,\n",
       "         [ 0.4782,  0.2297, -1.2598,  ...,  0.5464,  0.1965,  0.0150],\n",
       "         [ 0.4781,  0.2300, -1.2686,  ...,  0.5459,  0.1960,  0.0147],\n",
       "         [ 0.4780,  0.2304, -1.2444,  ...,  0.5461,  0.1953,  0.0154]]),\n",
       " tensor([[ 0.5051,  0.2433, -1.3371,  ...,  0.5701,  0.2185,  0.0094],\n",
       "         [ 0.5042,  0.2464, -1.4811,  ...,  0.5696,  0.2193,  0.0109],\n",
       "         [ 0.5039,  0.2479, -1.4928,  ...,  0.5700,  0.2201,  0.0112],\n",
       "         ...,\n",
       "         [ 0.4965,  0.2517, -1.4369,  ...,  0.5645,  0.2217,  0.0130],\n",
       "         [ 0.4956,  0.2516, -1.4394,  ...,  0.5637,  0.2215,  0.0129],\n",
       "         [ 0.4943,  0.2514, -1.4394,  ...,  0.5628,  0.2207,  0.0124]]),\n",
       " tensor([[ 0.5269,  0.2488, -1.5232,  ...,  0.5929,  0.2181,  0.0118],\n",
       "         [ 0.5260,  0.2493, -1.4445,  ...,  0.5918,  0.2172,  0.0111],\n",
       "         [ 0.5250,  0.2497, -1.4588,  ...,  0.5916,  0.2171,  0.0113],\n",
       "         ...,\n",
       "         [ 0.5126,  0.2514, -1.5292,  ...,  0.5827,  0.2212,  0.0138],\n",
       "         [ 0.5125,  0.2512, -1.5273,  ...,  0.5813,  0.2204,  0.0136],\n",
       "         [ 0.5123,  0.2512, -1.5221,  ...,  0.5795,  0.2200,  0.0137]]),\n",
       " tensor([[ 0.5103,  0.2330, -1.4731,  ...,  0.5745,  0.2056,  0.0102],\n",
       "         [ 0.5071,  0.2360, -1.5453,  ...,  0.5731,  0.2055,  0.0103],\n",
       "         [ 0.5052,  0.2381, -1.5650,  ...,  0.5733,  0.2056,  0.0100],\n",
       "         ...,\n",
       "         [ 0.4875,  0.2316, -1.5252,  ...,  0.5606,  0.1993,  0.0132],\n",
       "         [ 0.4872,  0.2318, -1.5227,  ...,  0.5604,  0.1997,  0.0129],\n",
       "         [ 0.4870,  0.2318, -1.5220,  ...,  0.5604,  0.2000,  0.0129]]),\n",
       " tensor([[ 0.4952,  0.2338, -1.3905,  ...,  0.5593,  0.2078,  0.0128],\n",
       "         [ 0.4926,  0.2435, -1.4861,  ...,  0.5600,  0.2072,  0.0117],\n",
       "         [ 0.4916,  0.2483, -1.4905,  ...,  0.5596,  0.2079,  0.0126],\n",
       "         ...,\n",
       "         [ 0.4846,  0.2462, -1.4163,  ...,  0.5649,  0.2045,  0.0151],\n",
       "         [ 0.4852,  0.2450, -1.4038,  ...,  0.5648,  0.2038,  0.0156],\n",
       "         [ 0.4857,  0.2436, -1.3897,  ...,  0.5648,  0.2033,  0.0155]]),\n",
       " tensor([[ 0.4828,  0.2604, -1.2334,  ...,  0.5483,  0.2258,  0.0073],\n",
       "         [ 0.4816,  0.2606, -1.4555,  ...,  0.5474,  0.2267,  0.0087],\n",
       "         [ 0.4809,  0.2608, -1.4653,  ...,  0.5475,  0.2266,  0.0088],\n",
       "         ...,\n",
       "         [ 0.4832,  0.2490, -1.4275,  ...,  0.5557,  0.2156,  0.0123],\n",
       "         [ 0.4845,  0.2491, -1.4277,  ...,  0.5566,  0.2158,  0.0124],\n",
       "         [ 0.4855,  0.2492, -1.4367,  ...,  0.5573,  0.2163,  0.0122]]),\n",
       " tensor([[ 0.5122,  0.2456, -1.3706,  ...,  0.5836,  0.2207,  0.0125],\n",
       "         [ 0.5121,  0.2461, -1.4417,  ...,  0.5818,  0.2208,  0.0118],\n",
       "         [ 0.5121,  0.2465, -1.4591,  ...,  0.5815,  0.2204,  0.0118],\n",
       "         ...,\n",
       "         [ 0.5017,  0.2434, -1.4740,  ...,  0.5812,  0.2105,  0.0155],\n",
       "         [ 0.5022,  0.2433, -1.4619,  ...,  0.5818,  0.2102,  0.0157],\n",
       "         [ 0.5032,  0.2431, -1.4609,  ...,  0.5821,  0.2097,  0.0163]]),\n",
       " tensor([[ 0.4849,  0.2484, -1.3873,  ...,  0.5543,  0.2162,  0.0108],\n",
       "         [ 0.4846,  0.2500, -1.4881,  ...,  0.5539,  0.2157,  0.0111],\n",
       "         [ 0.4844,  0.2507, -1.4935,  ...,  0.5537,  0.2161,  0.0111],\n",
       "         ...,\n",
       "         [ 0.4589,  0.2435, -1.4798,  ...,  0.5299,  0.2058,  0.0120],\n",
       "         [ 0.4586,  0.2436, -1.4788,  ...,  0.5293,  0.2056,  0.0122],\n",
       "         [ 0.4583,  0.2437, -1.4790,  ...,  0.5289,  0.2052,  0.0123]]),\n",
       " tensor([[ 0.5199,  0.2290, -1.2810,  ...,  0.5876,  0.2058,  0.0103],\n",
       "         [ 0.5195,  0.2307, -1.3821,  ...,  0.5873,  0.2059,  0.0106],\n",
       "         [ 0.5193,  0.2327, -1.4100,  ...,  0.5877,  0.2059,  0.0109],\n",
       "         ...,\n",
       "         [ 0.5108,  0.2431, -1.3919,  ...,  0.5781,  0.2077,  0.0105],\n",
       "         [ 0.5093,  0.2422, -1.3894,  ...,  0.5768,  0.2068,  0.0103],\n",
       "         [ 0.5079,  0.2405, -1.3818,  ...,  0.5751,  0.2053,  0.0102]]),\n",
       " tensor([[ 0.5005,  0.2439, -1.3629,  ...,  0.5694,  0.2139,  0.0154],\n",
       "         [ 0.5002,  0.2448, -1.5049,  ...,  0.5688,  0.2128,  0.0146],\n",
       "         [ 0.4999,  0.2457, -1.5287,  ...,  0.5683,  0.2134,  0.0148],\n",
       "         ...,\n",
       "         [ 0.4965,  0.2433, -1.3673,  ...,  0.5670,  0.2114,  0.0169],\n",
       "         [ 0.4960,  0.2433, -1.3676,  ...,  0.5660,  0.2107,  0.0168],\n",
       "         [ 0.4950,  0.2433, -1.3637,  ...,  0.5651,  0.2100,  0.0170]])]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the sequences\n",
    "import torch\n",
    "sequences = load_keypoint_sequences(file_paths)\n",
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40, 160, 1662])\n"
     ]
    }
   ],
   "source": [
    "# Pad the sequences to the same length\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "padded_sequences = pad_sequence(sequences, batch_first=True)\n",
    "pad_sequence\n",
    "print(padded_sequences.shape) # (batch_size, max_sequence_length, num_keypoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['กฎกระทรวง',\n",
       " 'กฎหมายรัฐธรรมนูญ',\n",
       " 'กรมอนามัย',\n",
       " 'กรรม',\n",
       " 'กรรมสิทธิ์',\n",
       " 'กระโดด',\n",
       " 'กล้วยบวชชี',\n",
       " 'กล้วยเชื่อม',\n",
       " 'กังวล',\n",
       " 'กีฬา',\n",
       " 'น้อง',\n",
       " 'เขิน',\n",
       " 'เขื่อนดิน',\n",
       " 'เขื่อนสิริกิติ์',\n",
       " 'เข้าใจผิด',\n",
       " 'เคย',\n",
       " 'เครียด',\n",
       " 'เครื่องปั่นดิน',\n",
       " 'เครื่องหมายการค้า',\n",
       " 'เจอ',\n",
       " 'เจ้าหนี้',\n",
       " 'เช่าซื้อ',\n",
       " 'เช่าทรัพย์',\n",
       " 'เซอร์เบีย',\n",
       " 'เซเนกัล',\n",
       " 'เซ็ง',\n",
       " 'เดิน',\n",
       " 'เดิมพัน',\n",
       " 'เพลีย',\n",
       " 'เมื่อย',\n",
       " 'เม็กซิโก',\n",
       " 'เฮโรอีน',\n",
       " 'แกมเบีย',\n",
       " 'แซมเบีย',\n",
       " 'โกหก',\n",
       " 'โจทก์',\n",
       " 'โชจู',\n",
       " 'ใกล้',\n",
       " 'ไดโนเสาร์',\n",
       " 'ไอซ์']"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [action.split(\".\")[0] for action in actions]\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "       34, 35, 36, 37, 38, 39], dtype=int64)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "labels = le.fit_transform(labels)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# Create a custom dataset\n",
    "class KeypointDataset(Dataset):\n",
    "    def __init__(self, file_paths, labels):\n",
    "        self.file_paths = file_paths\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        keypoints = np.load(self.file_paths[idx])\n",
    "        label = self.labels[idx]\n",
    "        return torch.tensor(keypoints, dtype=torch.float32), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset\n",
    "dataset = KeypointDataset(file_paths, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Data for different actions/กฎกระทรวง.mp4/กฎกระทรวง.npy', 'Data for different actions/กฎหมายรัฐธรรมนูญ.mp4/กฎหมายรัฐธรรมนูญ.npy', 'Data for different actions/กรมอนามัย.mp4/กรมอนามัย.npy', 'Data for different actions/กรรม.mp4/กรรม.npy', 'Data for different actions/กรรมสิทธิ์.mp4/กรรมสิทธิ์.npy', 'Data for different actions/กระโดด.mp4/กระโดด.npy', 'Data for different actions/กล้วยบวชชี.mp4/กล้วยบวชชี.npy', 'Data for different actions/กล้วยเชื่อม.mp4/กล้วยเชื่อม.npy', 'Data for different actions/กังวล.mp4/กังวล.npy', 'Data for different actions/กีฬา.mp4/กีฬา.npy', 'Data for different actions/น้อง.mp4/น้อง.npy', 'Data for different actions/เขิน.mp4/เขิน.npy', 'Data for different actions/เขื่อนดิน.mp4/เขื่อนดิน.npy', 'Data for different actions/เขื่อนสิริกิติ์.mp4/เขื่อนสิริกิติ์.npy', 'Data for different actions/เข้าใจผิด.mp4/เข้าใจผิด.npy', 'Data for different actions/เคย.mp4/เคย.npy', 'Data for different actions/เครียด.mp4/เครียด.npy', 'Data for different actions/เครื่องปั่นดิน.mp4/เครื่องปั่นดิน.npy', 'Data for different actions/เครื่องหมายการค้า.mp4/เครื่องหมายการค้า.npy', 'Data for different actions/เจอ.mp4/เจอ.npy', 'Data for different actions/เจ้าหนี้.mp4/เจ้าหนี้.npy', 'Data for different actions/เช่าซื้อ.mp4/เช่าซื้อ.npy', 'Data for different actions/เช่าทรัพย์.mp4/เช่าทรัพย์.npy', 'Data for different actions/เซอร์เบีย.mp4/เซอร์เบีย.npy', 'Data for different actions/เซเนกัล.mp4/เซเนกัล.npy', 'Data for different actions/เซ็ง.mp4/เซ็ง.npy', 'Data for different actions/เดิน.mp4/เดิน.npy', 'Data for different actions/เดิมพัน.mp4/เดิมพัน.npy', 'Data for different actions/เพลีย.mp4/เพลีย.npy', 'Data for different actions/เมื่อย.mp4/เมื่อย.npy', 'Data for different actions/เม็กซิโก.mp4/เม็กซิโก.npy', 'Data for different actions/เฮโรอีน.mp4/เฮโรอีน.npy', 'Data for different actions/แกมเบีย.mp4/แกมเบีย.npy', 'Data for different actions/แซมเบีย.mp4/แซมเบีย.npy', 'Data for different actions/โกหก.mp4/โกหก.npy', 'Data for different actions/โจทก์.mp4/โจทก์.npy', 'Data for different actions/โชจู.mp4/โชจู.npy', 'Data for different actions/ใกล้.mp4/ใกล้.npy', 'Data for different actions/ไดโนเสาร์.mp4/ไดโนเสาร์.npy', 'Data for different actions/ไอซ์.mp4/ไอซ์.npy']\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]\n"
     ]
    }
   ],
   "source": [
    "print(dataset.file_paths)\n",
    "print(dataset.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collate function for padding\n",
    "def collate_fn(batch):\n",
    "    sequences, labels = zip(*batch)\n",
    "    padded_sequences = pad_sequence(sequences, batch_first=True)\n",
    "    return padded_sequences, torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x2dac81add30>"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the DataLoader\n",
    "batch_size = 4\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        \n",
    "        # Forward propagate the LSTM\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        \n",
    "        # Use the last time step's output for classification\n",
    "        out = out[:, -1, :]\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set device (use GPU if available)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model, loss function, and optimizer\n",
    "model = LSTMModel(input_size=1662, hidden_size=128, num_layers=2, num_classes=40).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()  # For multi-class classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1200], Loss: 3.7810 , Accuracy : 0.00%\n",
      "Epoch [2/1200], Loss: 3.6636 , Accuracy : 2.50%\n",
      "Epoch [3/1200], Loss: 3.5815 , Accuracy : 2.50%\n",
      "Epoch [4/1200], Loss: 3.4915 , Accuracy : 2.50%\n",
      "Epoch [5/1200], Loss: 3.7647 , Accuracy : 5.00%\n",
      "Epoch [6/1200], Loss: 3.5749 , Accuracy : 2.50%\n",
      "Epoch [7/1200], Loss: 3.5216 , Accuracy : 0.00%\n",
      "Epoch [8/1200], Loss: 3.2230 , Accuracy : 0.00%\n",
      "Epoch [9/1200], Loss: 3.4597 , Accuracy : 2.50%\n",
      "Epoch [10/1200], Loss: 3.5898 , Accuracy : 2.50%\n",
      "Epoch [11/1200], Loss: 3.5472 , Accuracy : 7.50%\n",
      "Epoch [12/1200], Loss: 3.6885 , Accuracy : 2.50%\n",
      "Epoch [13/1200], Loss: 2.8373 , Accuracy : 5.00%\n",
      "Epoch [14/1200], Loss: 3.4267 , Accuracy : 5.00%\n",
      "Epoch [15/1200], Loss: 3.9432 , Accuracy : 2.50%\n",
      "Epoch [16/1200], Loss: 3.3971 , Accuracy : 5.00%\n",
      "Epoch [17/1200], Loss: 3.4749 , Accuracy : 7.50%\n",
      "Epoch [18/1200], Loss: 3.7209 , Accuracy : 7.50%\n",
      "Epoch [19/1200], Loss: 3.8852 , Accuracy : 7.50%\n",
      "Epoch [20/1200], Loss: 3.4751 , Accuracy : 10.00%\n",
      "Epoch [21/1200], Loss: 3.3599 , Accuracy : 5.00%\n",
      "Epoch [22/1200], Loss: 2.9074 , Accuracy : 7.50%\n",
      "Epoch [23/1200], Loss: 3.1995 , Accuracy : 10.00%\n",
      "Epoch [24/1200], Loss: 3.3334 , Accuracy : 10.00%\n",
      "Epoch [25/1200], Loss: 3.0191 , Accuracy : 10.00%\n",
      "Epoch [26/1200], Loss: 2.9776 , Accuracy : 12.50%\n",
      "Epoch [27/1200], Loss: 3.0222 , Accuracy : 7.50%\n",
      "Epoch [28/1200], Loss: 2.6021 , Accuracy : 5.00%\n",
      "Epoch [29/1200], Loss: 3.0527 , Accuracy : 12.50%\n",
      "Epoch [30/1200], Loss: 3.4112 , Accuracy : 5.00%\n",
      "Epoch [31/1200], Loss: 2.5906 , Accuracy : 10.00%\n",
      "Epoch [32/1200], Loss: 3.0413 , Accuracy : 10.00%\n",
      "Epoch [33/1200], Loss: 2.6411 , Accuracy : 7.50%\n",
      "Epoch [34/1200], Loss: 2.9869 , Accuracy : 12.50%\n",
      "Epoch [35/1200], Loss: 2.6725 , Accuracy : 12.50%\n",
      "Epoch [36/1200], Loss: 3.0987 , Accuracy : 10.00%\n",
      "Epoch [37/1200], Loss: 3.2110 , Accuracy : 10.00%\n",
      "Epoch [38/1200], Loss: 3.7084 , Accuracy : 10.00%\n",
      "Epoch [39/1200], Loss: 3.0565 , Accuracy : 7.50%\n",
      "Epoch [40/1200], Loss: 2.8676 , Accuracy : 10.00%\n",
      "Epoch [41/1200], Loss: 2.3191 , Accuracy : 15.00%\n",
      "Epoch [42/1200], Loss: 3.0342 , Accuracy : 17.50%\n",
      "Epoch [43/1200], Loss: 2.5447 , Accuracy : 10.00%\n",
      "Epoch [44/1200], Loss: 3.5301 , Accuracy : 15.00%\n",
      "Epoch [45/1200], Loss: 2.7921 , Accuracy : 12.50%\n",
      "Epoch [46/1200], Loss: 2.7184 , Accuracy : 12.50%\n",
      "Epoch [47/1200], Loss: 4.3511 , Accuracy : 12.50%\n",
      "Epoch [48/1200], Loss: 2.9413 , Accuracy : 17.50%\n",
      "Epoch [49/1200], Loss: 3.9802 , Accuracy : 17.50%\n",
      "Epoch [50/1200], Loss: 3.1041 , Accuracy : 12.50%\n",
      "Epoch [51/1200], Loss: 2.9555 , Accuracy : 15.00%\n",
      "Epoch [52/1200], Loss: 3.0721 , Accuracy : 12.50%\n",
      "Epoch [53/1200], Loss: 3.2687 , Accuracy : 15.00%\n",
      "Epoch [54/1200], Loss: 2.8749 , Accuracy : 17.50%\n",
      "Epoch [55/1200], Loss: 4.7573 , Accuracy : 12.50%\n",
      "Epoch [56/1200], Loss: 2.8430 , Accuracy : 15.00%\n",
      "Epoch [57/1200], Loss: 3.0492 , Accuracy : 12.50%\n",
      "Epoch [58/1200], Loss: 3.3335 , Accuracy : 17.50%\n",
      "Epoch [59/1200], Loss: 2.9738 , Accuracy : 17.50%\n",
      "Epoch [60/1200], Loss: 3.3819 , Accuracy : 17.50%\n",
      "Epoch [61/1200], Loss: 3.2391 , Accuracy : 12.50%\n",
      "Epoch [62/1200], Loss: 3.4129 , Accuracy : 5.00%\n",
      "Epoch [63/1200], Loss: 3.1221 , Accuracy : 7.50%\n",
      "Epoch [64/1200], Loss: 3.2841 , Accuracy : 2.50%\n",
      "Epoch [65/1200], Loss: 3.9196 , Accuracy : 17.50%\n",
      "Epoch [66/1200], Loss: 3.7227 , Accuracy : 15.00%\n",
      "Epoch [67/1200], Loss: 3.8113 , Accuracy : 20.00%\n",
      "Epoch [68/1200], Loss: 3.3159 , Accuracy : 17.50%\n",
      "Epoch [69/1200], Loss: 2.9568 , Accuracy : 17.50%\n",
      "Epoch [70/1200], Loss: 2.6140 , Accuracy : 30.00%\n",
      "Epoch [71/1200], Loss: 2.7449 , Accuracy : 17.50%\n",
      "Epoch [72/1200], Loss: 3.1769 , Accuracy : 20.00%\n",
      "Epoch [73/1200], Loss: 2.9985 , Accuracy : 20.00%\n",
      "Epoch [74/1200], Loss: 3.1231 , Accuracy : 20.00%\n",
      "Epoch [75/1200], Loss: 2.2401 , Accuracy : 22.50%\n",
      "Epoch [76/1200], Loss: 3.4307 , Accuracy : 17.50%\n",
      "Epoch [77/1200], Loss: 2.7072 , Accuracy : 25.00%\n",
      "Epoch [78/1200], Loss: 2.2149 , Accuracy : 20.00%\n",
      "Epoch [79/1200], Loss: 2.2824 , Accuracy : 25.00%\n",
      "Epoch [80/1200], Loss: 2.4367 , Accuracy : 15.00%\n",
      "Epoch [81/1200], Loss: 3.4235 , Accuracy : 12.50%\n",
      "Epoch [82/1200], Loss: 3.2231 , Accuracy : 22.50%\n",
      "Epoch [83/1200], Loss: 2.9569 , Accuracy : 12.50%\n",
      "Epoch [84/1200], Loss: 2.6737 , Accuracy : 22.50%\n",
      "Epoch [85/1200], Loss: 3.2345 , Accuracy : 22.50%\n",
      "Epoch [86/1200], Loss: 2.5956 , Accuracy : 27.50%\n",
      "Epoch [87/1200], Loss: 2.2042 , Accuracy : 15.00%\n",
      "Epoch [88/1200], Loss: 3.5085 , Accuracy : 25.00%\n",
      "Epoch [89/1200], Loss: 2.8959 , Accuracy : 20.00%\n",
      "Epoch [90/1200], Loss: 2.0736 , Accuracy : 25.00%\n",
      "Epoch [91/1200], Loss: 3.3021 , Accuracy : 27.50%\n",
      "Epoch [92/1200], Loss: 2.2850 , Accuracy : 25.00%\n",
      "Epoch [93/1200], Loss: 2.6736 , Accuracy : 27.50%\n",
      "Epoch [94/1200], Loss: 2.8480 , Accuracy : 30.00%\n",
      "Epoch [95/1200], Loss: 1.8196 , Accuracy : 25.00%\n",
      "Epoch [96/1200], Loss: 2.9221 , Accuracy : 22.50%\n",
      "Epoch [97/1200], Loss: 2.9570 , Accuracy : 32.50%\n",
      "Epoch [98/1200], Loss: 3.2607 , Accuracy : 27.50%\n",
      "Epoch [99/1200], Loss: 3.9950 , Accuracy : 32.50%\n",
      "Epoch [100/1200], Loss: 2.1920 , Accuracy : 30.00%\n",
      "Epoch [101/1200], Loss: 2.7456 , Accuracy : 35.00%\n",
      "Epoch [102/1200], Loss: 2.6592 , Accuracy : 30.00%\n",
      "Epoch [103/1200], Loss: 2.7499 , Accuracy : 22.50%\n",
      "Epoch [104/1200], Loss: 3.0185 , Accuracy : 32.50%\n",
      "Epoch [105/1200], Loss: 3.0082 , Accuracy : 30.00%\n",
      "Epoch [106/1200], Loss: 2.4554 , Accuracy : 32.50%\n",
      "Epoch [107/1200], Loss: 1.5170 , Accuracy : 32.50%\n",
      "Epoch [108/1200], Loss: 2.3822 , Accuracy : 30.00%\n",
      "Epoch [109/1200], Loss: 2.4176 , Accuracy : 25.00%\n",
      "Epoch [110/1200], Loss: 1.6527 , Accuracy : 30.00%\n",
      "Epoch [111/1200], Loss: 1.7705 , Accuracy : 30.00%\n",
      "Epoch [112/1200], Loss: 2.1837 , Accuracy : 25.00%\n",
      "Epoch [113/1200], Loss: 2.0859 , Accuracy : 37.50%\n",
      "Epoch [114/1200], Loss: 1.1797 , Accuracy : 32.50%\n",
      "Epoch [115/1200], Loss: 2.3751 , Accuracy : 35.00%\n",
      "Epoch [116/1200], Loss: 2.5552 , Accuracy : 40.00%\n",
      "Epoch [117/1200], Loss: 1.0043 , Accuracy : 35.00%\n",
      "Epoch [118/1200], Loss: 2.0414 , Accuracy : 30.00%\n",
      "Epoch [119/1200], Loss: 3.5214 , Accuracy : 22.50%\n",
      "Epoch [120/1200], Loss: 1.8854 , Accuracy : 15.00%\n",
      "Epoch [121/1200], Loss: 2.5146 , Accuracy : 22.50%\n",
      "Epoch [122/1200], Loss: 3.5949 , Accuracy : 15.00%\n",
      "Epoch [123/1200], Loss: 3.4078 , Accuracy : 15.00%\n",
      "Epoch [124/1200], Loss: 1.7538 , Accuracy : 17.50%\n",
      "Epoch [125/1200], Loss: 2.4557 , Accuracy : 20.00%\n",
      "Epoch [126/1200], Loss: 2.9925 , Accuracy : 25.00%\n",
      "Epoch [127/1200], Loss: 2.9763 , Accuracy : 30.00%\n",
      "Epoch [128/1200], Loss: 3.0815 , Accuracy : 20.00%\n",
      "Epoch [129/1200], Loss: 2.1319 , Accuracy : 17.50%\n",
      "Epoch [130/1200], Loss: 2.1751 , Accuracy : 15.00%\n",
      "Epoch [131/1200], Loss: 2.0773 , Accuracy : 25.00%\n",
      "Epoch [132/1200], Loss: 2.7445 , Accuracy : 30.00%\n",
      "Epoch [133/1200], Loss: 2.1603 , Accuracy : 20.00%\n",
      "Epoch [134/1200], Loss: 2.8789 , Accuracy : 25.00%\n",
      "Epoch [135/1200], Loss: 2.0592 , Accuracy : 22.50%\n",
      "Epoch [136/1200], Loss: 2.2175 , Accuracy : 30.00%\n",
      "Epoch [137/1200], Loss: 2.6647 , Accuracy : 35.00%\n",
      "Epoch [138/1200], Loss: 1.9658 , Accuracy : 25.00%\n",
      "Epoch [139/1200], Loss: 2.9839 , Accuracy : 27.50%\n",
      "Epoch [140/1200], Loss: 1.2557 , Accuracy : 30.00%\n",
      "Epoch [141/1200], Loss: 2.3335 , Accuracy : 30.00%\n",
      "Epoch [142/1200], Loss: 1.6963 , Accuracy : 30.00%\n",
      "Epoch [143/1200], Loss: 2.8991 , Accuracy : 32.50%\n",
      "Epoch [144/1200], Loss: 1.5075 , Accuracy : 30.00%\n",
      "Epoch [145/1200], Loss: 2.5882 , Accuracy : 30.00%\n",
      "Epoch [146/1200], Loss: 1.3357 , Accuracy : 37.50%\n",
      "Epoch [147/1200], Loss: 1.6754 , Accuracy : 30.00%\n",
      "Epoch [148/1200], Loss: 2.6169 , Accuracy : 32.50%\n",
      "Epoch [149/1200], Loss: 2.5326 , Accuracy : 32.50%\n",
      "Epoch [150/1200], Loss: 2.4319 , Accuracy : 37.50%\n",
      "Epoch [151/1200], Loss: 1.6326 , Accuracy : 32.50%\n",
      "Epoch [152/1200], Loss: 1.6737 , Accuracy : 32.50%\n",
      "Epoch [153/1200], Loss: 2.0626 , Accuracy : 37.50%\n",
      "Epoch [154/1200], Loss: 1.6328 , Accuracy : 22.50%\n",
      "Epoch [155/1200], Loss: 2.8582 , Accuracy : 25.00%\n",
      "Epoch [156/1200], Loss: 2.3190 , Accuracy : 27.50%\n",
      "Epoch [157/1200], Loss: 1.5782 , Accuracy : 22.50%\n",
      "Epoch [158/1200], Loss: 1.7277 , Accuracy : 45.00%\n",
      "Epoch [159/1200], Loss: 1.5023 , Accuracy : 37.50%\n",
      "Epoch [160/1200], Loss: 1.8194 , Accuracy : 45.00%\n",
      "Epoch [161/1200], Loss: 0.6691 , Accuracy : 30.00%\n",
      "Epoch [162/1200], Loss: 3.5049 , Accuracy : 45.00%\n",
      "Epoch [163/1200], Loss: 3.4195 , Accuracy : 42.50%\n",
      "Epoch [164/1200], Loss: 1.6749 , Accuracy : 30.00%\n",
      "Epoch [165/1200], Loss: 2.1402 , Accuracy : 32.50%\n",
      "Epoch [166/1200], Loss: 2.7638 , Accuracy : 27.50%\n",
      "Epoch [167/1200], Loss: 3.0209 , Accuracy : 22.50%\n",
      "Epoch [168/1200], Loss: 2.3276 , Accuracy : 32.50%\n",
      "Epoch [169/1200], Loss: 2.0715 , Accuracy : 27.50%\n",
      "Epoch [170/1200], Loss: 2.0293 , Accuracy : 37.50%\n",
      "Epoch [171/1200], Loss: 1.7336 , Accuracy : 35.00%\n",
      "Epoch [172/1200], Loss: 3.2066 , Accuracy : 42.50%\n",
      "Epoch [173/1200], Loss: 1.9223 , Accuracy : 37.50%\n",
      "Epoch [174/1200], Loss: 1.0597 , Accuracy : 37.50%\n",
      "Epoch [175/1200], Loss: 1.0796 , Accuracy : 37.50%\n",
      "Epoch [176/1200], Loss: 1.7860 , Accuracy : 40.00%\n",
      "Epoch [177/1200], Loss: 1.6532 , Accuracy : 40.00%\n",
      "Epoch [178/1200], Loss: 1.5694 , Accuracy : 45.00%\n",
      "Epoch [179/1200], Loss: 1.0709 , Accuracy : 42.50%\n",
      "Epoch [180/1200], Loss: 1.4966 , Accuracy : 37.50%\n",
      "Epoch [181/1200], Loss: 0.8369 , Accuracy : 45.00%\n",
      "Epoch [182/1200], Loss: 1.8236 , Accuracy : 37.50%\n",
      "Epoch [183/1200], Loss: 2.3478 , Accuracy : 45.00%\n",
      "Epoch [184/1200], Loss: 1.2902 , Accuracy : 37.50%\n",
      "Epoch [185/1200], Loss: 2.2555 , Accuracy : 27.50%\n",
      "Epoch [186/1200], Loss: 3.1736 , Accuracy : 35.00%\n",
      "Epoch [187/1200], Loss: 5.6177 , Accuracy : 32.50%\n",
      "Epoch [188/1200], Loss: 2.3628 , Accuracy : 35.00%\n",
      "Epoch [189/1200], Loss: 1.6926 , Accuracy : 37.50%\n",
      "Epoch [190/1200], Loss: 1.2228 , Accuracy : 40.00%\n",
      "Epoch [191/1200], Loss: 3.0237 , Accuracy : 40.00%\n",
      "Epoch [192/1200], Loss: 1.2388 , Accuracy : 35.00%\n",
      "Epoch [193/1200], Loss: 1.2312 , Accuracy : 37.50%\n",
      "Epoch [194/1200], Loss: 2.5845 , Accuracy : 40.00%\n",
      "Epoch [195/1200], Loss: 1.5007 , Accuracy : 45.00%\n",
      "Epoch [196/1200], Loss: 1.9450 , Accuracy : 40.00%\n",
      "Epoch [197/1200], Loss: 2.1111 , Accuracy : 40.00%\n",
      "Epoch [198/1200], Loss: 1.1892 , Accuracy : 42.50%\n",
      "Epoch [199/1200], Loss: 1.4781 , Accuracy : 37.50%\n",
      "Epoch [200/1200], Loss: 0.8845 , Accuracy : 35.00%\n",
      "Epoch [201/1200], Loss: 2.7563 , Accuracy : 47.50%\n",
      "Epoch [202/1200], Loss: 1.7677 , Accuracy : 40.00%\n",
      "Epoch [203/1200], Loss: 1.4912 , Accuracy : 40.00%\n",
      "Epoch [204/1200], Loss: 0.8332 , Accuracy : 40.00%\n",
      "Epoch [205/1200], Loss: 1.2821 , Accuracy : 40.00%\n",
      "Epoch [206/1200], Loss: 1.1575 , Accuracy : 42.50%\n",
      "Epoch [207/1200], Loss: 1.8889 , Accuracy : 45.00%\n",
      "Epoch [208/1200], Loss: 1.3353 , Accuracy : 35.00%\n",
      "Epoch [209/1200], Loss: 0.9382 , Accuracy : 45.00%\n",
      "Epoch [210/1200], Loss: 1.8298 , Accuracy : 52.50%\n",
      "Epoch [211/1200], Loss: 1.7542 , Accuracy : 30.00%\n",
      "Epoch [212/1200], Loss: 1.4093 , Accuracy : 37.50%\n",
      "Epoch [213/1200], Loss: 2.4428 , Accuracy : 35.00%\n",
      "Epoch [214/1200], Loss: 0.9804 , Accuracy : 35.00%\n",
      "Epoch [215/1200], Loss: 1.1885 , Accuracy : 45.00%\n",
      "Epoch [216/1200], Loss: 2.9016 , Accuracy : 42.50%\n",
      "Epoch [217/1200], Loss: 1.6690 , Accuracy : 35.00%\n",
      "Epoch [218/1200], Loss: 2.2498 , Accuracy : 35.00%\n",
      "Epoch [219/1200], Loss: 1.6244 , Accuracy : 35.00%\n",
      "Epoch [220/1200], Loss: 3.2349 , Accuracy : 35.00%\n",
      "Epoch [221/1200], Loss: 1.2332 , Accuracy : 22.50%\n",
      "Epoch [222/1200], Loss: 2.0789 , Accuracy : 35.00%\n",
      "Epoch [223/1200], Loss: 2.8854 , Accuracy : 27.50%\n",
      "Epoch [224/1200], Loss: 1.2074 , Accuracy : 35.00%\n",
      "Epoch [225/1200], Loss: 1.8244 , Accuracy : 42.50%\n",
      "Epoch [226/1200], Loss: 1.1306 , Accuracy : 37.50%\n",
      "Epoch [227/1200], Loss: 1.9109 , Accuracy : 42.50%\n",
      "Epoch [228/1200], Loss: 1.2691 , Accuracy : 30.00%\n",
      "Epoch [229/1200], Loss: 1.1374 , Accuracy : 32.50%\n",
      "Epoch [230/1200], Loss: 0.9933 , Accuracy : 37.50%\n",
      "Epoch [231/1200], Loss: 1.5116 , Accuracy : 40.00%\n",
      "Epoch [232/1200], Loss: 1.4989 , Accuracy : 37.50%\n",
      "Epoch [233/1200], Loss: 1.6280 , Accuracy : 45.00%\n",
      "Epoch [234/1200], Loss: 1.3852 , Accuracy : 37.50%\n",
      "Epoch [235/1200], Loss: 0.4533 , Accuracy : 32.50%\n",
      "Epoch [236/1200], Loss: 2.1082 , Accuracy : 40.00%\n",
      "Epoch [237/1200], Loss: 3.0935 , Accuracy : 50.00%\n",
      "Epoch [238/1200], Loss: 3.0111 , Accuracy : 37.50%\n",
      "Epoch [239/1200], Loss: 1.7530 , Accuracy : 45.00%\n",
      "Epoch [240/1200], Loss: 1.2552 , Accuracy : 40.00%\n",
      "Epoch [241/1200], Loss: 1.3363 , Accuracy : 50.00%\n",
      "Epoch [242/1200], Loss: 0.7745 , Accuracy : 45.00%\n",
      "Epoch [243/1200], Loss: 1.0692 , Accuracy : 37.50%\n",
      "Epoch [244/1200], Loss: 1.8542 , Accuracy : 50.00%\n",
      "Epoch [245/1200], Loss: 1.3959 , Accuracy : 37.50%\n",
      "Epoch [246/1200], Loss: 1.2340 , Accuracy : 40.00%\n",
      "Epoch [247/1200], Loss: 0.8047 , Accuracy : 37.50%\n",
      "Epoch [248/1200], Loss: 0.9577 , Accuracy : 45.00%\n",
      "Epoch [249/1200], Loss: 1.0120 , Accuracy : 47.50%\n",
      "Epoch [250/1200], Loss: 2.2629 , Accuracy : 40.00%\n",
      "Epoch [251/1200], Loss: 2.1454 , Accuracy : 40.00%\n",
      "Epoch [252/1200], Loss: 1.4469 , Accuracy : 47.50%\n",
      "Epoch [253/1200], Loss: 2.1931 , Accuracy : 35.00%\n",
      "Epoch [254/1200], Loss: 2.3094 , Accuracy : 32.50%\n",
      "Epoch [255/1200], Loss: 1.0721 , Accuracy : 37.50%\n",
      "Epoch [256/1200], Loss: 1.7874 , Accuracy : 42.50%\n",
      "Epoch [257/1200], Loss: 1.7295 , Accuracy : 45.00%\n",
      "Epoch [258/1200], Loss: 0.7692 , Accuracy : 37.50%\n",
      "Epoch [259/1200], Loss: 1.1009 , Accuracy : 42.50%\n",
      "Epoch [260/1200], Loss: 1.0202 , Accuracy : 52.50%\n",
      "Epoch [261/1200], Loss: 2.3466 , Accuracy : 40.00%\n",
      "Epoch [262/1200], Loss: 1.2872 , Accuracy : 52.50%\n",
      "Epoch [263/1200], Loss: 1.6019 , Accuracy : 47.50%\n",
      "Epoch [264/1200], Loss: 1.0110 , Accuracy : 45.00%\n",
      "Epoch [265/1200], Loss: 1.7691 , Accuracy : 35.00%\n",
      "Epoch [266/1200], Loss: 2.0738 , Accuracy : 27.50%\n",
      "Epoch [267/1200], Loss: 2.1171 , Accuracy : 35.00%\n",
      "Epoch [268/1200], Loss: 2.1209 , Accuracy : 35.00%\n",
      "Epoch [269/1200], Loss: 2.0828 , Accuracy : 35.00%\n",
      "Epoch [270/1200], Loss: 2.6625 , Accuracy : 50.00%\n",
      "Epoch [271/1200], Loss: 1.2753 , Accuracy : 47.50%\n",
      "Epoch [272/1200], Loss: 0.4832 , Accuracy : 45.00%\n",
      "Epoch [273/1200], Loss: 1.6694 , Accuracy : 35.00%\n",
      "Epoch [274/1200], Loss: 0.9187 , Accuracy : 47.50%\n",
      "Epoch [275/1200], Loss: 0.5811 , Accuracy : 42.50%\n",
      "Epoch [276/1200], Loss: 1.3417 , Accuracy : 45.00%\n",
      "Epoch [277/1200], Loss: 0.7813 , Accuracy : 55.00%\n",
      "Epoch [278/1200], Loss: 2.3132 , Accuracy : 52.50%\n",
      "Epoch [279/1200], Loss: 1.1679 , Accuracy : 42.50%\n",
      "Epoch [280/1200], Loss: 0.7298 , Accuracy : 52.50%\n",
      "Epoch [281/1200], Loss: 2.5952 , Accuracy : 50.00%\n",
      "Epoch [282/1200], Loss: 0.9504 , Accuracy : 45.00%\n",
      "Epoch [283/1200], Loss: 1.1399 , Accuracy : 45.00%\n",
      "Epoch [284/1200], Loss: 1.9591 , Accuracy : 45.00%\n",
      "Epoch [285/1200], Loss: 1.6679 , Accuracy : 35.00%\n",
      "Epoch [286/1200], Loss: 2.3146 , Accuracy : 40.00%\n",
      "Epoch [287/1200], Loss: 1.5986 , Accuracy : 47.50%\n",
      "Epoch [288/1200], Loss: 1.1404 , Accuracy : 37.50%\n",
      "Epoch [289/1200], Loss: 1.4592 , Accuracy : 52.50%\n",
      "Epoch [290/1200], Loss: 1.3303 , Accuracy : 45.00%\n",
      "Epoch [291/1200], Loss: 1.0763 , Accuracy : 55.00%\n",
      "Epoch [292/1200], Loss: 0.8947 , Accuracy : 42.50%\n",
      "Epoch [293/1200], Loss: 0.7115 , Accuracy : 52.50%\n",
      "Epoch [294/1200], Loss: 1.7014 , Accuracy : 47.50%\n",
      "Epoch [295/1200], Loss: 2.0453 , Accuracy : 60.00%\n",
      "Epoch [296/1200], Loss: 1.2542 , Accuracy : 47.50%\n",
      "Epoch [297/1200], Loss: 0.5537 , Accuracy : 40.00%\n",
      "Epoch [298/1200], Loss: 2.1182 , Accuracy : 45.00%\n",
      "Epoch [299/1200], Loss: 0.9326 , Accuracy : 47.50%\n",
      "Epoch [300/1200], Loss: 0.7928 , Accuracy : 50.00%\n",
      "Epoch [301/1200], Loss: 0.9445 , Accuracy : 47.50%\n",
      "Epoch [302/1200], Loss: 2.6121 , Accuracy : 40.00%\n",
      "Epoch [303/1200], Loss: 1.2337 , Accuracy : 32.50%\n",
      "Epoch [304/1200], Loss: 1.9213 , Accuracy : 40.00%\n",
      "Epoch [305/1200], Loss: 1.3373 , Accuracy : 47.50%\n",
      "Epoch [306/1200], Loss: 0.4172 , Accuracy : 57.50%\n",
      "Epoch [307/1200], Loss: 0.9073 , Accuracy : 47.50%\n",
      "Epoch [308/1200], Loss: 1.5463 , Accuracy : 40.00%\n",
      "Epoch [309/1200], Loss: 1.6138 , Accuracy : 47.50%\n",
      "Epoch [310/1200], Loss: 0.6032 , Accuracy : 42.50%\n",
      "Epoch [311/1200], Loss: 1.9138 , Accuracy : 42.50%\n",
      "Epoch [312/1200], Loss: 0.8156 , Accuracy : 40.00%\n",
      "Epoch [313/1200], Loss: 0.3971 , Accuracy : 40.00%\n",
      "Epoch [314/1200], Loss: 0.9014 , Accuracy : 42.50%\n",
      "Epoch [315/1200], Loss: 1.0772 , Accuracy : 50.00%\n",
      "Epoch [316/1200], Loss: 1.8055 , Accuracy : 45.00%\n",
      "Epoch [317/1200], Loss: 0.8078 , Accuracy : 55.00%\n",
      "Epoch [318/1200], Loss: 1.0133 , Accuracy : 60.00%\n",
      "Epoch [319/1200], Loss: 1.8694 , Accuracy : 37.50%\n",
      "Epoch [320/1200], Loss: 0.4219 , Accuracy : 47.50%\n",
      "Epoch [321/1200], Loss: 0.9092 , Accuracy : 50.00%\n",
      "Epoch [322/1200], Loss: 0.8690 , Accuracy : 42.50%\n",
      "Epoch [323/1200], Loss: 1.1712 , Accuracy : 47.50%\n",
      "Epoch [324/1200], Loss: 1.7615 , Accuracy : 50.00%\n",
      "Epoch [325/1200], Loss: 0.9740 , Accuracy : 45.00%\n",
      "Epoch [326/1200], Loss: 0.9493 , Accuracy : 37.50%\n",
      "Epoch [327/1200], Loss: 1.1705 , Accuracy : 52.50%\n",
      "Epoch [328/1200], Loss: 1.7657 , Accuracy : 47.50%\n",
      "Epoch [329/1200], Loss: 0.6493 , Accuracy : 57.50%\n",
      "Epoch [330/1200], Loss: 1.4094 , Accuracy : 45.00%\n",
      "Epoch [331/1200], Loss: 1.5080 , Accuracy : 50.00%\n",
      "Epoch [332/1200], Loss: 1.1911 , Accuracy : 47.50%\n",
      "Epoch [333/1200], Loss: 0.8415 , Accuracy : 47.50%\n",
      "Epoch [334/1200], Loss: 2.0808 , Accuracy : 47.50%\n",
      "Epoch [335/1200], Loss: 1.7793 , Accuracy : 42.50%\n",
      "Epoch [336/1200], Loss: 2.8332 , Accuracy : 27.50%\n",
      "Epoch [337/1200], Loss: 2.5774 , Accuracy : 52.50%\n",
      "Epoch [338/1200], Loss: 2.6508 , Accuracy : 42.50%\n",
      "Epoch [339/1200], Loss: 1.0712 , Accuracy : 35.00%\n",
      "Epoch [340/1200], Loss: 1.0439 , Accuracy : 32.50%\n",
      "Epoch [341/1200], Loss: 4.7968 , Accuracy : 20.00%\n",
      "Epoch [342/1200], Loss: 3.0126 , Accuracy : 10.00%\n",
      "Epoch [343/1200], Loss: 2.9383 , Accuracy : 15.00%\n",
      "Epoch [344/1200], Loss: 3.2162 , Accuracy : 15.00%\n",
      "Epoch [345/1200], Loss: 1.6312 , Accuracy : 22.50%\n",
      "Epoch [346/1200], Loss: 2.5798 , Accuracy : 25.00%\n",
      "Epoch [347/1200], Loss: 2.8275 , Accuracy : 30.00%\n",
      "Epoch [348/1200], Loss: 3.9796 , Accuracy : 37.50%\n",
      "Epoch [349/1200], Loss: 2.6897 , Accuracy : 25.00%\n",
      "Epoch [350/1200], Loss: 1.5683 , Accuracy : 25.00%\n",
      "Epoch [351/1200], Loss: 1.2181 , Accuracy : 42.50%\n",
      "Epoch [352/1200], Loss: 2.7055 , Accuracy : 37.50%\n",
      "Epoch [353/1200], Loss: 1.5026 , Accuracy : 37.50%\n",
      "Epoch [354/1200], Loss: 1.7809 , Accuracy : 42.50%\n",
      "Epoch [355/1200], Loss: 2.0289 , Accuracy : 32.50%\n",
      "Epoch [356/1200], Loss: 0.9804 , Accuracy : 42.50%\n",
      "Epoch [357/1200], Loss: 2.7748 , Accuracy : 40.00%\n",
      "Epoch [358/1200], Loss: 1.1292 , Accuracy : 37.50%\n",
      "Epoch [359/1200], Loss: 2.4010 , Accuracy : 52.50%\n",
      "Epoch [360/1200], Loss: 2.0154 , Accuracy : 45.00%\n",
      "Epoch [361/1200], Loss: 2.1177 , Accuracy : 35.00%\n",
      "Epoch [362/1200], Loss: 2.0848 , Accuracy : 37.50%\n",
      "Epoch [363/1200], Loss: 1.8731 , Accuracy : 47.50%\n",
      "Epoch [364/1200], Loss: 1.0597 , Accuracy : 50.00%\n",
      "Epoch [365/1200], Loss: 1.8452 , Accuracy : 42.50%\n",
      "Epoch [366/1200], Loss: 0.7491 , Accuracy : 55.00%\n",
      "Epoch [367/1200], Loss: 1.9028 , Accuracy : 47.50%\n",
      "Epoch [368/1200], Loss: 1.9229 , Accuracy : 32.50%\n",
      "Epoch [369/1200], Loss: 1.2862 , Accuracy : 55.00%\n",
      "Epoch [370/1200], Loss: 0.6959 , Accuracy : 40.00%\n",
      "Epoch [371/1200], Loss: 2.0536 , Accuracy : 50.00%\n",
      "Epoch [372/1200], Loss: 1.1555 , Accuracy : 42.50%\n",
      "Epoch [373/1200], Loss: 1.4715 , Accuracy : 45.00%\n",
      "Epoch [374/1200], Loss: 1.2930 , Accuracy : 42.50%\n",
      "Epoch [375/1200], Loss: 1.9382 , Accuracy : 45.00%\n",
      "Epoch [376/1200], Loss: 2.2728 , Accuracy : 45.00%\n",
      "Epoch [377/1200], Loss: 1.2438 , Accuracy : 32.50%\n",
      "Epoch [378/1200], Loss: 0.9678 , Accuracy : 40.00%\n",
      "Epoch [379/1200], Loss: 1.9042 , Accuracy : 42.50%\n",
      "Epoch [380/1200], Loss: 1.6194 , Accuracy : 40.00%\n",
      "Epoch [381/1200], Loss: 1.4475 , Accuracy : 52.50%\n",
      "Epoch [382/1200], Loss: 1.1920 , Accuracy : 45.00%\n",
      "Epoch [383/1200], Loss: 1.5576 , Accuracy : 40.00%\n",
      "Epoch [384/1200], Loss: 2.0468 , Accuracy : 57.50%\n",
      "Epoch [385/1200], Loss: 0.6703 , Accuracy : 42.50%\n",
      "Epoch [386/1200], Loss: 1.7210 , Accuracy : 42.50%\n",
      "Epoch [387/1200], Loss: 1.7944 , Accuracy : 45.00%\n",
      "Epoch [388/1200], Loss: 0.9123 , Accuracy : 42.50%\n",
      "Epoch [389/1200], Loss: 0.9676 , Accuracy : 32.50%\n",
      "Epoch [390/1200], Loss: 2.0141 , Accuracy : 25.00%\n",
      "Epoch [391/1200], Loss: 0.9704 , Accuracy : 37.50%\n",
      "Epoch [392/1200], Loss: 2.1792 , Accuracy : 37.50%\n",
      "Epoch [393/1200], Loss: 1.1910 , Accuracy : 52.50%\n",
      "Epoch [394/1200], Loss: 1.2222 , Accuracy : 52.50%\n",
      "Epoch [395/1200], Loss: 0.9582 , Accuracy : 40.00%\n",
      "Epoch [396/1200], Loss: 1.0859 , Accuracy : 42.50%\n",
      "Epoch [397/1200], Loss: 1.8639 , Accuracy : 47.50%\n",
      "Epoch [398/1200], Loss: 1.6135 , Accuracy : 50.00%\n",
      "Epoch [399/1200], Loss: 1.6444 , Accuracy : 47.50%\n",
      "Epoch [400/1200], Loss: 1.5463 , Accuracy : 62.50%\n",
      "Epoch [401/1200], Loss: 1.8445 , Accuracy : 37.50%\n",
      "Epoch [402/1200], Loss: 2.5388 , Accuracy : 32.50%\n",
      "Epoch [403/1200], Loss: 0.6626 , Accuracy : 32.50%\n",
      "Epoch [404/1200], Loss: 2.0604 , Accuracy : 30.00%\n",
      "Epoch [405/1200], Loss: 0.8725 , Accuracy : 25.00%\n",
      "Epoch [406/1200], Loss: 1.8781 , Accuracy : 55.00%\n",
      "Epoch [407/1200], Loss: 2.1078 , Accuracy : 45.00%\n",
      "Epoch [408/1200], Loss: 1.1530 , Accuracy : 47.50%\n",
      "Epoch [409/1200], Loss: 0.4028 , Accuracy : 42.50%\n",
      "Epoch [410/1200], Loss: 1.0781 , Accuracy : 45.00%\n",
      "Epoch [411/1200], Loss: 1.4868 , Accuracy : 50.00%\n",
      "Epoch [412/1200], Loss: 0.9635 , Accuracy : 60.00%\n",
      "Epoch [413/1200], Loss: 1.8740 , Accuracy : 50.00%\n",
      "Epoch [414/1200], Loss: 0.8930 , Accuracy : 50.00%\n",
      "Epoch [415/1200], Loss: 0.9248 , Accuracy : 47.50%\n",
      "Epoch [416/1200], Loss: 2.9037 , Accuracy : 57.50%\n",
      "Epoch [417/1200], Loss: 1.6851 , Accuracy : 50.00%\n",
      "Epoch [418/1200], Loss: 1.2701 , Accuracy : 52.50%\n",
      "Epoch [419/1200], Loss: 2.0044 , Accuracy : 52.50%\n",
      "Epoch [420/1200], Loss: 1.9961 , Accuracy : 47.50%\n",
      "Epoch [421/1200], Loss: 0.4375 , Accuracy : 42.50%\n",
      "Epoch [422/1200], Loss: 1.6501 , Accuracy : 50.00%\n",
      "Epoch [423/1200], Loss: 1.7596 , Accuracy : 42.50%\n",
      "Epoch [424/1200], Loss: 1.0617 , Accuracy : 55.00%\n",
      "Epoch [425/1200], Loss: 1.6364 , Accuracy : 55.00%\n",
      "Epoch [426/1200], Loss: 0.9263 , Accuracy : 47.50%\n",
      "Epoch [427/1200], Loss: 1.2870 , Accuracy : 47.50%\n",
      "Epoch [428/1200], Loss: 2.0088 , Accuracy : 30.00%\n",
      "Epoch [429/1200], Loss: 4.8626 , Accuracy : 22.50%\n",
      "Epoch [430/1200], Loss: 1.5433 , Accuracy : 17.50%\n",
      "Epoch [431/1200], Loss: 1.5772 , Accuracy : 35.00%\n",
      "Epoch [432/1200], Loss: 1.5178 , Accuracy : 40.00%\n",
      "Epoch [433/1200], Loss: 2.5336 , Accuracy : 47.50%\n",
      "Epoch [434/1200], Loss: 3.0437 , Accuracy : 22.50%\n",
      "Epoch [435/1200], Loss: 2.3609 , Accuracy : 25.00%\n",
      "Epoch [436/1200], Loss: 1.8207 , Accuracy : 32.50%\n",
      "Epoch [437/1200], Loss: 1.4598 , Accuracy : 32.50%\n",
      "Epoch [438/1200], Loss: 0.9419 , Accuracy : 47.50%\n",
      "Epoch [439/1200], Loss: 1.1447 , Accuracy : 45.00%\n",
      "Epoch [440/1200], Loss: 1.1503 , Accuracy : 50.00%\n",
      "Epoch [441/1200], Loss: 0.8619 , Accuracy : 50.00%\n",
      "Epoch [442/1200], Loss: 0.8686 , Accuracy : 47.50%\n",
      "Epoch [443/1200], Loss: 2.7293 , Accuracy : 37.50%\n",
      "Epoch [444/1200], Loss: 1.0549 , Accuracy : 50.00%\n",
      "Epoch [445/1200], Loss: 0.7297 , Accuracy : 42.50%\n",
      "Epoch [446/1200], Loss: 0.4640 , Accuracy : 52.50%\n",
      "Epoch [447/1200], Loss: 1.1836 , Accuracy : 45.00%\n",
      "Epoch [448/1200], Loss: 1.0778 , Accuracy : 45.00%\n",
      "Epoch [449/1200], Loss: 1.3035 , Accuracy : 45.00%\n",
      "Epoch [450/1200], Loss: 1.3684 , Accuracy : 50.00%\n",
      "Epoch [451/1200], Loss: 1.9841 , Accuracy : 47.50%\n",
      "Epoch [452/1200], Loss: 4.8403 , Accuracy : 45.00%\n",
      "Epoch [453/1200], Loss: 1.0185 , Accuracy : 52.50%\n",
      "Epoch [454/1200], Loss: 2.3073 , Accuracy : 50.00%\n",
      "Epoch [455/1200], Loss: 0.8967 , Accuracy : 45.00%\n",
      "Epoch [456/1200], Loss: 1.1762 , Accuracy : 47.50%\n",
      "Epoch [457/1200], Loss: 0.8128 , Accuracy : 55.00%\n",
      "Epoch [458/1200], Loss: 2.2476 , Accuracy : 45.00%\n",
      "Epoch [459/1200], Loss: 2.4502 , Accuracy : 50.00%\n",
      "Epoch [460/1200], Loss: 1.5230 , Accuracy : 52.50%\n",
      "Epoch [461/1200], Loss: 0.5062 , Accuracy : 55.00%\n",
      "Epoch [462/1200], Loss: 1.5579 , Accuracy : 62.50%\n",
      "Epoch [463/1200], Loss: 1.7810 , Accuracy : 50.00%\n",
      "Epoch [464/1200], Loss: 1.4456 , Accuracy : 52.50%\n",
      "Epoch [465/1200], Loss: 2.3787 , Accuracy : 55.00%\n",
      "Epoch [466/1200], Loss: 1.7902 , Accuracy : 45.00%\n",
      "Epoch [467/1200], Loss: 2.1003 , Accuracy : 52.50%\n",
      "Epoch [468/1200], Loss: 2.2597 , Accuracy : 37.50%\n",
      "Epoch [469/1200], Loss: 1.1281 , Accuracy : 42.50%\n",
      "Epoch [470/1200], Loss: 2.3142 , Accuracy : 55.00%\n",
      "Epoch [471/1200], Loss: 2.0050 , Accuracy : 50.00%\n",
      "Epoch [472/1200], Loss: 1.6851 , Accuracy : 40.00%\n",
      "Epoch [473/1200], Loss: 1.2866 , Accuracy : 40.00%\n",
      "Epoch [474/1200], Loss: 1.4156 , Accuracy : 47.50%\n",
      "Epoch [475/1200], Loss: 0.6839 , Accuracy : 60.00%\n",
      "Epoch [476/1200], Loss: 0.4754 , Accuracy : 55.00%\n",
      "Epoch [477/1200], Loss: 1.4408 , Accuracy : 52.50%\n",
      "Epoch [478/1200], Loss: 1.1714 , Accuracy : 45.00%\n",
      "Epoch [479/1200], Loss: 1.3824 , Accuracy : 47.50%\n",
      "Epoch [480/1200], Loss: 1.6540 , Accuracy : 57.50%\n",
      "Epoch [481/1200], Loss: 0.8095 , Accuracy : 47.50%\n",
      "Epoch [482/1200], Loss: 0.8095 , Accuracy : 55.00%\n",
      "Epoch [483/1200], Loss: 0.3605 , Accuracy : 57.50%\n",
      "Epoch [484/1200], Loss: 2.5550 , Accuracy : 57.50%\n",
      "Epoch [485/1200], Loss: 3.1773 , Accuracy : 12.50%\n",
      "Epoch [486/1200], Loss: 1.0740 , Accuracy : 47.50%\n",
      "Epoch [487/1200], Loss: 2.6358 , Accuracy : 35.00%\n",
      "Epoch [488/1200], Loss: 1.3544 , Accuracy : 42.50%\n",
      "Epoch [489/1200], Loss: 1.6554 , Accuracy : 42.50%\n",
      "Epoch [490/1200], Loss: 1.5497 , Accuracy : 50.00%\n",
      "Epoch [491/1200], Loss: 1.4112 , Accuracy : 35.00%\n",
      "Epoch [492/1200], Loss: 2.6451 , Accuracy : 50.00%\n",
      "Epoch [493/1200], Loss: 1.7141 , Accuracy : 47.50%\n",
      "Epoch [494/1200], Loss: 2.2471 , Accuracy : 37.50%\n",
      "Epoch [495/1200], Loss: 0.7108 , Accuracy : 40.00%\n",
      "Epoch [496/1200], Loss: 1.1356 , Accuracy : 47.50%\n",
      "Epoch [497/1200], Loss: 0.8155 , Accuracy : 52.50%\n",
      "Epoch [498/1200], Loss: 2.0092 , Accuracy : 47.50%\n",
      "Epoch [499/1200], Loss: 1.4759 , Accuracy : 40.00%\n",
      "Epoch [500/1200], Loss: 1.9512 , Accuracy : 45.00%\n",
      "Epoch [501/1200], Loss: 1.3045 , Accuracy : 62.50%\n",
      "Epoch [502/1200], Loss: 1.7699 , Accuracy : 42.50%\n",
      "Epoch [503/1200], Loss: 0.4062 , Accuracy : 52.50%\n",
      "Epoch [504/1200], Loss: 0.9413 , Accuracy : 57.50%\n",
      "Epoch [505/1200], Loss: 1.1456 , Accuracy : 55.00%\n",
      "Epoch [506/1200], Loss: 0.8911 , Accuracy : 57.50%\n",
      "Epoch [507/1200], Loss: 1.7840 , Accuracy : 40.00%\n",
      "Epoch [508/1200], Loss: 1.6710 , Accuracy : 47.50%\n",
      "Epoch [509/1200], Loss: 0.9097 , Accuracy : 52.50%\n",
      "Epoch [510/1200], Loss: 1.5670 , Accuracy : 50.00%\n",
      "Epoch [511/1200], Loss: 0.6627 , Accuracy : 52.50%\n",
      "Epoch [512/1200], Loss: 1.6868 , Accuracy : 57.50%\n",
      "Epoch [513/1200], Loss: 0.7335 , Accuracy : 52.50%\n",
      "Epoch [514/1200], Loss: 1.7942 , Accuracy : 50.00%\n",
      "Epoch [515/1200], Loss: 1.0617 , Accuracy : 57.50%\n",
      "Epoch [516/1200], Loss: 0.8981 , Accuracy : 42.50%\n",
      "Epoch [517/1200], Loss: 1.1600 , Accuracy : 55.00%\n",
      "Epoch [518/1200], Loss: 0.4735 , Accuracy : 47.50%\n",
      "Epoch [519/1200], Loss: 0.3196 , Accuracy : 50.00%\n",
      "Epoch [520/1200], Loss: 1.9219 , Accuracy : 60.00%\n",
      "Epoch [521/1200], Loss: 0.5909 , Accuracy : 47.50%\n",
      "Epoch [522/1200], Loss: 1.4075 , Accuracy : 50.00%\n",
      "Epoch [523/1200], Loss: 0.7628 , Accuracy : 55.00%\n",
      "Epoch [524/1200], Loss: 0.6939 , Accuracy : 55.00%\n",
      "Epoch [525/1200], Loss: 2.6048 , Accuracy : 47.50%\n",
      "Epoch [526/1200], Loss: 1.7740 , Accuracy : 45.00%\n",
      "Epoch [527/1200], Loss: 1.1895 , Accuracy : 57.50%\n",
      "Epoch [528/1200], Loss: 1.3983 , Accuracy : 52.50%\n",
      "Epoch [529/1200], Loss: 0.9713 , Accuracy : 62.50%\n",
      "Epoch [530/1200], Loss: 0.5301 , Accuracy : 50.00%\n",
      "Epoch [531/1200], Loss: 0.0716 , Accuracy : 55.00%\n",
      "Epoch [532/1200], Loss: 0.8504 , Accuracy : 60.00%\n",
      "Epoch [533/1200], Loss: 1.0739 , Accuracy : 42.50%\n",
      "Epoch [534/1200], Loss: 1.1011 , Accuracy : 50.00%\n",
      "Epoch [535/1200], Loss: 1.5881 , Accuracy : 50.00%\n",
      "Epoch [536/1200], Loss: 1.5277 , Accuracy : 55.00%\n",
      "Epoch [537/1200], Loss: 2.5339 , Accuracy : 45.00%\n",
      "Epoch [538/1200], Loss: 0.4451 , Accuracy : 50.00%\n",
      "Epoch [539/1200], Loss: 1.6876 , Accuracy : 62.50%\n",
      "Epoch [540/1200], Loss: 0.9253 , Accuracy : 57.50%\n",
      "Epoch [541/1200], Loss: 1.0670 , Accuracy : 55.00%\n",
      "Epoch [542/1200], Loss: 1.2583 , Accuracy : 47.50%\n",
      "Epoch [543/1200], Loss: 2.4750 , Accuracy : 35.00%\n",
      "Epoch [544/1200], Loss: 0.8524 , Accuracy : 55.00%\n",
      "Epoch [545/1200], Loss: 1.0337 , Accuracy : 37.50%\n",
      "Epoch [546/1200], Loss: 1.3511 , Accuracy : 50.00%\n",
      "Epoch [547/1200], Loss: 0.6640 , Accuracy : 45.00%\n",
      "Epoch [548/1200], Loss: 1.4590 , Accuracy : 47.50%\n",
      "Epoch [549/1200], Loss: 1.3350 , Accuracy : 45.00%\n",
      "Epoch [550/1200], Loss: 1.9126 , Accuracy : 42.50%\n",
      "Epoch [551/1200], Loss: 1.5873 , Accuracy : 50.00%\n",
      "Epoch [552/1200], Loss: 1.8439 , Accuracy : 50.00%\n",
      "Epoch [553/1200], Loss: 0.4161 , Accuracy : 55.00%\n",
      "Epoch [554/1200], Loss: 1.1645 , Accuracy : 52.50%\n",
      "Epoch [555/1200], Loss: 0.9684 , Accuracy : 45.00%\n",
      "Epoch [556/1200], Loss: 0.9320 , Accuracy : 45.00%\n",
      "Epoch [557/1200], Loss: 1.1156 , Accuracy : 52.50%\n",
      "Epoch [558/1200], Loss: 1.5714 , Accuracy : 57.50%\n",
      "Epoch [559/1200], Loss: 1.9002 , Accuracy : 45.00%\n",
      "Epoch [560/1200], Loss: 1.0275 , Accuracy : 60.00%\n",
      "Epoch [561/1200], Loss: 0.8885 , Accuracy : 50.00%\n",
      "Epoch [562/1200], Loss: 2.1710 , Accuracy : 47.50%\n",
      "Epoch [563/1200], Loss: 1.0494 , Accuracy : 55.00%\n",
      "Epoch [564/1200], Loss: 1.6033 , Accuracy : 52.50%\n",
      "Epoch [565/1200], Loss: 1.1270 , Accuracy : 47.50%\n",
      "Epoch [566/1200], Loss: 0.7593 , Accuracy : 60.00%\n",
      "Epoch [567/1200], Loss: 1.2639 , Accuracy : 55.00%\n",
      "Epoch [568/1200], Loss: 0.4224 , Accuracy : 52.50%\n",
      "Epoch [569/1200], Loss: 0.5420 , Accuracy : 47.50%\n",
      "Epoch [570/1200], Loss: 1.6573 , Accuracy : 50.00%\n",
      "Epoch [571/1200], Loss: 2.4152 , Accuracy : 52.50%\n",
      "Epoch [572/1200], Loss: 1.4673 , Accuracy : 52.50%\n",
      "Epoch [573/1200], Loss: 1.7459 , Accuracy : 55.00%\n",
      "Epoch [574/1200], Loss: 1.6201 , Accuracy : 57.50%\n",
      "Epoch [575/1200], Loss: 0.8110 , Accuracy : 55.00%\n",
      "Epoch [576/1200], Loss: 1.4384 , Accuracy : 55.00%\n",
      "Epoch [577/1200], Loss: 1.0204 , Accuracy : 60.00%\n",
      "Epoch [578/1200], Loss: 0.1307 , Accuracy : 60.00%\n",
      "Epoch [579/1200], Loss: 0.5291 , Accuracy : 52.50%\n",
      "Epoch [580/1200], Loss: 1.4114 , Accuracy : 45.00%\n",
      "Epoch [581/1200], Loss: 1.8059 , Accuracy : 45.00%\n",
      "Epoch [582/1200], Loss: 1.0755 , Accuracy : 37.50%\n",
      "Epoch [583/1200], Loss: 1.0189 , Accuracy : 52.50%\n",
      "Epoch [584/1200], Loss: 0.6656 , Accuracy : 50.00%\n",
      "Epoch [585/1200], Loss: 1.0998 , Accuracy : 50.00%\n",
      "Epoch [586/1200], Loss: 1.1615 , Accuracy : 52.50%\n",
      "Epoch [587/1200], Loss: 0.5191 , Accuracy : 40.00%\n",
      "Epoch [588/1200], Loss: 0.6342 , Accuracy : 55.00%\n",
      "Epoch [589/1200], Loss: 3.3601 , Accuracy : 42.50%\n",
      "Epoch [590/1200], Loss: 2.4817 , Accuracy : 37.50%\n",
      "Epoch [591/1200], Loss: 1.7092 , Accuracy : 35.00%\n",
      "Epoch [592/1200], Loss: 1.7963 , Accuracy : 40.00%\n",
      "Epoch [593/1200], Loss: 0.6249 , Accuracy : 55.00%\n",
      "Epoch [594/1200], Loss: 3.2375 , Accuracy : 40.00%\n",
      "Epoch [595/1200], Loss: 1.4644 , Accuracy : 27.50%\n",
      "Epoch [596/1200], Loss: 1.8576 , Accuracy : 40.00%\n",
      "Epoch [597/1200], Loss: 1.3265 , Accuracy : 47.50%\n",
      "Epoch [598/1200], Loss: 1.5886 , Accuracy : 47.50%\n",
      "Epoch [599/1200], Loss: 1.5443 , Accuracy : 42.50%\n",
      "Epoch [600/1200], Loss: 1.0754 , Accuracy : 40.00%\n",
      "Epoch [601/1200], Loss: 0.5582 , Accuracy : 47.50%\n",
      "Epoch [602/1200], Loss: 1.0084 , Accuracy : 47.50%\n",
      "Epoch [603/1200], Loss: 0.6980 , Accuracy : 57.50%\n",
      "Epoch [604/1200], Loss: 0.7318 , Accuracy : 55.00%\n",
      "Epoch [605/1200], Loss: 1.8528 , Accuracy : 55.00%\n",
      "Epoch [606/1200], Loss: 1.5296 , Accuracy : 57.50%\n",
      "Epoch [607/1200], Loss: 0.7836 , Accuracy : 70.00%\n",
      "Epoch [608/1200], Loss: 1.3947 , Accuracy : 50.00%\n",
      "Epoch [609/1200], Loss: 0.4987 , Accuracy : 57.50%\n",
      "Epoch [610/1200], Loss: 1.1554 , Accuracy : 50.00%\n",
      "Epoch [611/1200], Loss: 1.0539 , Accuracy : 57.50%\n",
      "Epoch [612/1200], Loss: 0.5579 , Accuracy : 52.50%\n",
      "Epoch [613/1200], Loss: 1.3323 , Accuracy : 57.50%\n",
      "Epoch [614/1200], Loss: 0.8171 , Accuracy : 55.00%\n",
      "Epoch [615/1200], Loss: 0.9863 , Accuracy : 52.50%\n",
      "Epoch [616/1200], Loss: 1.4093 , Accuracy : 40.00%\n",
      "Epoch [617/1200], Loss: 1.2053 , Accuracy : 62.50%\n",
      "Epoch [618/1200], Loss: 0.8878 , Accuracy : 45.00%\n",
      "Epoch [619/1200], Loss: 2.6225 , Accuracy : 30.00%\n",
      "Epoch [620/1200], Loss: 1.1723 , Accuracy : 45.00%\n",
      "Epoch [621/1200], Loss: 0.7426 , Accuracy : 40.00%\n",
      "Epoch [622/1200], Loss: 1.4290 , Accuracy : 57.50%\n",
      "Epoch [623/1200], Loss: 1.9084 , Accuracy : 50.00%\n",
      "Epoch [624/1200], Loss: 0.7154 , Accuracy : 50.00%\n",
      "Epoch [625/1200], Loss: 1.2404 , Accuracy : 50.00%\n",
      "Epoch [626/1200], Loss: 0.5213 , Accuracy : 45.00%\n",
      "Epoch [627/1200], Loss: 0.8367 , Accuracy : 52.50%\n",
      "Epoch [628/1200], Loss: 0.6391 , Accuracy : 47.50%\n",
      "Epoch [629/1200], Loss: 0.7061 , Accuracy : 65.00%\n",
      "Epoch [630/1200], Loss: 0.4456 , Accuracy : 65.00%\n",
      "Epoch [631/1200], Loss: 0.8916 , Accuracy : 55.00%\n",
      "Epoch [632/1200], Loss: 1.3858 , Accuracy : 52.50%\n",
      "Epoch [633/1200], Loss: 1.1617 , Accuracy : 47.50%\n",
      "Epoch [634/1200], Loss: 0.8972 , Accuracy : 67.50%\n",
      "Epoch [635/1200], Loss: 0.3751 , Accuracy : 65.00%\n",
      "Epoch [636/1200], Loss: 0.9326 , Accuracy : 60.00%\n",
      "Epoch [637/1200], Loss: 1.5627 , Accuracy : 60.00%\n",
      "Epoch [638/1200], Loss: 1.3290 , Accuracy : 55.00%\n",
      "Epoch [639/1200], Loss: 0.3704 , Accuracy : 65.00%\n",
      "Epoch [640/1200], Loss: 0.5729 , Accuracy : 60.00%\n",
      "Epoch [641/1200], Loss: 1.8005 , Accuracy : 52.50%\n",
      "Epoch [642/1200], Loss: 0.6267 , Accuracy : 67.50%\n",
      "Epoch [643/1200], Loss: 1.6977 , Accuracy : 57.50%\n",
      "Epoch [644/1200], Loss: 1.5261 , Accuracy : 57.50%\n",
      "Epoch [645/1200], Loss: 0.8431 , Accuracy : 72.50%\n",
      "Epoch [646/1200], Loss: 1.0670 , Accuracy : 60.00%\n",
      "Epoch [647/1200], Loss: 1.2645 , Accuracy : 55.00%\n",
      "Epoch [648/1200], Loss: 1.3562 , Accuracy : 55.00%\n",
      "Epoch [649/1200], Loss: 0.1098 , Accuracy : 62.50%\n",
      "Epoch [650/1200], Loss: 0.5861 , Accuracy : 47.50%\n",
      "Epoch [651/1200], Loss: 1.0692 , Accuracy : 50.00%\n",
      "Epoch [652/1200], Loss: 0.9447 , Accuracy : 52.50%\n",
      "Epoch [653/1200], Loss: 1.4969 , Accuracy : 55.00%\n",
      "Epoch [654/1200], Loss: 0.4531 , Accuracy : 65.00%\n",
      "Epoch [655/1200], Loss: 1.6101 , Accuracy : 50.00%\n",
      "Epoch [656/1200], Loss: 0.6856 , Accuracy : 62.50%\n",
      "Epoch [657/1200], Loss: 1.1655 , Accuracy : 62.50%\n",
      "Epoch [658/1200], Loss: 1.3594 , Accuracy : 60.00%\n",
      "Epoch [659/1200], Loss: 1.1728 , Accuracy : 75.00%\n",
      "Epoch [660/1200], Loss: 0.3022 , Accuracy : 62.50%\n",
      "Epoch [661/1200], Loss: 0.5467 , Accuracy : 50.00%\n",
      "Epoch [662/1200], Loss: 0.8525 , Accuracy : 67.50%\n",
      "Epoch [663/1200], Loss: 0.5893 , Accuracy : 52.50%\n",
      "Epoch [664/1200], Loss: 0.5091 , Accuracy : 57.50%\n",
      "Epoch [665/1200], Loss: 0.4274 , Accuracy : 65.00%\n",
      "Epoch [666/1200], Loss: 0.5436 , Accuracy : 65.00%\n",
      "Epoch [667/1200], Loss: 0.9231 , Accuracy : 55.00%\n",
      "Epoch [668/1200], Loss: 0.7374 , Accuracy : 60.00%\n",
      "Epoch [669/1200], Loss: 0.5535 , Accuracy : 67.50%\n",
      "Epoch [670/1200], Loss: 0.5217 , Accuracy : 50.00%\n",
      "Epoch [671/1200], Loss: 0.9272 , Accuracy : 72.50%\n",
      "Epoch [672/1200], Loss: 0.3670 , Accuracy : 60.00%\n",
      "Epoch [673/1200], Loss: 2.2670 , Accuracy : 60.00%\n",
      "Epoch [674/1200], Loss: 0.4071 , Accuracy : 57.50%\n",
      "Epoch [675/1200], Loss: 0.9482 , Accuracy : 57.50%\n",
      "Epoch [676/1200], Loss: 0.4122 , Accuracy : 55.00%\n",
      "Epoch [677/1200], Loss: 0.5797 , Accuracy : 65.00%\n",
      "Epoch [678/1200], Loss: 0.9447 , Accuracy : 65.00%\n",
      "Epoch [679/1200], Loss: 0.3347 , Accuracy : 60.00%\n",
      "Epoch [680/1200], Loss: 0.4038 , Accuracy : 72.50%\n",
      "Epoch [681/1200], Loss: 1.0490 , Accuracy : 72.50%\n",
      "Epoch [682/1200], Loss: 0.5715 , Accuracy : 70.00%\n",
      "Epoch [683/1200], Loss: 0.3694 , Accuracy : 55.00%\n",
      "Epoch [684/1200], Loss: 0.7251 , Accuracy : 67.50%\n",
      "Epoch [685/1200], Loss: 0.4533 , Accuracy : 60.00%\n",
      "Epoch [686/1200], Loss: 0.5689 , Accuracy : 70.00%\n",
      "Epoch [687/1200], Loss: 1.5425 , Accuracy : 62.50%\n",
      "Epoch [688/1200], Loss: 0.8673 , Accuracy : 67.50%\n",
      "Epoch [689/1200], Loss: 2.2111 , Accuracy : 57.50%\n",
      "Epoch [690/1200], Loss: 1.2520 , Accuracy : 55.00%\n",
      "Epoch [691/1200], Loss: 1.5370 , Accuracy : 50.00%\n",
      "Epoch [692/1200], Loss: 0.3063 , Accuracy : 65.00%\n",
      "Epoch [693/1200], Loss: 0.8152 , Accuracy : 72.50%\n",
      "Epoch [694/1200], Loss: 0.7856 , Accuracy : 65.00%\n",
      "Epoch [695/1200], Loss: 0.7983 , Accuracy : 72.50%\n",
      "Epoch [696/1200], Loss: 0.2638 , Accuracy : 75.00%\n",
      "Epoch [697/1200], Loss: 0.4495 , Accuracy : 65.00%\n",
      "Epoch [698/1200], Loss: 1.6858 , Accuracy : 55.00%\n",
      "Epoch [699/1200], Loss: 1.1671 , Accuracy : 52.50%\n",
      "Epoch [700/1200], Loss: 1.2172 , Accuracy : 62.50%\n",
      "Epoch [701/1200], Loss: 0.0898 , Accuracy : 70.00%\n",
      "Epoch [702/1200], Loss: 0.3793 , Accuracy : 70.00%\n",
      "Epoch [703/1200], Loss: 1.0750 , Accuracy : 75.00%\n",
      "Epoch [704/1200], Loss: 0.6535 , Accuracy : 62.50%\n",
      "Epoch [705/1200], Loss: 1.1064 , Accuracy : 57.50%\n",
      "Epoch [706/1200], Loss: 0.5617 , Accuracy : 62.50%\n",
      "Epoch [707/1200], Loss: 0.0953 , Accuracy : 70.00%\n",
      "Epoch [708/1200], Loss: 0.7477 , Accuracy : 67.50%\n",
      "Epoch [709/1200], Loss: 0.6382 , Accuracy : 60.00%\n",
      "Epoch [710/1200], Loss: 0.1692 , Accuracy : 65.00%\n",
      "Epoch [711/1200], Loss: 1.3889 , Accuracy : 62.50%\n",
      "Epoch [712/1200], Loss: 1.0657 , Accuracy : 57.50%\n",
      "Epoch [713/1200], Loss: 0.3684 , Accuracy : 57.50%\n",
      "Epoch [714/1200], Loss: 1.7530 , Accuracy : 70.00%\n",
      "Epoch [715/1200], Loss: 0.5283 , Accuracy : 67.50%\n",
      "Epoch [716/1200], Loss: 0.9531 , Accuracy : 65.00%\n",
      "Epoch [717/1200], Loss: 1.1722 , Accuracy : 57.50%\n",
      "Epoch [718/1200], Loss: 0.3918 , Accuracy : 67.50%\n",
      "Epoch [719/1200], Loss: 1.3329 , Accuracy : 57.50%\n",
      "Epoch [720/1200], Loss: 1.1314 , Accuracy : 57.50%\n",
      "Epoch [721/1200], Loss: 0.4463 , Accuracy : 62.50%\n",
      "Epoch [722/1200], Loss: 0.4437 , Accuracy : 65.00%\n",
      "Epoch [723/1200], Loss: 0.9010 , Accuracy : 72.50%\n",
      "Epoch [724/1200], Loss: 0.8984 , Accuracy : 62.50%\n",
      "Epoch [725/1200], Loss: 0.1954 , Accuracy : 62.50%\n",
      "Epoch [726/1200], Loss: 0.4652 , Accuracy : 52.50%\n",
      "Epoch [727/1200], Loss: 1.4923 , Accuracy : 52.50%\n",
      "Epoch [728/1200], Loss: 1.2108 , Accuracy : 67.50%\n",
      "Epoch [729/1200], Loss: 1.7924 , Accuracy : 62.50%\n",
      "Epoch [730/1200], Loss: 0.4956 , Accuracy : 55.00%\n",
      "Epoch [731/1200], Loss: 2.0949 , Accuracy : 55.00%\n",
      "Epoch [732/1200], Loss: 1.7178 , Accuracy : 60.00%\n",
      "Epoch [733/1200], Loss: 0.9492 , Accuracy : 50.00%\n",
      "Epoch [734/1200], Loss: 1.3937 , Accuracy : 67.50%\n",
      "Epoch [735/1200], Loss: 1.7383 , Accuracy : 57.50%\n",
      "Epoch [736/1200], Loss: 0.8920 , Accuracy : 57.50%\n",
      "Epoch [737/1200], Loss: 0.6036 , Accuracy : 47.50%\n",
      "Epoch [738/1200], Loss: 0.1614 , Accuracy : 50.00%\n",
      "Epoch [739/1200], Loss: 0.5222 , Accuracy : 60.00%\n",
      "Epoch [740/1200], Loss: 1.0579 , Accuracy : 72.50%\n",
      "Epoch [741/1200], Loss: 0.5807 , Accuracy : 75.00%\n",
      "Epoch [742/1200], Loss: 0.5447 , Accuracy : 47.50%\n",
      "Epoch [743/1200], Loss: 0.3202 , Accuracy : 60.00%\n",
      "Epoch [744/1200], Loss: 1.4883 , Accuracy : 57.50%\n",
      "Epoch [745/1200], Loss: 1.4990 , Accuracy : 62.50%\n",
      "Epoch [746/1200], Loss: 1.4108 , Accuracy : 67.50%\n",
      "Epoch [747/1200], Loss: 0.5973 , Accuracy : 65.00%\n",
      "Epoch [748/1200], Loss: 1.7090 , Accuracy : 60.00%\n",
      "Epoch [749/1200], Loss: 1.4621 , Accuracy : 57.50%\n",
      "Epoch [750/1200], Loss: 1.0404 , Accuracy : 62.50%\n",
      "Epoch [751/1200], Loss: 1.9500 , Accuracy : 62.50%\n",
      "Epoch [752/1200], Loss: 0.2639 , Accuracy : 67.50%\n",
      "Epoch [753/1200], Loss: 0.4540 , Accuracy : 72.50%\n",
      "Epoch [754/1200], Loss: 0.1569 , Accuracy : 75.00%\n",
      "Epoch [755/1200], Loss: 0.3990 , Accuracy : 75.00%\n",
      "Epoch [756/1200], Loss: 1.8587 , Accuracy : 70.00%\n",
      "Epoch [757/1200], Loss: 0.2729 , Accuracy : 62.50%\n",
      "Epoch [758/1200], Loss: 0.2662 , Accuracy : 70.00%\n",
      "Epoch [759/1200], Loss: 0.2213 , Accuracy : 67.50%\n",
      "Epoch [760/1200], Loss: 0.4278 , Accuracy : 70.00%\n",
      "Epoch [761/1200], Loss: 0.5732 , Accuracy : 55.00%\n",
      "Epoch [762/1200], Loss: 0.6891 , Accuracy : 67.50%\n",
      "Epoch [763/1200], Loss: 0.8300 , Accuracy : 62.50%\n",
      "Epoch [764/1200], Loss: 1.0485 , Accuracy : 67.50%\n",
      "Epoch [765/1200], Loss: 1.0940 , Accuracy : 67.50%\n",
      "Epoch [766/1200], Loss: 0.6493 , Accuracy : 70.00%\n",
      "Epoch [767/1200], Loss: 0.9833 , Accuracy : 55.00%\n",
      "Epoch [768/1200], Loss: 0.3373 , Accuracy : 57.50%\n",
      "Epoch [769/1200], Loss: 1.3593 , Accuracy : 65.00%\n",
      "Epoch [770/1200], Loss: 0.8102 , Accuracy : 55.00%\n",
      "Epoch [771/1200], Loss: 1.7355 , Accuracy : 62.50%\n",
      "Epoch [772/1200], Loss: 0.9492 , Accuracy : 67.50%\n",
      "Epoch [773/1200], Loss: 0.4791 , Accuracy : 55.00%\n",
      "Epoch [774/1200], Loss: 1.3639 , Accuracy : 70.00%\n",
      "Epoch [775/1200], Loss: 0.0454 , Accuracy : 65.00%\n",
      "Epoch [776/1200], Loss: 1.8655 , Accuracy : 65.00%\n",
      "Epoch [777/1200], Loss: 3.6109 , Accuracy : 45.00%\n",
      "Epoch [778/1200], Loss: 0.9260 , Accuracy : 42.50%\n",
      "Epoch [779/1200], Loss: 1.3861 , Accuracy : 45.00%\n",
      "Epoch [780/1200], Loss: 3.8288 , Accuracy : 52.50%\n",
      "Epoch [781/1200], Loss: 1.4615 , Accuracy : 42.50%\n",
      "Epoch [782/1200], Loss: 1.4119 , Accuracy : 52.50%\n",
      "Epoch [783/1200], Loss: 1.4940 , Accuracy : 52.50%\n",
      "Epoch [784/1200], Loss: 1.0713 , Accuracy : 42.50%\n",
      "Epoch [785/1200], Loss: 1.2363 , Accuracy : 62.50%\n",
      "Epoch [786/1200], Loss: 1.4479 , Accuracy : 47.50%\n",
      "Epoch [787/1200], Loss: 0.1741 , Accuracy : 52.50%\n",
      "Epoch [788/1200], Loss: 1.8180 , Accuracy : 40.00%\n",
      "Epoch [789/1200], Loss: 1.8094 , Accuracy : 57.50%\n",
      "Epoch [790/1200], Loss: 0.5337 , Accuracy : 65.00%\n",
      "Epoch [791/1200], Loss: 1.2127 , Accuracy : 42.50%\n",
      "Epoch [792/1200], Loss: 0.8478 , Accuracy : 65.00%\n",
      "Epoch [793/1200], Loss: 0.2514 , Accuracy : 57.50%\n",
      "Epoch [794/1200], Loss: 0.4846 , Accuracy : 57.50%\n",
      "Epoch [795/1200], Loss: 0.5397 , Accuracy : 60.00%\n",
      "Epoch [796/1200], Loss: 1.5440 , Accuracy : 67.50%\n",
      "Epoch [797/1200], Loss: 1.1821 , Accuracy : 50.00%\n",
      "Epoch [798/1200], Loss: 0.0399 , Accuracy : 65.00%\n",
      "Epoch [799/1200], Loss: 1.3503 , Accuracy : 75.00%\n",
      "Epoch [800/1200], Loss: 1.7964 , Accuracy : 62.50%\n",
      "Epoch [801/1200], Loss: 0.3213 , Accuracy : 55.00%\n",
      "Epoch [802/1200], Loss: 1.4148 , Accuracy : 65.00%\n",
      "Epoch [803/1200], Loss: 0.7403 , Accuracy : 60.00%\n",
      "Epoch [804/1200], Loss: 0.4945 , Accuracy : 62.50%\n",
      "Epoch [805/1200], Loss: 0.8125 , Accuracy : 55.00%\n",
      "Epoch [806/1200], Loss: 1.6504 , Accuracy : 62.50%\n",
      "Epoch [807/1200], Loss: 0.6976 , Accuracy : 57.50%\n",
      "Epoch [808/1200], Loss: 0.6029 , Accuracy : 65.00%\n",
      "Epoch [809/1200], Loss: 1.0854 , Accuracy : 65.00%\n",
      "Epoch [810/1200], Loss: 1.0012 , Accuracy : 60.00%\n",
      "Epoch [811/1200], Loss: 0.4259 , Accuracy : 65.00%\n",
      "Epoch [812/1200], Loss: 2.2794 , Accuracy : 57.50%\n",
      "Epoch [813/1200], Loss: 1.0003 , Accuracy : 62.50%\n",
      "Epoch [814/1200], Loss: 0.9889 , Accuracy : 65.00%\n",
      "Epoch [815/1200], Loss: 0.8987 , Accuracy : 57.50%\n",
      "Epoch [816/1200], Loss: 1.5961 , Accuracy : 65.00%\n",
      "Epoch [817/1200], Loss: 1.0693 , Accuracy : 57.50%\n",
      "Epoch [818/1200], Loss: 0.4680 , Accuracy : 52.50%\n",
      "Epoch [819/1200], Loss: 2.4194 , Accuracy : 22.50%\n",
      "Epoch [820/1200], Loss: 1.3461 , Accuracy : 27.50%\n",
      "Epoch [821/1200], Loss: 2.9399 , Accuracy : 40.00%\n",
      "Epoch [822/1200], Loss: 1.1984 , Accuracy : 45.00%\n",
      "Epoch [823/1200], Loss: 1.2775 , Accuracy : 47.50%\n",
      "Epoch [824/1200], Loss: 1.2436 , Accuracy : 42.50%\n",
      "Epoch [825/1200], Loss: 0.4637 , Accuracy : 62.50%\n",
      "Epoch [826/1200], Loss: 0.4084 , Accuracy : 55.00%\n",
      "Epoch [827/1200], Loss: 2.3662 , Accuracy : 45.00%\n",
      "Epoch [828/1200], Loss: 0.9697 , Accuracy : 42.50%\n",
      "Epoch [829/1200], Loss: 1.4609 , Accuracy : 37.50%\n",
      "Epoch [830/1200], Loss: 1.4375 , Accuracy : 50.00%\n",
      "Epoch [831/1200], Loss: 1.6875 , Accuracy : 37.50%\n",
      "Epoch [832/1200], Loss: 1.3542 , Accuracy : 45.00%\n",
      "Epoch [833/1200], Loss: 1.0131 , Accuracy : 45.00%\n",
      "Epoch [834/1200], Loss: 1.1763 , Accuracy : 65.00%\n",
      "Epoch [835/1200], Loss: 1.1376 , Accuracy : 62.50%\n",
      "Epoch [836/1200], Loss: 2.1716 , Accuracy : 45.00%\n",
      "Epoch [837/1200], Loss: 1.0996 , Accuracy : 55.00%\n",
      "Epoch [838/1200], Loss: 1.7613 , Accuracy : 45.00%\n",
      "Epoch [839/1200], Loss: 0.5937 , Accuracy : 47.50%\n",
      "Epoch [840/1200], Loss: 0.9357 , Accuracy : 52.50%\n",
      "Epoch [841/1200], Loss: 0.3973 , Accuracy : 67.50%\n",
      "Epoch [842/1200], Loss: 1.7221 , Accuracy : 60.00%\n",
      "Epoch [843/1200], Loss: 0.8526 , Accuracy : 57.50%\n",
      "Epoch [844/1200], Loss: 0.5479 , Accuracy : 55.00%\n",
      "Epoch [845/1200], Loss: 1.8090 , Accuracy : 57.50%\n",
      "Epoch [846/1200], Loss: 0.3523 , Accuracy : 55.00%\n",
      "Epoch [847/1200], Loss: 1.0037 , Accuracy : 57.50%\n",
      "Epoch [848/1200], Loss: 1.4636 , Accuracy : 62.50%\n",
      "Epoch [849/1200], Loss: 1.3462 , Accuracy : 65.00%\n",
      "Epoch [850/1200], Loss: 1.0461 , Accuracy : 50.00%\n",
      "Epoch [851/1200], Loss: 0.3752 , Accuracy : 65.00%\n",
      "Epoch [852/1200], Loss: 0.8595 , Accuracy : 55.00%\n",
      "Epoch [853/1200], Loss: 0.7464 , Accuracy : 57.50%\n",
      "Epoch [854/1200], Loss: 0.3422 , Accuracy : 62.50%\n",
      "Epoch [855/1200], Loss: 0.1765 , Accuracy : 45.00%\n",
      "Epoch [856/1200], Loss: 1.1302 , Accuracy : 57.50%\n",
      "Epoch [857/1200], Loss: 1.1643 , Accuracy : 62.50%\n",
      "Epoch [858/1200], Loss: 0.5360 , Accuracy : 62.50%\n",
      "Epoch [859/1200], Loss: 1.6085 , Accuracy : 62.50%\n",
      "Epoch [860/1200], Loss: 0.2430 , Accuracy : 60.00%\n",
      "Epoch [861/1200], Loss: 0.8668 , Accuracy : 65.00%\n",
      "Epoch [862/1200], Loss: 1.7670 , Accuracy : 62.50%\n",
      "Epoch [863/1200], Loss: 0.8230 , Accuracy : 67.50%\n",
      "Epoch [864/1200], Loss: 1.2239 , Accuracy : 65.00%\n",
      "Epoch [865/1200], Loss: 1.0236 , Accuracy : 70.00%\n",
      "Epoch [866/1200], Loss: 2.0985 , Accuracy : 62.50%\n",
      "Epoch [867/1200], Loss: 0.4444 , Accuracy : 75.00%\n",
      "Epoch [868/1200], Loss: 0.8067 , Accuracy : 62.50%\n",
      "Epoch [869/1200], Loss: 1.3978 , Accuracy : 60.00%\n",
      "Epoch [870/1200], Loss: 1.6426 , Accuracy : 65.00%\n",
      "Epoch [871/1200], Loss: 1.9830 , Accuracy : 45.00%\n",
      "Epoch [872/1200], Loss: 0.6887 , Accuracy : 50.00%\n",
      "Epoch [873/1200], Loss: 2.5473 , Accuracy : 47.50%\n",
      "Epoch [874/1200], Loss: 0.1456 , Accuracy : 47.50%\n",
      "Epoch [875/1200], Loss: 2.4176 , Accuracy : 52.50%\n",
      "Epoch [876/1200], Loss: 1.2940 , Accuracy : 52.50%\n",
      "Epoch [877/1200], Loss: 1.1061 , Accuracy : 57.50%\n",
      "Epoch [878/1200], Loss: 1.1338 , Accuracy : 55.00%\n",
      "Epoch [879/1200], Loss: 1.2642 , Accuracy : 57.50%\n",
      "Epoch [880/1200], Loss: 1.8112 , Accuracy : 50.00%\n",
      "Epoch [881/1200], Loss: 2.0838 , Accuracy : 35.00%\n",
      "Epoch [882/1200], Loss: 0.9045 , Accuracy : 50.00%\n",
      "Epoch [883/1200], Loss: 0.8885 , Accuracy : 52.50%\n",
      "Epoch [884/1200], Loss: 0.5651 , Accuracy : 57.50%\n",
      "Epoch [885/1200], Loss: 0.7975 , Accuracy : 60.00%\n",
      "Epoch [886/1200], Loss: 0.9794 , Accuracy : 62.50%\n",
      "Epoch [887/1200], Loss: 1.7420 , Accuracy : 57.50%\n",
      "Epoch [888/1200], Loss: 0.6133 , Accuracy : 57.50%\n",
      "Epoch [889/1200], Loss: 0.3811 , Accuracy : 70.00%\n",
      "Epoch [890/1200], Loss: 1.4846 , Accuracy : 62.50%\n",
      "Epoch [891/1200], Loss: 1.1020 , Accuracy : 55.00%\n",
      "Epoch [892/1200], Loss: 1.1613 , Accuracy : 62.50%\n",
      "Epoch [893/1200], Loss: 0.4188 , Accuracy : 65.00%\n",
      "Epoch [894/1200], Loss: 0.8440 , Accuracy : 60.00%\n",
      "Epoch [895/1200], Loss: 0.4557 , Accuracy : 70.00%\n",
      "Epoch [896/1200], Loss: 1.3427 , Accuracy : 57.50%\n",
      "Epoch [897/1200], Loss: 1.2318 , Accuracy : 70.00%\n",
      "Epoch [898/1200], Loss: 0.8330 , Accuracy : 65.00%\n",
      "Epoch [899/1200], Loss: 1.0943 , Accuracy : 57.50%\n",
      "Epoch [900/1200], Loss: 3.3150 , Accuracy : 35.00%\n",
      "Epoch [901/1200], Loss: 0.7479 , Accuracy : 35.00%\n",
      "Epoch [902/1200], Loss: 1.3426 , Accuracy : 40.00%\n",
      "Epoch [903/1200], Loss: 0.4859 , Accuracy : 52.50%\n",
      "Epoch [904/1200], Loss: 1.5439 , Accuracy : 55.00%\n",
      "Epoch [905/1200], Loss: 2.4019 , Accuracy : 42.50%\n",
      "Epoch [906/1200], Loss: 0.6492 , Accuracy : 62.50%\n",
      "Epoch [907/1200], Loss: 0.5591 , Accuracy : 55.00%\n",
      "Epoch [908/1200], Loss: 0.2933 , Accuracy : 60.00%\n",
      "Epoch [909/1200], Loss: 1.4775 , Accuracy : 50.00%\n",
      "Epoch [910/1200], Loss: 1.8912 , Accuracy : 67.50%\n",
      "Epoch [911/1200], Loss: 0.4703 , Accuracy : 75.00%\n",
      "Epoch [912/1200], Loss: 0.4140 , Accuracy : 62.50%\n",
      "Epoch [913/1200], Loss: 0.7252 , Accuracy : 57.50%\n",
      "Epoch [914/1200], Loss: 1.3639 , Accuracy : 70.00%\n",
      "Epoch [915/1200], Loss: 0.6331 , Accuracy : 72.50%\n",
      "Epoch [916/1200], Loss: 0.2504 , Accuracy : 70.00%\n",
      "Epoch [917/1200], Loss: 0.2740 , Accuracy : 67.50%\n",
      "Epoch [918/1200], Loss: 1.1332 , Accuracy : 75.00%\n",
      "Epoch [919/1200], Loss: 0.5650 , Accuracy : 62.50%\n",
      "Epoch [920/1200], Loss: 0.1600 , Accuracy : 72.50%\n",
      "Epoch [921/1200], Loss: 0.3152 , Accuracy : 65.00%\n",
      "Epoch [922/1200], Loss: 1.2166 , Accuracy : 55.00%\n",
      "Epoch [923/1200], Loss: 0.7689 , Accuracy : 62.50%\n",
      "Epoch [924/1200], Loss: 1.3146 , Accuracy : 75.00%\n",
      "Epoch [925/1200], Loss: 0.9878 , Accuracy : 65.00%\n",
      "Epoch [926/1200], Loss: 0.1670 , Accuracy : 65.00%\n",
      "Epoch [927/1200], Loss: 0.7628 , Accuracy : 62.50%\n",
      "Epoch [928/1200], Loss: 0.3997 , Accuracy : 55.00%\n",
      "Epoch [929/1200], Loss: 0.7542 , Accuracy : 72.50%\n",
      "Epoch [930/1200], Loss: 2.4419 , Accuracy : 62.50%\n",
      "Epoch [931/1200], Loss: 0.3728 , Accuracy : 62.50%\n",
      "Epoch [932/1200], Loss: 0.4504 , Accuracy : 75.00%\n",
      "Epoch [933/1200], Loss: 0.5542 , Accuracy : 57.50%\n",
      "Epoch [934/1200], Loss: 0.6290 , Accuracy : 65.00%\n",
      "Epoch [935/1200], Loss: 0.4074 , Accuracy : 60.00%\n",
      "Epoch [936/1200], Loss: 1.4256 , Accuracy : 70.00%\n",
      "Epoch [937/1200], Loss: 0.7046 , Accuracy : 75.00%\n",
      "Epoch [938/1200], Loss: 1.0991 , Accuracy : 62.50%\n",
      "Epoch [939/1200], Loss: 1.9857 , Accuracy : 70.00%\n",
      "Epoch [940/1200], Loss: 0.2045 , Accuracy : 72.50%\n",
      "Epoch [941/1200], Loss: 1.6099 , Accuracy : 70.00%\n",
      "Epoch [942/1200], Loss: 0.2847 , Accuracy : 70.00%\n",
      "Epoch [943/1200], Loss: 0.7158 , Accuracy : 77.50%\n",
      "Epoch [944/1200], Loss: 1.3968 , Accuracy : 72.50%\n",
      "Epoch [945/1200], Loss: 1.1815 , Accuracy : 72.50%\n",
      "Epoch [946/1200], Loss: 1.0918 , Accuracy : 67.50%\n",
      "Epoch [947/1200], Loss: 1.1937 , Accuracy : 75.00%\n",
      "Epoch [948/1200], Loss: 0.0151 , Accuracy : 75.00%\n",
      "Epoch [949/1200], Loss: 1.3711 , Accuracy : 72.50%\n",
      "Epoch [950/1200], Loss: 1.9490 , Accuracy : 65.00%\n",
      "Epoch [951/1200], Loss: 0.8932 , Accuracy : 67.50%\n",
      "Epoch [952/1200], Loss: 1.0914 , Accuracy : 67.50%\n",
      "Epoch [953/1200], Loss: 0.5771 , Accuracy : 65.00%\n",
      "Epoch [954/1200], Loss: 0.4786 , Accuracy : 60.00%\n",
      "Epoch [955/1200], Loss: 0.3185 , Accuracy : 70.00%\n",
      "Epoch [956/1200], Loss: 1.8001 , Accuracy : 75.00%\n",
      "Epoch [957/1200], Loss: 0.6275 , Accuracy : 65.00%\n",
      "Epoch [958/1200], Loss: 0.8278 , Accuracy : 75.00%\n",
      "Epoch [959/1200], Loss: 0.2188 , Accuracy : 67.50%\n",
      "Epoch [960/1200], Loss: 1.1060 , Accuracy : 72.50%\n",
      "Epoch [961/1200], Loss: 0.3977 , Accuracy : 77.50%\n",
      "Epoch [962/1200], Loss: 0.3162 , Accuracy : 70.00%\n",
      "Epoch [963/1200], Loss: 0.7802 , Accuracy : 65.00%\n",
      "Epoch [964/1200], Loss: 1.1147 , Accuracy : 75.00%\n",
      "Epoch [965/1200], Loss: 0.5967 , Accuracy : 60.00%\n",
      "Epoch [966/1200], Loss: 0.2695 , Accuracy : 67.50%\n",
      "Epoch [967/1200], Loss: 0.6390 , Accuracy : 72.50%\n",
      "Epoch [968/1200], Loss: 1.0942 , Accuracy : 70.00%\n",
      "Epoch [969/1200], Loss: 0.9094 , Accuracy : 75.00%\n",
      "Epoch [970/1200], Loss: 1.0326 , Accuracy : 82.50%\n",
      "Epoch [971/1200], Loss: 0.7858 , Accuracy : 77.50%\n",
      "Epoch [972/1200], Loss: 1.2990 , Accuracy : 72.50%\n",
      "Epoch [973/1200], Loss: 1.2015 , Accuracy : 67.50%\n",
      "Epoch [974/1200], Loss: 0.7291 , Accuracy : 62.50%\n",
      "Epoch [975/1200], Loss: 0.3955 , Accuracy : 65.00%\n",
      "Epoch [976/1200], Loss: 0.5875 , Accuracy : 72.50%\n",
      "Epoch [977/1200], Loss: 0.9505 , Accuracy : 62.50%\n",
      "Epoch [978/1200], Loss: 0.7406 , Accuracy : 75.00%\n",
      "Epoch [979/1200], Loss: 0.6593 , Accuracy : 62.50%\n",
      "Epoch [980/1200], Loss: 0.9616 , Accuracy : 65.00%\n",
      "Epoch [981/1200], Loss: 0.0945 , Accuracy : 75.00%\n",
      "Epoch [982/1200], Loss: 0.8017 , Accuracy : 67.50%\n",
      "Epoch [983/1200], Loss: 0.7305 , Accuracy : 82.50%\n",
      "Epoch [984/1200], Loss: 0.1066 , Accuracy : 82.50%\n",
      "Epoch [985/1200], Loss: 0.4347 , Accuracy : 80.00%\n",
      "Epoch [986/1200], Loss: 0.0464 , Accuracy : 70.00%\n",
      "Epoch [987/1200], Loss: 0.4530 , Accuracy : 80.00%\n",
      "Epoch [988/1200], Loss: 0.7100 , Accuracy : 72.50%\n",
      "Epoch [989/1200], Loss: 1.1646 , Accuracy : 65.00%\n",
      "Epoch [990/1200], Loss: 0.8672 , Accuracy : 72.50%\n",
      "Epoch [991/1200], Loss: 0.5299 , Accuracy : 65.00%\n",
      "Epoch [992/1200], Loss: 0.4924 , Accuracy : 65.00%\n",
      "Epoch [993/1200], Loss: 0.9558 , Accuracy : 67.50%\n",
      "Epoch [994/1200], Loss: 0.8617 , Accuracy : 67.50%\n",
      "Epoch [995/1200], Loss: 0.5095 , Accuracy : 52.50%\n",
      "Epoch [996/1200], Loss: 0.4469 , Accuracy : 55.00%\n",
      "Epoch [997/1200], Loss: 0.0471 , Accuracy : 67.50%\n",
      "Epoch [998/1200], Loss: 1.8413 , Accuracy : 67.50%\n",
      "Epoch [999/1200], Loss: 0.6560 , Accuracy : 57.50%\n",
      "Epoch [1000/1200], Loss: 1.0021 , Accuracy : 60.00%\n",
      "Epoch [1001/1200], Loss: 0.9157 , Accuracy : 65.00%\n",
      "Epoch [1002/1200], Loss: 0.7733 , Accuracy : 45.00%\n",
      "Epoch [1003/1200], Loss: 0.2925 , Accuracy : 67.50%\n",
      "Epoch [1004/1200], Loss: 0.1933 , Accuracy : 65.00%\n",
      "Epoch [1005/1200], Loss: 0.2153 , Accuracy : 72.50%\n",
      "Epoch [1006/1200], Loss: 1.5388 , Accuracy : 57.50%\n",
      "Epoch [1007/1200], Loss: 0.5205 , Accuracy : 72.50%\n",
      "Epoch [1008/1200], Loss: 4.3079 , Accuracy : 62.50%\n",
      "Epoch [1009/1200], Loss: 1.4639 , Accuracy : 52.50%\n",
      "Epoch [1010/1200], Loss: 0.4365 , Accuracy : 70.00%\n",
      "Epoch [1011/1200], Loss: 0.6300 , Accuracy : 60.00%\n",
      "Epoch [1012/1200], Loss: 0.3229 , Accuracy : 75.00%\n",
      "Epoch [1013/1200], Loss: 1.2982 , Accuracy : 65.00%\n",
      "Epoch [1014/1200], Loss: 0.8307 , Accuracy : 72.50%\n",
      "Epoch [1015/1200], Loss: 0.1726 , Accuracy : 70.00%\n",
      "Epoch [1016/1200], Loss: 0.7025 , Accuracy : 62.50%\n",
      "Epoch [1017/1200], Loss: 1.5876 , Accuracy : 72.50%\n",
      "Epoch [1018/1200], Loss: 1.6320 , Accuracy : 60.00%\n",
      "Epoch [1019/1200], Loss: 1.4204 , Accuracy : 77.50%\n",
      "Epoch [1020/1200], Loss: 0.7689 , Accuracy : 70.00%\n",
      "Epoch [1021/1200], Loss: 1.5640 , Accuracy : 62.50%\n",
      "Epoch [1022/1200], Loss: 0.5872 , Accuracy : 72.50%\n",
      "Epoch [1023/1200], Loss: 0.5118 , Accuracy : 72.50%\n",
      "Epoch [1024/1200], Loss: 0.7940 , Accuracy : 60.00%\n",
      "Epoch [1025/1200], Loss: 0.7315 , Accuracy : 55.00%\n",
      "Epoch [1026/1200], Loss: 2.0172 , Accuracy : 60.00%\n",
      "Epoch [1027/1200], Loss: 0.7147 , Accuracy : 80.00%\n",
      "Epoch [1028/1200], Loss: 0.6475 , Accuracy : 70.00%\n",
      "Epoch [1029/1200], Loss: 1.6552 , Accuracy : 72.50%\n",
      "Epoch [1030/1200], Loss: 0.3072 , Accuracy : 75.00%\n",
      "Epoch [1031/1200], Loss: 0.3300 , Accuracy : 70.00%\n",
      "Epoch [1032/1200], Loss: 0.4472 , Accuracy : 62.50%\n",
      "Epoch [1033/1200], Loss: 0.0556 , Accuracy : 67.50%\n",
      "Epoch [1034/1200], Loss: 0.2703 , Accuracy : 72.50%\n",
      "Epoch [1035/1200], Loss: 0.2428 , Accuracy : 70.00%\n",
      "Epoch [1036/1200], Loss: 0.2324 , Accuracy : 65.00%\n",
      "Epoch [1037/1200], Loss: 0.5709 , Accuracy : 72.50%\n",
      "Epoch [1038/1200], Loss: 0.4306 , Accuracy : 87.50%\n",
      "Epoch [1039/1200], Loss: 0.4277 , Accuracy : 70.00%\n",
      "Epoch [1040/1200], Loss: 0.3979 , Accuracy : 72.50%\n",
      "Epoch [1041/1200], Loss: 0.9171 , Accuracy : 80.00%\n",
      "Epoch [1042/1200], Loss: 0.2813 , Accuracy : 70.00%\n",
      "Epoch [1043/1200], Loss: 0.4466 , Accuracy : 80.00%\n",
      "Epoch [1044/1200], Loss: 0.2229 , Accuracy : 72.50%\n",
      "Epoch [1045/1200], Loss: 0.5425 , Accuracy : 75.00%\n",
      "Epoch [1046/1200], Loss: 0.4699 , Accuracy : 75.00%\n",
      "Epoch [1047/1200], Loss: 1.0945 , Accuracy : 80.00%\n",
      "Epoch [1048/1200], Loss: 2.0890 , Accuracy : 75.00%\n",
      "Epoch [1049/1200], Loss: 0.0791 , Accuracy : 80.00%\n",
      "Epoch [1050/1200], Loss: 0.5857 , Accuracy : 72.50%\n",
      "Epoch [1051/1200], Loss: 0.5713 , Accuracy : 82.50%\n",
      "Epoch [1052/1200], Loss: 0.8340 , Accuracy : 72.50%\n",
      "Epoch [1053/1200], Loss: 0.1388 , Accuracy : 75.00%\n",
      "Epoch [1054/1200], Loss: 0.2695 , Accuracy : 70.00%\n",
      "Epoch [1055/1200], Loss: 1.0389 , Accuracy : 70.00%\n",
      "Epoch [1056/1200], Loss: 0.7205 , Accuracy : 72.50%\n",
      "Epoch [1057/1200], Loss: 0.6778 , Accuracy : 72.50%\n",
      "Epoch [1058/1200], Loss: 0.2476 , Accuracy : 67.50%\n",
      "Epoch [1059/1200], Loss: 0.4634 , Accuracy : 62.50%\n",
      "Epoch [1060/1200], Loss: 0.9823 , Accuracy : 75.00%\n",
      "Epoch [1061/1200], Loss: 0.0166 , Accuracy : 75.00%\n",
      "Epoch [1062/1200], Loss: 0.3584 , Accuracy : 70.00%\n",
      "Epoch [1063/1200], Loss: 0.2477 , Accuracy : 82.50%\n",
      "Epoch [1064/1200], Loss: 0.7526 , Accuracy : 75.00%\n",
      "Epoch [1065/1200], Loss: 0.7651 , Accuracy : 72.50%\n",
      "Epoch [1066/1200], Loss: 0.0860 , Accuracy : 80.00%\n",
      "Epoch [1067/1200], Loss: 0.3663 , Accuracy : 80.00%\n",
      "Epoch [1068/1200], Loss: 0.9449 , Accuracy : 80.00%\n",
      "Epoch [1069/1200], Loss: 0.4932 , Accuracy : 72.50%\n",
      "Epoch [1070/1200], Loss: 0.0471 , Accuracy : 82.50%\n",
      "Epoch [1071/1200], Loss: 0.1681 , Accuracy : 87.50%\n",
      "Epoch [1072/1200], Loss: 0.0589 , Accuracy : 62.50%\n",
      "Epoch [1073/1200], Loss: 0.7167 , Accuracy : 67.50%\n",
      "Epoch [1074/1200], Loss: 0.7130 , Accuracy : 72.50%\n",
      "Epoch [1075/1200], Loss: 0.8466 , Accuracy : 72.50%\n",
      "Epoch [1076/1200], Loss: 0.6597 , Accuracy : 52.50%\n",
      "Epoch [1077/1200], Loss: 1.0229 , Accuracy : 62.50%\n",
      "Epoch [1078/1200], Loss: 0.3471 , Accuracy : 60.00%\n",
      "Epoch [1079/1200], Loss: 0.4262 , Accuracy : 65.00%\n",
      "Epoch [1080/1200], Loss: 0.0212 , Accuracy : 82.50%\n",
      "Epoch [1081/1200], Loss: 0.0234 , Accuracy : 77.50%\n",
      "Epoch [1082/1200], Loss: 0.7599 , Accuracy : 60.00%\n",
      "Epoch [1083/1200], Loss: 1.2127 , Accuracy : 67.50%\n",
      "Epoch [1084/1200], Loss: 0.3125 , Accuracy : 70.00%\n",
      "Epoch [1085/1200], Loss: 0.9464 , Accuracy : 60.00%\n",
      "Epoch [1086/1200], Loss: 0.4913 , Accuracy : 62.50%\n",
      "Epoch [1087/1200], Loss: 1.3502 , Accuracy : 55.00%\n",
      "Epoch [1088/1200], Loss: 1.0172 , Accuracy : 60.00%\n",
      "Epoch [1089/1200], Loss: 0.6311 , Accuracy : 70.00%\n",
      "Epoch [1090/1200], Loss: 0.4826 , Accuracy : 57.50%\n",
      "Epoch [1091/1200], Loss: 0.9523 , Accuracy : 62.50%\n",
      "Epoch [1092/1200], Loss: 1.2648 , Accuracy : 57.50%\n",
      "Epoch [1093/1200], Loss: 0.2926 , Accuracy : 67.50%\n",
      "Epoch [1094/1200], Loss: 2.5370 , Accuracy : 40.00%\n",
      "Epoch [1095/1200], Loss: 1.0190 , Accuracy : 50.00%\n",
      "Epoch [1096/1200], Loss: 1.4351 , Accuracy : 65.00%\n",
      "Epoch [1097/1200], Loss: 0.3336 , Accuracy : 70.00%\n",
      "Epoch [1098/1200], Loss: 1.9688 , Accuracy : 60.00%\n",
      "Epoch [1099/1200], Loss: 0.4244 , Accuracy : 62.50%\n",
      "Epoch [1100/1200], Loss: 2.1597 , Accuracy : 72.50%\n",
      "Epoch [1101/1200], Loss: 0.1682 , Accuracy : 65.00%\n",
      "Epoch [1102/1200], Loss: 0.9657 , Accuracy : 67.50%\n",
      "Epoch [1103/1200], Loss: 0.9293 , Accuracy : 57.50%\n",
      "Epoch [1104/1200], Loss: 0.0971 , Accuracy : 65.00%\n",
      "Epoch [1105/1200], Loss: 0.5497 , Accuracy : 60.00%\n",
      "Epoch [1106/1200], Loss: 0.5272 , Accuracy : 67.50%\n",
      "Epoch [1107/1200], Loss: 0.9769 , Accuracy : 67.50%\n",
      "Epoch [1108/1200], Loss: 0.1254 , Accuracy : 72.50%\n",
      "Epoch [1109/1200], Loss: 1.9165 , Accuracy : 67.50%\n",
      "Epoch [1110/1200], Loss: 0.5429 , Accuracy : 57.50%\n",
      "Epoch [1111/1200], Loss: 1.1635 , Accuracy : 65.00%\n",
      "Epoch [1112/1200], Loss: 0.5540 , Accuracy : 67.50%\n",
      "Epoch [1113/1200], Loss: 1.3823 , Accuracy : 70.00%\n",
      "Epoch [1114/1200], Loss: 0.3528 , Accuracy : 62.50%\n",
      "Epoch [1115/1200], Loss: 0.9198 , Accuracy : 62.50%\n",
      "Epoch [1116/1200], Loss: 0.2494 , Accuracy : 60.00%\n",
      "Epoch [1117/1200], Loss: 1.1833 , Accuracy : 60.00%\n",
      "Epoch [1118/1200], Loss: 0.4525 , Accuracy : 60.00%\n",
      "Epoch [1119/1200], Loss: 0.2923 , Accuracy : 65.00%\n",
      "Epoch [1120/1200], Loss: 1.3797 , Accuracy : 72.50%\n",
      "Epoch [1121/1200], Loss: 0.2633 , Accuracy : 70.00%\n",
      "Epoch [1122/1200], Loss: 0.7198 , Accuracy : 80.00%\n",
      "Epoch [1123/1200], Loss: 0.7614 , Accuracy : 72.50%\n",
      "Epoch [1124/1200], Loss: 0.1195 , Accuracy : 75.00%\n",
      "Epoch [1125/1200], Loss: 1.9064 , Accuracy : 65.00%\n",
      "Epoch [1126/1200], Loss: 2.2752 , Accuracy : 70.00%\n",
      "Epoch [1127/1200], Loss: 0.1027 , Accuracy : 70.00%\n",
      "Epoch [1128/1200], Loss: 0.1779 , Accuracy : 75.00%\n",
      "Epoch [1129/1200], Loss: 0.2610 , Accuracy : 65.00%\n",
      "Epoch [1130/1200], Loss: 0.6940 , Accuracy : 77.50%\n",
      "Epoch [1131/1200], Loss: 0.9800 , Accuracy : 67.50%\n",
      "Epoch [1132/1200], Loss: 0.4911 , Accuracy : 72.50%\n",
      "Epoch [1133/1200], Loss: 1.6265 , Accuracy : 72.50%\n",
      "Epoch [1134/1200], Loss: 1.8513 , Accuracy : 62.50%\n",
      "Epoch [1135/1200], Loss: 0.4560 , Accuracy : 75.00%\n",
      "Epoch [1136/1200], Loss: 1.6223 , Accuracy : 72.50%\n",
      "Epoch [1137/1200], Loss: 0.9476 , Accuracy : 70.00%\n",
      "Epoch [1138/1200], Loss: 3.2298 , Accuracy : 70.00%\n",
      "Epoch [1139/1200], Loss: 1.4010 , Accuracy : 75.00%\n",
      "Epoch [1140/1200], Loss: 0.6288 , Accuracy : 62.50%\n",
      "Epoch [1141/1200], Loss: 1.2835 , Accuracy : 65.00%\n",
      "Epoch [1142/1200], Loss: 0.7603 , Accuracy : 62.50%\n",
      "Epoch [1143/1200], Loss: 0.6140 , Accuracy : 65.00%\n",
      "Epoch [1144/1200], Loss: 0.4321 , Accuracy : 67.50%\n",
      "Epoch [1145/1200], Loss: 2.2753 , Accuracy : 65.00%\n",
      "Epoch [1146/1200], Loss: 1.6617 , Accuracy : 52.50%\n",
      "Epoch [1147/1200], Loss: 1.0200 , Accuracy : 55.00%\n",
      "Epoch [1148/1200], Loss: 1.0624 , Accuracy : 72.50%\n",
      "Epoch [1149/1200], Loss: 2.0853 , Accuracy : 75.00%\n",
      "Epoch [1150/1200], Loss: 0.0508 , Accuracy : 67.50%\n",
      "Epoch [1151/1200], Loss: 0.2753 , Accuracy : 72.50%\n",
      "Epoch [1152/1200], Loss: 0.6919 , Accuracy : 70.00%\n",
      "Epoch [1153/1200], Loss: 0.9065 , Accuracy : 82.50%\n",
      "Epoch [1154/1200], Loss: 0.1753 , Accuracy : 85.00%\n",
      "Epoch [1155/1200], Loss: 0.4417 , Accuracy : 80.00%\n",
      "Epoch [1156/1200], Loss: 0.4639 , Accuracy : 80.00%\n",
      "Epoch [1157/1200], Loss: 0.0852 , Accuracy : 70.00%\n",
      "Epoch [1158/1200], Loss: 1.1714 , Accuracy : 72.50%\n",
      "Epoch [1159/1200], Loss: 0.8544 , Accuracy : 72.50%\n",
      "Epoch [1160/1200], Loss: 0.3208 , Accuracy : 67.50%\n",
      "Epoch [1161/1200], Loss: 0.3174 , Accuracy : 67.50%\n",
      "Epoch [1162/1200], Loss: 0.0960 , Accuracy : 70.00%\n",
      "Epoch [1163/1200], Loss: 1.1632 , Accuracy : 80.00%\n",
      "Epoch [1164/1200], Loss: 1.0556 , Accuracy : 52.50%\n",
      "Epoch [1165/1200], Loss: 0.7591 , Accuracy : 47.50%\n",
      "Epoch [1166/1200], Loss: 0.0186 , Accuracy : 55.00%\n",
      "Epoch [1167/1200], Loss: 0.6701 , Accuracy : 67.50%\n",
      "Epoch [1168/1200], Loss: 1.3827 , Accuracy : 60.00%\n",
      "Epoch [1169/1200], Loss: 0.6499 , Accuracy : 62.50%\n",
      "Epoch [1170/1200], Loss: 0.7890 , Accuracy : 70.00%\n",
      "Epoch [1171/1200], Loss: 0.4539 , Accuracy : 57.50%\n",
      "Epoch [1172/1200], Loss: 0.8325 , Accuracy : 67.50%\n",
      "Epoch [1173/1200], Loss: 0.5874 , Accuracy : 70.00%\n",
      "Epoch [1174/1200], Loss: 1.3419 , Accuracy : 72.50%\n",
      "Epoch [1175/1200], Loss: 0.3318 , Accuracy : 70.00%\n",
      "Epoch [1176/1200], Loss: 0.3541 , Accuracy : 75.00%\n",
      "Epoch [1177/1200], Loss: 0.4282 , Accuracy : 67.50%\n",
      "Epoch [1178/1200], Loss: 0.8316 , Accuracy : 72.50%\n",
      "Epoch [1179/1200], Loss: 1.4689 , Accuracy : 65.00%\n",
      "Epoch [1180/1200], Loss: 1.8672 , Accuracy : 57.50%\n",
      "Epoch [1181/1200], Loss: 2.4188 , Accuracy : 57.50%\n",
      "Epoch [1182/1200], Loss: 1.9309 , Accuracy : 67.50%\n",
      "Epoch [1183/1200], Loss: 2.6739 , Accuracy : 60.00%\n",
      "Epoch [1184/1200], Loss: 1.8587 , Accuracy : 57.50%\n",
      "Epoch [1185/1200], Loss: 0.6584 , Accuracy : 67.50%\n",
      "Epoch [1186/1200], Loss: 0.4449 , Accuracy : 72.50%\n",
      "Epoch [1187/1200], Loss: 0.0521 , Accuracy : 77.50%\n",
      "Epoch [1188/1200], Loss: 0.6463 , Accuracy : 67.50%\n",
      "Epoch [1189/1200], Loss: 0.1060 , Accuracy : 77.50%\n",
      "Epoch [1190/1200], Loss: 1.3574 , Accuracy : 70.00%\n",
      "Epoch [1191/1200], Loss: 0.2239 , Accuracy : 85.00%\n",
      "Epoch [1192/1200], Loss: 0.3606 , Accuracy : 82.50%\n",
      "Epoch [1193/1200], Loss: 0.5384 , Accuracy : 80.00%\n",
      "Epoch [1194/1200], Loss: 0.3282 , Accuracy : 75.00%\n",
      "Epoch [1195/1200], Loss: 1.1277 , Accuracy : 72.50%\n",
      "Epoch [1196/1200], Loss: 0.2317 , Accuracy : 65.00%\n",
      "Epoch [1197/1200], Loss: 0.2558 , Accuracy : 77.50%\n",
      "Epoch [1198/1200], Loss: 1.1526 , Accuracy : 82.50%\n",
      "Epoch [1199/1200], Loss: 0.5184 , Accuracy : 80.00%\n",
      "Epoch [1200/1200], Loss: 1.1677 , Accuracy : 85.00%\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "# References : https://saturncloud.io/blog/calculating-the-accuracy-of-pytorch-models-every-epoch/#:~:text=In%20order%20to%20calculate%20the,tensor%20along%20a%20specified%20dimension\n",
    "num_epochs = 1200\n",
    "for epoch in range(num_epochs):\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    model.train()\n",
    "    for i, (sequences, labels) in enumerate(data_loader):\n",
    "        # Move data to the device\n",
    "        sequences = sequences.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(sequences)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        total_correct += (predicted == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    accuracy = 100 * total_correct /total_samples\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f} , Accuracy : {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.4868,  0.2821, -1.4668,  ...,  0.5711,  0.2335,  0.0116],\n",
       "         [ 0.4861,  0.2786, -1.5812,  ...,  0.5702,  0.2334,  0.0129],\n",
       "         [ 0.4856,  0.2769, -1.6059,  ...,  0.5699,  0.2333,  0.0131],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.5103,  0.2428, -1.1660,  ...,  0.5757,  0.2179,  0.0081],\n",
       "         [ 0.5106,  0.2437, -1.2850,  ...,  0.5751,  0.2183,  0.0099],\n",
       "         [ 0.5112,  0.2443, -1.2880,  ...,  0.5748,  0.2189,  0.0108],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.5134,  0.2614, -1.4426,  ...,  0.5818,  0.2272,  0.0153],\n",
       "         [ 0.5130,  0.2604, -1.4262,  ...,  0.5810,  0.2273,  0.0147],\n",
       "         [ 0.5126,  0.2599, -1.4278,  ...,  0.5810,  0.2276,  0.0150],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.5013,  0.2452, -1.2167,  ...,  0.5663,  0.2188,  0.0098],\n",
       "         [ 0.4997,  0.2482, -1.4690,  ...,  0.5652,  0.2181,  0.0106],\n",
       "         [ 0.4984,  0.2500, -1.4853,  ...,  0.5654,  0.2185,  0.0112],\n",
       "         ...,\n",
       "         [ 0.4861,  0.2513, -1.3416,  ...,  0.5572,  0.2177,  0.0091],\n",
       "         [ 0.4873,  0.2514, -1.3574,  ...,  0.5575,  0.2172,  0.0097],\n",
       "         [ 0.4883,  0.2516, -1.3579,  ...,  0.5577,  0.2170,  0.0101]]])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_sequence(sequences, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 8.4886, -2.2391, -0.2556,  ..., -2.0864,  3.2579, -3.2054],\n",
       "        [-4.1864,  9.4720, -3.5149,  ...,  3.1613, -1.4555, -2.7038],\n",
       "        [-0.8747, -2.0196, 11.1850,  ..., -6.3004,  0.1408,  0.7032],\n",
       "        ...,\n",
       "        [-6.0408,  0.3973, -9.3390,  ...,  8.6894, -4.4498,  0.4777],\n",
       "        [-0.6473, -2.4444, -4.8697,  ..., -3.9147,  8.5207, -2.8640],\n",
       "        [-4.8162, -3.5016, -3.8957,  ..., -0.6957, -2.9981,  6.3166]])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Put the model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# No need to track gradients during inference\n",
    "with torch.no_grad():\n",
    "    # Get the model's output (logits)\n",
    "    outputs = model(padded_sequences)\n",
    "\n",
    "# outputs = torch.softmax(outputs, dim=1)\n",
    "# outputs = torch.max(outputs,1)\n",
    "\n",
    "outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.5013,  0.2452, -1.2167,  ...,  0.5663,  0.2188,  0.0098],\n",
       "         [ 0.4997,  0.2482, -1.4690,  ...,  0.5652,  0.2181,  0.0106],\n",
       "         [ 0.4984,  0.2500, -1.4853,  ...,  0.5654,  0.2185,  0.0112],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.4922,  0.2382, -1.2850,  ...,  0.5578,  0.2124,  0.0094],\n",
       "         [ 0.4920,  0.2405, -1.4288,  ...,  0.5571,  0.2116,  0.0099],\n",
       "         [ 0.4920,  0.2409, -1.4093,  ...,  0.5567,  0.2122,  0.0098],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.5049,  0.2371, -1.2115,  ...,  0.5643,  0.2082,  0.0088],\n",
       "         [ 0.5045,  0.2381, -1.1896,  ...,  0.5643,  0.2081,  0.0085],\n",
       "         [ 0.5041,  0.2385, -1.1915,  ...,  0.5643,  0.2080,  0.0089],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.4849,  0.2484, -1.3873,  ...,  0.5543,  0.2162,  0.0108],\n",
       "         [ 0.4846,  0.2500, -1.4881,  ...,  0.5539,  0.2157,  0.0111],\n",
       "         [ 0.4844,  0.2507, -1.4935,  ...,  0.5537,  0.2161,  0.0111],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.5199,  0.2290, -1.2810,  ...,  0.5876,  0.2058,  0.0103],\n",
       "         [ 0.5195,  0.2307, -1.3821,  ...,  0.5873,  0.2059,  0.0106],\n",
       "         [ 0.5193,  0.2327, -1.4100,  ...,  0.5877,  0.2059,  0.0109],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.5005,  0.2439, -1.3629,  ...,  0.5694,  0.2139,  0.0154],\n",
       "         [ 0.5002,  0.2448, -1.5049,  ...,  0.5688,  0.2128,  0.0146],\n",
       "         [ 0.4999,  0.2457, -1.5287,  ...,  0.5683,  0.2134,  0.0148],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(padded_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = [\"Data for different actions/กล้วยบวชชี_2.mp4/กล้วยบวชชี_2.npy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.5319,  0.2821, -1.6797,  ...,  0.6169,  0.2514,  0.0109],\n",
       "         [ 0.5346,  0.2813, -1.7538,  ...,  0.6164,  0.2506,  0.0119],\n",
       "         [ 0.5365,  0.2812, -1.7556,  ...,  0.6163,  0.2507,  0.0109],\n",
       "         ...,\n",
       "         [ 0.5340,  0.2852, -1.2054,  ...,  0.6196,  0.2422,  0.0160],\n",
       "         [ 0.5345,  0.2806, -1.4284,  ...,  0.6202,  0.2413,  0.0160],\n",
       "         [ 0.5356,  0.2758, -1.3837,  ...,  0.6207,  0.2407,  0.0163]]])"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the sequences\n",
    "import torch\n",
    "sequences = load_keypoint_sequences(file_paths)\n",
    "# Change list to numpy array \n",
    "sequences = np.array(sequences)\n",
    "# Change numpy array to tensor\n",
    "sequences = torch.FloatTensor(sequences)\n",
    "sequences = pad_sequence(sequences, batch_first=True)\n",
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.6489, -4.6696, -0.0753, -2.9835, -1.6236, -3.7760,  8.7149, -2.9589,\n",
       "         -2.2924,  2.5370, -1.8308, -2.8557, -0.8328,  2.9264, -2.1582, -5.2478,\n",
       "          0.3017, -1.6514, -4.3147, -2.6456, -0.1971,  0.1996, 10.4806, -2.8355,\n",
       "          3.0094, -1.5649, -3.9936,  0.6804,  0.8259, -4.1843,  4.9341,  3.6058,\n",
       "          0.0363, -3.5094, -2.1526,  2.2892,  0.4896, -3.9278,  3.6323, -1.7342]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model(sequences)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['กฎกระทรวง',\n",
       " 'กฎหมายรัฐธรรมนูญ',\n",
       " 'กรมอนามัย',\n",
       " 'กรรม',\n",
       " 'กรรมสิทธิ์',\n",
       " 'กระโดด',\n",
       " 'กล้วยบวชชี',\n",
       " 'กล้วยเชื่อม',\n",
       " 'กังวล',\n",
       " 'กีฬา',\n",
       " 'น้อง',\n",
       " 'เขิน',\n",
       " 'เขื่อนดิน',\n",
       " 'เขื่อนสิริกิติ์',\n",
       " 'เข้าใจผิด',\n",
       " 'เคย',\n",
       " 'เครียด',\n",
       " 'เครื่องปั่นดิน',\n",
       " 'เครื่องหมายการค้า',\n",
       " 'เจอ',\n",
       " 'เจ้าหนี้',\n",
       " 'เช่าซื้อ',\n",
       " 'เช่าทรัพย์',\n",
       " 'เซอร์เบีย',\n",
       " 'เซเนกัล',\n",
       " 'เซ็ง',\n",
       " 'เดิน',\n",
       " 'เดิมพัน',\n",
       " 'เพลีย',\n",
       " 'เมื่อย',\n",
       " 'เม็กซิโก',\n",
       " 'เฮโรอีน',\n",
       " 'แกมเบีย',\n",
       " 'แซมเบีย',\n",
       " 'โกหก',\n",
       " 'โจทก์',\n",
       " 'โชจู',\n",
       " 'ใกล้',\n",
       " 'ไดโนเสาร์',\n",
       " 'ไอซ์']"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [action.split(\".\")[0] for action in actions]\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -------------------------------------------------------------------------------------------------------------------------------------------- ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch\n",
    "# Load the sequences\n",
    "import numpy as np \n",
    "import os\n",
    "Model_Data=os.path.join('Data for different actions')\n",
    "action = \"กฎหมายรัฐธรรมนูญ.mp4\"\n",
    "a = np.load(os.path.join(Model_Data, action, \"กฎหมายรัฐธรรมนูญ.npy\"))\n",
    "a = torch.from_numpy(a)\n",
    "\n",
    "# Pad the sequences to the same length\n",
    "padded_sequences = pad_sequence(a, batch_first=True)\n",
    "len(padded_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelMap = {label:num for num, label in enumerate(actions)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 806,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs, labels = [], []\n",
    "\n",
    "for action in actions:\n",
    "    for seq in range(no_of_seqs):\n",
    "        window = []\n",
    "        for frame_num in range(seq_length):\n",
    "            res = np.load(os.path.join(Model_Data, action, f\"frame_{frame_num}.npy\")) \n",
    "            window.append(res)\n",
    "        seqs.append(window)\n",
    "\n",
    "        labels.append(labelMap[action])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(seqs).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 809,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = np.array(seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing the labels from 0,1,2 to categorical data for easier accessebility\n",
    "Y_label = to_categorical(labels).astype(int)\n",
    "Y_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_data, Y_label, test_size=0.3)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 816,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding the logs folder\n",
    "log_dir = os.path.join('Logs')\n",
    "tb_callback = TensorBoard(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural network\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, return_sequences=True, activation='relu', input_shape=(30,1662)))\n",
    "model.add(LSTM(128, return_sequences=True, activation='relu'))\n",
    "model.add(LSTM(64, return_sequences=False, activation='relu'))\n",
    "\n",
    "# adding 64 units for dense layer\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(actions.shape[0], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eg\n",
    "eg_res = [.7, 0.2, 0.1]\n",
    "actions[np.argmax(eg_res)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 819,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, Y_train, epochs=300, callbacks=[tb_callback])\n",
    "# tensorboard --logdir=."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# again the actions with the max value provided by softmax is returned\n",
    "actions[np.argmax(res[4])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions[np.argmax(Y_test[4])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_hat = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_true = np.argmax(Y_train, axis=1).tolist()\n",
    "# one hot encoding\n",
    "Y_hat = np.argmax(Y_hat, axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confution matrix\n",
    "multilabel_confusion_matrix(Y_true, Y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(Y_true, Y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
