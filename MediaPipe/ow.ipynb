{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 742,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import mediapipe as mp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holist = mp.solutions.holistic \n",
    "mp_draw = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_detection(img, model):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img.flags.writeable = False                 \n",
    "    result = model.process(img)                 # Make prediction\n",
    "    img.flags.writeable = True                   \n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR) \n",
    "    return img, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_landmarks(img, result):\n",
    "    mp_draw.draw_landmarks(img, result.face_landmarks, mp_holist.FACEMESH_CONTOURS) # Draw face connections\n",
    "    mp_draw.draw_landmarks(img, result.pose_landmarks, mp_holist.POSE_CONNECTIONS) # Draw pose connections\n",
    "    mp_draw.draw_landmarks(img, result.left_hand_landmarks, mp_holist.HAND_CONNECTIONS) # Draw left hand connections\n",
    "    mp_draw.draw_landmarks(img, result.right_hand_landmarks, mp_holist.HAND_CONNECTIONS) # Draw right hand connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_styled_landmarks(img, result):\n",
    "    mp_draw.draw_landmarks(img, result.face_landmarks, mp_holist.FACEMESH_CONTOURS, \n",
    "                             mp_draw.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1), # color the joint \n",
    "                             mp_draw.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1) #color the connection\n",
    "                             ) \n",
    "    # mp_draw.draw_landmarks(img, result.face_landmarks, mp_holist.FACEMESH_CONTOURS, \n",
    "    #                          mp_draw.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1), # color the joint \n",
    "    #                          mp_draw.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1) #color the connection\n",
    "    #                          ) \n",
    "    \n",
    "    mp_draw.draw_landmarks(img, result.pose_landmarks, mp_holist.POSE_CONNECTIONS,\n",
    "                             mp_draw.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4), \n",
    "                             mp_draw.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                             ) \n",
    "    mp_draw.draw_landmarks(img, result.left_hand_landmarks, mp_holist.HAND_CONNECTIONS, \n",
    "                             mp_draw.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4), \n",
    "                             mp_draw.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                             ) \n",
    "    mp_draw.draw_landmarks(img, result.right_hand_landmarks, mp_holist.HAND_CONNECTIONS, \n",
    "                             mp_draw.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4), \n",
    "                             mp_draw.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                             ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holist.POSE_CONNECTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "# Set mediapipe model \n",
    "with mp_holist.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        image, results = mediapipe_detection(frame, holistic)\n",
    "        print(results)\n",
    "        \n",
    "        draw_styled_landmarks(image, results)\n",
    "\n",
    "        cv2.imshow('OpenCV Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.pose_landmarks.landmark[0].visibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(results.pose_landmarks.landmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keypoints(results):\n",
    "    pose=np.array([[res.x,res.y,res.z,res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*4)\n",
    "    left_hnd=np.array([[res.x,res.y,res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "    right_hnd=np.array([[res.x,res.y,res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "    face=np.array([[res.x,res.y,res.z] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(468*3)\n",
    "    return np.concatenate([pose,left_hnd,right_hnd,face])\n",
    "# concatenating for the model to detect the sign language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_keypoints(results).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 797,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 797,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "video_dir = \"C:/Users/araya/Desktop/keypoints/video_extract\"\n",
    "video_list = []\n",
    "video_list = os.listdir(video_dir)\n",
    "\n",
    "len(video_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['กฎกระทรวง.mp4',\n",
       " 'กฎหมายรัฐธรรมนูญ.mp4',\n",
       " 'กรมอนามัย.mp4',\n",
       " 'กรรม.mp4',\n",
       " 'กรรมสิทธิ์.mp4',\n",
       " 'กระโดด.mp4',\n",
       " 'กลับ.mp4',\n",
       " 'กล้วยบวชชี.mp4',\n",
       " 'กล้วยเชื่อม.mp4',\n",
       " 'ข้าวพันผัก.mp4',\n",
       " 'ตลาดหัวดง.mp4',\n",
       " 'นก.mp4',\n",
       " 'น้อง.mp4',\n",
       " 'บัวลอยน้ำขัง.mp4',\n",
       " 'เขิน.mp4',\n",
       " 'เคย.mp4',\n",
       " 'เจอ.mp4',\n",
       " 'เจ้าหนี้.mp4',\n",
       " 'เช่าซื้อ.mp4',\n",
       " 'เดิน.mp4',\n",
       " 'เดิมพัน.mp4',\n",
       " 'เนื้อวัว.mp4',\n",
       " 'เนื้อหมู.mp4',\n",
       " 'เปรู.mp4',\n",
       " 'เพนกวิน.mp4',\n",
       " 'เพลีย.mp4',\n",
       " 'เมื่อย.mp4',\n",
       " 'เรียก.mp4',\n",
       " 'เรือข้ามฟาก.mp4',\n",
       " 'เร่งมือ.mp4',\n",
       " 'เล็ก.mp4',\n",
       " 'เวอร์ไป.mp4',\n",
       " 'เวเนซุเอลา.mp4',\n",
       " 'เศรษฐกิจ.mp4',\n",
       " 'เสรีภาพ.mp4',\n",
       " 'เสือก.mp4',\n",
       " 'เส้น.mp4',\n",
       " 'เหตุสุดวิสัย.mp4',\n",
       " 'เห็นด้วย.mp4',\n",
       " 'เฮโรอีน.mp4',\n",
       " 'แท็บเล็ต.mp4',\n",
       " 'แบก.mp4',\n",
       " 'แผนที่.mp4',\n",
       " 'แม่ลาว (อำเภอ).mp4',\n",
       " 'แม่วงก์ (อำเภอ).mp4',\n",
       " 'แหวน.mp4',\n",
       " 'แองโกลา.mp4',\n",
       " 'แอฟริกาใต้.mp4',\n",
       " 'แอลจีเรีย.mp4',\n",
       " 'แอลเบเนีย.mp4',\n",
       " 'โกหก.mp4',\n",
       " 'โจทก์.mp4',\n",
       " 'โชจู.mp4',\n",
       " 'โนโหวต.mp4',\n",
       " 'โบ๊เบ๊.mp4',\n",
       " 'โรงงานทำ.mp4',\n",
       " 'โรมาเนีย.mp4',\n",
       " 'ใหญ่.mp4',\n",
       " 'ไดโนเสาร์.mp4',\n",
       " 'ไถ่ถอน.mp4',\n",
       " 'ไนกี้.mp4',\n",
       " 'ไอซ์.mp4']"
      ]
     },
     "execution_count": 798,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for exported data, numpy arrays\n",
    "Model_Data=os.path.join('Data for different actions')\n",
    "\n",
    "actions = np.array(video_list)\n",
    "\n",
    "no_of_seqs = 1\n",
    "\n",
    "# 30 frames in length\n",
    "seq_length = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just creating the folders and sub folders\n",
    "\n",
    "for action in actions: \n",
    "    try: \n",
    "        os.makedirs(os.path.join(Model_Data, action))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collecting keypoint values for Training nd Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory where your videos are stored\n",
    "directory = \"C:/Users/araya/Desktop/keypoints/video_extract\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/araya/Desktop/keypoints/video_extract'"
      ]
     },
     "execution_count": 801,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/araya/Desktop/keypoints/video_extract/กฎกระทรวง.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/กฎหมายรัฐธรรมนูญ.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/กรมอนามัย.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/กรรม.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/กรรมสิทธิ์.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/กระโดด.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/กลับ.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/กล้วยบวชชี.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/กล้วยเชื่อม.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/ข้าวพันผัก.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/ตลาดหัวดง.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/นก.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/น้อง.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/บัวลอยน้ำขัง.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เขิน.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เคย.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เจอ.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เจ้าหนี้.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เช่าซื้อ.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เดิน.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เดิมพัน.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เนื้อวัว.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เนื้อหมู.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เปรู.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เพนกวิน.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เพลีย.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เมื่อย.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เรียก.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เรือข้ามฟาก.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เร่งมือ.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เล็ก.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เวอร์ไป.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เวเนซุเอลา.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เศรษฐกิจ.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เสรีภาพ.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เสือก.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เส้น.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เหตุสุดวิสัย.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เห็นด้วย.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เฮโรอีน.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/แท็บเล็ต.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/แบก.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/แผนที่.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/แม่ลาว (อำเภอ).mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/แม่วงก์ (อำเภอ).mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/แหวน.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/แองโกลา.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/แอฟริกาใต้.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/แอลจีเรีย.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/แอลเบเนีย.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/โกหก.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/โจทก์.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/โชจู.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/โนโหวต.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/โบ๊เบ๊.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/โรงงานทำ.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/โรมาเนีย.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/ใหญ่.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/ไดโนเสาร์.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/ไถ่ถอน.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/ไนกี้.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/ไอซ์.mp4\n"
     ]
    }
   ],
   "source": [
    "for filename in actions:\n",
    "    print(directory + '/' + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set mediapipe model \n",
    "for action in actions:\n",
    "    video_path = os.path.join(\"C:/Users/araya/Desktop/keypoints/video_extract\", action)\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    cap.set(cv2.CAP_PROP_FPS, 60)\n",
    "    length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    print(\"LENGTH:\" + str(length))\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error opening video file: {video_path}\")\n",
    "        continue\n",
    "\n",
    "    with mp_holist.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "        for seq in range(no_of_seqs):\n",
    "            for frame_num in range(seq_length):\n",
    "\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    print(f\"End of video {video_path}\")\n",
    "                    break\n",
    "                \n",
    "                img, results = mediapipe_detection(frame, holistic)\n",
    "                draw_styled_landmarks(img, results)\n",
    "\n",
    "                # print(frame_num)\n",
    "\n",
    "                if frame_num == 0: \n",
    "                    cv2.putText(img, 'DATA COLLECTION STARTED', (120,200), \n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255, 0), 4, cv2.LINE_AA)\n",
    "                    cv2.putText(img, f'Collecting frames for - {action} Sequence Number - {seq}', (15,12), \n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "                    cv2.imshow('OpenCV Window', img)\n",
    "                    cv2.waitKey(2000)  # 2 seconds delay for setup\n",
    "                else: \n",
    "                    cv2.putText(img, f'Collecting frames for - {action} Sequence Number - {seq}', (15,12), \n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "                    cv2.imshow('OpenCV Window', img)\n",
    "\n",
    "                keypoints = extract_keypoints(results)\n",
    "                npy_path = os.path.join(Model_Data, action, f\"frame_{frame_num}.npy\")\n",
    "                os.makedirs(os.path.dirname(npy_path), exist_ok=True)\n",
    "                np.save(npy_path, keypoints)\n",
    "\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set mediapipe model \n",
    "# for action in actions:\n",
    "#     video_path = os.path.join(video_dir, action)\n",
    "#     cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "#     if not cap.isOpened():\n",
    "#         print(f\"Error opening video file: {video_path}\")\n",
    "#         continue\n",
    "\n",
    "#     with mp_holist.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "#         frames = []\n",
    "\n",
    "#         while True:\n",
    "#             ret, frame = cap.read()\n",
    "#             if not ret:\n",
    "#                 break\n",
    "            \n",
    "#             img, results = mediapipe_detection(frame, holistic)\n",
    "#             keypoints = extract_keypoints(results)\n",
    "#             frames.append(keypoints)\n",
    "\n",
    "#         # Padding or trimming to fixed sequence length\n",
    "#         if len(frames) < seq_length:\n",
    "#             padding = [np.zeros_like(frames[0]) for _ in range(seq_length - len(frames))]\n",
    "#             frames.extend(padding)\n",
    "#         else:\n",
    "#             frames = frames[:seq_length]\n",
    "\n",
    "#         # Save sequences\n",
    "#         for i in range(len(frames)):\n",
    "#             npy_path = os.path.join(Model_Data, action, f\"frame_{i}.npy\")\n",
    "#             np.save(npy_path, frames[i])\n",
    "\n",
    "#     cap.release()\n",
    "\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Loop through all files in the directory\n",
    "# for filename in os.listdir(directory):\n",
    "#     # Check if the file is a video by checking its extension\n",
    "#     if filename.endswith(('.mp4', '.avi', '.mkv', '.mov')):\n",
    "#         print(f\"Processing {filename}...\")\n",
    "#         video_path = os.path.join(directory, filename)\n",
    "\n",
    "#         class_name = os.path.splitext(os.path.basename(video_path))[0]\n",
    "        \n",
    "#         cap = cv2.VideoCapture(video_path)\n",
    "#         with mp_holist.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "#             for action in actions:\n",
    "#                 for seq in range(no_of_seqs):\n",
    "#                     for frame_num in range(seq_length):\n",
    "#                         ret, frame = cap.read()\n",
    "#                         if not ret:\n",
    "#                             print(\"Error: Failed to read frame.\")\n",
    "#                             break  # Exit the loop if frame read fails\n",
    "                        \n",
    "#                         img, results = mediapipe_detection(frame, holistic)\n",
    "#                         draw_styled_landmarks(img, results)\n",
    "\n",
    "#                         # logic is for the formatting portion\n",
    "#                         if frame_num == 0: \n",
    "#                             cv2.putText(img, 'DATA COLLECTION STARTED', (120,200), \n",
    "#                                     cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255, 0), 4, cv2.LINE_AA)\n",
    "#                             cv2.putText(img, 'Collecting frames for - {} and Sequence Number - {}'.format(action, seq), (15,12), \n",
    "#                                     cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "#                             # Show to screen\n",
    "#                             cv2.imshow('OpenCV Window', img)\n",
    "#                             # providing the break for adjusting the posture\n",
    "#                             cv2.waitKey(2000) # 2 sec\n",
    "#                         else: \n",
    "#                             cv2.putText(img, 'Collecting frames for - {} and Sequence Number - {}'.format(action, seq), (15,12), \n",
    "#                                     cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "#                             # Show to screen\n",
    "#                             cv2.imshow('OpenCV Window', img)\n",
    "\n",
    "#                         keypoints = extract_keypoints(results)\n",
    "#                         npy_path = os.path.join(Model_Data, action, str(seq), str(frame_num))\n",
    "#                         np.save(npy_path, keypoints)\n",
    "\n",
    "#                         if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "#                             break\n",
    "\n",
    "#         cap.release()\n",
    "#         cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelMap = {label:num for num, label in enumerate(actions)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'กฎกระทรวง.mp4': 0,\n",
       " 'กฎหมายรัฐธรรมนูญ.mp4': 1,\n",
       " 'กรมอนามัย.mp4': 2,\n",
       " 'กรรม.mp4': 3,\n",
       " 'กรรมสิทธิ์.mp4': 4,\n",
       " 'กระโดด.mp4': 5,\n",
       " 'กลับ.mp4': 6,\n",
       " 'กล้วยบวชชี.mp4': 7,\n",
       " 'กล้วยเชื่อม.mp4': 8,\n",
       " 'ข้าวพันผัก.mp4': 9,\n",
       " 'ตลาดหัวดง.mp4': 10,\n",
       " 'นก.mp4': 11,\n",
       " 'น้อง.mp4': 12,\n",
       " 'บัวลอยน้ำขัง.mp4': 13,\n",
       " 'เขิน.mp4': 14,\n",
       " 'เคย.mp4': 15,\n",
       " 'เจอ.mp4': 16,\n",
       " 'เจ้าหนี้.mp4': 17,\n",
       " 'เช่าซื้อ.mp4': 18,\n",
       " 'เดิน.mp4': 19,\n",
       " 'เดิมพัน.mp4': 20,\n",
       " 'เนื้อวัว.mp4': 21,\n",
       " 'เนื้อหมู.mp4': 22,\n",
       " 'เปรู.mp4': 23,\n",
       " 'เพนกวิน.mp4': 24,\n",
       " 'เพลีย.mp4': 25,\n",
       " 'เมื่อย.mp4': 26,\n",
       " 'เรียก.mp4': 27,\n",
       " 'เรือข้ามฟาก.mp4': 28,\n",
       " 'เร่งมือ.mp4': 29,\n",
       " 'เล็ก.mp4': 30,\n",
       " 'เวอร์ไป.mp4': 31,\n",
       " 'เวเนซุเอลา.mp4': 32,\n",
       " 'เศรษฐกิจ.mp4': 33,\n",
       " 'เสรีภาพ.mp4': 34,\n",
       " 'เสือก.mp4': 35,\n",
       " 'เส้น.mp4': 36,\n",
       " 'เหตุสุดวิสัย.mp4': 37,\n",
       " 'เห็นด้วย.mp4': 38,\n",
       " 'เฮโรอีน.mp4': 39,\n",
       " 'แท็บเล็ต.mp4': 40,\n",
       " 'แบก.mp4': 41,\n",
       " 'แผนที่.mp4': 42,\n",
       " 'แม่ลาว (อำเภอ).mp4': 43,\n",
       " 'แม่วงก์ (อำเภอ).mp4': 44,\n",
       " 'แหวน.mp4': 45,\n",
       " 'แองโกลา.mp4': 46,\n",
       " 'แอฟริกาใต้.mp4': 47,\n",
       " 'แอลจีเรีย.mp4': 48,\n",
       " 'แอลเบเนีย.mp4': 49,\n",
       " 'โกหก.mp4': 50,\n",
       " 'โจทก์.mp4': 51,\n",
       " 'โชจู.mp4': 52,\n",
       " 'โนโหวต.mp4': 53,\n",
       " 'โบ๊เบ๊.mp4': 54,\n",
       " 'โรงงานทำ.mp4': 55,\n",
       " 'โรมาเนีย.mp4': 56,\n",
       " 'ใหญ่.mp4': 57,\n",
       " 'ไดโนเสาร์.mp4': 58,\n",
       " 'ไถ่ถอน.mp4': 59,\n",
       " 'ไนกี้.mp4': 60,\n",
       " 'ไอซ์.mp4': 61}"
      ]
     },
     "execution_count": 805,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 806,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs, labels = [], []\n",
    "\n",
    "for action in actions:\n",
    "    for seq in range(no_of_seqs):\n",
    "        window = []\n",
    "        for frame_num in range(seq_length):\n",
    "            res = np.load(os.path.join(Model_Data, action, f\"frame_{frame_num}.npy\")) \n",
    "            window.append(res)\n",
    "        seqs.append(window)\n",
    "\n",
    "        labels.append(labelMap[action])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 807,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.50134957,  0.2452457 , -1.21669424, ...,  0.56630969,\n",
       "        0.21883607,  0.00977684])"
      ]
     },
     "execution_count": 807,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import os\n",
    "Model_Data=os.path.join('Data for different actions')\n",
    "action = \"กฎกระทรวง.mp4\"\n",
    "a = np.load(os.path.join(Model_Data, action, \"frame_0.npy\"))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62, 30, 1662)"
      ]
     },
     "execution_count": 808,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(seqs).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 809,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = np.array(seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62, 30, 1662)"
      ]
     },
     "execution_count": 810,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61]"
      ]
     },
     "execution_count": 811,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 1, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 1]])"
      ]
     },
     "execution_count": 812,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# changing the labels from 0,1,2 to categorical data for easier accessebility\n",
    "Y_label = to_categorical(labels).astype(int)\n",
    "Y_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62, 62)"
      ]
     },
     "execution_count": 813,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 30, 1662)"
      ]
     },
     "execution_count": 814,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# splitting\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_data, Y_label, test_size=0.3)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 816,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding the logs folder\n",
    "log_dir = os.path.join('Logs')\n",
    "tb_callback = TensorBoard(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 817,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\araya\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# neural network\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, return_sequences=True, activation='relu', input_shape=(30,1662)))\n",
    "model.add(LSTM(128, return_sequences=True, activation='relu'))\n",
    "model.add(LSTM(64, return_sequences=False, activation='relu'))\n",
    "\n",
    "# adding 64 units for dense layer\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(actions.shape[0], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 818,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'กฎกระทรวง.mp4'"
      ]
     },
     "execution_count": 818,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# eg\n",
    "eg_res = [.7, 0.2, 0.1]\n",
    "actions[np.argmax(eg_res)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 819,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 820,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 76ms/step - categorical_accuracy: 0.0000e+00 - loss: 4.1605\n",
      "Epoch 2/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - categorical_accuracy: 0.0155 - loss: 17.4790  \n",
      "Epoch 3/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - categorical_accuracy: 0.0259 - loss: 5.6571\n",
      "Epoch 4/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - categorical_accuracy: 0.0518 - loss: 4.1316 \n",
      "Epoch 5/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - categorical_accuracy: 0.0259 - loss: 4.2661\n",
      "Epoch 6/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - categorical_accuracy: 0.0259 - loss: 4.4333\n",
      "Epoch 7/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - categorical_accuracy: 0.0000e+00 - loss: 4.3245\n",
      "Epoch 8/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - categorical_accuracy: 0.0155 - loss: 4.1519    \n",
      "Epoch 9/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - categorical_accuracy: 0.0259 - loss: 4.2284\n",
      "Epoch 10/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - categorical_accuracy: 0.0155 - loss: 4.1265    \n",
      "Epoch 11/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - categorical_accuracy: 0.0259 - loss: 4.1491\n",
      "Epoch 12/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - categorical_accuracy: 0.0518 - loss: 4.1061\n",
      "Epoch 13/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - categorical_accuracy: 0.0155 - loss: 4.1058    \n",
      "Epoch 14/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - categorical_accuracy: 0.0518 - loss: 4.0968\n",
      "Epoch 15/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - categorical_accuracy: 0.0000e+00 - loss: 4.0842 \n",
      "Epoch 16/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - categorical_accuracy: 0.0259 - loss: 4.0670\n",
      "Epoch 17/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - categorical_accuracy: 0.0155 - loss: 4.0576    \n",
      "Epoch 18/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - categorical_accuracy: 0.0259 - loss: 4.0471\n",
      "Epoch 19/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - categorical_accuracy: 0.0259 - loss: 4.0325\n",
      "Epoch 20/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - categorical_accuracy: 0.0259 - loss: 4.0374\n",
      "Epoch 21/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - categorical_accuracy: 0.0259 - loss: 4.0329\n",
      "Epoch 22/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - categorical_accuracy: 0.0259 - loss: 4.0416\n",
      "Epoch 23/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - categorical_accuracy: 0.0259 - loss: 4.0240\n",
      "Epoch 24/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - categorical_accuracy: 0.0259 - loss: 4.0054\n",
      "Epoch 25/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - categorical_accuracy: 0.0259 - loss: 3.9747\n",
      "Epoch 26/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - categorical_accuracy: 0.0155 - loss: 3.9763    \n",
      "Epoch 27/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - categorical_accuracy: 0.0259 - loss: 3.8858\n",
      "Epoch 28/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - categorical_accuracy: 0.0155 - loss: 4.0216    \n",
      "Epoch 29/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - categorical_accuracy: 0.0259 - loss: 3.9257\n",
      "Epoch 30/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - categorical_accuracy: 0.0155 - loss: 3.8711    \n",
      "Epoch 31/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - categorical_accuracy: 0.0155 - loss: 3.8933    \n",
      "Epoch 32/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - categorical_accuracy: 0.0414 - loss: 3.8808\n",
      "Epoch 33/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - categorical_accuracy: 0.0414 - loss: 3.9034\n",
      "Epoch 34/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - categorical_accuracy: 0.0414 - loss: 3.8453\n",
      "Epoch 35/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - categorical_accuracy: 0.0000e+00 - loss: 3.8633\n",
      "Epoch 36/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - categorical_accuracy: 0.0778 - loss: 3.8790\n",
      "Epoch 37/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - categorical_accuracy: 0.0259 - loss: 4.0085\n",
      "Epoch 38/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - categorical_accuracy: 0.0155 - loss: 3.9948    \n",
      "Epoch 39/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - categorical_accuracy: 0.0259 - loss: 3.9943\n",
      "Epoch 40/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - categorical_accuracy: 0.0414 - loss: 3.9800\n",
      "Epoch 41/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - categorical_accuracy: 0.0673 - loss: 3.8982\n",
      "Epoch 42/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - categorical_accuracy: 0.0933 - loss: 3.8894\n",
      "Epoch 43/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - categorical_accuracy: 0.0518 - loss: 3.7969\n",
      "Epoch 44/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - categorical_accuracy: 0.0518 - loss: 3.8558\n",
      "Epoch 45/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - categorical_accuracy: 0.0518 - loss: 3.7721\n",
      "Epoch 46/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - categorical_accuracy: 0.0259 - loss: 3.7047\n",
      "Epoch 47/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - categorical_accuracy: 0.0569 - loss: 3.7153\n",
      "Epoch 48/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - categorical_accuracy: 0.0673 - loss: 3.6690\n",
      "Epoch 49/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - categorical_accuracy: 0.0724 - loss: 3.6846\n",
      "Epoch 50/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - categorical_accuracy: 0.0518 - loss: 3.6650\n",
      "Epoch 51/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - categorical_accuracy: 0.0518 - loss: 3.7265\n",
      "Epoch 52/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - categorical_accuracy: 0.1037 - loss: 3.5854\n",
      "Epoch 53/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - categorical_accuracy: 0.0673 - loss: 3.6257\n",
      "Epoch 54/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - categorical_accuracy: 0.0673 - loss: 3.5859\n",
      "Epoch 55/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - categorical_accuracy: 0.0673 - loss: 3.6029\n",
      "Epoch 56/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - categorical_accuracy: 0.0414 - loss: 3.6593\n",
      "Epoch 57/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - categorical_accuracy: 0.1088 - loss: 3.5510\n",
      "Epoch 58/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - categorical_accuracy: 0.0673 - loss: 3.5692\n",
      "Epoch 59/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - categorical_accuracy: 0.0778 - loss: 3.5539\n",
      "Epoch 60/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - categorical_accuracy: 0.0518 - loss: 3.7347\n",
      "Epoch 61/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - categorical_accuracy: 0.0569 - loss: 3.9097\n",
      "Epoch 62/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - categorical_accuracy: 0.0673 - loss: 3.6196\n",
      "Epoch 63/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - categorical_accuracy: 0.0414 - loss: 3.6573\n",
      "Epoch 64/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - categorical_accuracy: 0.0414 - loss: 3.6047\n",
      "Epoch 65/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - categorical_accuracy: 0.0518 - loss: 3.5316\n",
      "Epoch 66/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - categorical_accuracy: 0.0673 - loss: 3.4776\n",
      "Epoch 67/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - categorical_accuracy: 0.1088 - loss: 3.3984\n",
      "Epoch 68/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - categorical_accuracy: 0.1037 - loss: 3.2825\n",
      "Epoch 69/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - categorical_accuracy: 0.0673 - loss: 3.2596\n",
      "Epoch 70/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - categorical_accuracy: 0.0518 - loss: 3.3013\n",
      "Epoch 71/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - categorical_accuracy: 0.1347 - loss: 3.1604\n",
      "Epoch 72/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - categorical_accuracy: 0.0778 - loss: 3.1847\n",
      "Epoch 73/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - categorical_accuracy: 0.1243 - loss: 3.0260\n",
      "Epoch 74/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - categorical_accuracy: 0.1451 - loss: 3.0073\n",
      "Epoch 75/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - categorical_accuracy: 0.1192 - loss: 2.9625\n",
      "Epoch 76/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - categorical_accuracy: 0.0828 - loss: 3.0374\n",
      "Epoch 77/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - categorical_accuracy: 0.1502 - loss: 3.0302\n",
      "Epoch 78/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - categorical_accuracy: 0.1347 - loss: 2.9875\n",
      "Epoch 79/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - categorical_accuracy: 0.1243 - loss: 2.8360\n",
      "Epoch 80/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - categorical_accuracy: 0.1347 - loss: 2.8582\n",
      "Epoch 81/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - categorical_accuracy: 0.0984 - loss: 3.1744\n",
      "Epoch 82/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - categorical_accuracy: 0.1969 - loss: 2.8488\n",
      "Epoch 83/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - categorical_accuracy: 0.1451 - loss: 2.7919\n",
      "Epoch 84/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - categorical_accuracy: 0.1192 - loss: 2.8613\n",
      "Epoch 85/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - categorical_accuracy: 0.2125 - loss: 2.8160\n",
      "Epoch 86/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - categorical_accuracy: 0.1814 - loss: 2.7233\n",
      "Epoch 87/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - categorical_accuracy: 0.1710 - loss: 2.5467\n",
      "Epoch 88/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - categorical_accuracy: 0.1606 - loss: 2.4331\n",
      "Epoch 89/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - categorical_accuracy: 0.2071 - loss: 2.5128\n",
      "Epoch 90/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - categorical_accuracy: 0.2539 - loss: 2.3232\n",
      "Epoch 91/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - categorical_accuracy: 0.2953 - loss: 2.1901\n",
      "Epoch 92/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - categorical_accuracy: 0.2539 - loss: 2.1527\n",
      "Epoch 93/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - categorical_accuracy: 0.1967 - loss: 2.2250\n",
      "Epoch 94/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - categorical_accuracy: 0.2643 - loss: 2.1834\n",
      "Epoch 95/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - categorical_accuracy: 0.1969 - loss: 2.2179\n",
      "Epoch 96/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - categorical_accuracy: 0.3471 - loss: 2.0000\n",
      "Epoch 97/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - categorical_accuracy: 0.3680 - loss: 1.8907\n",
      "Epoch 98/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - categorical_accuracy: 0.3680 - loss: 1.7897 \n",
      "Epoch 99/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - categorical_accuracy: 0.3212 - loss: 1.8538\n",
      "Epoch 100/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - categorical_accuracy: 0.2229 - loss: 1.9728\n",
      "Epoch 101/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - categorical_accuracy: 0.3471 - loss: 1.8508\n",
      "Epoch 102/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - categorical_accuracy: 0.3161 - loss: 1.9592\n",
      "Epoch 103/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - categorical_accuracy: 0.2747 - loss: 2.0691\n",
      "Epoch 104/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - categorical_accuracy: 0.1555 - loss: 2.3482\n",
      "Epoch 105/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - categorical_accuracy: 0.2643 - loss: 2.2056\n",
      "Epoch 106/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - categorical_accuracy: 0.1916 - loss: 2.5875\n",
      "Epoch 107/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - categorical_accuracy: 0.2902 - loss: 2.1713\n",
      "Epoch 108/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - categorical_accuracy: 0.1865 - loss: 2.1446\n",
      "Epoch 109/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - categorical_accuracy: 0.3316 - loss: 1.8913\n",
      "Epoch 110/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - categorical_accuracy: 0.3367 - loss: 1.8181\n",
      "Epoch 111/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - categorical_accuracy: 0.3212 - loss: 1.8295\n",
      "Epoch 112/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - categorical_accuracy: 0.3212 - loss: 1.7288\n",
      "Epoch 113/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - categorical_accuracy: 0.3990 - loss: 1.5843\n",
      "Epoch 114/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - categorical_accuracy: 0.3525 - loss: 1.7205\n",
      "Epoch 115/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - categorical_accuracy: 0.2849 - loss: 1.8044\n",
      "Epoch 116/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - categorical_accuracy: 0.3367 - loss: 1.8389\n",
      "Epoch 117/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - categorical_accuracy: 0.3626 - loss: 1.6973\n",
      "Epoch 118/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - categorical_accuracy: 0.4249 - loss: 1.6043\n",
      "Epoch 119/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - categorical_accuracy: 0.4094 - loss: 1.5244\n",
      "Epoch 120/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - categorical_accuracy: 0.5441 - loss: 1.3920\n",
      "Epoch 121/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - categorical_accuracy: 0.3990 - loss: 1.5698\n",
      "Epoch 122/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - categorical_accuracy: 0.4249 - loss: 1.4464\n",
      "Epoch 123/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - categorical_accuracy: 0.4767 - loss: 1.3057\n",
      "Epoch 124/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - categorical_accuracy: 0.3367 - loss: 1.8102\n",
      "Epoch 125/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - categorical_accuracy: 0.3781 - loss: 1.6555\n",
      "Epoch 126/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - categorical_accuracy: 0.3108 - loss: 1.8491\n",
      "Epoch 127/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - categorical_accuracy: 0.3939 - loss: 1.5236\n",
      "Epoch 128/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - categorical_accuracy: 0.3576 - loss: 1.4776\n",
      "Epoch 129/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - categorical_accuracy: 0.3731 - loss: 1.8306\n",
      "Epoch 130/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - categorical_accuracy: 0.3212 - loss: 1.7010\n",
      "Epoch 131/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - categorical_accuracy: 0.3886 - loss: 1.4084\n",
      "Epoch 132/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - categorical_accuracy: 0.4145 - loss: 1.4693\n",
      "Epoch 133/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - categorical_accuracy: 0.4973 - loss: 1.4221\n",
      "Epoch 134/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - categorical_accuracy: 0.5024 - loss: 1.2562\n",
      "Epoch 135/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - categorical_accuracy: 0.4767 - loss: 1.2786\n",
      "Epoch 136/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - categorical_accuracy: 0.4872 - loss: 1.2908\n",
      "Epoch 137/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - categorical_accuracy: 0.4353 - loss: 1.4973\n",
      "Epoch 138/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - categorical_accuracy: 0.5182 - loss: 1.2119\n",
      "Epoch 139/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - categorical_accuracy: 0.2643 - loss: 1.8305\n",
      "Epoch 140/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - categorical_accuracy: 0.3886 - loss: 1.4873\n",
      "Epoch 141/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - categorical_accuracy: 0.4041 - loss: 1.5047\n",
      "Epoch 142/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - categorical_accuracy: 0.5596 - loss: 1.3354\n",
      "Epoch 143/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - categorical_accuracy: 0.5700 - loss: 1.3690\n",
      "Epoch 144/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - categorical_accuracy: 0.4717 - loss: 1.3195\n",
      "Epoch 145/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - categorical_accuracy: 0.6063 - loss: 1.2119\n",
      "Epoch 146/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - categorical_accuracy: 0.4818 - loss: 1.1331\n",
      "Epoch 147/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - categorical_accuracy: 0.6061 - loss: 1.0951\n",
      "Epoch 148/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - categorical_accuracy: 0.6063 - loss: 1.0955\n",
      "Epoch 149/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - categorical_accuracy: 0.5337 - loss: 1.1761\n",
      "Epoch 150/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - categorical_accuracy: 0.5337 - loss: 1.1774\n",
      "Epoch 151/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - categorical_accuracy: 0.5959 - loss: 1.0554\n",
      "Epoch 152/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - categorical_accuracy: 0.5286 - loss: 1.0676\n",
      "Epoch 153/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - categorical_accuracy: 0.6114 - loss: 0.9999\n",
      "Epoch 154/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - categorical_accuracy: 0.5182 - loss: 1.4301\n",
      "Epoch 155/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - categorical_accuracy: 0.6424 - loss: 0.9434\n",
      "Epoch 156/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - categorical_accuracy: 0.5751 - loss: 1.0708\n",
      "Epoch 157/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - categorical_accuracy: 0.6269 - loss: 1.0398\n",
      "Epoch 158/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - categorical_accuracy: 0.5959 - loss: 1.0770\n",
      "Epoch 159/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - categorical_accuracy: 0.7306 - loss: 0.9985\n",
      "Epoch 160/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - categorical_accuracy: 0.7461 - loss: 0.9139\n",
      "Epoch 161/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - categorical_accuracy: 0.6424 - loss: 0.8979\n",
      "Epoch 162/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - categorical_accuracy: 0.7151 - loss: 0.8216\n",
      "Epoch 163/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - categorical_accuracy: 0.7047 - loss: 0.7930\n",
      "Epoch 164/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - categorical_accuracy: 0.6529 - loss: 0.8409\n",
      "Epoch 165/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - categorical_accuracy: 0.5647 - loss: 0.9201\n",
      "Epoch 166/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - categorical_accuracy: 0.6582 - loss: 0.9325\n",
      "Epoch 167/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - categorical_accuracy: 0.5906 - loss: 0.9321\n",
      "Epoch 168/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - categorical_accuracy: 0.6737 - loss: 1.0143\n",
      "Epoch 169/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - categorical_accuracy: 0.5286 - loss: 1.1290\n",
      "Epoch 170/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - categorical_accuracy: 0.4922 - loss: 1.4191\n",
      "Epoch 171/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - categorical_accuracy: 0.4508 - loss: 1.3296\n",
      "Epoch 172/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - categorical_accuracy: 0.5441 - loss: 1.1371\n",
      "Epoch 173/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - categorical_accuracy: 0.5182 - loss: 1.1319\n",
      "Epoch 174/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - categorical_accuracy: 0.6010 - loss: 0.9939\n",
      "Epoch 175/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - categorical_accuracy: 0.6374 - loss: 1.0523\n",
      "Epoch 176/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - categorical_accuracy: 0.6684 - loss: 0.9167\n",
      "Epoch 177/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - categorical_accuracy: 0.5906 - loss: 1.0188\n",
      "Epoch 178/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - categorical_accuracy: 0.6216 - loss: 0.9969\n",
      "Epoch 179/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - categorical_accuracy: 0.7357 - loss: 0.8385\n",
      "Epoch 180/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - categorical_accuracy: 0.7357 - loss: 0.7161\n",
      "Epoch 181/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - categorical_accuracy: 0.7359 - loss: 0.7676\n",
      "Epoch 182/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - categorical_accuracy: 0.6633 - loss: 0.7466\n",
      "Epoch 183/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - categorical_accuracy: 0.6374 - loss: 0.8617\n",
      "Epoch 184/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - categorical_accuracy: 0.6010 - loss: 0.8932\n",
      "Epoch 185/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - categorical_accuracy: 0.6943 - loss: 0.7609\n",
      "Epoch 186/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - categorical_accuracy: 0.7306 - loss: 0.7746\n",
      "Epoch 187/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - categorical_accuracy: 0.6943 - loss: 0.7980\n",
      "Epoch 188/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - categorical_accuracy: 0.6010 - loss: 0.9881\n",
      "Epoch 189/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - categorical_accuracy: 0.7151 - loss: 0.7655\n",
      "Epoch 190/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - categorical_accuracy: 0.6216 - loss: 0.7472\n",
      "Epoch 191/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - categorical_accuracy: 0.7306 - loss: 0.6623\n",
      "Epoch 192/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - categorical_accuracy: 0.4661 - loss: 1.1203\n",
      "Epoch 193/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - categorical_accuracy: 0.6579 - loss: 0.7501\n",
      "Epoch 194/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - categorical_accuracy: 0.6269 - loss: 0.8143\n",
      "Epoch 195/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - categorical_accuracy: 0.6788 - loss: 0.7292\n",
      "Epoch 196/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - categorical_accuracy: 0.7929 - loss: 0.6472\n",
      "Epoch 197/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - categorical_accuracy: 0.8394 - loss: 0.5773\n",
      "Epoch 198/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - categorical_accuracy: 0.6579 - loss: 0.8280\n",
      "Epoch 199/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - categorical_accuracy: 0.6737 - loss: 1.0787\n",
      "Epoch 200/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - categorical_accuracy: 0.6788 - loss: 0.8023\n",
      "Epoch 201/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - categorical_accuracy: 0.5233 - loss: 1.1808\n",
      "Epoch 202/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - categorical_accuracy: 0.6269 - loss: 0.8770\n",
      "Epoch 203/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - categorical_accuracy: 0.5078 - loss: 1.1007\n",
      "Epoch 204/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - categorical_accuracy: 0.6943 - loss: 0.8372\n",
      "Epoch 205/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - categorical_accuracy: 0.7151 - loss: 0.7990\n",
      "Epoch 206/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - categorical_accuracy: 0.7098 - loss: 0.8103\n",
      "Epoch 207/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - categorical_accuracy: 0.7098 - loss: 0.7775\n",
      "Epoch 208/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - categorical_accuracy: 0.7253 - loss: 0.7267\n",
      "Epoch 209/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - categorical_accuracy: 0.8084 - loss: 0.6373\n",
      "Epoch 210/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - categorical_accuracy: 0.8290 - loss: 0.6265\n",
      "Epoch 211/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - categorical_accuracy: 0.8290 - loss: 0.5635\n",
      "Epoch 212/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - categorical_accuracy: 0.7875 - loss: 0.5465\n",
      "Epoch 213/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - categorical_accuracy: 0.8135 - loss: 0.5461\n",
      "Epoch 214/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - categorical_accuracy: 0.8498 - loss: 0.4734\n",
      "Epoch 215/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - categorical_accuracy: 0.8031 - loss: 0.4812\n",
      "Epoch 216/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - categorical_accuracy: 0.7616 - loss: 0.5147\n",
      "Epoch 217/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - categorical_accuracy: 0.1555 - loss: 6.2732\n",
      "Epoch 218/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - categorical_accuracy: 0.2384 - loss: 3.2637 \n",
      "Epoch 219/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - categorical_accuracy: 0.0933 - loss: 2.9359\n",
      "Epoch 220/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - categorical_accuracy: 0.1037 - loss: 2.9573\n",
      "Epoch 221/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - categorical_accuracy: 0.1088 - loss: 2.8422\n",
      "Epoch 222/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - categorical_accuracy: 0.1451 - loss: 2.7512\n",
      "Epoch 223/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - categorical_accuracy: 0.1969 - loss: 2.7039\n",
      "Epoch 224/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - categorical_accuracy: 0.1606 - loss: 2.4863\n",
      "Epoch 225/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - categorical_accuracy: 0.3367 - loss: 1.9892\n",
      "Epoch 226/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - categorical_accuracy: 0.3006 - loss: 1.8709\n",
      "Epoch 227/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - categorical_accuracy: 0.2384 - loss: 2.5408\n",
      "Epoch 228/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - categorical_accuracy: 0.2020 - loss: 2.1838\n",
      "Epoch 229/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - categorical_accuracy: 0.3835 - loss: 1.7731\n",
      "Epoch 230/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - categorical_accuracy: 0.3212 - loss: 1.9228\n",
      "Epoch 231/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - categorical_accuracy: 0.3576 - loss: 1.8666\n",
      "Epoch 232/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - categorical_accuracy: 0.3939 - loss: 1.6974\n",
      "Epoch 233/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - categorical_accuracy: 0.3937 - loss: 1.5755\n",
      "Epoch 234/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - categorical_accuracy: 0.5596 - loss: 1.3159\n",
      "Epoch 235/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - categorical_accuracy: 0.5441 - loss: 1.2921\n",
      "Epoch 236/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - categorical_accuracy: 0.5751 - loss: 1.2176\n",
      "Epoch 237/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - categorical_accuracy: 0.6063 - loss: 1.2647\n",
      "Epoch 238/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - categorical_accuracy: 0.5182 - loss: 1.1812\n",
      "Epoch 239/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - categorical_accuracy: 0.6010 - loss: 1.1919\n",
      "Epoch 240/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - categorical_accuracy: 0.6114 - loss: 1.0234\n",
      "Epoch 241/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - categorical_accuracy: 0.5751 - loss: 1.1309\n",
      "Epoch 242/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - categorical_accuracy: 0.5959 - loss: 1.0354\n",
      "Epoch 243/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - categorical_accuracy: 0.6010 - loss: 1.0369\n",
      "Epoch 244/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - categorical_accuracy: 0.6114 - loss: 0.9923\n",
      "Epoch 245/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - categorical_accuracy: 0.6994 - loss: 0.9038\n",
      "Epoch 246/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - categorical_accuracy: 0.7202 - loss: 0.8441\n",
      "Epoch 247/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - categorical_accuracy: 0.7151 - loss: 0.9028\n",
      "Epoch 248/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - categorical_accuracy: 0.6323 - loss: 0.9411\n",
      "Epoch 249/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - categorical_accuracy: 0.5959 - loss: 1.0452\n",
      "Epoch 250/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - categorical_accuracy: 0.5596 - loss: 1.0291\n",
      "Epoch 251/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - categorical_accuracy: 0.6529 - loss: 0.9333\n",
      "Epoch 252/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - categorical_accuracy: 0.6579 - loss: 1.0145\n",
      "Epoch 253/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - categorical_accuracy: 0.6529 - loss: 0.9048\n",
      "Epoch 254/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - categorical_accuracy: 0.6219 - loss: 0.8887\n",
      "Epoch 255/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - categorical_accuracy: 0.6114 - loss: 0.8620\n",
      "Epoch 256/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - categorical_accuracy: 0.8343 - loss: 0.7212\n",
      "Epoch 257/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - categorical_accuracy: 0.7980 - loss: 0.7083\n",
      "Epoch 258/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - categorical_accuracy: 0.7512 - loss: 0.7045\n",
      "Epoch 259/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - categorical_accuracy: 0.8084 - loss: 0.6360\n",
      "Epoch 260/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - categorical_accuracy: 0.7461 - loss: 0.6360\n",
      "Epoch 261/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - categorical_accuracy: 0.7306 - loss: 0.6257\n",
      "Epoch 262/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - categorical_accuracy: 0.7720 - loss: 0.5830\n",
      "Epoch 263/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - categorical_accuracy: 0.7357 - loss: 0.7426\n",
      "Epoch 264/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - categorical_accuracy: 0.7616 - loss: 0.5870\n",
      "Epoch 265/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - categorical_accuracy: 0.7825 - loss: 0.5742\n",
      "Epoch 266/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - categorical_accuracy: 0.7875 - loss: 0.5739\n",
      "Epoch 267/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - categorical_accuracy: 0.7825 - loss: 0.5900\n",
      "Epoch 268/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - categorical_accuracy: 0.8290 - loss: 0.5526\n",
      "Epoch 269/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - categorical_accuracy: 0.7565 - loss: 0.6139\n",
      "Epoch 270/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - categorical_accuracy: 0.7253 - loss: 0.7403\n",
      "Epoch 271/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - categorical_accuracy: 0.7771 - loss: 0.5876\n",
      "Epoch 272/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - categorical_accuracy: 0.8135 - loss: 0.5115\n",
      "Epoch 273/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - categorical_accuracy: 0.8031 - loss: 0.5440\n",
      "Epoch 274/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - categorical_accuracy: 0.8031 - loss: 0.5227\n",
      "Epoch 275/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - categorical_accuracy: 0.8239 - loss: 0.4618\n",
      "Epoch 276/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - categorical_accuracy: 0.8498 - loss: 0.4321\n",
      "Epoch 277/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - categorical_accuracy: 0.8549 - loss: 0.4258\n",
      "Epoch 278/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - categorical_accuracy: 0.8290 - loss: 0.4650\n",
      "Epoch 279/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - categorical_accuracy: 0.7926 - loss: 0.4975\n",
      "Epoch 280/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - categorical_accuracy: 0.8084 - loss: 0.4526\n",
      "Epoch 281/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - categorical_accuracy: 0.7771 - loss: 0.7500\n",
      "Epoch 282/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - categorical_accuracy: 0.7670 - loss: 0.6165\n",
      "Epoch 283/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - categorical_accuracy: 0.8135 - loss: 0.5582\n",
      "Epoch 284/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - categorical_accuracy: 0.8549 - loss: 0.4934\n",
      "Epoch 285/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - categorical_accuracy: 0.8549 - loss: 0.5195\n",
      "Epoch 286/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - categorical_accuracy: 0.7720 - loss: 0.6112\n",
      "Epoch 287/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - categorical_accuracy: 0.7616 - loss: 0.6810\n",
      "Epoch 288/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - categorical_accuracy: 0.8290 - loss: 0.4905\n",
      "Epoch 289/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - categorical_accuracy: 0.8549 - loss: 0.4447\n",
      "Epoch 290/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - categorical_accuracy: 0.8239 - loss: 0.4604\n",
      "Epoch 291/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - categorical_accuracy: 0.8394 - loss: 0.4177\n",
      "Epoch 292/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - categorical_accuracy: 0.8808 - loss: 0.3964\n",
      "Epoch 293/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - categorical_accuracy: 0.8394 - loss: 0.3971\n",
      "Epoch 294/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - categorical_accuracy: 0.8135 - loss: 0.4059\n",
      "Epoch 295/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - categorical_accuracy: 0.8549 - loss: 0.4085\n",
      "Epoch 296/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - categorical_accuracy: 0.8290 - loss: 0.4165\n",
      "Epoch 297/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - categorical_accuracy: 0.8186 - loss: 0.5309\n",
      "Epoch 298/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - categorical_accuracy: 0.8498 - loss: 0.3487\n",
      "Epoch 299/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - categorical_accuracy: 0.8808 - loss: 0.3982\n",
      "Epoch 300/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - categorical_accuracy: 0.8394 - loss: 0.4230\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x219b9305ac0>"
      ]
     },
     "execution_count": 820,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, epochs=300, callbacks=[tb_callback])\n",
    "# tensorboard --logdir=."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 821,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_16\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_16\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">442,112</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,046</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_48 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │       \u001b[38;5;34m442,112\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_49 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m98,816\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_50 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m49,408\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_48 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_49 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_50 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m62\u001b[0m)             │         \u001b[38;5;34m2,046\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,795,868</span> (6.85 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,795,868\u001b[0m (6.85 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">598,622</span> (2.28 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m598,622\u001b[0m (2.28 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,197,246</span> (4.57 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m1,197,246\u001b[0m (4.57 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 822,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351ms/step\n"
     ]
    }
   ],
   "source": [
    "res=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 833,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'เสรีภาพ.mp4'"
      ]
     },
     "execution_count": 833,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# again the actions with the max value provided by softmax is returned\n",
    "actions[np.argmax(res[4])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'กระโดด.mp4'"
      ]
     },
     "execution_count": 834,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions[np.argmax(Y_test[4])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 825,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.3614169e-10, 3.0754967e-12, 2.0070323e-12, 2.1532799e-24,\n",
       "       2.1561692e-20, 1.7584062e-26, 1.2675041e-01, 1.7304397e-09,\n",
       "       4.4307029e-07, 1.8685256e-10, 2.5035581e-12, 3.3671555e-14,\n",
       "       1.4661473e-02, 4.7236715e-33, 8.5786980e-01, 3.1077927e-16,\n",
       "       4.1084547e-04, 1.7123599e-08, 4.5735862e-28, 1.0999481e-07,\n",
       "       6.9791474e-07, 7.5544902e-24, 2.0473088e-04, 2.5380922e-10,\n",
       "       1.3093950e-20, 4.2368713e-11, 4.1878586e-05, 2.9478992e-06,\n",
       "       5.2299626e-11, 8.7867194e-18, 1.2265722e-12, 1.5006026e-23,\n",
       "       4.5834929e-07, 3.5660457e-20, 3.3237083e-10, 1.5653501e-14,\n",
       "       8.4509399e-11, 4.2719859e-29, 3.2512336e-13, 2.4185783e-32,\n",
       "       4.3881471e-05, 2.6073999e-07, 6.6510985e-14, 3.1582798e-13,\n",
       "       1.4811833e-08, 1.6452044e-10, 1.2757273e-24, 3.3762517e-20,\n",
       "       2.3390094e-27, 8.3827112e-11, 1.2340488e-08, 6.0356321e-18,\n",
       "       1.7330809e-18, 5.0725322e-12, 7.4164032e-24, 2.3928138e-21,\n",
       "       1.0240447e-15, 1.2674446e-09, 1.1723580e-05, 1.2631021e-18,\n",
       "       5.2438846e-08, 2.6350125e-07], dtype=float32)"
      ]
     },
     "execution_count": 825,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 835,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 837,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step \n"
     ]
    }
   ],
   "source": [
    "Y_hat = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_true = np.argmax(Y_train, axis=1).tolist()\n",
    "# one hot encoding\n",
    "Y_hat = np.argmax(Y_hat, axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7,\n",
       " 14,\n",
       " 10,\n",
       " 45,\n",
       " 26,\n",
       " 22,\n",
       " 36,\n",
       " 17,\n",
       " 10,\n",
       " 15,\n",
       " 58,\n",
       " 6,\n",
       " 30,\n",
       " 11,\n",
       " 11,\n",
       " 25,\n",
       " 56,\n",
       " 32,\n",
       " 0,\n",
       " 38,\n",
       " 27,\n",
       " 8,\n",
       " 28,\n",
       " 61,\n",
       " 34,\n",
       " 11,\n",
       " 41,\n",
       " 11,\n",
       " 57,\n",
       " 12,\n",
       " 27,\n",
       " 44,\n",
       " 16,\n",
       " 1,\n",
       " 53,\n",
       " 19,\n",
       " 43,\n",
       " 11,\n",
       " 20,\n",
       " 40,\n",
       " 51,\n",
       " 49,\n",
       " 23]"
      ]
     },
     "execution_count": 839,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[42,  0],\n",
       "        [ 0,  1]],\n",
       "\n",
       "       [[42,  0],\n",
       "        [ 0,  1]],\n",
       "\n",
       "       [[42,  0],\n",
       "        [ 1,  0]],\n",
       "\n",
       "       [[42,  0],\n",
       "        [ 0,  1]],\n",
       "\n",
       "       [[42,  0],\n",
       "        [ 0,  1]],\n",
       "\n",
       "       [[42,  0],\n",
       "        [ 0,  1]],\n",
       "\n",
       "       [[42,  0],\n",
       "        [ 1,  0]],\n",
       "\n",
       "       [[40,  2],\n",
       "        [ 1,  0]],\n",
       "\n",
       "       [[38,  4],\n",
       "        [ 0,  1]],\n",
       "\n",
       "       [[42,  0],\n",
       "        [ 0,  1]],\n",
       "\n",
       "       [[42,  0],\n",
       "        [ 0,  1]],\n",
       "\n",
       "       [[42,  0],\n",
       "        [ 0,  1]],\n",
       "\n",
       "       [[42,  0],\n",
       "        [ 0,  1]],\n",
       "\n",
       "       [[42,  0],\n",
       "        [ 0,  1]],\n",
       "\n",
       "       [[42,  0],\n",
       "        [ 0,  1]],\n",
       "\n",
       "       [[42,  0],\n",
       "        [ 0,  1]],\n",
       "\n",
       "       [[42,  0],\n",
       "        [ 0,  1]],\n",
       "\n",
       "       [[42,  0],\n",
       "        [ 0,  1]],\n",
       "\n",
       "       [[42,  0],\n",
       "        [ 0,  1]],\n",
       "\n",
       "       [[42,  0],\n",
       "        [ 0,  1]],\n",
       "\n",
       "       [[41,  1],\n",
       "        [ 0,  1]],\n",
       "\n",
       "       [[42,  0],\n",
       "        [ 0,  1]],\n",
       "\n",
       "       [[42,  0],\n",
       "        [ 1,  0]],\n",
       "\n",
       "       [[42,  0],\n",
       "        [ 0,  1]],\n",
       "\n",
       "       [[42,  0],\n",
       "        [ 0,  1]],\n",
       "\n",
       "       [[42,  0],\n",
       "        [ 0,  1]],\n",
       "\n",
       "       [[42,  0],\n",
       "        [ 1,  0]],\n",
       "\n",
       "       [[42,  0],\n",
       "        [ 0,  1]],\n",
       "\n",
       "       [[42,  0],\n",
       "        [ 0,  1]],\n",
       "\n",
       "       [[42,  0],\n",
       "        [ 0,  1]],\n",
       "\n",
       "       [[42,  0],\n",
       "        [ 0,  1]],\n",
       "\n",
       "       [[42,  0],\n",
       "        [ 0,  1]],\n",
       "\n",
       "       [[42,  0],\n",
       "        [ 0,  1]],\n",
       "\n",
       "       [[42,  0],\n",
       "        [ 0,  1]],\n",
       "\n",
       "       [[42,  0],\n",
       "        [ 0,  1]],\n",
       "\n",
       "       [[42,  0],\n",
       "        [ 1,  0]],\n",
       "\n",
       "       [[42,  0],\n",
       "        [ 0,  1]],\n",
       "\n",
       "       [[42,  0],\n",
       "        [ 0,  1]],\n",
       "\n",
       "       [[42,  0],\n",
       "        [ 0,  1]],\n",
       "\n",
       "       [[42,  0],\n",
       "        [ 0,  1]],\n",
       "\n",
       "       [[42,  0],\n",
       "        [ 0,  1]],\n",
       "\n",
       "       [[42,  0],\n",
       "        [ 1,  0]],\n",
       "\n",
       "       [[42,  0],\n",
       "        [ 0,  1]]], dtype=int64)"
      ]
     },
     "execution_count": 840,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confution matrix\n",
    "multilabel_confusion_matrix(Y_true, Y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 841,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8372093023255814"
      ]
     },
     "execution_count": 841,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y_true, Y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
