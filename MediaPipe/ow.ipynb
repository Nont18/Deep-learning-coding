{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video Classification using only LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import mediapipe as mp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holist = mp.solutions.holistic \n",
    "mp_draw = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_detection(img, model):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img.flags.writeable = False                 \n",
    "    result = model.process(img)                 # Make prediction\n",
    "    img.flags.writeable = True                   \n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR) \n",
    "    return img, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_landmarks(img, result):\n",
    "    mp_draw.draw_landmarks(img, result.face_landmarks, mp_holist.FACEMESH_CONTOURS) # Draw face connections\n",
    "    mp_draw.draw_landmarks(img, result.pose_landmarks, mp_holist.POSE_CONNECTIONS) # Draw pose connections\n",
    "    mp_draw.draw_landmarks(img, result.left_hand_landmarks, mp_holist.HAND_CONNECTIONS) # Draw left hand connections\n",
    "    mp_draw.draw_landmarks(img, result.right_hand_landmarks, mp_holist.HAND_CONNECTIONS) # Draw right hand connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_styled_landmarks(img, result):\n",
    "    mp_draw.draw_landmarks(img, result.face_landmarks, mp_holist.FACEMESH_CONTOURS, \n",
    "                             mp_draw.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1), # color the joint \n",
    "                             mp_draw.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1) #color the connection\n",
    "                             ) \n",
    "    # mp_draw.draw_landmarks(img, result.face_landmarks, mp_holist.FACEMESH_CONTOURS, \n",
    "    #                          mp_draw.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1), # color the joint \n",
    "    #                          mp_draw.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1) #color the connection\n",
    "    #                          ) \n",
    "    \n",
    "    mp_draw.draw_landmarks(img, result.pose_landmarks, mp_holist.POSE_CONNECTIONS,\n",
    "                             mp_draw.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4), \n",
    "                             mp_draw.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                             ) \n",
    "    mp_draw.draw_landmarks(img, result.left_hand_landmarks, mp_holist.HAND_CONNECTIONS, \n",
    "                             mp_draw.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4), \n",
    "                             mp_draw.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                             ) \n",
    "    mp_draw.draw_landmarks(img, result.right_hand_landmarks, mp_holist.HAND_CONNECTIONS, \n",
    "                             mp_draw.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4), \n",
    "                             mp_draw.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                             ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frozenset({(0, 1),\n",
       "           (0, 4),\n",
       "           (1, 2),\n",
       "           (2, 3),\n",
       "           (3, 7),\n",
       "           (4, 5),\n",
       "           (5, 6),\n",
       "           (6, 8),\n",
       "           (9, 10),\n",
       "           (11, 12),\n",
       "           (11, 13),\n",
       "           (11, 23),\n",
       "           (12, 14),\n",
       "           (12, 24),\n",
       "           (13, 15),\n",
       "           (14, 16),\n",
       "           (15, 17),\n",
       "           (15, 19),\n",
       "           (15, 21),\n",
       "           (16, 18),\n",
       "           (16, 20),\n",
       "           (16, 22),\n",
       "           (17, 19),\n",
       "           (18, 20),\n",
       "           (23, 24),\n",
       "           (23, 25),\n",
       "           (24, 26),\n",
       "           (25, 27),\n",
       "           (26, 28),\n",
       "           (27, 29),\n",
       "           (27, 31),\n",
       "           (28, 30),\n",
       "           (28, 32),\n",
       "           (29, 31),\n",
       "           (30, 32)})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp_holist.POSE_CONNECTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\araya\\AppData\\Roaming\\Python\\Python312\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "# Set mediapipe model \n",
    "with mp_holist.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        image, results = mediapipe_detection(frame, holistic)\n",
    "        print(results)\n",
    "        \n",
    "        draw_styled_landmarks(image, results)\n",
    "\n",
    "        cv2.imshow('OpenCV Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9986712336540222"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.pose_landmarks.landmark[0].visibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results.pose_landmarks.landmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keypoints(results):\n",
    "    pose=np.array([[res.x,res.y,res.z,res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*4)\n",
    "    left_hnd=np.array([[res.x,res.y,res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "    right_hnd=np.array([[res.x,res.y,res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "    face=np.array([[res.x,res.y,res.z] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(468*3)\n",
    "    return np.concatenate([pose,left_hnd,right_hnd,face])\n",
    "# concatenating for the model to detect the sign language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1662,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_keypoints(results).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "video_dir = \"C:/Users/araya/Desktop/keypoints/video_extract\"\n",
    "video_list = []\n",
    "video_list = os.listdir(video_dir)\n",
    "\n",
    "len(video_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['กฎกระทรวง.mp4',\n",
       " 'กฎหมายรัฐธรรมนูญ.mp4',\n",
       " 'กรมอนามัย.mp4',\n",
       " 'กรรม.mp4',\n",
       " 'กรรมสิทธิ์.mp4',\n",
       " 'กระโดด.mp4',\n",
       " 'กล้วยบวชชี.mp4',\n",
       " 'กล้วยเชื่อม.mp4',\n",
       " 'กังวล.mp4',\n",
       " 'กีฬา.mp4',\n",
       " 'น้อง.mp4',\n",
       " 'เขิน.mp4',\n",
       " 'เขื่อนดิน.mp4',\n",
       " 'เขื่อนสิริกิติ์.mp4',\n",
       " 'เข้าใจผิด.mp4',\n",
       " 'เคย.mp4',\n",
       " 'เครียด.mp4',\n",
       " 'เครื่องปั่นดิน.mp4',\n",
       " 'เครื่องหมายการค้า.mp4',\n",
       " 'เจอ.mp4',\n",
       " 'เจ้าหนี้.mp4',\n",
       " 'เช่าซื้อ.mp4',\n",
       " 'เช่าทรัพย์.mp4',\n",
       " 'เซอร์เบีย.mp4',\n",
       " 'เซเนกัล.mp4',\n",
       " 'เซ็ง.mp4',\n",
       " 'เดิน.mp4',\n",
       " 'เดิมพัน.mp4',\n",
       " 'เพลีย.mp4',\n",
       " 'เมื่อย.mp4',\n",
       " 'เม็กซิโก.mp4',\n",
       " 'เฮโรอีน.mp4',\n",
       " 'แกมเบีย.mp4',\n",
       " 'แซมเบีย.mp4',\n",
       " 'โกหก.mp4',\n",
       " 'โจทก์.mp4',\n",
       " 'โชจู.mp4',\n",
       " 'ใกล้.mp4',\n",
       " 'ไดโนเสาร์.mp4',\n",
       " 'ไอซ์.mp4']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for exported data, numpy arrays\n",
    "Model_Data=os.path.join('Data for different actions')\n",
    "\n",
    "actions = np.array(video_list)\n",
    "\n",
    "no_of_seqs = 1\n",
    "\n",
    "# 30 frames in length\n",
    "seq_length = 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['กฎกระทรวง.mp4', 'กฎหมายรัฐธรรมนูญ.mp4', 'กรมอนามัย.mp4',\n",
       "       'กรรม.mp4', 'กรรมสิทธิ์.mp4', 'กระโดด.mp4', 'กล้วยบวชชี.mp4',\n",
       "       'กล้วยเชื่อม.mp4', 'กังวล.mp4', 'กีฬา.mp4', 'น้อง.mp4', 'เขิน.mp4',\n",
       "       'เขื่อนดิน.mp4', 'เขื่อนสิริกิติ์.mp4', 'เข้าใจผิด.mp4', 'เคย.mp4',\n",
       "       'เครียด.mp4', 'เครื่องปั่นดิน.mp4', 'เครื่องหมายการค้า.mp4',\n",
       "       'เจอ.mp4', 'เจ้าหนี้.mp4', 'เช่าซื้อ.mp4', 'เช่าทรัพย์.mp4',\n",
       "       'เซอร์เบีย.mp4', 'เซเนกัล.mp4', 'เซ็ง.mp4', 'เดิน.mp4',\n",
       "       'เดิมพัน.mp4', 'เพลีย.mp4', 'เมื่อย.mp4', 'เม็กซิโก.mp4',\n",
       "       'เฮโรอีน.mp4', 'แกมเบีย.mp4', 'แซมเบีย.mp4', 'โกหก.mp4',\n",
       "       'โจทก์.mp4', 'โชจู.mp4', 'ใกล้.mp4', 'ไดโนเสาร์.mp4', 'ไอซ์.mp4'],\n",
       "      dtype='<U21')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just creating the folders and sub folders\n",
    "\n",
    "for action in actions: \n",
    "    try: \n",
    "        os.makedirs(os.path.join(Model_Data, action))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# augment_dir = \"C:/Users/araya/Desktop/augments\"\n",
    "\n",
    "# augment_list = []\n",
    "# augment_list = os.listdir(augment_dir)\n",
    "# augment_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actions = list(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in augment_list:\n",
    "#     # print(x)\n",
    "#     actions.append(x)\n",
    "# actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actions = np.array(actions)\n",
    "# actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collecting keypoint values for Training nd Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory where your videos are stored\n",
    "directory = \"C:/Users/araya/Desktop/keypoints/video_extract\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/araya/Desktop/keypoints/video_extract'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/araya/Desktop/keypoints/video_extract/กฎกระทรวง.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/กฎหมายรัฐธรรมนูญ.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/กรมอนามัย.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/กรรม.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/กรรมสิทธิ์.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/กระโดด.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/กล้วยบวชชี.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/กล้วยเชื่อม.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/กังวล.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/กีฬา.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/น้อง.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เขิน.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เขื่อนดิน.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เขื่อนสิริกิติ์.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เข้าใจผิด.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เคย.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เครียด.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เครื่องปั่นดิน.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เครื่องหมายการค้า.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เจอ.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เจ้าหนี้.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เช่าซื้อ.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เช่าทรัพย์.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เซอร์เบีย.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เซเนกัล.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เซ็ง.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เดิน.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เดิมพัน.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เพลีย.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เมื่อย.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เม็กซิโก.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เฮโรอีน.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/แกมเบีย.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/แซมเบีย.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/โกหก.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/โจทก์.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/โชจู.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/ใกล้.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/ไดโนเสาร์.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/ไอซ์.mp4\n"
     ]
    }
   ],
   "source": [
    "for filename in actions:\n",
    "    print(directory + '/' + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set mediapipe model \n",
    "# for action in actions:\n",
    "#     video_path = os.path.join(\"C:/Users/araya/Desktop/keypoints/video_extract\", action)\n",
    "#     cap = cv2.VideoCapture(video_path)\n",
    "#     cap.set(cv2.CAP_PROP_FPS, 60)\n",
    "#     length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "#     print(\"LENGTH:\" + str(length))\n",
    "#     # keypoints = []\n",
    "\n",
    "#     if not cap.isOpened():\n",
    "#         print(f\"Error opening video file: {video_path}\")\n",
    "#         continue\n",
    "\n",
    "#     with mp_holist.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "#         for seq in range(no_of_seqs):\n",
    "#             for frame_num in range(seq_length):\n",
    "\n",
    "#                 ret, frame = cap.read()\n",
    "#                 if not ret:\n",
    "#                     print(f\"End of video {video_path}\")\n",
    "#                     break\n",
    "                \n",
    "#                 img, results = mediapipe_detection(frame, holistic)\n",
    "#                 draw_styled_landmarks(img, results)\n",
    "\n",
    "#                 # print(frame_num)\n",
    "\n",
    "#                 if frame_num == 0: \n",
    "#                     cv2.putText(img, 'DATA COLLECTION STARTED', (120,200), \n",
    "#                                 cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255, 0), 4, cv2.LINE_AA)\n",
    "#                     cv2.putText(img, f'Collecting frames for - {action} Sequence Number - {seq}', (15,12), \n",
    "#                                 cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "#                     cv2.imshow('OpenCV Window', img)\n",
    "#                     cv2.waitKey(2000)  # 2 seconds delay for setup\n",
    "#                 else: \n",
    "#                     cv2.putText(img, f'Collecting frames for - {action} Sequence Number - {seq}', (15,12), \n",
    "#                                 cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "#                     cv2.imshow('OpenCV Window', img)\n",
    "\n",
    "#                 keypoints = extract_keypoints(results)\n",
    "#                 # keypoints.append(results)\n",
    "#                 npy_path = os.path.join(Model_Data, action, f\"frame_{frame_num}.npy\")\n",
    "#                 os.makedirs(os.path.dirname(npy_path), exist_ok=True)\n",
    "#                 np.save(npy_path, keypoints)\n",
    "\n",
    "#                 if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#                     break\n",
    "\n",
    "#             if not ret:\n",
    "#                 break\n",
    "\n",
    "#     cap.release()\n",
    "#     cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LENGTH:142\n",
      "End of video C:/Users/araya/Desktop/keypoints/video_extract\\กฎกระทรวง.mp4\n",
      "LENGTH:134\n",
      "End of video C:/Users/araya/Desktop/keypoints/video_extract\\กฎหมายรัฐธรรมนูญ.mp4\n",
      "LENGTH:151\n",
      "End of video C:/Users/araya/Desktop/keypoints/video_extract\\กรมอนามัย.mp4\n",
      "LENGTH:100\n",
      "End of video C:/Users/araya/Desktop/keypoints/video_extract\\กรรม.mp4\n",
      "LENGTH:184\n",
      "LENGTH:94\n",
      "End of video C:/Users/araya/Desktop/keypoints/video_extract\\กระโดด.mp4\n",
      "LENGTH:182\n",
      "LENGTH:128\n",
      "End of video C:/Users/araya/Desktop/keypoints/video_extract\\กล้วยเชื่อม.mp4\n",
      "LENGTH:170\n",
      "LENGTH:196\n",
      "LENGTH:108\n",
      "End of video C:/Users/araya/Desktop/keypoints/video_extract\\น้อง.mp4\n",
      "LENGTH:100\n",
      "End of video C:/Users/araya/Desktop/keypoints/video_extract\\เขิน.mp4\n",
      "LENGTH:161\n",
      "LENGTH:208\n",
      "LENGTH:105\n",
      "End of video C:/Users/araya/Desktop/keypoints/video_extract\\เข้าใจผิด.mp4\n",
      "LENGTH:82\n",
      "End of video C:/Users/araya/Desktop/keypoints/video_extract\\เคย.mp4\n",
      "LENGTH:118\n",
      "End of video C:/Users/araya/Desktop/keypoints/video_extract\\เครียด.mp4\n",
      "LENGTH:234\n",
      "LENGTH:126\n",
      "End of video C:/Users/araya/Desktop/keypoints/video_extract\\เครื่องหมายการค้า.mp4\n",
      "LENGTH:92\n",
      "End of video C:/Users/araya/Desktop/keypoints/video_extract\\เจอ.mp4\n",
      "LENGTH:117\n",
      "End of video C:/Users/araya/Desktop/keypoints/video_extract\\เจ้าหนี้.mp4\n",
      "LENGTH:138\n",
      "End of video C:/Users/araya/Desktop/keypoints/video_extract\\เช่าซื้อ.mp4\n",
      "LENGTH:111\n",
      "End of video C:/Users/araya/Desktop/keypoints/video_extract\\เช่าทรัพย์.mp4\n",
      "LENGTH:99\n",
      "End of video C:/Users/araya/Desktop/keypoints/video_extract\\เซอร์เบีย.mp4\n",
      "LENGTH:110\n",
      "End of video C:/Users/araya/Desktop/keypoints/video_extract\\เซเนกัล.mp4\n",
      "LENGTH:92\n",
      "End of video C:/Users/araya/Desktop/keypoints/video_extract\\เซ็ง.mp4\n",
      "LENGTH:105\n",
      "End of video C:/Users/araya/Desktop/keypoints/video_extract\\เดิน.mp4\n",
      "LENGTH:81\n",
      "End of video C:/Users/araya/Desktop/keypoints/video_extract\\เดิมพัน.mp4\n",
      "LENGTH:78\n",
      "End of video C:/Users/araya/Desktop/keypoints/video_extract\\เพลีย.mp4\n",
      "LENGTH:110\n",
      "End of video C:/Users/araya/Desktop/keypoints/video_extract\\เมื่อย.mp4\n",
      "LENGTH:120\n",
      "End of video C:/Users/araya/Desktop/keypoints/video_extract\\เม็กซิโก.mp4\n",
      "LENGTH:137\n",
      "End of video C:/Users/araya/Desktop/keypoints/video_extract\\เฮโรอีน.mp4\n",
      "LENGTH:106\n",
      "End of video C:/Users/araya/Desktop/keypoints/video_extract\\แกมเบีย.mp4\n",
      "LENGTH:126\n",
      "End of video C:/Users/araya/Desktop/keypoints/video_extract\\แซมเบีย.mp4\n",
      "LENGTH:105\n",
      "End of video C:/Users/araya/Desktop/keypoints/video_extract\\โกหก.mp4\n",
      "LENGTH:108\n",
      "End of video C:/Users/araya/Desktop/keypoints/video_extract\\โจทก์.mp4\n",
      "LENGTH:126\n",
      "End of video C:/Users/araya/Desktop/keypoints/video_extract\\โชจู.mp4\n",
      "LENGTH:83\n",
      "End of video C:/Users/araya/Desktop/keypoints/video_extract\\ใกล้.mp4\n",
      "LENGTH:126\n",
      "End of video C:/Users/araya/Desktop/keypoints/video_extract\\ไดโนเสาร์.mp4\n",
      "LENGTH:96\n",
      "End of video C:/Users/araya/Desktop/keypoints/video_extract\\ไอซ์.mp4\n"
     ]
    }
   ],
   "source": [
    "# Set mediapipe model \n",
    "for action in actions:\n",
    "    video_path = os.path.join(\"C:/Users/araya/Desktop/keypoints/video_extract\", action)\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    cap.set(cv2.CAP_PROP_FPS, 60)\n",
    "    length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    print(\"LENGTH:\" + str(length))\n",
    "    keypoints = []\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error opening video file: {video_path}\")\n",
    "        continue\n",
    "\n",
    "    with mp_holist.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "        for seq in range(no_of_seqs):\n",
    "            for frame_num in range(seq_length):\n",
    "\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    print(f\"End of video {video_path}\")\n",
    "                    break\n",
    "                \n",
    "                img, results = mediapipe_detection(frame, holistic)\n",
    "                draw_styled_landmarks(img, results)\n",
    "\n",
    "                # print(frame_num)\n",
    "\n",
    "                if frame_num == 0: \n",
    "                    cv2.putText(img, 'DATA COLLECTION STARTED', (120,200), \n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255, 0), 4, cv2.LINE_AA)\n",
    "                    cv2.putText(img, f'Collecting frames for - {action} Sequence Number - {seq}', (15,12), \n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "                    cv2.imshow('OpenCV Window', img)\n",
    "                    cv2.waitKey(2000)  # 2 seconds delay for setup\n",
    "                else: \n",
    "                    cv2.putText(img, f'Collecting frames for - {action} Sequence Number - {seq}', (15,12), \n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "                    cv2.imshow('OpenCV Window', img)\n",
    "\n",
    "                x = extract_keypoints(results)\n",
    "                keypoints.append(x)\n",
    "                npy_path = os.path.join(Model_Data, action, f\"{action.split(\".\")[0]}.npy\")\n",
    "                os.makedirs(os.path.dirname(npy_path), exist_ok=True)\n",
    "                np.save(npy_path, keypoints)\n",
    "\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Data for different actions/กฎกระทรวง.mp4/กฎกระทรวง.npy', 'Data for different actions/กฎหมายรัฐธรรมนูญ.mp4/กฎหมายรัฐธรรมนูญ.npy', 'Data for different actions/กรมอนามัย.mp4/กรมอนามัย.npy', 'Data for different actions/กรรม.mp4/กรรม.npy', 'Data for different actions/กรรมสิทธิ์.mp4/กรรมสิทธิ์.npy', 'Data for different actions/กระโดด.mp4/กระโดด.npy', 'Data for different actions/กล้วยบวชชี.mp4/กล้วยบวชชี.npy', 'Data for different actions/กล้วยเชื่อม.mp4/กล้วยเชื่อม.npy', 'Data for different actions/กังวล.mp4/กังวล.npy', 'Data for different actions/กีฬา.mp4/กีฬา.npy', 'Data for different actions/น้อง.mp4/น้อง.npy', 'Data for different actions/เขิน.mp4/เขิน.npy', 'Data for different actions/เขื่อนดิน.mp4/เขื่อนดิน.npy', 'Data for different actions/เขื่อนสิริกิติ์.mp4/เขื่อนสิริกิติ์.npy', 'Data for different actions/เข้าใจผิด.mp4/เข้าใจผิด.npy', 'Data for different actions/เคย.mp4/เคย.npy', 'Data for different actions/เครียด.mp4/เครียด.npy', 'Data for different actions/เครื่องปั่นดิน.mp4/เครื่องปั่นดิน.npy', 'Data for different actions/เครื่องหมายการค้า.mp4/เครื่องหมายการค้า.npy', 'Data for different actions/เจอ.mp4/เจอ.npy', 'Data for different actions/เจ้าหนี้.mp4/เจ้าหนี้.npy', 'Data for different actions/เช่าซื้อ.mp4/เช่าซื้อ.npy', 'Data for different actions/เช่าทรัพย์.mp4/เช่าทรัพย์.npy', 'Data for different actions/เซอร์เบีย.mp4/เซอร์เบีย.npy', 'Data for different actions/เซเนกัล.mp4/เซเนกัล.npy', 'Data for different actions/เซ็ง.mp4/เซ็ง.npy', 'Data for different actions/เดิน.mp4/เดิน.npy', 'Data for different actions/เดิมพัน.mp4/เดิมพัน.npy', 'Data for different actions/เพลีย.mp4/เพลีย.npy', 'Data for different actions/เมื่อย.mp4/เมื่อย.npy', 'Data for different actions/เม็กซิโก.mp4/เม็กซิโก.npy', 'Data for different actions/เฮโรอีน.mp4/เฮโรอีน.npy', 'Data for different actions/แกมเบีย.mp4/แกมเบีย.npy', 'Data for different actions/แซมเบีย.mp4/แซมเบีย.npy', 'Data for different actions/โกหก.mp4/โกหก.npy', 'Data for different actions/โจทก์.mp4/โจทก์.npy', 'Data for different actions/โชจู.mp4/โชจู.npy', 'Data for different actions/ใกล้.mp4/ใกล้.npy', 'Data for different actions/ไดโนเสาร์.mp4/ไดโนเสาร์.npy', 'Data for different actions/ไอซ์.mp4/ไอซ์.npy']\n"
     ]
    }
   ],
   "source": [
    "file_paths = []\n",
    "for action in actions:\n",
    "    video_path = os.path.join('Data for different actions/', action)\n",
    "    # print(video_path)\n",
    "    # print(action)\n",
    "    file_paths.append(video_path + '/' + action.split(\".\")[0] + \".npy\")\n",
    "print(file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_keypoint_sequences(file_paths):\n",
    "    keypoint_sequences = []\n",
    "    for file_path in file_paths:\n",
    "        keypoints = np.load(file_path)\n",
    "        keypoint_sequences.append(torch.tensor(keypoints, dtype=torch.float32))\n",
    "    return keypoint_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 0.5013,  0.2452, -1.2167,  ...,  0.5663,  0.2188,  0.0098],\n",
       "         [ 0.4997,  0.2482, -1.4690,  ...,  0.5652,  0.2181,  0.0106],\n",
       "         [ 0.4984,  0.2500, -1.4853,  ...,  0.5654,  0.2185,  0.0112],\n",
       "         ...,\n",
       "         [ 0.4861,  0.2513, -1.3416,  ...,  0.5572,  0.2177,  0.0091],\n",
       "         [ 0.4873,  0.2514, -1.3574,  ...,  0.5575,  0.2172,  0.0097],\n",
       "         [ 0.4883,  0.2516, -1.3579,  ...,  0.5577,  0.2170,  0.0101]]),\n",
       " tensor([[ 0.4922,  0.2382, -1.2850,  ...,  0.5578,  0.2124,  0.0094],\n",
       "         [ 0.4920,  0.2405, -1.4288,  ...,  0.5571,  0.2116,  0.0099],\n",
       "         [ 0.4920,  0.2409, -1.4093,  ...,  0.5567,  0.2122,  0.0098],\n",
       "         ...,\n",
       "         [ 0.4814,  0.2260, -1.3318,  ...,  0.5503,  0.1923,  0.0123],\n",
       "         [ 0.4815,  0.2257, -1.3351,  ...,  0.5503,  0.1921,  0.0122],\n",
       "         [ 0.4815,  0.2255, -1.3497,  ...,  0.5501,  0.1919,  0.0124]]),\n",
       " tensor([[ 0.5049,  0.2371, -1.2115,  ...,  0.5643,  0.2082,  0.0088],\n",
       "         [ 0.5045,  0.2381, -1.1896,  ...,  0.5643,  0.2081,  0.0085],\n",
       "         [ 0.5041,  0.2385, -1.1915,  ...,  0.5643,  0.2080,  0.0089],\n",
       "         ...,\n",
       "         [ 0.4963,  0.2307, -1.3096,  ...,  0.5624,  0.2043,  0.0127],\n",
       "         [ 0.4965,  0.2308, -1.3085,  ...,  0.5625,  0.2045,  0.0126],\n",
       "         [ 0.4972,  0.2312, -1.3053,  ...,  0.5633,  0.2045,  0.0128]]),\n",
       " tensor([[ 0.5134,  0.2614, -1.4426,  ...,  0.5818,  0.2272,  0.0153],\n",
       "         [ 0.5130,  0.2604, -1.4262,  ...,  0.5810,  0.2273,  0.0147],\n",
       "         [ 0.5126,  0.2599, -1.4278,  ...,  0.5810,  0.2276,  0.0150],\n",
       "         ...,\n",
       "         [ 0.5079,  0.2693, -1.4999,  ...,  0.5780,  0.2349,  0.0115],\n",
       "         [ 0.5090,  0.2688, -1.4936,  ...,  0.5782,  0.2346,  0.0116],\n",
       "         [ 0.5092,  0.2683, -1.4518,  ...,  0.5786,  0.2341,  0.0116]]),\n",
       " tensor([[ 0.4883,  0.2402, -1.1024,  ...,  0.5482,  0.2132,  0.0081],\n",
       "         [ 0.4878,  0.2402, -1.1906,  ...,  0.5469,  0.2135,  0.0083],\n",
       "         [ 0.4863,  0.2402, -1.1774,  ...,  0.5477,  0.2141,  0.0087],\n",
       "         ...,\n",
       "         [ 0.4788,  0.3129, -1.6072,  ...,  0.5349,  0.2531,  0.0022],\n",
       "         [ 0.4782,  0.3129, -1.6350,  ...,  0.5344,  0.2525,  0.0022],\n",
       "         [ 0.4771,  0.3131, -1.6312,  ...,  0.5339,  0.2515,  0.0022]]),\n",
       " tensor([[ 0.4992,  0.1994, -1.1906,  ...,  0.5657,  0.1731,  0.0116],\n",
       "         [ 0.4988,  0.2047, -1.3590,  ...,  0.5663,  0.1723,  0.0123],\n",
       "         [ 0.4982,  0.2082, -1.3140,  ...,  0.5671,  0.1730,  0.0129],\n",
       "         ...,\n",
       "         [ 0.4743,  0.1974, -1.3230,  ...,  0.5475,  0.1620,  0.0155],\n",
       "         [ 0.4732,  0.1974, -1.3174,  ...,  0.5461,  0.1615,  0.0151],\n",
       "         [ 0.4720,  0.1974, -1.3149,  ...,  0.5453,  0.1614,  0.0149]]),\n",
       " tensor([[ 0.5023,  0.2809, -1.6242,  ...,  0.5847,  0.2321,  0.0112],\n",
       "         [ 0.5023,  0.2806, -1.6631,  ...,  0.5840,  0.2322,  0.0130],\n",
       "         [ 0.5022,  0.2805, -1.6912,  ...,  0.5837,  0.2322,  0.0122],\n",
       "         ...,\n",
       "         [ 0.5037,  0.2791, -1.5789,  ...,  0.5834,  0.2224,  0.0129],\n",
       "         [ 0.5044,  0.2774, -1.5686,  ...,  0.5831,  0.2220,  0.0130],\n",
       "         [ 0.5052,  0.2722, -1.5527,  ...,  0.5827,  0.2216,  0.0132]]),\n",
       " tensor([[ 0.4868,  0.2821, -1.4668,  ...,  0.5711,  0.2335,  0.0116],\n",
       "         [ 0.4861,  0.2786, -1.5812,  ...,  0.5702,  0.2334,  0.0129],\n",
       "         [ 0.4856,  0.2769, -1.6059,  ...,  0.5699,  0.2333,  0.0131],\n",
       "         ...,\n",
       "         [ 0.4826,  0.2583, -1.6140,  ...,  0.5606,  0.2261,  0.0154],\n",
       "         [ 0.4820,  0.2583, -1.5231,  ...,  0.5603,  0.2261,  0.0156],\n",
       "         [ 0.4818,  0.2580, -1.5255,  ...,  0.5600,  0.2263,  0.0156]]),\n",
       " tensor([[ 0.5016,  0.2321, -1.1859,  ...,  0.5647,  0.2139,  0.0072],\n",
       "         [ 0.5015,  0.2340, -1.1996,  ...,  0.5645,  0.2135,  0.0076],\n",
       "         [ 0.5016,  0.2346, -1.2272,  ...,  0.5644,  0.2137,  0.0082],\n",
       "         ...,\n",
       "         [ 0.4743,  0.2622, -1.4181,  ...,  0.5499,  0.2133,  0.0080],\n",
       "         [ 0.4763,  0.2599, -1.4742,  ...,  0.5519,  0.2118,  0.0090],\n",
       "         [ 0.4787,  0.2522, -1.6440,  ...,  0.5537,  0.2110,  0.0093]]),\n",
       " tensor([[ 0.4926,  0.1945, -1.2354,  ...,  0.5488,  0.1581,  0.0085],\n",
       "         [ 0.4942,  0.1949, -1.4254,  ...,  0.5481,  0.1576,  0.0085],\n",
       "         [ 0.4948,  0.1960, -1.4483,  ...,  0.5479,  0.1581,  0.0084],\n",
       "         ...,\n",
       "         [ 0.4917,  0.1882, -1.3355,  ...,  0.5458,  0.1536,  0.0126],\n",
       "         [ 0.4918,  0.1885, -1.3154,  ...,  0.5456,  0.1536,  0.0125],\n",
       "         [ 0.4918,  0.1886, -1.3147,  ...,  0.5453,  0.1537,  0.0124]]),\n",
       " tensor([[ 0.4956,  0.2681, -1.1361,  ...,  0.5554,  0.2332,  0.0147],\n",
       "         [ 0.4948,  0.2681, -1.3768,  ...,  0.5540,  0.2333,  0.0116],\n",
       "         [ 0.4943,  0.2681, -1.3754,  ...,  0.5538,  0.2332,  0.0116],\n",
       "         ...,\n",
       "         [ 0.4895,  0.2689, -1.2187,  ...,  0.5513,  0.2276,  0.0135],\n",
       "         [ 0.4889,  0.2688, -1.2198,  ...,  0.5508,  0.2276,  0.0134],\n",
       "         [ 0.4882,  0.2688, -1.2172,  ...,  0.5507,  0.2276,  0.0134]]),\n",
       " tensor([[ 0.5032,  0.2228, -1.1998,  ...,  0.5663,  0.1971,  0.0106],\n",
       "         [ 0.5035,  0.2228, -1.2072,  ...,  0.5662,  0.1969,  0.0106],\n",
       "         [ 0.5035,  0.2230, -1.2082,  ...,  0.5664,  0.1963,  0.0108],\n",
       "         ...,\n",
       "         [ 0.4982,  0.2206, -1.2743,  ...,  0.5578,  0.1892,  0.0092],\n",
       "         [ 0.4983,  0.2178, -1.2380,  ...,  0.5581,  0.1883,  0.0091],\n",
       "         [ 0.4979,  0.2173, -1.2264,  ...,  0.5578,  0.1877,  0.0096]]),\n",
       " tensor([[ 0.5442,  0.2507, -1.4443,  ...,  0.6105,  0.2203,  0.0123],\n",
       "         [ 0.5444,  0.2508, -1.6574,  ...,  0.6094,  0.2198,  0.0134],\n",
       "         [ 0.5445,  0.2510, -1.7250,  ...,  0.6093,  0.2195,  0.0144],\n",
       "         ...,\n",
       "         [ 0.5324,  0.2577, -1.6704,  ...,  0.5975,  0.2210,  0.0145],\n",
       "         [ 0.5323,  0.2560, -1.6673,  ...,  0.5966,  0.2206,  0.0148],\n",
       "         [ 0.5323,  0.2553, -1.6826,  ...,  0.5957,  0.2201,  0.0146]]),\n",
       " tensor([[ 0.5402,  0.2562, -1.5458,  ...,  0.6041,  0.2257,  0.0125],\n",
       "         [ 0.5389,  0.2596, -1.7020,  ...,  0.6031,  0.2264,  0.0130],\n",
       "         [ 0.5379,  0.2616, -1.7134,  ...,  0.6027,  0.2258,  0.0139],\n",
       "         ...,\n",
       "         [ 0.5153,  0.2631, -1.6030,  ...,  0.5956,  0.2125,  0.0142],\n",
       "         [ 0.5176,  0.2626, -1.6101,  ...,  0.5985,  0.2126,  0.0139],\n",
       "         [ 0.5197,  0.2624, -1.5662,  ...,  0.6011,  0.2119,  0.0145]]),\n",
       " tensor([[ 0.5030,  0.2553, -1.1988,  ...,  0.5699,  0.2265,  0.0097],\n",
       "         [ 0.5028,  0.2582, -1.2761,  ...,  0.5689,  0.2266,  0.0109],\n",
       "         [ 0.5028,  0.2605, -1.3315,  ...,  0.5690,  0.2269,  0.0105],\n",
       "         ...,\n",
       "         [ 0.5028,  0.2675, -1.4499,  ...,  0.5672,  0.2323,  0.0110],\n",
       "         [ 0.5007,  0.2672, -1.4234,  ...,  0.5668,  0.2317,  0.0115],\n",
       "         [ 0.4988,  0.2671, -1.4308,  ...,  0.5670,  0.2312,  0.0118]]),\n",
       " tensor([[ 0.5069,  0.2355, -1.3384,  ...,  0.5700,  0.2051,  0.0053],\n",
       "         [ 0.5045,  0.2395, -1.5097,  ...,  0.5699,  0.2043,  0.0064],\n",
       "         [ 0.5028,  0.2420, -1.5081,  ...,  0.5699,  0.2045,  0.0069],\n",
       "         ...,\n",
       "         [ 0.4952,  0.2462, -1.4319,  ...,  0.5658,  0.2015,  0.0122],\n",
       "         [ 0.4952,  0.2448, -1.4781,  ...,  0.5661,  0.2014,  0.0123],\n",
       "         [ 0.4953,  0.2436, -1.4689,  ...,  0.5662,  0.2013,  0.0124]]),\n",
       " tensor([[ 0.5035,  0.2282, -1.1379,  ...,  0.5710,  0.1953,  0.0120],\n",
       "         [ 0.5033,  0.2284, -1.2771,  ...,  0.5713,  0.1954,  0.0123],\n",
       "         [ 0.5032,  0.2286, -1.2743,  ...,  0.5715,  0.1957,  0.0122],\n",
       "         ...,\n",
       "         [ 0.4810,  0.2296, -1.4129,  ...,  0.5542,  0.1897,  0.0133],\n",
       "         [ 0.4812,  0.2296, -1.4275,  ...,  0.5549,  0.1900,  0.0130],\n",
       "         [ 0.4816,  0.2299, -1.4337,  ...,  0.5557,  0.1903,  0.0133]]),\n",
       " tensor([[ 0.5108,  0.2425, -1.1053,  ...,  0.5724,  0.2176,  0.0127],\n",
       "         [ 0.5091,  0.2430, -1.3007,  ...,  0.5713,  0.2177,  0.0129],\n",
       "         [ 0.5080,  0.2432, -1.3035,  ...,  0.5714,  0.2179,  0.0130],\n",
       "         ...,\n",
       "         [ 0.4966,  0.2620, -1.5367,  ...,  0.5653,  0.2259,  0.0082],\n",
       "         [ 0.4968,  0.2621, -1.5419,  ...,  0.5656,  0.2262,  0.0083],\n",
       "         [ 0.4971,  0.2623, -1.5482,  ...,  0.5658,  0.2263,  0.0086]]),\n",
       " tensor([[ 0.4878,  0.2235, -1.2515,  ...,  0.5511,  0.1981,  0.0114],\n",
       "         [ 0.4870,  0.2286, -1.4279,  ...,  0.5506,  0.1977,  0.0105],\n",
       "         [ 0.4865,  0.2315, -1.4431,  ...,  0.5508,  0.1984,  0.0110],\n",
       "         ...,\n",
       "         [ 0.4901,  0.2217, -1.3449,  ...,  0.5576,  0.1888,  0.0156],\n",
       "         [ 0.4898,  0.2224, -1.3780,  ...,  0.5575,  0.1892,  0.0157],\n",
       "         [ 0.4896,  0.2232, -1.4140,  ...,  0.5572,  0.1897,  0.0156]]),\n",
       " tensor([[ 0.5194,  0.2227, -1.3410,  ...,  0.5911,  0.1970,  0.0142],\n",
       "         [ 0.5200,  0.2228, -1.3298,  ...,  0.5912,  0.1965,  0.0131],\n",
       "         [ 0.5202,  0.2230, -1.3074,  ...,  0.5909,  0.1970,  0.0149],\n",
       "         ...,\n",
       "         [ 0.5146,  0.2198, -1.3267,  ...,  0.5821,  0.1907,  0.0159],\n",
       "         [ 0.5141,  0.2205, -1.3207,  ...,  0.5816,  0.1911,  0.0154],\n",
       "         [ 0.5137,  0.2209, -1.3223,  ...,  0.5812,  0.1917,  0.0161]]),\n",
       " tensor([[ 0.5103,  0.2428, -1.1660,  ...,  0.5757,  0.2179,  0.0081],\n",
       "         [ 0.5106,  0.2437, -1.2850,  ...,  0.5751,  0.2183,  0.0099],\n",
       "         [ 0.5112,  0.2443, -1.2880,  ...,  0.5748,  0.2189,  0.0108],\n",
       "         ...,\n",
       "         [ 0.4800,  0.2603, -1.3086,  ...,  0.5532,  0.2237,  0.0069],\n",
       "         [ 0.4807,  0.2604, -1.2544,  ...,  0.5539,  0.2238,  0.0067],\n",
       "         [ 0.4813,  0.2604, -1.2161,  ...,  0.5548,  0.2238,  0.0065]]),\n",
       " tensor([[ 0.4945,  0.2362, -1.1227,  ...,  0.5529,  0.2086,  0.0088],\n",
       "         [ 0.4947,  0.2363, -1.1264,  ...,  0.5528,  0.2094,  0.0088],\n",
       "         [ 0.4951,  0.2364, -1.1371,  ...,  0.5531,  0.2099,  0.0089],\n",
       "         ...,\n",
       "         [ 0.4933,  0.2480, -1.2424,  ...,  0.5563,  0.2184,  0.0091],\n",
       "         [ 0.4933,  0.2480, -1.2443,  ...,  0.5565,  0.2185,  0.0093],\n",
       "         [ 0.4932,  0.2480, -1.2944,  ...,  0.5564,  0.2185,  0.0095]]),\n",
       " tensor([[ 0.5038,  0.2425, -1.1550,  ...,  0.5665,  0.2136,  0.0080],\n",
       "         [ 0.5027,  0.2423, -1.2423,  ...,  0.5653,  0.2133,  0.0092],\n",
       "         [ 0.5018,  0.2423, -1.2565,  ...,  0.5649,  0.2130,  0.0094],\n",
       "         ...,\n",
       "         [ 0.4950,  0.2412, -1.1727,  ...,  0.5624,  0.2175,  0.0087],\n",
       "         [ 0.4951,  0.2412, -1.1690,  ...,  0.5625,  0.2177,  0.0082],\n",
       "         [ 0.4951,  0.2412, -1.1910,  ...,  0.5626,  0.2180,  0.0079]]),\n",
       " tensor([[ 0.4916,  0.2518, -1.3187,  ...,  0.5597,  0.2202,  0.0108],\n",
       "         [ 0.4907,  0.2519, -1.3672,  ...,  0.5580,  0.2209,  0.0105],\n",
       "         [ 0.4896,  0.2520, -1.4026,  ...,  0.5580,  0.2210,  0.0110],\n",
       "         ...,\n",
       "         [ 0.4850,  0.2552, -1.4312,  ...,  0.5509,  0.2199,  0.0138],\n",
       "         [ 0.4839,  0.2550, -1.4298,  ...,  0.5505,  0.2199,  0.0138],\n",
       "         [ 0.4831,  0.2549, -1.4164,  ...,  0.5501,  0.2200,  0.0137]]),\n",
       " tensor([[ 0.5051,  0.2347, -1.4390,  ...,  0.5717,  0.2094,  0.0091],\n",
       "         [ 0.5024,  0.2389, -1.5627,  ...,  0.5707,  0.2087,  0.0090],\n",
       "         [ 0.5005,  0.2417, -1.5896,  ...,  0.5704,  0.2090,  0.0098],\n",
       "         ...,\n",
       "         [ 0.4950,  0.2365, -1.4622,  ...,  0.5663,  0.2072,  0.0114],\n",
       "         [ 0.4950,  0.2366, -1.4772,  ...,  0.5667,  0.2075,  0.0115],\n",
       "         [ 0.4949,  0.2366, -1.4725,  ...,  0.5671,  0.2078,  0.0120]]),\n",
       " tensor([[ 0.5064,  0.2529, -1.3080,  ...,  0.5751,  0.2261,  0.0114],\n",
       "         [ 0.5055,  0.2550, -1.3556,  ...,  0.5752,  0.2257,  0.0106],\n",
       "         [ 0.5048,  0.2568, -1.3925,  ...,  0.5751,  0.2260,  0.0110],\n",
       "         ...,\n",
       "         [ 0.4960,  0.2624, -1.3587,  ...,  0.5642,  0.2311,  0.0101],\n",
       "         [ 0.4961,  0.2619, -1.3373,  ...,  0.5652,  0.2307,  0.0104],\n",
       "         [ 0.4961,  0.2615, -1.3405,  ...,  0.5653,  0.2302,  0.0102]]),\n",
       " tensor([[ 0.5267,  0.2322, -1.2986,  ...,  0.5921,  0.1996,  0.0123],\n",
       "         [ 0.5267,  0.2305, -1.3156,  ...,  0.5925,  0.1999,  0.0112],\n",
       "         [ 0.5266,  0.2296, -1.3147,  ...,  0.5928,  0.1997,  0.0121],\n",
       "         ...,\n",
       "         [ 0.5122,  0.2243, -1.2697,  ...,  0.5819,  0.1855,  0.0147],\n",
       "         [ 0.5114,  0.2239, -1.2687,  ...,  0.5817,  0.1857,  0.0145],\n",
       "         [ 0.5110,  0.2235, -1.2585,  ...,  0.5815,  0.1858,  0.0145]]),\n",
       " tensor([[ 0.5050,  0.2164, -1.1575,  ...,  0.5700,  0.1959,  0.0103],\n",
       "         [ 0.5041,  0.2187, -1.3621,  ...,  0.5689,  0.1959,  0.0100],\n",
       "         [ 0.5031,  0.2218, -1.3920,  ...,  0.5693,  0.1959,  0.0109],\n",
       "         ...,\n",
       "         [ 0.4987,  0.2252, -1.2609,  ...,  0.5655,  0.1932,  0.0101],\n",
       "         [ 0.4982,  0.2238, -1.2657,  ...,  0.5653,  0.1926,  0.0103],\n",
       "         [ 0.4969,  0.2230, -1.2967,  ...,  0.5649,  0.1919,  0.0105]]),\n",
       " tensor([[ 0.5097,  0.2301, -1.2305,  ...,  0.5773,  0.2070,  0.0135],\n",
       "         [ 0.5098,  0.2316, -1.4094,  ...,  0.5762,  0.2072,  0.0130],\n",
       "         [ 0.5099,  0.2328, -1.4219,  ...,  0.5754,  0.2074,  0.0134],\n",
       "         ...,\n",
       "         [ 0.5106,  0.2519, -1.1800,  ...,  0.5731,  0.2204,  0.0132],\n",
       "         [ 0.5082,  0.2514, -1.1958,  ...,  0.5717,  0.2193,  0.0134],\n",
       "         [ 0.5074,  0.2516, -1.2210,  ...,  0.5703,  0.2182,  0.0128]]),\n",
       " tensor([[ 0.5410,  0.2495, -1.3908,  ...,  0.6085,  0.2224,  0.0099],\n",
       "         [ 0.5399,  0.2502, -1.3960,  ...,  0.6066,  0.2219,  0.0111],\n",
       "         [ 0.5390,  0.2511, -1.3861,  ...,  0.6062,  0.2215,  0.0105],\n",
       "         ...,\n",
       "         [ 0.5131,  0.2461, -1.3199,  ...,  0.5857,  0.2158,  0.0118],\n",
       "         [ 0.5137,  0.2459, -1.3370,  ...,  0.5858,  0.2153,  0.0118],\n",
       "         [ 0.5141,  0.2456, -1.3376,  ...,  0.5860,  0.2150,  0.0116]]),\n",
       " tensor([[ 0.4813,  0.2267, -1.2462,  ...,  0.5499,  0.2013,  0.0123],\n",
       "         [ 0.4796,  0.2283, -1.4595,  ...,  0.5479,  0.2026,  0.0127],\n",
       "         [ 0.4786,  0.2300, -1.5108,  ...,  0.5480,  0.2025,  0.0122],\n",
       "         ...,\n",
       "         [ 0.4782,  0.2297, -1.2598,  ...,  0.5464,  0.1965,  0.0150],\n",
       "         [ 0.4781,  0.2300, -1.2686,  ...,  0.5459,  0.1960,  0.0147],\n",
       "         [ 0.4780,  0.2304, -1.2444,  ...,  0.5461,  0.1953,  0.0154]]),\n",
       " tensor([[ 0.5051,  0.2433, -1.3371,  ...,  0.5701,  0.2185,  0.0094],\n",
       "         [ 0.5042,  0.2464, -1.4811,  ...,  0.5696,  0.2193,  0.0109],\n",
       "         [ 0.5039,  0.2479, -1.4928,  ...,  0.5700,  0.2201,  0.0112],\n",
       "         ...,\n",
       "         [ 0.4965,  0.2517, -1.4369,  ...,  0.5645,  0.2217,  0.0130],\n",
       "         [ 0.4956,  0.2516, -1.4394,  ...,  0.5637,  0.2215,  0.0129],\n",
       "         [ 0.4943,  0.2514, -1.4394,  ...,  0.5628,  0.2207,  0.0124]]),\n",
       " tensor([[ 0.5269,  0.2488, -1.5232,  ...,  0.5929,  0.2181,  0.0118],\n",
       "         [ 0.5260,  0.2493, -1.4445,  ...,  0.5918,  0.2172,  0.0111],\n",
       "         [ 0.5250,  0.2497, -1.4588,  ...,  0.5916,  0.2171,  0.0113],\n",
       "         ...,\n",
       "         [ 0.5126,  0.2514, -1.5292,  ...,  0.5827,  0.2212,  0.0138],\n",
       "         [ 0.5125,  0.2512, -1.5273,  ...,  0.5813,  0.2204,  0.0136],\n",
       "         [ 0.5123,  0.2512, -1.5221,  ...,  0.5795,  0.2200,  0.0137]]),\n",
       " tensor([[ 0.5103,  0.2330, -1.4731,  ...,  0.5745,  0.2056,  0.0102],\n",
       "         [ 0.5071,  0.2360, -1.5453,  ...,  0.5731,  0.2055,  0.0103],\n",
       "         [ 0.5052,  0.2381, -1.5650,  ...,  0.5733,  0.2056,  0.0100],\n",
       "         ...,\n",
       "         [ 0.4875,  0.2316, -1.5252,  ...,  0.5606,  0.1993,  0.0132],\n",
       "         [ 0.4872,  0.2318, -1.5227,  ...,  0.5604,  0.1997,  0.0129],\n",
       "         [ 0.4870,  0.2318, -1.5220,  ...,  0.5604,  0.2000,  0.0129]]),\n",
       " tensor([[ 0.4952,  0.2338, -1.3905,  ...,  0.5593,  0.2078,  0.0128],\n",
       "         [ 0.4926,  0.2435, -1.4861,  ...,  0.5600,  0.2072,  0.0117],\n",
       "         [ 0.4916,  0.2483, -1.4905,  ...,  0.5596,  0.2079,  0.0126],\n",
       "         ...,\n",
       "         [ 0.4846,  0.2462, -1.4163,  ...,  0.5649,  0.2045,  0.0151],\n",
       "         [ 0.4852,  0.2450, -1.4038,  ...,  0.5648,  0.2038,  0.0156],\n",
       "         [ 0.4857,  0.2436, -1.3897,  ...,  0.5648,  0.2033,  0.0155]]),\n",
       " tensor([[ 0.4828,  0.2604, -1.2334,  ...,  0.5483,  0.2258,  0.0073],\n",
       "         [ 0.4816,  0.2606, -1.4555,  ...,  0.5474,  0.2267,  0.0087],\n",
       "         [ 0.4809,  0.2608, -1.4653,  ...,  0.5475,  0.2266,  0.0088],\n",
       "         ...,\n",
       "         [ 0.4832,  0.2490, -1.4275,  ...,  0.5557,  0.2156,  0.0123],\n",
       "         [ 0.4845,  0.2491, -1.4277,  ...,  0.5566,  0.2158,  0.0124],\n",
       "         [ 0.4855,  0.2492, -1.4367,  ...,  0.5573,  0.2163,  0.0122]]),\n",
       " tensor([[ 0.5122,  0.2456, -1.3706,  ...,  0.5836,  0.2207,  0.0125],\n",
       "         [ 0.5121,  0.2461, -1.4417,  ...,  0.5818,  0.2208,  0.0118],\n",
       "         [ 0.5121,  0.2465, -1.4591,  ...,  0.5815,  0.2204,  0.0118],\n",
       "         ...,\n",
       "         [ 0.5017,  0.2434, -1.4740,  ...,  0.5812,  0.2105,  0.0155],\n",
       "         [ 0.5022,  0.2433, -1.4619,  ...,  0.5818,  0.2102,  0.0157],\n",
       "         [ 0.5032,  0.2431, -1.4609,  ...,  0.5821,  0.2097,  0.0163]]),\n",
       " tensor([[ 0.4849,  0.2484, -1.3873,  ...,  0.5543,  0.2162,  0.0108],\n",
       "         [ 0.4846,  0.2500, -1.4881,  ...,  0.5539,  0.2157,  0.0111],\n",
       "         [ 0.4844,  0.2507, -1.4935,  ...,  0.5537,  0.2161,  0.0111],\n",
       "         ...,\n",
       "         [ 0.4589,  0.2435, -1.4798,  ...,  0.5299,  0.2058,  0.0120],\n",
       "         [ 0.4586,  0.2436, -1.4788,  ...,  0.5293,  0.2056,  0.0122],\n",
       "         [ 0.4583,  0.2437, -1.4790,  ...,  0.5289,  0.2052,  0.0123]]),\n",
       " tensor([[ 0.5199,  0.2290, -1.2810,  ...,  0.5876,  0.2058,  0.0103],\n",
       "         [ 0.5195,  0.2307, -1.3821,  ...,  0.5873,  0.2059,  0.0106],\n",
       "         [ 0.5193,  0.2327, -1.4100,  ...,  0.5877,  0.2059,  0.0109],\n",
       "         ...,\n",
       "         [ 0.5108,  0.2431, -1.3919,  ...,  0.5781,  0.2077,  0.0105],\n",
       "         [ 0.5093,  0.2422, -1.3894,  ...,  0.5768,  0.2068,  0.0103],\n",
       "         [ 0.5079,  0.2405, -1.3818,  ...,  0.5751,  0.2053,  0.0102]]),\n",
       " tensor([[ 0.5005,  0.2439, -1.3629,  ...,  0.5694,  0.2139,  0.0154],\n",
       "         [ 0.5002,  0.2448, -1.5049,  ...,  0.5688,  0.2128,  0.0146],\n",
       "         [ 0.4999,  0.2457, -1.5287,  ...,  0.5683,  0.2134,  0.0148],\n",
       "         ...,\n",
       "         [ 0.4965,  0.2433, -1.3673,  ...,  0.5670,  0.2114,  0.0169],\n",
       "         [ 0.4960,  0.2433, -1.3676,  ...,  0.5660,  0.2107,  0.0168],\n",
       "         [ 0.4950,  0.2433, -1.3637,  ...,  0.5651,  0.2100,  0.0170]])]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the sequences\n",
    "import torch\n",
    "sequences = load_keypoint_sequences(file_paths)\n",
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40, 160, 1662])\n"
     ]
    }
   ],
   "source": [
    "# Pad the sequences to the same length\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "padded_sequences = pad_sequence(sequences, batch_first=True)\n",
    "pad_sequence\n",
    "print(padded_sequences.shape) # (batch_size, max_sequence_length, num_keypoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['กฎกระทรวง',\n",
       " 'กฎหมายรัฐธรรมนูญ',\n",
       " 'กรมอนามัย',\n",
       " 'กรรม',\n",
       " 'กรรมสิทธิ์',\n",
       " 'กระโดด',\n",
       " 'กล้วยบวชชี',\n",
       " 'กล้วยเชื่อม',\n",
       " 'กังวล',\n",
       " 'กีฬา',\n",
       " 'น้อง',\n",
       " 'เขิน',\n",
       " 'เขื่อนดิน',\n",
       " 'เขื่อนสิริกิติ์',\n",
       " 'เข้าใจผิด',\n",
       " 'เคย',\n",
       " 'เครียด',\n",
       " 'เครื่องปั่นดิน',\n",
       " 'เครื่องหมายการค้า',\n",
       " 'เจอ',\n",
       " 'เจ้าหนี้',\n",
       " 'เช่าซื้อ',\n",
       " 'เช่าทรัพย์',\n",
       " 'เซอร์เบีย',\n",
       " 'เซเนกัล',\n",
       " 'เซ็ง',\n",
       " 'เดิน',\n",
       " 'เดิมพัน',\n",
       " 'เพลีย',\n",
       " 'เมื่อย',\n",
       " 'เม็กซิโก',\n",
       " 'เฮโรอีน',\n",
       " 'แกมเบีย',\n",
       " 'แซมเบีย',\n",
       " 'โกหก',\n",
       " 'โจทก์',\n",
       " 'โชจู',\n",
       " 'ใกล้',\n",
       " 'ไดโนเสาร์',\n",
       " 'ไอซ์']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [action.split(\".\")[0] for action in actions]\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "       34, 35, 36, 37, 38, 39], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "labels = le.fit_transform(labels)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# Create a custom dataset\n",
    "class KeypointDataset(Dataset):\n",
    "    def __init__(self, file_paths, labels):\n",
    "        self.file_paths = file_paths\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        keypoints = np.load(self.file_paths[idx])\n",
    "        label = self.labels[idx]\n",
    "        return torch.tensor(keypoints, dtype=torch.float32), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset\n",
    "dataset = KeypointDataset(file_paths, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Data for different actions/กฎกระทรวง.mp4/กฎกระทรวง.npy', 'Data for different actions/กฎหมายรัฐธรรมนูญ.mp4/กฎหมายรัฐธรรมนูญ.npy', 'Data for different actions/กรมอนามัย.mp4/กรมอนามัย.npy', 'Data for different actions/กรรม.mp4/กรรม.npy', 'Data for different actions/กรรมสิทธิ์.mp4/กรรมสิทธิ์.npy', 'Data for different actions/กระโดด.mp4/กระโดด.npy', 'Data for different actions/กล้วยบวชชี.mp4/กล้วยบวชชี.npy', 'Data for different actions/กล้วยเชื่อม.mp4/กล้วยเชื่อม.npy', 'Data for different actions/กังวล.mp4/กังวล.npy', 'Data for different actions/กีฬา.mp4/กีฬา.npy', 'Data for different actions/น้อง.mp4/น้อง.npy', 'Data for different actions/เขิน.mp4/เขิน.npy', 'Data for different actions/เขื่อนดิน.mp4/เขื่อนดิน.npy', 'Data for different actions/เขื่อนสิริกิติ์.mp4/เขื่อนสิริกิติ์.npy', 'Data for different actions/เข้าใจผิด.mp4/เข้าใจผิด.npy', 'Data for different actions/เคย.mp4/เคย.npy', 'Data for different actions/เครียด.mp4/เครียด.npy', 'Data for different actions/เครื่องปั่นดิน.mp4/เครื่องปั่นดิน.npy', 'Data for different actions/เครื่องหมายการค้า.mp4/เครื่องหมายการค้า.npy', 'Data for different actions/เจอ.mp4/เจอ.npy', 'Data for different actions/เจ้าหนี้.mp4/เจ้าหนี้.npy', 'Data for different actions/เช่าซื้อ.mp4/เช่าซื้อ.npy', 'Data for different actions/เช่าทรัพย์.mp4/เช่าทรัพย์.npy', 'Data for different actions/เซอร์เบีย.mp4/เซอร์เบีย.npy', 'Data for different actions/เซเนกัล.mp4/เซเนกัล.npy', 'Data for different actions/เซ็ง.mp4/เซ็ง.npy', 'Data for different actions/เดิน.mp4/เดิน.npy', 'Data for different actions/เดิมพัน.mp4/เดิมพัน.npy', 'Data for different actions/เพลีย.mp4/เพลีย.npy', 'Data for different actions/เมื่อย.mp4/เมื่อย.npy', 'Data for different actions/เม็กซิโก.mp4/เม็กซิโก.npy', 'Data for different actions/เฮโรอีน.mp4/เฮโรอีน.npy', 'Data for different actions/แกมเบีย.mp4/แกมเบีย.npy', 'Data for different actions/แซมเบีย.mp4/แซมเบีย.npy', 'Data for different actions/โกหก.mp4/โกหก.npy', 'Data for different actions/โจทก์.mp4/โจทก์.npy', 'Data for different actions/โชจู.mp4/โชจู.npy', 'Data for different actions/ใกล้.mp4/ใกล้.npy', 'Data for different actions/ไดโนเสาร์.mp4/ไดโนเสาร์.npy', 'Data for different actions/ไอซ์.mp4/ไอซ์.npy']\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]\n"
     ]
    }
   ],
   "source": [
    "print(dataset.file_paths)\n",
    "print(dataset.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collate function for padding\n",
    "def collate_fn(batch):\n",
    "    sequences, labels = zip(*batch)\n",
    "    padded_sequences = pad_sequence(sequences, batch_first=True)\n",
    "    return padded_sequences, torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x18cc98b9340>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the DataLoader\n",
    "batch_size = 4\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        \n",
    "        # Forward propagate the LSTM\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        \n",
    "        # Use the last time step's output for classification\n",
    "        out = out[:, -1, :]\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set device (use GPU if available)\n",
    "device = torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model, loss function, and optimizer\n",
    "model = LSTMModel(input_size=1662, hidden_size=128, num_layers=2, num_classes=40).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()  # For multi-class classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1200], Loss: 3.7298 , Accuracy : 0.00%\n",
      "Epoch [2/1200], Loss: 3.5302 , Accuracy : 2.50%\n",
      "Epoch [3/1200], Loss: 3.5068 , Accuracy : 2.50%\n",
      "Epoch [4/1200], Loss: 3.2496 , Accuracy : 2.50%\n",
      "Epoch [5/1200], Loss: 3.6900 , Accuracy : 2.50%\n",
      "Epoch [6/1200], Loss: 4.3020 , Accuracy : 0.00%\n",
      "Epoch [7/1200], Loss: 3.4690 , Accuracy : 2.50%\n",
      "Epoch [8/1200], Loss: 3.6176 , Accuracy : 5.00%\n",
      "Epoch [9/1200], Loss: 3.6993 , Accuracy : 2.50%\n",
      "Epoch [10/1200], Loss: 3.2685 , Accuracy : 2.50%\n",
      "Epoch [11/1200], Loss: 3.2187 , Accuracy : 0.00%\n",
      "Epoch [12/1200], Loss: 3.1055 , Accuracy : 5.00%\n",
      "Epoch [13/1200], Loss: 3.4622 , Accuracy : 2.50%\n",
      "Epoch [14/1200], Loss: 3.5140 , Accuracy : 10.00%\n",
      "Epoch [15/1200], Loss: 3.2181 , Accuracy : 7.50%\n",
      "Epoch [16/1200], Loss: 3.4295 , Accuracy : 10.00%\n",
      "Epoch [17/1200], Loss: 3.4592 , Accuracy : 7.50%\n",
      "Epoch [18/1200], Loss: 2.4497 , Accuracy : 7.50%\n",
      "Epoch [19/1200], Loss: 3.4281 , Accuracy : 7.50%\n",
      "Epoch [20/1200], Loss: 2.8668 , Accuracy : 5.00%\n",
      "Epoch [21/1200], Loss: 3.5205 , Accuracy : 7.50%\n",
      "Epoch [22/1200], Loss: 3.4720 , Accuracy : 12.50%\n",
      "Epoch [23/1200], Loss: 2.9937 , Accuracy : 7.50%\n",
      "Epoch [24/1200], Loss: 2.8585 , Accuracy : 7.50%\n",
      "Epoch [25/1200], Loss: 2.4222 , Accuracy : 5.00%\n",
      "Epoch [26/1200], Loss: 2.7962 , Accuracy : 10.00%\n",
      "Epoch [27/1200], Loss: 3.3877 , Accuracy : 5.00%\n",
      "Epoch [28/1200], Loss: 3.5281 , Accuracy : 10.00%\n",
      "Epoch [29/1200], Loss: 2.6992 , Accuracy : 10.00%\n",
      "Epoch [30/1200], Loss: 2.8526 , Accuracy : 7.50%\n",
      "Epoch [31/1200], Loss: 3.0994 , Accuracy : 5.00%\n",
      "Epoch [32/1200], Loss: 2.9730 , Accuracy : 10.00%\n",
      "Epoch [33/1200], Loss: 2.9851 , Accuracy : 5.00%\n",
      "Epoch [34/1200], Loss: 3.0825 , Accuracy : 10.00%\n",
      "Epoch [35/1200], Loss: 4.0502 , Accuracy : 10.00%\n",
      "Epoch [36/1200], Loss: 3.1315 , Accuracy : 5.00%\n",
      "Epoch [37/1200], Loss: 2.9151 , Accuracy : 7.50%\n",
      "Epoch [38/1200], Loss: 3.3991 , Accuracy : 17.50%\n",
      "Epoch [39/1200], Loss: 2.6053 , Accuracy : 15.00%\n",
      "Epoch [40/1200], Loss: 2.7682 , Accuracy : 10.00%\n",
      "Epoch [41/1200], Loss: 3.0480 , Accuracy : 10.00%\n",
      "Epoch [42/1200], Loss: 2.7405 , Accuracy : 12.50%\n",
      "Epoch [43/1200], Loss: 3.7480 , Accuracy : 12.50%\n",
      "Epoch [44/1200], Loss: 2.3821 , Accuracy : 15.00%\n",
      "Epoch [45/1200], Loss: 2.6116 , Accuracy : 7.50%\n",
      "Epoch [46/1200], Loss: 2.7655 , Accuracy : 10.00%\n",
      "Epoch [47/1200], Loss: 2.8786 , Accuracy : 15.00%\n",
      "Epoch [48/1200], Loss: 2.6014 , Accuracy : 17.50%\n",
      "Epoch [49/1200], Loss: 2.8551 , Accuracy : 22.50%\n",
      "Epoch [50/1200], Loss: 3.0408 , Accuracy : 7.50%\n",
      "Epoch [51/1200], Loss: 2.2554 , Accuracy : 15.00%\n",
      "Epoch [52/1200], Loss: 2.4241 , Accuracy : 15.00%\n",
      "Epoch [53/1200], Loss: 2.6090 , Accuracy : 17.50%\n",
      "Epoch [54/1200], Loss: 2.7835 , Accuracy : 20.00%\n",
      "Epoch [55/1200], Loss: 3.1007 , Accuracy : 25.00%\n",
      "Epoch [56/1200], Loss: 2.8126 , Accuracy : 10.00%\n",
      "Epoch [57/1200], Loss: 3.3293 , Accuracy : 7.50%\n",
      "Epoch [58/1200], Loss: 2.3102 , Accuracy : 17.50%\n",
      "Epoch [59/1200], Loss: 2.6203 , Accuracy : 20.00%\n",
      "Epoch [60/1200], Loss: 2.4651 , Accuracy : 17.50%\n",
      "Epoch [61/1200], Loss: 2.9884 , Accuracy : 15.00%\n",
      "Epoch [62/1200], Loss: 2.4219 , Accuracy : 22.50%\n",
      "Epoch [63/1200], Loss: 2.4762 , Accuracy : 22.50%\n",
      "Epoch [64/1200], Loss: 2.5824 , Accuracy : 25.00%\n",
      "Epoch [65/1200], Loss: 2.7084 , Accuracy : 20.00%\n",
      "Epoch [66/1200], Loss: 2.0378 , Accuracy : 20.00%\n",
      "Epoch [67/1200], Loss: 1.6123 , Accuracy : 20.00%\n",
      "Epoch [68/1200], Loss: 3.4917 , Accuracy : 22.50%\n",
      "Epoch [69/1200], Loss: 2.9423 , Accuracy : 15.00%\n",
      "Epoch [70/1200], Loss: 2.4210 , Accuracy : 15.00%\n",
      "Epoch [71/1200], Loss: 2.7265 , Accuracy : 17.50%\n",
      "Epoch [72/1200], Loss: 2.8480 , Accuracy : 22.50%\n",
      "Epoch [73/1200], Loss: 2.7737 , Accuracy : 22.50%\n",
      "Epoch [74/1200], Loss: 2.6980 , Accuracy : 25.00%\n",
      "Epoch [75/1200], Loss: 3.0109 , Accuracy : 17.50%\n",
      "Epoch [76/1200], Loss: 2.7241 , Accuracy : 30.00%\n",
      "Epoch [77/1200], Loss: 1.9938 , Accuracy : 22.50%\n",
      "Epoch [78/1200], Loss: 2.5109 , Accuracy : 17.50%\n",
      "Epoch [79/1200], Loss: 1.6333 , Accuracy : 27.50%\n",
      "Epoch [80/1200], Loss: 2.7116 , Accuracy : 27.50%\n",
      "Epoch [81/1200], Loss: 2.4962 , Accuracy : 27.50%\n",
      "Epoch [82/1200], Loss: 4.5594 , Accuracy : 27.50%\n",
      "Epoch [83/1200], Loss: 2.5585 , Accuracy : 27.50%\n",
      "Epoch [84/1200], Loss: 2.2066 , Accuracy : 25.00%\n",
      "Epoch [85/1200], Loss: 4.0293 , Accuracy : 25.00%\n",
      "Epoch [86/1200], Loss: 2.3372 , Accuracy : 30.00%\n",
      "Epoch [87/1200], Loss: 2.5949 , Accuracy : 22.50%\n",
      "Epoch [88/1200], Loss: 2.8064 , Accuracy : 17.50%\n",
      "Epoch [89/1200], Loss: 2.7650 , Accuracy : 27.50%\n",
      "Epoch [90/1200], Loss: 2.0676 , Accuracy : 35.00%\n",
      "Epoch [91/1200], Loss: 2.1389 , Accuracy : 27.50%\n",
      "Epoch [92/1200], Loss: 1.5937 , Accuracy : 15.00%\n",
      "Epoch [93/1200], Loss: 1.3520 , Accuracy : 25.00%\n",
      "Epoch [94/1200], Loss: 1.7089 , Accuracy : 27.50%\n",
      "Epoch [95/1200], Loss: 2.2424 , Accuracy : 27.50%\n",
      "Epoch [96/1200], Loss: 3.6504 , Accuracy : 17.50%\n",
      "Epoch [97/1200], Loss: 4.0210 , Accuracy : 10.00%\n",
      "Epoch [98/1200], Loss: 3.3016 , Accuracy : 17.50%\n",
      "Epoch [99/1200], Loss: 3.4913 , Accuracy : 17.50%\n",
      "Epoch [100/1200], Loss: 2.4321 , Accuracy : 15.00%\n",
      "Epoch [101/1200], Loss: 2.3794 , Accuracy : 17.50%\n",
      "Epoch [102/1200], Loss: 2.6457 , Accuracy : 20.00%\n",
      "Epoch [103/1200], Loss: 2.7495 , Accuracy : 17.50%\n",
      "Epoch [104/1200], Loss: 3.3315 , Accuracy : 12.50%\n",
      "Epoch [105/1200], Loss: 2.7460 , Accuracy : 17.50%\n",
      "Epoch [106/1200], Loss: 2.3837 , Accuracy : 17.50%\n",
      "Epoch [107/1200], Loss: 1.8298 , Accuracy : 15.00%\n",
      "Epoch [108/1200], Loss: 2.4439 , Accuracy : 20.00%\n",
      "Epoch [109/1200], Loss: 2.5520 , Accuracy : 12.50%\n",
      "Epoch [110/1200], Loss: 3.1341 , Accuracy : 22.50%\n",
      "Epoch [111/1200], Loss: 2.6468 , Accuracy : 22.50%\n",
      "Epoch [112/1200], Loss: 2.4837 , Accuracy : 10.00%\n",
      "Epoch [113/1200], Loss: 2.5186 , Accuracy : 17.50%\n",
      "Epoch [114/1200], Loss: 1.5518 , Accuracy : 20.00%\n",
      "Epoch [115/1200], Loss: 2.7307 , Accuracy : 22.50%\n",
      "Epoch [116/1200], Loss: 5.1194 , Accuracy : 25.00%\n",
      "Epoch [117/1200], Loss: 1.6742 , Accuracy : 20.00%\n",
      "Epoch [118/1200], Loss: 2.0594 , Accuracy : 25.00%\n",
      "Epoch [119/1200], Loss: 2.2527 , Accuracy : 25.00%\n",
      "Epoch [120/1200], Loss: 2.1758 , Accuracy : 20.00%\n",
      "Epoch [121/1200], Loss: 3.0736 , Accuracy : 25.00%\n",
      "Epoch [122/1200], Loss: 2.5028 , Accuracy : 30.00%\n",
      "Epoch [123/1200], Loss: 3.8491 , Accuracy : 27.50%\n",
      "Epoch [124/1200], Loss: 3.1196 , Accuracy : 37.50%\n",
      "Epoch [125/1200], Loss: 2.5951 , Accuracy : 20.00%\n",
      "Epoch [126/1200], Loss: 2.0975 , Accuracy : 20.00%\n",
      "Epoch [127/1200], Loss: 2.2392 , Accuracy : 17.50%\n",
      "Epoch [128/1200], Loss: 2.8979 , Accuracy : 25.00%\n",
      "Epoch [129/1200], Loss: 2.9531 , Accuracy : 25.00%\n",
      "Epoch [130/1200], Loss: 4.4561 , Accuracy : 12.50%\n",
      "Epoch [131/1200], Loss: 1.4940 , Accuracy : 22.50%\n",
      "Epoch [132/1200], Loss: 4.6136 , Accuracy : 15.00%\n",
      "Epoch [133/1200], Loss: 1.9705 , Accuracy : 17.50%\n",
      "Epoch [134/1200], Loss: 2.9658 , Accuracy : 12.50%\n",
      "Epoch [135/1200], Loss: 2.5006 , Accuracy : 12.50%\n",
      "Epoch [136/1200], Loss: 3.4234 , Accuracy : 12.50%\n",
      "Epoch [137/1200], Loss: 3.2948 , Accuracy : 25.00%\n",
      "Epoch [138/1200], Loss: 0.9296 , Accuracy : 10.00%\n",
      "Epoch [139/1200], Loss: 3.3198 , Accuracy : 20.00%\n",
      "Epoch [140/1200], Loss: 2.2784 , Accuracy : 20.00%\n",
      "Epoch [141/1200], Loss: 2.1554 , Accuracy : 30.00%\n",
      "Epoch [142/1200], Loss: 3.0302 , Accuracy : 25.00%\n",
      "Epoch [143/1200], Loss: 3.9561 , Accuracy : 22.50%\n",
      "Epoch [144/1200], Loss: 2.1571 , Accuracy : 32.50%\n",
      "Epoch [145/1200], Loss: 2.5960 , Accuracy : 27.50%\n",
      "Epoch [146/1200], Loss: 1.7691 , Accuracy : 27.50%\n",
      "Epoch [147/1200], Loss: 2.3670 , Accuracy : 20.00%\n",
      "Epoch [148/1200], Loss: 1.3709 , Accuracy : 27.50%\n",
      "Epoch [149/1200], Loss: 1.5602 , Accuracy : 45.00%\n",
      "Epoch [150/1200], Loss: 1.8922 , Accuracy : 30.00%\n",
      "Epoch [151/1200], Loss: 3.7583 , Accuracy : 37.50%\n",
      "Epoch [152/1200], Loss: 3.0533 , Accuracy : 37.50%\n",
      "Epoch [153/1200], Loss: 1.2871 , Accuracy : 32.50%\n",
      "Epoch [154/1200], Loss: 3.2302 , Accuracy : 35.00%\n",
      "Epoch [155/1200], Loss: 3.5791 , Accuracy : 25.00%\n",
      "Epoch [156/1200], Loss: 2.5959 , Accuracy : 27.50%\n",
      "Epoch [157/1200], Loss: 2.2951 , Accuracy : 20.00%\n",
      "Epoch [158/1200], Loss: 1.0147 , Accuracy : 37.50%\n",
      "Epoch [159/1200], Loss: 2.9642 , Accuracy : 30.00%\n",
      "Epoch [160/1200], Loss: 2.4616 , Accuracy : 37.50%\n",
      "Epoch [161/1200], Loss: 2.5341 , Accuracy : 30.00%\n",
      "Epoch [162/1200], Loss: 1.3512 , Accuracy : 30.00%\n",
      "Epoch [163/1200], Loss: 3.0148 , Accuracy : 17.50%\n",
      "Epoch [164/1200], Loss: 3.4418 , Accuracy : 7.50%\n",
      "Epoch [165/1200], Loss: 3.6063 , Accuracy : 2.50%\n",
      "Epoch [166/1200], Loss: 3.4584 , Accuracy : 5.00%\n",
      "Epoch [167/1200], Loss: 2.4590 , Accuracy : 2.50%\n",
      "Epoch [168/1200], Loss: 4.1343 , Accuracy : 5.00%\n",
      "Epoch [169/1200], Loss: 3.9460 , Accuracy : 10.00%\n",
      "Epoch [170/1200], Loss: 3.6948 , Accuracy : 12.50%\n",
      "Epoch [171/1200], Loss: 3.7195 , Accuracy : 7.50%\n",
      "Epoch [172/1200], Loss: 2.8603 , Accuracy : 10.00%\n",
      "Epoch [173/1200], Loss: 2.7808 , Accuracy : 2.50%\n",
      "Epoch [174/1200], Loss: 2.9134 , Accuracy : 7.50%\n",
      "Epoch [175/1200], Loss: 3.3720 , Accuracy : 7.50%\n",
      "Epoch [176/1200], Loss: 3.2057 , Accuracy : 10.00%\n",
      "Epoch [177/1200], Loss: 3.3704 , Accuracy : 5.00%\n",
      "Epoch [178/1200], Loss: 2.4755 , Accuracy : 7.50%\n",
      "Epoch [179/1200], Loss: 2.4988 , Accuracy : 15.00%\n",
      "Epoch [180/1200], Loss: 2.5135 , Accuracy : 17.50%\n",
      "Epoch [181/1200], Loss: 2.6953 , Accuracy : 12.50%\n",
      "Epoch [182/1200], Loss: 4.1615 , Accuracy : 15.00%\n",
      "Epoch [183/1200], Loss: 3.8029 , Accuracy : 2.50%\n",
      "Epoch [184/1200], Loss: 3.5303 , Accuracy : 7.50%\n",
      "Epoch [185/1200], Loss: 2.5451 , Accuracy : 20.00%\n",
      "Epoch [186/1200], Loss: 2.4041 , Accuracy : 20.00%\n",
      "Epoch [187/1200], Loss: 2.5759 , Accuracy : 10.00%\n",
      "Epoch [188/1200], Loss: 2.5777 , Accuracy : 20.00%\n",
      "Epoch [189/1200], Loss: 2.3445 , Accuracy : 22.50%\n",
      "Epoch [190/1200], Loss: 2.4866 , Accuracy : 15.00%\n",
      "Epoch [191/1200], Loss: 3.5987 , Accuracy : 10.00%\n",
      "Epoch [192/1200], Loss: 3.7056 , Accuracy : 15.00%\n",
      "Epoch [193/1200], Loss: 2.8787 , Accuracy : 30.00%\n",
      "Epoch [194/1200], Loss: 3.5551 , Accuracy : 20.00%\n",
      "Epoch [195/1200], Loss: 3.3375 , Accuracy : 22.50%\n",
      "Epoch [196/1200], Loss: 2.6161 , Accuracy : 17.50%\n",
      "Epoch [197/1200], Loss: 2.7197 , Accuracy : 15.00%\n",
      "Epoch [198/1200], Loss: 2.3296 , Accuracy : 15.00%\n",
      "Epoch [199/1200], Loss: 3.3477 , Accuracy : 20.00%\n",
      "Epoch [200/1200], Loss: 2.7122 , Accuracy : 22.50%\n",
      "Epoch [201/1200], Loss: 3.6072 , Accuracy : 17.50%\n",
      "Epoch [202/1200], Loss: 2.5153 , Accuracy : 5.00%\n",
      "Epoch [203/1200], Loss: 2.5591 , Accuracy : 7.50%\n",
      "Epoch [204/1200], Loss: 3.3754 , Accuracy : 10.00%\n",
      "Epoch [205/1200], Loss: 3.7567 , Accuracy : 15.00%\n",
      "Epoch [206/1200], Loss: 4.4305 , Accuracy : 20.00%\n",
      "Epoch [207/1200], Loss: 3.3572 , Accuracy : 20.00%\n",
      "Epoch [208/1200], Loss: 2.1119 , Accuracy : 22.50%\n",
      "Epoch [209/1200], Loss: 2.9614 , Accuracy : 20.00%\n",
      "Epoch [210/1200], Loss: 3.0949 , Accuracy : 22.50%\n",
      "Epoch [211/1200], Loss: 2.1145 , Accuracy : 25.00%\n",
      "Epoch [212/1200], Loss: 3.4252 , Accuracy : 30.00%\n",
      "Epoch [213/1200], Loss: 3.4500 , Accuracy : 25.00%\n",
      "Epoch [214/1200], Loss: 2.0615 , Accuracy : 25.00%\n",
      "Epoch [215/1200], Loss: 3.0259 , Accuracy : 20.00%\n",
      "Epoch [216/1200], Loss: 2.8771 , Accuracy : 25.00%\n",
      "Epoch [217/1200], Loss: 3.9345 , Accuracy : 25.00%\n",
      "Epoch [218/1200], Loss: 2.4387 , Accuracy : 10.00%\n",
      "Epoch [219/1200], Loss: 3.6091 , Accuracy : 15.00%\n",
      "Epoch [220/1200], Loss: 2.5405 , Accuracy : 15.00%\n",
      "Epoch [221/1200], Loss: 3.2449 , Accuracy : 17.50%\n",
      "Epoch [222/1200], Loss: 1.8089 , Accuracy : 22.50%\n",
      "Epoch [223/1200], Loss: 2.6801 , Accuracy : 30.00%\n",
      "Epoch [224/1200], Loss: 1.9368 , Accuracy : 17.50%\n",
      "Epoch [225/1200], Loss: 2.0921 , Accuracy : 30.00%\n",
      "Epoch [226/1200], Loss: 3.4749 , Accuracy : 30.00%\n",
      "Epoch [227/1200], Loss: 1.9017 , Accuracy : 30.00%\n",
      "Epoch [228/1200], Loss: 3.0709 , Accuracy : 17.50%\n",
      "Epoch [229/1200], Loss: 1.8887 , Accuracy : 22.50%\n",
      "Epoch [230/1200], Loss: 1.8491 , Accuracy : 17.50%\n",
      "Epoch [231/1200], Loss: 3.0427 , Accuracy : 20.00%\n",
      "Epoch [232/1200], Loss: 2.3919 , Accuracy : 12.50%\n",
      "Epoch [233/1200], Loss: 2.3836 , Accuracy : 10.00%\n",
      "Epoch [234/1200], Loss: 3.3768 , Accuracy : 17.50%\n",
      "Epoch [235/1200], Loss: 1.4996 , Accuracy : 25.00%\n",
      "Epoch [236/1200], Loss: 1.7208 , Accuracy : 27.50%\n",
      "Epoch [237/1200], Loss: 2.7861 , Accuracy : 45.00%\n",
      "Epoch [238/1200], Loss: 2.8028 , Accuracy : 32.50%\n",
      "Epoch [239/1200], Loss: 1.5016 , Accuracy : 37.50%\n",
      "Epoch [240/1200], Loss: 3.2506 , Accuracy : 32.50%\n",
      "Epoch [241/1200], Loss: 1.7808 , Accuracy : 32.50%\n",
      "Epoch [242/1200], Loss: 2.6495 , Accuracy : 25.00%\n",
      "Epoch [243/1200], Loss: 3.3009 , Accuracy : 27.50%\n",
      "Epoch [244/1200], Loss: 1.5536 , Accuracy : 22.50%\n",
      "Epoch [245/1200], Loss: 1.8139 , Accuracy : 35.00%\n",
      "Epoch [246/1200], Loss: 1.5895 , Accuracy : 35.00%\n",
      "Epoch [247/1200], Loss: 1.3875 , Accuracy : 35.00%\n",
      "Epoch [248/1200], Loss: 1.9748 , Accuracy : 37.50%\n",
      "Epoch [249/1200], Loss: 2.6002 , Accuracy : 22.50%\n",
      "Epoch [250/1200], Loss: 2.5453 , Accuracy : 27.50%\n",
      "Epoch [251/1200], Loss: 1.2252 , Accuracy : 37.50%\n",
      "Epoch [252/1200], Loss: 2.3065 , Accuracy : 42.50%\n",
      "Epoch [253/1200], Loss: 1.9428 , Accuracy : 32.50%\n",
      "Epoch [254/1200], Loss: 2.4083 , Accuracy : 27.50%\n",
      "Epoch [255/1200], Loss: 2.6280 , Accuracy : 35.00%\n",
      "Epoch [256/1200], Loss: 1.7074 , Accuracy : 35.00%\n",
      "Epoch [257/1200], Loss: 1.5622 , Accuracy : 32.50%\n",
      "Epoch [258/1200], Loss: 2.5748 , Accuracy : 30.00%\n",
      "Epoch [259/1200], Loss: 2.7382 , Accuracy : 30.00%\n",
      "Epoch [260/1200], Loss: 1.6133 , Accuracy : 32.50%\n",
      "Epoch [261/1200], Loss: 2.5429 , Accuracy : 32.50%\n",
      "Epoch [262/1200], Loss: 2.5777 , Accuracy : 25.00%\n",
      "Epoch [263/1200], Loss: 1.4008 , Accuracy : 50.00%\n",
      "Epoch [264/1200], Loss: 1.5534 , Accuracy : 40.00%\n",
      "Epoch [265/1200], Loss: 2.5013 , Accuracy : 37.50%\n",
      "Epoch [266/1200], Loss: 2.3449 , Accuracy : 32.50%\n",
      "Epoch [267/1200], Loss: 0.9683 , Accuracy : 35.00%\n",
      "Epoch [268/1200], Loss: 2.6050 , Accuracy : 32.50%\n",
      "Epoch [269/1200], Loss: 1.4137 , Accuracy : 27.50%\n",
      "Epoch [270/1200], Loss: 1.5110 , Accuracy : 50.00%\n",
      "Epoch [271/1200], Loss: 1.5147 , Accuracy : 30.00%\n",
      "Epoch [272/1200], Loss: 2.7140 , Accuracy : 17.50%\n",
      "Epoch [273/1200], Loss: 1.5885 , Accuracy : 35.00%\n",
      "Epoch [274/1200], Loss: 3.0107 , Accuracy : 37.50%\n",
      "Epoch [275/1200], Loss: 1.6638 , Accuracy : 32.50%\n",
      "Epoch [276/1200], Loss: 1.5430 , Accuracy : 32.50%\n",
      "Epoch [277/1200], Loss: 2.1425 , Accuracy : 27.50%\n",
      "Epoch [278/1200], Loss: 1.4521 , Accuracy : 30.00%\n",
      "Epoch [279/1200], Loss: 2.2392 , Accuracy : 40.00%\n",
      "Epoch [280/1200], Loss: 2.3068 , Accuracy : 47.50%\n",
      "Epoch [281/1200], Loss: 0.9843 , Accuracy : 42.50%\n",
      "Epoch [282/1200], Loss: 1.4935 , Accuracy : 45.00%\n",
      "Epoch [283/1200], Loss: 3.5127 , Accuracy : 35.00%\n",
      "Epoch [284/1200], Loss: 2.6604 , Accuracy : 40.00%\n",
      "Epoch [285/1200], Loss: 1.8236 , Accuracy : 35.00%\n",
      "Epoch [286/1200], Loss: 1.1894 , Accuracy : 27.50%\n",
      "Epoch [287/1200], Loss: 1.4786 , Accuracy : 35.00%\n",
      "Epoch [288/1200], Loss: 3.2573 , Accuracy : 45.00%\n",
      "Epoch [289/1200], Loss: 2.5329 , Accuracy : 30.00%\n",
      "Epoch [290/1200], Loss: 1.4341 , Accuracy : 27.50%\n",
      "Epoch [291/1200], Loss: 3.3063 , Accuracy : 32.50%\n",
      "Epoch [292/1200], Loss: 4.8340 , Accuracy : 17.50%\n",
      "Epoch [293/1200], Loss: 3.5537 , Accuracy : 10.00%\n",
      "Epoch [294/1200], Loss: 2.6845 , Accuracy : 15.00%\n",
      "Epoch [295/1200], Loss: 2.3662 , Accuracy : 17.50%\n",
      "Epoch [296/1200], Loss: 2.4098 , Accuracy : 20.00%\n",
      "Epoch [297/1200], Loss: 1.9975 , Accuracy : 20.00%\n",
      "Epoch [298/1200], Loss: 1.8959 , Accuracy : 17.50%\n",
      "Epoch [299/1200], Loss: 3.0836 , Accuracy : 20.00%\n",
      "Epoch [300/1200], Loss: 1.9316 , Accuracy : 20.00%\n",
      "Epoch [301/1200], Loss: 2.0348 , Accuracy : 17.50%\n",
      "Epoch [302/1200], Loss: 2.1104 , Accuracy : 22.50%\n",
      "Epoch [303/1200], Loss: 2.5032 , Accuracy : 7.50%\n",
      "Epoch [304/1200], Loss: 3.5008 , Accuracy : 15.00%\n",
      "Epoch [305/1200], Loss: 2.0629 , Accuracy : 17.50%\n",
      "Epoch [306/1200], Loss: 3.2491 , Accuracy : 17.50%\n",
      "Epoch [307/1200], Loss: 1.9388 , Accuracy : 25.00%\n",
      "Epoch [308/1200], Loss: 3.0476 , Accuracy : 27.50%\n",
      "Epoch [309/1200], Loss: 3.5568 , Accuracy : 15.00%\n",
      "Epoch [310/1200], Loss: 2.3743 , Accuracy : 12.50%\n",
      "Epoch [311/1200], Loss: 2.7227 , Accuracy : 30.00%\n",
      "Epoch [312/1200], Loss: 1.7268 , Accuracy : 30.00%\n",
      "Epoch [313/1200], Loss: 1.7181 , Accuracy : 37.50%\n",
      "Epoch [314/1200], Loss: 3.9740 , Accuracy : 32.50%\n",
      "Epoch [315/1200], Loss: 1.8955 , Accuracy : 27.50%\n",
      "Epoch [316/1200], Loss: 1.7649 , Accuracy : 15.00%\n",
      "Epoch [317/1200], Loss: 2.0218 , Accuracy : 32.50%\n",
      "Epoch [318/1200], Loss: 3.2113 , Accuracy : 37.50%\n",
      "Epoch [319/1200], Loss: 1.6061 , Accuracy : 22.50%\n",
      "Epoch [320/1200], Loss: 1.6418 , Accuracy : 32.50%\n",
      "Epoch [321/1200], Loss: 2.1045 , Accuracy : 22.50%\n",
      "Epoch [322/1200], Loss: 3.0928 , Accuracy : 32.50%\n",
      "Epoch [323/1200], Loss: 3.0778 , Accuracy : 37.50%\n",
      "Epoch [324/1200], Loss: 2.6958 , Accuracy : 27.50%\n",
      "Epoch [325/1200], Loss: 1.3347 , Accuracy : 25.00%\n",
      "Epoch [326/1200], Loss: 1.6016 , Accuracy : 32.50%\n",
      "Epoch [327/1200], Loss: 1.4461 , Accuracy : 27.50%\n",
      "Epoch [328/1200], Loss: 3.5993 , Accuracy : 32.50%\n",
      "Epoch [329/1200], Loss: 1.3743 , Accuracy : 37.50%\n",
      "Epoch [330/1200], Loss: 1.7565 , Accuracy : 22.50%\n",
      "Epoch [331/1200], Loss: 1.5296 , Accuracy : 30.00%\n",
      "Epoch [332/1200], Loss: 1.2922 , Accuracy : 30.00%\n",
      "Epoch [333/1200], Loss: 1.3086 , Accuracy : 30.00%\n",
      "Epoch [334/1200], Loss: 1.2525 , Accuracy : 35.00%\n",
      "Epoch [335/1200], Loss: 1.5013 , Accuracy : 35.00%\n",
      "Epoch [336/1200], Loss: 2.6928 , Accuracy : 25.00%\n",
      "Epoch [337/1200], Loss: 2.3699 , Accuracy : 35.00%\n",
      "Epoch [338/1200], Loss: 2.7792 , Accuracy : 15.00%\n",
      "Epoch [339/1200], Loss: 3.7031 , Accuracy : 17.50%\n",
      "Epoch [340/1200], Loss: 3.4459 , Accuracy : 17.50%\n",
      "Epoch [341/1200], Loss: 1.8905 , Accuracy : 30.00%\n",
      "Epoch [342/1200], Loss: 3.0597 , Accuracy : 27.50%\n",
      "Epoch [343/1200], Loss: 3.9471 , Accuracy : 30.00%\n",
      "Epoch [344/1200], Loss: 1.6668 , Accuracy : 25.00%\n",
      "Epoch [345/1200], Loss: 2.9611 , Accuracy : 27.50%\n",
      "Epoch [346/1200], Loss: 2.6640 , Accuracy : 32.50%\n",
      "Epoch [347/1200], Loss: 2.6069 , Accuracy : 25.00%\n",
      "Epoch [348/1200], Loss: 3.0022 , Accuracy : 27.50%\n",
      "Epoch [349/1200], Loss: 1.4460 , Accuracy : 40.00%\n",
      "Epoch [350/1200], Loss: 1.2778 , Accuracy : 32.50%\n",
      "Epoch [351/1200], Loss: 2.6577 , Accuracy : 37.50%\n",
      "Epoch [352/1200], Loss: 1.3097 , Accuracy : 35.00%\n",
      "Epoch [353/1200], Loss: 2.4445 , Accuracy : 35.00%\n",
      "Epoch [354/1200], Loss: 1.4220 , Accuracy : 35.00%\n",
      "Epoch [355/1200], Loss: 1.3576 , Accuracy : 40.00%\n",
      "Epoch [356/1200], Loss: 1.4061 , Accuracy : 45.00%\n",
      "Epoch [357/1200], Loss: 1.2603 , Accuracy : 40.00%\n",
      "Epoch [358/1200], Loss: 2.6883 , Accuracy : 25.00%\n",
      "Epoch [359/1200], Loss: 1.2552 , Accuracy : 25.00%\n",
      "Epoch [360/1200], Loss: 1.5925 , Accuracy : 30.00%\n",
      "Epoch [361/1200], Loss: 2.2325 , Accuracy : 32.50%\n",
      "Epoch [362/1200], Loss: 1.1860 , Accuracy : 32.50%\n",
      "Epoch [363/1200], Loss: 1.4707 , Accuracy : 30.00%\n",
      "Epoch [364/1200], Loss: 1.3295 , Accuracy : 40.00%\n",
      "Epoch [365/1200], Loss: 1.2667 , Accuracy : 37.50%\n",
      "Epoch [366/1200], Loss: 0.9551 , Accuracy : 37.50%\n",
      "Epoch [367/1200], Loss: 1.8673 , Accuracy : 30.00%\n",
      "Epoch [368/1200], Loss: 1.2786 , Accuracy : 35.00%\n",
      "Epoch [369/1200], Loss: 2.2865 , Accuracy : 35.00%\n",
      "Epoch [370/1200], Loss: 1.2663 , Accuracy : 37.50%\n",
      "Epoch [371/1200], Loss: 2.0126 , Accuracy : 47.50%\n",
      "Epoch [372/1200], Loss: 2.4023 , Accuracy : 45.00%\n",
      "Epoch [373/1200], Loss: 1.5256 , Accuracy : 27.50%\n",
      "Epoch [374/1200], Loss: 1.3119 , Accuracy : 32.50%\n",
      "Epoch [375/1200], Loss: 2.8992 , Accuracy : 32.50%\n",
      "Epoch [376/1200], Loss: 1.4800 , Accuracy : 37.50%\n",
      "Epoch [377/1200], Loss: 2.5574 , Accuracy : 35.00%\n",
      "Epoch [378/1200], Loss: 2.2443 , Accuracy : 50.00%\n",
      "Epoch [379/1200], Loss: 0.9374 , Accuracy : 37.50%\n",
      "Epoch [380/1200], Loss: 1.1288 , Accuracy : 40.00%\n",
      "Epoch [381/1200], Loss: 2.2381 , Accuracy : 42.50%\n",
      "Epoch [382/1200], Loss: 2.2803 , Accuracy : 50.00%\n",
      "Epoch [383/1200], Loss: 1.4326 , Accuracy : 45.00%\n",
      "Epoch [384/1200], Loss: 1.2624 , Accuracy : 52.50%\n",
      "Epoch [385/1200], Loss: 1.1576 , Accuracy : 45.00%\n",
      "Epoch [386/1200], Loss: 1.5936 , Accuracy : 50.00%\n",
      "Epoch [387/1200], Loss: 1.3354 , Accuracy : 47.50%\n",
      "Epoch [388/1200], Loss: 1.0891 , Accuracy : 42.50%\n",
      "Epoch [389/1200], Loss: 1.2400 , Accuracy : 52.50%\n",
      "Epoch [390/1200], Loss: 0.8042 , Accuracy : 37.50%\n",
      "Epoch [391/1200], Loss: 0.9791 , Accuracy : 47.50%\n",
      "Epoch [392/1200], Loss: 2.3545 , Accuracy : 52.50%\n",
      "Epoch [393/1200], Loss: 2.0362 , Accuracy : 40.00%\n",
      "Epoch [394/1200], Loss: 1.1196 , Accuracy : 37.50%\n",
      "Epoch [395/1200], Loss: 3.1174 , Accuracy : 42.50%\n",
      "Epoch [396/1200], Loss: 2.1154 , Accuracy : 50.00%\n",
      "Epoch [397/1200], Loss: 1.2125 , Accuracy : 45.00%\n",
      "Epoch [398/1200], Loss: 3.1315 , Accuracy : 45.00%\n",
      "Epoch [399/1200], Loss: 1.5822 , Accuracy : 45.00%\n",
      "Epoch [400/1200], Loss: 2.7911 , Accuracy : 52.50%\n",
      "Epoch [401/1200], Loss: 2.6208 , Accuracy : 47.50%\n",
      "Epoch [402/1200], Loss: 0.9423 , Accuracy : 42.50%\n",
      "Epoch [403/1200], Loss: 2.3383 , Accuracy : 42.50%\n",
      "Epoch [404/1200], Loss: 0.9353 , Accuracy : 40.00%\n",
      "Epoch [405/1200], Loss: 1.9796 , Accuracy : 47.50%\n",
      "Epoch [406/1200], Loss: 0.9478 , Accuracy : 45.00%\n",
      "Epoch [407/1200], Loss: 1.3995 , Accuracy : 35.00%\n",
      "Epoch [408/1200], Loss: 0.9242 , Accuracy : 32.50%\n",
      "Epoch [409/1200], Loss: 2.9190 , Accuracy : 27.50%\n",
      "Epoch [410/1200], Loss: 2.3887 , Accuracy : 22.50%\n",
      "Epoch [411/1200], Loss: 1.5080 , Accuracy : 32.50%\n",
      "Epoch [412/1200], Loss: 1.3639 , Accuracy : 35.00%\n",
      "Epoch [413/1200], Loss: 1.1438 , Accuracy : 45.00%\n",
      "Epoch [414/1200], Loss: 1.4667 , Accuracy : 52.50%\n",
      "Epoch [415/1200], Loss: 1.9828 , Accuracy : 50.00%\n",
      "Epoch [416/1200], Loss: 0.9760 , Accuracy : 45.00%\n",
      "Epoch [417/1200], Loss: 0.9329 , Accuracy : 35.00%\n",
      "Epoch [418/1200], Loss: 0.8762 , Accuracy : 45.00%\n",
      "Epoch [419/1200], Loss: 0.9030 , Accuracy : 42.50%\n",
      "Epoch [420/1200], Loss: 1.0574 , Accuracy : 50.00%\n",
      "Epoch [421/1200], Loss: 0.8497 , Accuracy : 45.00%\n",
      "Epoch [422/1200], Loss: 1.1592 , Accuracy : 40.00%\n",
      "Epoch [423/1200], Loss: 1.2761 , Accuracy : 32.50%\n",
      "Epoch [424/1200], Loss: 1.1525 , Accuracy : 45.00%\n",
      "Epoch [425/1200], Loss: 0.7719 , Accuracy : 42.50%\n",
      "Epoch [426/1200], Loss: 1.2143 , Accuracy : 47.50%\n",
      "Epoch [427/1200], Loss: 1.7769 , Accuracy : 50.00%\n",
      "Epoch [428/1200], Loss: 0.8239 , Accuracy : 42.50%\n",
      "Epoch [429/1200], Loss: 0.8153 , Accuracy : 40.00%\n",
      "Epoch [430/1200], Loss: 0.8184 , Accuracy : 57.50%\n",
      "Epoch [431/1200], Loss: 0.8942 , Accuracy : 52.50%\n",
      "Epoch [432/1200], Loss: 3.9458 , Accuracy : 25.00%\n",
      "Epoch [433/1200], Loss: 5.3692 , Accuracy : 25.00%\n",
      "Epoch [434/1200], Loss: 4.9630 , Accuracy : 12.50%\n",
      "Epoch [435/1200], Loss: 1.9866 , Accuracy : 17.50%\n",
      "Epoch [436/1200], Loss: 2.2951 , Accuracy : 12.50%\n",
      "Epoch [437/1200], Loss: 2.6573 , Accuracy : 15.00%\n",
      "Epoch [438/1200], Loss: 3.1039 , Accuracy : 20.00%\n",
      "Epoch [439/1200], Loss: 2.9198 , Accuracy : 25.00%\n",
      "Epoch [440/1200], Loss: 3.4626 , Accuracy : 22.50%\n",
      "Epoch [441/1200], Loss: 1.2671 , Accuracy : 25.00%\n",
      "Epoch [442/1200], Loss: 3.4119 , Accuracy : 20.00%\n",
      "Epoch [443/1200], Loss: 2.9254 , Accuracy : 32.50%\n",
      "Epoch [444/1200], Loss: 1.6307 , Accuracy : 22.50%\n",
      "Epoch [445/1200], Loss: 1.6037 , Accuracy : 30.00%\n",
      "Epoch [446/1200], Loss: 2.5498 , Accuracy : 22.50%\n",
      "Epoch [447/1200], Loss: 2.3377 , Accuracy : 40.00%\n",
      "Epoch [448/1200], Loss: 1.7442 , Accuracy : 35.00%\n",
      "Epoch [449/1200], Loss: 2.5975 , Accuracy : 37.50%\n",
      "Epoch [450/1200], Loss: 2.4421 , Accuracy : 40.00%\n",
      "Epoch [451/1200], Loss: 1.1186 , Accuracy : 40.00%\n",
      "Epoch [452/1200], Loss: 3.5295 , Accuracy : 37.50%\n",
      "Epoch [453/1200], Loss: 1.0613 , Accuracy : 45.00%\n",
      "Epoch [454/1200], Loss: 3.0757 , Accuracy : 42.50%\n",
      "Epoch [455/1200], Loss: 1.2105 , Accuracy : 47.50%\n",
      "Epoch [456/1200], Loss: 1.0652 , Accuracy : 37.50%\n",
      "Epoch [457/1200], Loss: 2.8221 , Accuracy : 40.00%\n",
      "Epoch [458/1200], Loss: 4.5847 , Accuracy : 27.50%\n",
      "Epoch [459/1200], Loss: 3.1033 , Accuracy : 22.50%\n",
      "Epoch [460/1200], Loss: 2.2120 , Accuracy : 42.50%\n",
      "Epoch [461/1200], Loss: 2.0143 , Accuracy : 32.50%\n",
      "Epoch [462/1200], Loss: 1.9040 , Accuracy : 45.00%\n",
      "Epoch [463/1200], Loss: 1.5048 , Accuracy : 37.50%\n",
      "Epoch [464/1200], Loss: 3.1076 , Accuracy : 27.50%\n",
      "Epoch [465/1200], Loss: 2.5668 , Accuracy : 42.50%\n",
      "Epoch [466/1200], Loss: 2.0679 , Accuracy : 47.50%\n",
      "Epoch [467/1200], Loss: 2.4084 , Accuracy : 52.50%\n",
      "Epoch [468/1200], Loss: 2.0408 , Accuracy : 50.00%\n",
      "Epoch [469/1200], Loss: 3.5345 , Accuracy : 37.50%\n",
      "Epoch [470/1200], Loss: 5.5714 , Accuracy : 20.00%\n",
      "Epoch [471/1200], Loss: 1.7171 , Accuracy : 22.50%\n",
      "Epoch [472/1200], Loss: 3.1293 , Accuracy : 32.50%\n",
      "Epoch [473/1200], Loss: 2.3351 , Accuracy : 27.50%\n",
      "Epoch [474/1200], Loss: 1.1016 , Accuracy : 30.00%\n",
      "Epoch [475/1200], Loss: 1.1936 , Accuracy : 57.50%\n",
      "Epoch [476/1200], Loss: 3.1179 , Accuracy : 50.00%\n",
      "Epoch [477/1200], Loss: 0.6544 , Accuracy : 55.00%\n",
      "Epoch [478/1200], Loss: 2.3966 , Accuracy : 50.00%\n",
      "Epoch [479/1200], Loss: 1.0815 , Accuracy : 50.00%\n",
      "Epoch [480/1200], Loss: 2.4040 , Accuracy : 50.00%\n",
      "Epoch [481/1200], Loss: 2.3580 , Accuracy : 52.50%\n",
      "Epoch [482/1200], Loss: 0.8105 , Accuracy : 47.50%\n",
      "Epoch [483/1200], Loss: 2.2284 , Accuracy : 40.00%\n",
      "Epoch [484/1200], Loss: 2.9789 , Accuracy : 52.50%\n",
      "Epoch [485/1200], Loss: 1.8626 , Accuracy : 40.00%\n",
      "Epoch [486/1200], Loss: 0.8512 , Accuracy : 42.50%\n",
      "Epoch [487/1200], Loss: 1.1963 , Accuracy : 50.00%\n",
      "Epoch [488/1200], Loss: 1.0459 , Accuracy : 40.00%\n",
      "Epoch [489/1200], Loss: 1.3243 , Accuracy : 37.50%\n",
      "Epoch [490/1200], Loss: 4.7292 , Accuracy : 40.00%\n",
      "Epoch [491/1200], Loss: 0.6725 , Accuracy : 45.00%\n",
      "Epoch [492/1200], Loss: 0.7586 , Accuracy : 52.50%\n",
      "Epoch [493/1200], Loss: 2.6729 , Accuracy : 47.50%\n",
      "Epoch [494/1200], Loss: 3.2813 , Accuracy : 52.50%\n",
      "Epoch [495/1200], Loss: 1.1231 , Accuracy : 45.00%\n",
      "Epoch [496/1200], Loss: 2.1072 , Accuracy : 35.00%\n",
      "Epoch [497/1200], Loss: 2.7251 , Accuracy : 42.50%\n",
      "Epoch [498/1200], Loss: 1.2288 , Accuracy : 42.50%\n",
      "Epoch [499/1200], Loss: 1.8315 , Accuracy : 45.00%\n",
      "Epoch [500/1200], Loss: 2.7921 , Accuracy : 40.00%\n",
      "Epoch [501/1200], Loss: 0.9700 , Accuracy : 47.50%\n",
      "Epoch [502/1200], Loss: 2.4839 , Accuracy : 45.00%\n",
      "Epoch [503/1200], Loss: 2.4286 , Accuracy : 50.00%\n",
      "Epoch [504/1200], Loss: 0.3163 , Accuracy : 55.00%\n",
      "Epoch [505/1200], Loss: 0.7138 , Accuracy : 47.50%\n",
      "Epoch [506/1200], Loss: 1.0175 , Accuracy : 40.00%\n",
      "Epoch [507/1200], Loss: 0.7853 , Accuracy : 37.50%\n",
      "Epoch [508/1200], Loss: 2.6470 , Accuracy : 50.00%\n",
      "Epoch [509/1200], Loss: 2.3636 , Accuracy : 52.50%\n",
      "Epoch [510/1200], Loss: 0.9502 , Accuracy : 50.00%\n",
      "Epoch [511/1200], Loss: 2.4934 , Accuracy : 50.00%\n",
      "Epoch [512/1200], Loss: 2.6052 , Accuracy : 40.00%\n",
      "Epoch [513/1200], Loss: 0.7695 , Accuracy : 50.00%\n",
      "Epoch [514/1200], Loss: 0.8570 , Accuracy : 47.50%\n",
      "Epoch [515/1200], Loss: 0.8201 , Accuracy : 50.00%\n",
      "Epoch [516/1200], Loss: 1.4876 , Accuracy : 60.00%\n",
      "Epoch [517/1200], Loss: 1.8962 , Accuracy : 42.50%\n",
      "Epoch [518/1200], Loss: 0.7019 , Accuracy : 50.00%\n",
      "Epoch [519/1200], Loss: 1.0493 , Accuracy : 50.00%\n",
      "Epoch [520/1200], Loss: 2.0903 , Accuracy : 40.00%\n",
      "Epoch [521/1200], Loss: 0.5326 , Accuracy : 55.00%\n",
      "Epoch [522/1200], Loss: 1.0291 , Accuracy : 47.50%\n",
      "Epoch [523/1200], Loss: 2.3484 , Accuracy : 52.50%\n",
      "Epoch [524/1200], Loss: 0.9314 , Accuracy : 50.00%\n",
      "Epoch [525/1200], Loss: 0.9366 , Accuracy : 60.00%\n",
      "Epoch [526/1200], Loss: 0.5412 , Accuracy : 57.50%\n",
      "Epoch [527/1200], Loss: 5.0348 , Accuracy : 40.00%\n",
      "Epoch [528/1200], Loss: 0.8931 , Accuracy : 50.00%\n",
      "Epoch [529/1200], Loss: 1.3404 , Accuracy : 42.50%\n",
      "Epoch [530/1200], Loss: 1.7767 , Accuracy : 42.50%\n",
      "Epoch [531/1200], Loss: 0.9303 , Accuracy : 47.50%\n",
      "Epoch [532/1200], Loss: 2.5608 , Accuracy : 37.50%\n",
      "Epoch [533/1200], Loss: 2.6018 , Accuracy : 42.50%\n",
      "Epoch [534/1200], Loss: 1.2363 , Accuracy : 62.50%\n",
      "Epoch [535/1200], Loss: 2.0601 , Accuracy : 47.50%\n",
      "Epoch [536/1200], Loss: 3.1008 , Accuracy : 30.00%\n",
      "Epoch [537/1200], Loss: 1.6357 , Accuracy : 37.50%\n",
      "Epoch [538/1200], Loss: 0.8364 , Accuracy : 47.50%\n",
      "Epoch [539/1200], Loss: 3.2092 , Accuracy : 45.00%\n",
      "Epoch [540/1200], Loss: 0.8833 , Accuracy : 55.00%\n",
      "Epoch [541/1200], Loss: 0.9336 , Accuracy : 57.50%\n",
      "Epoch [542/1200], Loss: 0.5712 , Accuracy : 60.00%\n",
      "Epoch [543/1200], Loss: 0.8311 , Accuracy : 40.00%\n",
      "Epoch [544/1200], Loss: 2.3811 , Accuracy : 50.00%\n",
      "Epoch [545/1200], Loss: 0.7007 , Accuracy : 27.50%\n",
      "Epoch [546/1200], Loss: 2.1157 , Accuracy : 47.50%\n",
      "Epoch [547/1200], Loss: 0.9292 , Accuracy : 47.50%\n",
      "Epoch [548/1200], Loss: 2.2050 , Accuracy : 45.00%\n",
      "Epoch [549/1200], Loss: 1.2691 , Accuracy : 52.50%\n",
      "Epoch [550/1200], Loss: 1.0746 , Accuracy : 47.50%\n",
      "Epoch [551/1200], Loss: 0.8482 , Accuracy : 45.00%\n",
      "Epoch [552/1200], Loss: 2.4627 , Accuracy : 52.50%\n",
      "Epoch [553/1200], Loss: 2.1142 , Accuracy : 35.00%\n",
      "Epoch [554/1200], Loss: 0.6284 , Accuracy : 65.00%\n",
      "Epoch [555/1200], Loss: 1.3326 , Accuracy : 42.50%\n",
      "Epoch [556/1200], Loss: 0.7765 , Accuracy : 55.00%\n",
      "Epoch [557/1200], Loss: 0.9528 , Accuracy : 50.00%\n",
      "Epoch [558/1200], Loss: 0.7699 , Accuracy : 55.00%\n",
      "Epoch [559/1200], Loss: 0.7480 , Accuracy : 57.50%\n",
      "Epoch [560/1200], Loss: 2.2751 , Accuracy : 52.50%\n",
      "Epoch [561/1200], Loss: 2.7512 , Accuracy : 57.50%\n",
      "Epoch [562/1200], Loss: 2.4161 , Accuracy : 50.00%\n",
      "Epoch [563/1200], Loss: 2.2072 , Accuracy : 52.50%\n",
      "Epoch [564/1200], Loss: 0.5369 , Accuracy : 65.00%\n",
      "Epoch [565/1200], Loss: 2.6315 , Accuracy : 52.50%\n",
      "Epoch [566/1200], Loss: 1.0150 , Accuracy : 45.00%\n",
      "Epoch [567/1200], Loss: 0.8395 , Accuracy : 50.00%\n",
      "Epoch [568/1200], Loss: 2.9905 , Accuracy : 42.50%\n",
      "Epoch [569/1200], Loss: 0.7786 , Accuracy : 35.00%\n",
      "Epoch [570/1200], Loss: 1.0341 , Accuracy : 30.00%\n",
      "Epoch [571/1200], Loss: 0.7379 , Accuracy : 57.50%\n",
      "Epoch [572/1200], Loss: 0.8561 , Accuracy : 60.00%\n",
      "Epoch [573/1200], Loss: 0.8007 , Accuracy : 50.00%\n",
      "Epoch [574/1200], Loss: 2.3397 , Accuracy : 50.00%\n",
      "Epoch [575/1200], Loss: 1.8619 , Accuracy : 50.00%\n",
      "Epoch [576/1200], Loss: 1.2919 , Accuracy : 42.50%\n",
      "Epoch [577/1200], Loss: 2.4614 , Accuracy : 45.00%\n",
      "Epoch [578/1200], Loss: 1.4281 , Accuracy : 55.00%\n",
      "Epoch [579/1200], Loss: 1.4911 , Accuracy : 20.00%\n",
      "Epoch [580/1200], Loss: 1.4279 , Accuracy : 17.50%\n",
      "Epoch [581/1200], Loss: 4.4755 , Accuracy : 15.00%\n",
      "Epoch [582/1200], Loss: 3.1401 , Accuracy : 22.50%\n",
      "Epoch [583/1200], Loss: 3.3089 , Accuracy : 27.50%\n",
      "Epoch [584/1200], Loss: 2.8577 , Accuracy : 22.50%\n",
      "Epoch [585/1200], Loss: 1.4651 , Accuracy : 32.50%\n",
      "Epoch [586/1200], Loss: 2.5144 , Accuracy : 27.50%\n",
      "Epoch [587/1200], Loss: 2.7144 , Accuracy : 17.50%\n",
      "Epoch [588/1200], Loss: 2.9085 , Accuracy : 27.50%\n",
      "Epoch [589/1200], Loss: 3.2934 , Accuracy : 27.50%\n",
      "Epoch [590/1200], Loss: 2.9687 , Accuracy : 27.50%\n",
      "Epoch [591/1200], Loss: 2.1536 , Accuracy : 30.00%\n",
      "Epoch [592/1200], Loss: 0.8556 , Accuracy : 27.50%\n",
      "Epoch [593/1200], Loss: 1.6520 , Accuracy : 37.50%\n",
      "Epoch [594/1200], Loss: 1.5464 , Accuracy : 37.50%\n",
      "Epoch [595/1200], Loss: 2.7598 , Accuracy : 32.50%\n",
      "Epoch [596/1200], Loss: 2.0465 , Accuracy : 40.00%\n",
      "Epoch [597/1200], Loss: 1.8501 , Accuracy : 40.00%\n",
      "Epoch [598/1200], Loss: 1.6044 , Accuracy : 35.00%\n",
      "Epoch [599/1200], Loss: 0.8005 , Accuracy : 40.00%\n",
      "Epoch [600/1200], Loss: 2.9707 , Accuracy : 40.00%\n",
      "Epoch [601/1200], Loss: 2.9768 , Accuracy : 42.50%\n",
      "Epoch [602/1200], Loss: 1.2317 , Accuracy : 40.00%\n",
      "Epoch [603/1200], Loss: 1.3547 , Accuracy : 35.00%\n",
      "Epoch [604/1200], Loss: 2.3028 , Accuracy : 40.00%\n",
      "Epoch [605/1200], Loss: 1.7189 , Accuracy : 25.00%\n",
      "Epoch [606/1200], Loss: 3.1823 , Accuracy : 42.50%\n",
      "Epoch [607/1200], Loss: 0.8084 , Accuracy : 30.00%\n",
      "Epoch [608/1200], Loss: 2.9417 , Accuracy : 40.00%\n",
      "Epoch [609/1200], Loss: 3.4356 , Accuracy : 47.50%\n",
      "Epoch [610/1200], Loss: 2.4753 , Accuracy : 42.50%\n",
      "Epoch [611/1200], Loss: 1.1721 , Accuracy : 50.00%\n",
      "Epoch [612/1200], Loss: 3.0201 , Accuracy : 35.00%\n",
      "Epoch [613/1200], Loss: 1.9319 , Accuracy : 37.50%\n",
      "Epoch [614/1200], Loss: 2.3857 , Accuracy : 55.00%\n",
      "Epoch [615/1200], Loss: 2.1223 , Accuracy : 50.00%\n",
      "Epoch [616/1200], Loss: 3.2458 , Accuracy : 47.50%\n",
      "Epoch [617/1200], Loss: 1.4361 , Accuracy : 32.50%\n",
      "Epoch [618/1200], Loss: 0.4379 , Accuracy : 47.50%\n",
      "Epoch [619/1200], Loss: 1.8241 , Accuracy : 47.50%\n",
      "Epoch [620/1200], Loss: 0.5882 , Accuracy : 40.00%\n",
      "Epoch [621/1200], Loss: 1.6749 , Accuracy : 45.00%\n",
      "Epoch [622/1200], Loss: 2.7870 , Accuracy : 40.00%\n",
      "Epoch [623/1200], Loss: 1.1720 , Accuracy : 40.00%\n",
      "Epoch [624/1200], Loss: 1.9059 , Accuracy : 40.00%\n",
      "Epoch [625/1200], Loss: 3.2680 , Accuracy : 32.50%\n",
      "Epoch [626/1200], Loss: 0.8378 , Accuracy : 40.00%\n",
      "Epoch [627/1200], Loss: 1.4176 , Accuracy : 40.00%\n",
      "Epoch [628/1200], Loss: 0.7649 , Accuracy : 42.50%\n",
      "Epoch [629/1200], Loss: 0.4599 , Accuracy : 45.00%\n",
      "Epoch [630/1200], Loss: 0.8230 , Accuracy : 42.50%\n",
      "Epoch [631/1200], Loss: 2.0202 , Accuracy : 45.00%\n",
      "Epoch [632/1200], Loss: 1.2015 , Accuracy : 42.50%\n",
      "Epoch [633/1200], Loss: 2.3520 , Accuracy : 37.50%\n",
      "Epoch [634/1200], Loss: 3.0840 , Accuracy : 42.50%\n",
      "Epoch [635/1200], Loss: 1.8234 , Accuracy : 50.00%\n",
      "Epoch [636/1200], Loss: 0.9537 , Accuracy : 42.50%\n",
      "Epoch [637/1200], Loss: 0.6242 , Accuracy : 52.50%\n",
      "Epoch [638/1200], Loss: 0.8694 , Accuracy : 47.50%\n",
      "Epoch [639/1200], Loss: 1.1443 , Accuracy : 52.50%\n",
      "Epoch [640/1200], Loss: 0.6796 , Accuracy : 62.50%\n",
      "Epoch [641/1200], Loss: 1.8643 , Accuracy : 42.50%\n",
      "Epoch [642/1200], Loss: 2.9625 , Accuracy : 47.50%\n",
      "Epoch [643/1200], Loss: 2.1834 , Accuracy : 57.50%\n",
      "Epoch [644/1200], Loss: 1.9703 , Accuracy : 52.50%\n",
      "Epoch [645/1200], Loss: 2.6285 , Accuracy : 50.00%\n",
      "Epoch [646/1200], Loss: 0.9179 , Accuracy : 47.50%\n",
      "Epoch [647/1200], Loss: 2.7690 , Accuracy : 52.50%\n",
      "Epoch [648/1200], Loss: 2.3859 , Accuracy : 47.50%\n",
      "Epoch [649/1200], Loss: 0.6273 , Accuracy : 47.50%\n",
      "Epoch [650/1200], Loss: 0.6337 , Accuracy : 47.50%\n",
      "Epoch [651/1200], Loss: 1.5126 , Accuracy : 50.00%\n",
      "Epoch [652/1200], Loss: 1.1111 , Accuracy : 25.00%\n",
      "Epoch [653/1200], Loss: 1.5255 , Accuracy : 27.50%\n",
      "Epoch [654/1200], Loss: 0.8387 , Accuracy : 52.50%\n",
      "Epoch [655/1200], Loss: 2.5172 , Accuracy : 42.50%\n",
      "Epoch [656/1200], Loss: 0.6444 , Accuracy : 52.50%\n",
      "Epoch [657/1200], Loss: 0.8097 , Accuracy : 55.00%\n",
      "Epoch [658/1200], Loss: 1.5142 , Accuracy : 47.50%\n",
      "Epoch [659/1200], Loss: 1.7963 , Accuracy : 55.00%\n",
      "Epoch [660/1200], Loss: 0.7895 , Accuracy : 52.50%\n",
      "Epoch [661/1200], Loss: 2.5851 , Accuracy : 47.50%\n",
      "Epoch [662/1200], Loss: 0.7358 , Accuracy : 55.00%\n",
      "Epoch [663/1200], Loss: 1.0415 , Accuracy : 50.00%\n",
      "Epoch [664/1200], Loss: 0.7408 , Accuracy : 40.00%\n",
      "Epoch [665/1200], Loss: 1.7660 , Accuracy : 40.00%\n",
      "Epoch [666/1200], Loss: 2.3769 , Accuracy : 50.00%\n",
      "Epoch [667/1200], Loss: 0.8710 , Accuracy : 45.00%\n",
      "Epoch [668/1200], Loss: 2.2993 , Accuracy : 62.50%\n",
      "Epoch [669/1200], Loss: 0.6462 , Accuracy : 57.50%\n",
      "Epoch [670/1200], Loss: 1.0010 , Accuracy : 50.00%\n",
      "Epoch [671/1200], Loss: 0.7279 , Accuracy : 62.50%\n",
      "Epoch [672/1200], Loss: 1.6969 , Accuracy : 55.00%\n",
      "Epoch [673/1200], Loss: 0.7379 , Accuracy : 60.00%\n",
      "Epoch [674/1200], Loss: 0.3940 , Accuracy : 55.00%\n",
      "Epoch [675/1200], Loss: 2.3979 , Accuracy : 55.00%\n",
      "Epoch [676/1200], Loss: 1.8920 , Accuracy : 47.50%\n",
      "Epoch [677/1200], Loss: 0.9240 , Accuracy : 62.50%\n",
      "Epoch [678/1200], Loss: 1.4636 , Accuracy : 55.00%\n",
      "Epoch [679/1200], Loss: 1.0161 , Accuracy : 67.50%\n",
      "Epoch [680/1200], Loss: 2.7739 , Accuracy : 55.00%\n",
      "Epoch [681/1200], Loss: 0.5875 , Accuracy : 55.00%\n",
      "Epoch [682/1200], Loss: 1.8873 , Accuracy : 55.00%\n",
      "Epoch [683/1200], Loss: 0.4827 , Accuracy : 52.50%\n",
      "Epoch [684/1200], Loss: 0.5171 , Accuracy : 70.00%\n",
      "Epoch [685/1200], Loss: 0.6921 , Accuracy : 70.00%\n",
      "Epoch [686/1200], Loss: 2.0271 , Accuracy : 67.50%\n",
      "Epoch [687/1200], Loss: 2.5031 , Accuracy : 42.50%\n",
      "Epoch [688/1200], Loss: 1.6272 , Accuracy : 55.00%\n",
      "Epoch [689/1200], Loss: 0.9136 , Accuracy : 57.50%\n",
      "Epoch [690/1200], Loss: 2.8164 , Accuracy : 50.00%\n",
      "Epoch [691/1200], Loss: 2.2872 , Accuracy : 55.00%\n",
      "Epoch [692/1200], Loss: 1.8203 , Accuracy : 57.50%\n",
      "Epoch [693/1200], Loss: 1.4394 , Accuracy : 55.00%\n",
      "Epoch [694/1200], Loss: 0.5794 , Accuracy : 40.00%\n",
      "Epoch [695/1200], Loss: 1.9003 , Accuracy : 40.00%\n",
      "Epoch [696/1200], Loss: 2.2147 , Accuracy : 50.00%\n",
      "Epoch [697/1200], Loss: 1.7463 , Accuracy : 50.00%\n",
      "Epoch [698/1200], Loss: 0.5240 , Accuracy : 45.00%\n",
      "Epoch [699/1200], Loss: 2.0834 , Accuracy : 17.50%\n",
      "Epoch [700/1200], Loss: 2.6210 , Accuracy : 30.00%\n",
      "Epoch [701/1200], Loss: 0.8181 , Accuracy : 32.50%\n",
      "Epoch [702/1200], Loss: 0.7850 , Accuracy : 47.50%\n",
      "Epoch [703/1200], Loss: 0.3490 , Accuracy : 60.00%\n",
      "Epoch [704/1200], Loss: 0.7382 , Accuracy : 42.50%\n",
      "Epoch [705/1200], Loss: 0.5262 , Accuracy : 65.00%\n",
      "Epoch [706/1200], Loss: 0.4934 , Accuracy : 60.00%\n",
      "Epoch [707/1200], Loss: 0.6244 , Accuracy : 65.00%\n",
      "Epoch [708/1200], Loss: 0.6362 , Accuracy : 60.00%\n",
      "Epoch [709/1200], Loss: 1.0430 , Accuracy : 50.00%\n",
      "Epoch [710/1200], Loss: 0.4796 , Accuracy : 65.00%\n",
      "Epoch [711/1200], Loss: 0.9590 , Accuracy : 57.50%\n",
      "Epoch [712/1200], Loss: 0.4931 , Accuracy : 65.00%\n",
      "Epoch [713/1200], Loss: 1.3486 , Accuracy : 60.00%\n",
      "Epoch [714/1200], Loss: 0.4615 , Accuracy : 47.50%\n",
      "Epoch [715/1200], Loss: 1.3768 , Accuracy : 70.00%\n",
      "Epoch [716/1200], Loss: 0.6977 , Accuracy : 65.00%\n",
      "Epoch [717/1200], Loss: 0.6024 , Accuracy : 62.50%\n",
      "Epoch [718/1200], Loss: 2.0526 , Accuracy : 50.00%\n",
      "Epoch [719/1200], Loss: 0.5190 , Accuracy : 62.50%\n",
      "Epoch [720/1200], Loss: 0.6563 , Accuracy : 50.00%\n",
      "Epoch [721/1200], Loss: 0.7585 , Accuracy : 55.00%\n",
      "Epoch [722/1200], Loss: 0.4045 , Accuracy : 62.50%\n",
      "Epoch [723/1200], Loss: 0.5783 , Accuracy : 57.50%\n",
      "Epoch [724/1200], Loss: 1.2196 , Accuracy : 55.00%\n",
      "Epoch [725/1200], Loss: 1.2340 , Accuracy : 62.50%\n",
      "Epoch [726/1200], Loss: 1.9033 , Accuracy : 60.00%\n",
      "Epoch [727/1200], Loss: 0.8618 , Accuracy : 52.50%\n",
      "Epoch [728/1200], Loss: 0.6857 , Accuracy : 55.00%\n",
      "Epoch [729/1200], Loss: 1.6800 , Accuracy : 42.50%\n",
      "Epoch [730/1200], Loss: 0.8920 , Accuracy : 57.50%\n",
      "Epoch [731/1200], Loss: 1.5735 , Accuracy : 62.50%\n",
      "Epoch [732/1200], Loss: 0.3631 , Accuracy : 77.50%\n",
      "Epoch [733/1200], Loss: 0.2577 , Accuracy : 62.50%\n",
      "Epoch [734/1200], Loss: 2.3729 , Accuracy : 57.50%\n",
      "Epoch [735/1200], Loss: 0.2318 , Accuracy : 67.50%\n",
      "Epoch [736/1200], Loss: 1.7430 , Accuracy : 55.00%\n",
      "Epoch [737/1200], Loss: 1.5860 , Accuracy : 55.00%\n",
      "Epoch [738/1200], Loss: 0.9347 , Accuracy : 40.00%\n",
      "Epoch [739/1200], Loss: 0.9909 , Accuracy : 35.00%\n",
      "Epoch [740/1200], Loss: 2.3671 , Accuracy : 25.00%\n",
      "Epoch [741/1200], Loss: 2.7481 , Accuracy : 35.00%\n",
      "Epoch [742/1200], Loss: 3.2801 , Accuracy : 37.50%\n",
      "Epoch [743/1200], Loss: 1.7906 , Accuracy : 37.50%\n",
      "Epoch [744/1200], Loss: 1.8926 , Accuracy : 27.50%\n",
      "Epoch [745/1200], Loss: 2.6470 , Accuracy : 32.50%\n",
      "Epoch [746/1200], Loss: 1.4077 , Accuracy : 45.00%\n",
      "Epoch [747/1200], Loss: 2.1797 , Accuracy : 50.00%\n",
      "Epoch [748/1200], Loss: 1.0913 , Accuracy : 37.50%\n",
      "Epoch [749/1200], Loss: 2.4763 , Accuracy : 37.50%\n",
      "Epoch [750/1200], Loss: 1.0087 , Accuracy : 47.50%\n",
      "Epoch [751/1200], Loss: 2.1959 , Accuracy : 45.00%\n",
      "Epoch [752/1200], Loss: 0.7760 , Accuracy : 52.50%\n",
      "Epoch [753/1200], Loss: 0.7165 , Accuracy : 45.00%\n",
      "Epoch [754/1200], Loss: 0.9298 , Accuracy : 52.50%\n",
      "Epoch [755/1200], Loss: 1.6622 , Accuracy : 52.50%\n",
      "Epoch [756/1200], Loss: 1.7748 , Accuracy : 55.00%\n",
      "Epoch [757/1200], Loss: 2.3080 , Accuracy : 47.50%\n",
      "Epoch [758/1200], Loss: 0.5763 , Accuracy : 55.00%\n",
      "Epoch [759/1200], Loss: 0.7707 , Accuracy : 42.50%\n",
      "Epoch [760/1200], Loss: 1.2936 , Accuracy : 62.50%\n",
      "Epoch [761/1200], Loss: 1.9229 , Accuracy : 45.00%\n",
      "Epoch [762/1200], Loss: 0.8979 , Accuracy : 45.00%\n",
      "Epoch [763/1200], Loss: 2.0382 , Accuracy : 57.50%\n",
      "Epoch [764/1200], Loss: 1.1162 , Accuracy : 47.50%\n",
      "Epoch [765/1200], Loss: 0.3032 , Accuracy : 52.50%\n",
      "Epoch [766/1200], Loss: 1.0065 , Accuracy : 52.50%\n",
      "Epoch [767/1200], Loss: 2.3562 , Accuracy : 52.50%\n",
      "Epoch [768/1200], Loss: 0.7944 , Accuracy : 50.00%\n",
      "Epoch [769/1200], Loss: 0.6034 , Accuracy : 60.00%\n",
      "Epoch [770/1200], Loss: 2.1050 , Accuracy : 62.50%\n",
      "Epoch [771/1200], Loss: 0.4666 , Accuracy : 70.00%\n",
      "Epoch [772/1200], Loss: 2.1302 , Accuracy : 57.50%\n",
      "Epoch [773/1200], Loss: 0.8729 , Accuracy : 57.50%\n",
      "Epoch [774/1200], Loss: 1.7162 , Accuracy : 65.00%\n",
      "Epoch [775/1200], Loss: 2.5788 , Accuracy : 52.50%\n",
      "Epoch [776/1200], Loss: 2.9759 , Accuracy : 52.50%\n",
      "Epoch [777/1200], Loss: 0.6659 , Accuracy : 57.50%\n",
      "Epoch [778/1200], Loss: 1.3780 , Accuracy : 57.50%\n",
      "Epoch [779/1200], Loss: 0.5303 , Accuracy : 57.50%\n",
      "Epoch [780/1200], Loss: 0.7524 , Accuracy : 37.50%\n",
      "Epoch [781/1200], Loss: 2.0576 , Accuracy : 65.00%\n",
      "Epoch [782/1200], Loss: 1.9816 , Accuracy : 40.00%\n",
      "Epoch [783/1200], Loss: 1.6453 , Accuracy : 45.00%\n",
      "Epoch [784/1200], Loss: 1.0141 , Accuracy : 45.00%\n",
      "Epoch [785/1200], Loss: 0.9483 , Accuracy : 40.00%\n",
      "Epoch [786/1200], Loss: 1.9383 , Accuracy : 35.00%\n",
      "Epoch [787/1200], Loss: 2.5818 , Accuracy : 32.50%\n",
      "Epoch [788/1200], Loss: 2.2891 , Accuracy : 42.50%\n",
      "Epoch [789/1200], Loss: 1.6064 , Accuracy : 37.50%\n",
      "Epoch [790/1200], Loss: 0.5762 , Accuracy : 50.00%\n",
      "Epoch [791/1200], Loss: 0.7875 , Accuracy : 55.00%\n",
      "Epoch [792/1200], Loss: 0.7134 , Accuracy : 52.50%\n",
      "Epoch [793/1200], Loss: 2.5780 , Accuracy : 55.00%\n",
      "Epoch [794/1200], Loss: 1.0519 , Accuracy : 60.00%\n",
      "Epoch [795/1200], Loss: 0.8640 , Accuracy : 60.00%\n",
      "Epoch [796/1200], Loss: 0.7438 , Accuracy : 65.00%\n",
      "Epoch [797/1200], Loss: 0.7278 , Accuracy : 67.50%\n",
      "Epoch [798/1200], Loss: 0.6858 , Accuracy : 57.50%\n",
      "Epoch [799/1200], Loss: 0.5782 , Accuracy : 50.00%\n",
      "Epoch [800/1200], Loss: 0.7720 , Accuracy : 60.00%\n",
      "Epoch [801/1200], Loss: 0.7339 , Accuracy : 50.00%\n",
      "Epoch [802/1200], Loss: 0.6188 , Accuracy : 67.50%\n",
      "Epoch [803/1200], Loss: 0.8566 , Accuracy : 55.00%\n",
      "Epoch [804/1200], Loss: 1.3292 , Accuracy : 62.50%\n",
      "Epoch [805/1200], Loss: 1.9768 , Accuracy : 50.00%\n",
      "Epoch [806/1200], Loss: 1.6401 , Accuracy : 55.00%\n",
      "Epoch [807/1200], Loss: 1.8663 , Accuracy : 57.50%\n",
      "Epoch [808/1200], Loss: 0.8400 , Accuracy : 70.00%\n",
      "Epoch [809/1200], Loss: 0.3748 , Accuracy : 65.00%\n",
      "Epoch [810/1200], Loss: 0.9899 , Accuracy : 42.50%\n",
      "Epoch [811/1200], Loss: 2.4937 , Accuracy : 22.50%\n",
      "Epoch [812/1200], Loss: 1.9803 , Accuracy : 37.50%\n",
      "Epoch [813/1200], Loss: 1.4565 , Accuracy : 45.00%\n",
      "Epoch [814/1200], Loss: 1.7712 , Accuracy : 62.50%\n",
      "Epoch [815/1200], Loss: 0.7339 , Accuracy : 62.50%\n",
      "Epoch [816/1200], Loss: 0.6737 , Accuracy : 65.00%\n",
      "Epoch [817/1200], Loss: 2.4465 , Accuracy : 55.00%\n",
      "Epoch [818/1200], Loss: 1.4224 , Accuracy : 62.50%\n",
      "Epoch [819/1200], Loss: 0.6331 , Accuracy : 55.00%\n",
      "Epoch [820/1200], Loss: 2.1140 , Accuracy : 50.00%\n",
      "Epoch [821/1200], Loss: 1.8698 , Accuracy : 47.50%\n",
      "Epoch [822/1200], Loss: 0.7849 , Accuracy : 52.50%\n",
      "Epoch [823/1200], Loss: 0.5157 , Accuracy : 72.50%\n",
      "Epoch [824/1200], Loss: 1.5028 , Accuracy : 77.50%\n",
      "Epoch [825/1200], Loss: 2.6195 , Accuracy : 62.50%\n",
      "Epoch [826/1200], Loss: 0.2986 , Accuracy : 57.50%\n",
      "Epoch [827/1200], Loss: 1.7371 , Accuracy : 55.00%\n",
      "Epoch [828/1200], Loss: 2.0679 , Accuracy : 52.50%\n",
      "Epoch [829/1200], Loss: 0.3583 , Accuracy : 67.50%\n",
      "Epoch [830/1200], Loss: 0.4914 , Accuracy : 50.00%\n",
      "Epoch [831/1200], Loss: 2.2282 , Accuracy : 52.50%\n",
      "Epoch [832/1200], Loss: 0.4883 , Accuracy : 70.00%\n",
      "Epoch [833/1200], Loss: 0.6085 , Accuracy : 62.50%\n",
      "Epoch [834/1200], Loss: 1.1988 , Accuracy : 62.50%\n",
      "Epoch [835/1200], Loss: 0.4252 , Accuracy : 62.50%\n",
      "Epoch [836/1200], Loss: 0.3083 , Accuracy : 60.00%\n",
      "Epoch [837/1200], Loss: 1.3364 , Accuracy : 67.50%\n",
      "Epoch [838/1200], Loss: 0.5967 , Accuracy : 57.50%\n",
      "Epoch [839/1200], Loss: 0.3864 , Accuracy : 70.00%\n",
      "Epoch [840/1200], Loss: 0.8338 , Accuracy : 65.00%\n",
      "Epoch [841/1200], Loss: 0.3261 , Accuracy : 60.00%\n",
      "Epoch [842/1200], Loss: 0.4130 , Accuracy : 67.50%\n",
      "Epoch [843/1200], Loss: 1.8721 , Accuracy : 57.50%\n",
      "Epoch [844/1200], Loss: 1.1275 , Accuracy : 55.00%\n",
      "Epoch [845/1200], Loss: 1.5093 , Accuracy : 47.50%\n",
      "Epoch [846/1200], Loss: 1.4447 , Accuracy : 60.00%\n",
      "Epoch [847/1200], Loss: 1.3201 , Accuracy : 77.50%\n",
      "Epoch [848/1200], Loss: 0.5767 , Accuracy : 67.50%\n",
      "Epoch [849/1200], Loss: 0.6112 , Accuracy : 55.00%\n",
      "Epoch [850/1200], Loss: 0.5066 , Accuracy : 62.50%\n",
      "Epoch [851/1200], Loss: 1.4734 , Accuracy : 47.50%\n",
      "Epoch [852/1200], Loss: 0.9469 , Accuracy : 50.00%\n",
      "Epoch [853/1200], Loss: 0.8352 , Accuracy : 42.50%\n",
      "Epoch [854/1200], Loss: 1.6871 , Accuracy : 55.00%\n",
      "Epoch [855/1200], Loss: 0.6222 , Accuracy : 52.50%\n",
      "Epoch [856/1200], Loss: 1.1628 , Accuracy : 45.00%\n",
      "Epoch [857/1200], Loss: 0.8523 , Accuracy : 60.00%\n",
      "Epoch [858/1200], Loss: 3.0159 , Accuracy : 37.50%\n",
      "Epoch [859/1200], Loss: 1.9489 , Accuracy : 60.00%\n",
      "Epoch [860/1200], Loss: 1.0942 , Accuracy : 57.50%\n",
      "Epoch [861/1200], Loss: 0.5049 , Accuracy : 47.50%\n",
      "Epoch [862/1200], Loss: 1.6834 , Accuracy : 60.00%\n",
      "Epoch [863/1200], Loss: 2.0581 , Accuracy : 60.00%\n",
      "Epoch [864/1200], Loss: 0.5240 , Accuracy : 52.50%\n",
      "Epoch [865/1200], Loss: 2.6355 , Accuracy : 62.50%\n",
      "Epoch [866/1200], Loss: 1.8526 , Accuracy : 77.50%\n",
      "Epoch [867/1200], Loss: 2.3218 , Accuracy : 47.50%\n",
      "Epoch [868/1200], Loss: 1.6255 , Accuracy : 57.50%\n",
      "Epoch [869/1200], Loss: 0.4884 , Accuracy : 62.50%\n",
      "Epoch [870/1200], Loss: 2.3112 , Accuracy : 65.00%\n",
      "Epoch [871/1200], Loss: 0.8311 , Accuracy : 60.00%\n",
      "Epoch [872/1200], Loss: 1.1856 , Accuracy : 62.50%\n",
      "Epoch [873/1200], Loss: 0.4623 , Accuracy : 75.00%\n",
      "Epoch [874/1200], Loss: 0.4861 , Accuracy : 67.50%\n",
      "Epoch [875/1200], Loss: 0.4372 , Accuracy : 50.00%\n",
      "Epoch [876/1200], Loss: 1.5843 , Accuracy : 62.50%\n",
      "Epoch [877/1200], Loss: 1.9149 , Accuracy : 52.50%\n",
      "Epoch [878/1200], Loss: 1.2984 , Accuracy : 67.50%\n",
      "Epoch [879/1200], Loss: 0.7506 , Accuracy : 65.00%\n",
      "Epoch [880/1200], Loss: 0.5839 , Accuracy : 60.00%\n",
      "Epoch [881/1200], Loss: 1.5770 , Accuracy : 60.00%\n",
      "Epoch [882/1200], Loss: 0.6527 , Accuracy : 65.00%\n",
      "Epoch [883/1200], Loss: 1.3246 , Accuracy : 50.00%\n",
      "Epoch [884/1200], Loss: 1.0572 , Accuracy : 55.00%\n",
      "Epoch [885/1200], Loss: 0.6230 , Accuracy : 60.00%\n",
      "Epoch [886/1200], Loss: 1.5952 , Accuracy : 47.50%\n",
      "Epoch [887/1200], Loss: 1.9887 , Accuracy : 55.00%\n",
      "Epoch [888/1200], Loss: 0.4781 , Accuracy : 55.00%\n",
      "Epoch [889/1200], Loss: 2.0603 , Accuracy : 40.00%\n",
      "Epoch [890/1200], Loss: 0.3370 , Accuracy : 62.50%\n",
      "Epoch [891/1200], Loss: 2.3959 , Accuracy : 60.00%\n",
      "Epoch [892/1200], Loss: 1.9038 , Accuracy : 70.00%\n",
      "Epoch [893/1200], Loss: 1.3287 , Accuracy : 45.00%\n",
      "Epoch [894/1200], Loss: 0.8412 , Accuracy : 65.00%\n",
      "Epoch [895/1200], Loss: 1.7764 , Accuracy : 47.50%\n",
      "Epoch [896/1200], Loss: 1.2708 , Accuracy : 62.50%\n",
      "Epoch [897/1200], Loss: 0.5799 , Accuracy : 70.00%\n",
      "Epoch [898/1200], Loss: 0.3543 , Accuracy : 65.00%\n",
      "Epoch [899/1200], Loss: 0.8204 , Accuracy : 55.00%\n",
      "Epoch [900/1200], Loss: 1.4526 , Accuracy : 60.00%\n",
      "Epoch [901/1200], Loss: 0.2554 , Accuracy : 65.00%\n",
      "Epoch [902/1200], Loss: 0.2145 , Accuracy : 65.00%\n",
      "Epoch [903/1200], Loss: 0.2673 , Accuracy : 67.50%\n",
      "Epoch [904/1200], Loss: 0.4931 , Accuracy : 72.50%\n",
      "Epoch [905/1200], Loss: 2.9481 , Accuracy : 70.00%\n",
      "Epoch [906/1200], Loss: 0.7834 , Accuracy : 65.00%\n",
      "Epoch [907/1200], Loss: 0.5261 , Accuracy : 62.50%\n",
      "Epoch [908/1200], Loss: 1.1690 , Accuracy : 57.50%\n",
      "Epoch [909/1200], Loss: 0.2497 , Accuracy : 57.50%\n",
      "Epoch [910/1200], Loss: 1.3063 , Accuracy : 55.00%\n",
      "Epoch [911/1200], Loss: 0.5379 , Accuracy : 70.00%\n",
      "Epoch [912/1200], Loss: 1.2330 , Accuracy : 70.00%\n",
      "Epoch [913/1200], Loss: 0.4186 , Accuracy : 62.50%\n",
      "Epoch [914/1200], Loss: 1.1394 , Accuracy : 70.00%\n",
      "Epoch [915/1200], Loss: 1.2409 , Accuracy : 70.00%\n",
      "Epoch [916/1200], Loss: 1.7636 , Accuracy : 40.00%\n",
      "Epoch [917/1200], Loss: 2.4779 , Accuracy : 55.00%\n",
      "Epoch [918/1200], Loss: 0.2621 , Accuracy : 55.00%\n",
      "Epoch [919/1200], Loss: 0.8625 , Accuracy : 55.00%\n",
      "Epoch [920/1200], Loss: 1.3440 , Accuracy : 72.50%\n",
      "Epoch [921/1200], Loss: 0.3287 , Accuracy : 55.00%\n",
      "Epoch [922/1200], Loss: 0.9652 , Accuracy : 60.00%\n",
      "Epoch [923/1200], Loss: 1.8724 , Accuracy : 60.00%\n",
      "Epoch [924/1200], Loss: 1.4181 , Accuracy : 67.50%\n",
      "Epoch [925/1200], Loss: 0.4516 , Accuracy : 62.50%\n",
      "Epoch [926/1200], Loss: 0.7158 , Accuracy : 55.00%\n",
      "Epoch [927/1200], Loss: 0.1043 , Accuracy : 67.50%\n",
      "Epoch [928/1200], Loss: 0.0524 , Accuracy : 65.00%\n",
      "Epoch [929/1200], Loss: 1.1532 , Accuracy : 60.00%\n",
      "Epoch [930/1200], Loss: 1.8708 , Accuracy : 75.00%\n",
      "Epoch [931/1200], Loss: 1.0507 , Accuracy : 62.50%\n",
      "Epoch [932/1200], Loss: 1.7758 , Accuracy : 62.50%\n",
      "Epoch [933/1200], Loss: 0.4756 , Accuracy : 77.50%\n",
      "Epoch [934/1200], Loss: 1.2104 , Accuracy : 60.00%\n",
      "Epoch [935/1200], Loss: 0.2276 , Accuracy : 62.50%\n",
      "Epoch [936/1200], Loss: 0.3257 , Accuracy : 65.00%\n",
      "Epoch [937/1200], Loss: 0.3768 , Accuracy : 65.00%\n",
      "Epoch [938/1200], Loss: 1.1849 , Accuracy : 60.00%\n",
      "Epoch [939/1200], Loss: 2.1665 , Accuracy : 65.00%\n",
      "Epoch [940/1200], Loss: 2.0238 , Accuracy : 77.50%\n",
      "Epoch [941/1200], Loss: 0.5113 , Accuracy : 65.00%\n",
      "Epoch [942/1200], Loss: 0.6779 , Accuracy : 72.50%\n",
      "Epoch [943/1200], Loss: 1.5304 , Accuracy : 70.00%\n",
      "Epoch [944/1200], Loss: 0.3900 , Accuracy : 60.00%\n",
      "Epoch [945/1200], Loss: 1.2986 , Accuracy : 72.50%\n",
      "Epoch [946/1200], Loss: 0.1310 , Accuracy : 70.00%\n",
      "Epoch [947/1200], Loss: 1.5957 , Accuracy : 65.00%\n",
      "Epoch [948/1200], Loss: 1.3463 , Accuracy : 72.50%\n",
      "Epoch [949/1200], Loss: 0.0836 , Accuracy : 67.50%\n",
      "Epoch [950/1200], Loss: 1.0597 , Accuracy : 62.50%\n",
      "Epoch [951/1200], Loss: 0.6860 , Accuracy : 77.50%\n",
      "Epoch [952/1200], Loss: 0.7527 , Accuracy : 75.00%\n",
      "Epoch [953/1200], Loss: 1.1525 , Accuracy : 70.00%\n",
      "Epoch [954/1200], Loss: 0.4042 , Accuracy : 75.00%\n",
      "Epoch [955/1200], Loss: 0.5540 , Accuracy : 62.50%\n",
      "Epoch [956/1200], Loss: 0.5103 , Accuracy : 70.00%\n",
      "Epoch [957/1200], Loss: 0.3543 , Accuracy : 65.00%\n",
      "Epoch [958/1200], Loss: 2.0216 , Accuracy : 60.00%\n",
      "Epoch [959/1200], Loss: 1.7469 , Accuracy : 62.50%\n",
      "Epoch [960/1200], Loss: 0.9589 , Accuracy : 82.50%\n",
      "Epoch [961/1200], Loss: 1.0580 , Accuracy : 65.00%\n",
      "Epoch [962/1200], Loss: 0.3357 , Accuracy : 67.50%\n",
      "Epoch [963/1200], Loss: 0.7763 , Accuracy : 70.00%\n",
      "Epoch [964/1200], Loss: 1.0185 , Accuracy : 60.00%\n",
      "Epoch [965/1200], Loss: 0.3855 , Accuracy : 65.00%\n",
      "Epoch [966/1200], Loss: 0.5923 , Accuracy : 65.00%\n",
      "Epoch [967/1200], Loss: 0.1584 , Accuracy : 67.50%\n",
      "Epoch [968/1200], Loss: 0.3798 , Accuracy : 75.00%\n",
      "Epoch [969/1200], Loss: 2.1261 , Accuracy : 55.00%\n",
      "Epoch [970/1200], Loss: 0.9500 , Accuracy : 67.50%\n",
      "Epoch [971/1200], Loss: 1.5226 , Accuracy : 70.00%\n",
      "Epoch [972/1200], Loss: 0.1258 , Accuracy : 60.00%\n",
      "Epoch [973/1200], Loss: 0.9178 , Accuracy : 67.50%\n",
      "Epoch [974/1200], Loss: 1.5591 , Accuracy : 57.50%\n",
      "Epoch [975/1200], Loss: 1.3755 , Accuracy : 67.50%\n",
      "Epoch [976/1200], Loss: 0.4225 , Accuracy : 70.00%\n",
      "Epoch [977/1200], Loss: 0.6339 , Accuracy : 67.50%\n",
      "Epoch [978/1200], Loss: 0.6642 , Accuracy : 70.00%\n",
      "Epoch [979/1200], Loss: 1.9020 , Accuracy : 62.50%\n",
      "Epoch [980/1200], Loss: 0.4379 , Accuracy : 67.50%\n",
      "Epoch [981/1200], Loss: 0.1235 , Accuracy : 60.00%\n",
      "Epoch [982/1200], Loss: 0.3117 , Accuracy : 67.50%\n",
      "Epoch [983/1200], Loss: 1.0972 , Accuracy : 75.00%\n",
      "Epoch [984/1200], Loss: 0.3221 , Accuracy : 65.00%\n",
      "Epoch [985/1200], Loss: 0.1682 , Accuracy : 65.00%\n",
      "Epoch [986/1200], Loss: 1.7773 , Accuracy : 67.50%\n",
      "Epoch [987/1200], Loss: 0.1234 , Accuracy : 77.50%\n",
      "Epoch [988/1200], Loss: 0.1227 , Accuracy : 72.50%\n",
      "Epoch [989/1200], Loss: 0.5582 , Accuracy : 62.50%\n",
      "Epoch [990/1200], Loss: 1.2194 , Accuracy : 67.50%\n",
      "Epoch [991/1200], Loss: 1.9189 , Accuracy : 77.50%\n",
      "Epoch [992/1200], Loss: 0.6096 , Accuracy : 72.50%\n",
      "Epoch [993/1200], Loss: 1.4410 , Accuracy : 57.50%\n",
      "Epoch [994/1200], Loss: 1.1356 , Accuracy : 67.50%\n",
      "Epoch [995/1200], Loss: 0.6234 , Accuracy : 70.00%\n",
      "Epoch [996/1200], Loss: 1.1842 , Accuracy : 60.00%\n",
      "Epoch [997/1200], Loss: 1.1863 , Accuracy : 60.00%\n",
      "Epoch [998/1200], Loss: 0.1921 , Accuracy : 70.00%\n",
      "Epoch [999/1200], Loss: 0.6791 , Accuracy : 60.00%\n",
      "Epoch [1000/1200], Loss: 0.9765 , Accuracy : 72.50%\n",
      "Epoch [1001/1200], Loss: 0.3877 , Accuracy : 65.00%\n",
      "Epoch [1002/1200], Loss: 1.2310 , Accuracy : 65.00%\n",
      "Epoch [1003/1200], Loss: 1.2073 , Accuracy : 60.00%\n",
      "Epoch [1004/1200], Loss: 0.8418 , Accuracy : 67.50%\n",
      "Epoch [1005/1200], Loss: 2.1480 , Accuracy : 60.00%\n",
      "Epoch [1006/1200], Loss: 0.5307 , Accuracy : 62.50%\n",
      "Epoch [1007/1200], Loss: 1.3733 , Accuracy : 70.00%\n",
      "Epoch [1008/1200], Loss: 1.7088 , Accuracy : 72.50%\n",
      "Epoch [1009/1200], Loss: 0.3150 , Accuracy : 62.50%\n",
      "Epoch [1010/1200], Loss: 0.9670 , Accuracy : 77.50%\n",
      "Epoch [1011/1200], Loss: 1.5488 , Accuracy : 77.50%\n",
      "Epoch [1012/1200], Loss: 2.0136 , Accuracy : 52.50%\n",
      "Epoch [1013/1200], Loss: 0.5344 , Accuracy : 62.50%\n",
      "Epoch [1014/1200], Loss: 0.8153 , Accuracy : 70.00%\n",
      "Epoch [1015/1200], Loss: 1.5723 , Accuracy : 62.50%\n",
      "Epoch [1016/1200], Loss: 0.4499 , Accuracy : 50.00%\n",
      "Epoch [1017/1200], Loss: 1.0802 , Accuracy : 60.00%\n",
      "Epoch [1018/1200], Loss: 0.9628 , Accuracy : 60.00%\n",
      "Epoch [1019/1200], Loss: 1.1537 , Accuracy : 65.00%\n",
      "Epoch [1020/1200], Loss: 0.1258 , Accuracy : 72.50%\n",
      "Epoch [1021/1200], Loss: 0.3515 , Accuracy : 60.00%\n",
      "Epoch [1022/1200], Loss: 0.3505 , Accuracy : 67.50%\n",
      "Epoch [1023/1200], Loss: 2.7371 , Accuracy : 72.50%\n",
      "Epoch [1024/1200], Loss: 2.0667 , Accuracy : 65.00%\n",
      "Epoch [1025/1200], Loss: 0.5000 , Accuracy : 62.50%\n",
      "Epoch [1026/1200], Loss: 2.2191 , Accuracy : 65.00%\n",
      "Epoch [1027/1200], Loss: 0.2589 , Accuracy : 67.50%\n",
      "Epoch [1028/1200], Loss: 1.8105 , Accuracy : 70.00%\n",
      "Epoch [1029/1200], Loss: 0.9924 , Accuracy : 67.50%\n",
      "Epoch [1030/1200], Loss: 2.1114 , Accuracy : 70.00%\n",
      "Epoch [1031/1200], Loss: 0.1242 , Accuracy : 60.00%\n",
      "Epoch [1032/1200], Loss: 0.7047 , Accuracy : 57.50%\n",
      "Epoch [1033/1200], Loss: 1.0250 , Accuracy : 62.50%\n",
      "Epoch [1034/1200], Loss: 1.1443 , Accuracy : 65.00%\n",
      "Epoch [1035/1200], Loss: 0.2569 , Accuracy : 57.50%\n",
      "Epoch [1036/1200], Loss: 2.4043 , Accuracy : 60.00%\n",
      "Epoch [1037/1200], Loss: 0.2103 , Accuracy : 65.00%\n",
      "Epoch [1038/1200], Loss: 0.8470 , Accuracy : 65.00%\n",
      "Epoch [1039/1200], Loss: 0.5681 , Accuracy : 67.50%\n",
      "Epoch [1040/1200], Loss: 1.7986 , Accuracy : 65.00%\n",
      "Epoch [1041/1200], Loss: 0.4382 , Accuracy : 60.00%\n",
      "Epoch [1042/1200], Loss: 1.6099 , Accuracy : 67.50%\n",
      "Epoch [1043/1200], Loss: 0.8947 , Accuracy : 60.00%\n",
      "Epoch [1044/1200], Loss: 1.9531 , Accuracy : 62.50%\n",
      "Epoch [1045/1200], Loss: 0.4779 , Accuracy : 70.00%\n",
      "Epoch [1046/1200], Loss: 1.5425 , Accuracy : 72.50%\n",
      "Epoch [1047/1200], Loss: 0.7334 , Accuracy : 80.00%\n",
      "Epoch [1048/1200], Loss: 0.1015 , Accuracy : 70.00%\n",
      "Epoch [1049/1200], Loss: 0.9148 , Accuracy : 62.50%\n",
      "Epoch [1050/1200], Loss: 0.0382 , Accuracy : 60.00%\n",
      "Epoch [1051/1200], Loss: 0.1388 , Accuracy : 65.00%\n",
      "Epoch [1052/1200], Loss: 1.0154 , Accuracy : 57.50%\n",
      "Epoch [1053/1200], Loss: 1.4252 , Accuracy : 62.50%\n",
      "Epoch [1054/1200], Loss: 0.2340 , Accuracy : 77.50%\n",
      "Epoch [1055/1200], Loss: 0.2309 , Accuracy : 62.50%\n",
      "Epoch [1056/1200], Loss: 0.3455 , Accuracy : 75.00%\n",
      "Epoch [1057/1200], Loss: 1.8734 , Accuracy : 57.50%\n",
      "Epoch [1058/1200], Loss: 0.6226 , Accuracy : 55.00%\n",
      "Epoch [1059/1200], Loss: 1.5305 , Accuracy : 72.50%\n",
      "Epoch [1060/1200], Loss: 1.2235 , Accuracy : 55.00%\n",
      "Epoch [1061/1200], Loss: 0.8787 , Accuracy : 60.00%\n",
      "Epoch [1062/1200], Loss: 1.4272 , Accuracy : 75.00%\n",
      "Epoch [1063/1200], Loss: 0.9967 , Accuracy : 65.00%\n",
      "Epoch [1064/1200], Loss: 1.4897 , Accuracy : 67.50%\n",
      "Epoch [1065/1200], Loss: 0.4377 , Accuracy : 80.00%\n",
      "Epoch [1066/1200], Loss: 0.0701 , Accuracy : 72.50%\n",
      "Epoch [1067/1200], Loss: 0.2693 , Accuracy : 67.50%\n",
      "Epoch [1068/1200], Loss: 0.2291 , Accuracy : 85.00%\n",
      "Epoch [1069/1200], Loss: 0.4877 , Accuracy : 80.00%\n",
      "Epoch [1070/1200], Loss: 1.0123 , Accuracy : 65.00%\n",
      "Epoch [1071/1200], Loss: 2.0538 , Accuracy : 60.00%\n",
      "Epoch [1072/1200], Loss: 0.5705 , Accuracy : 55.00%\n",
      "Epoch [1073/1200], Loss: 0.5597 , Accuracy : 42.50%\n",
      "Epoch [1074/1200], Loss: 1.2397 , Accuracy : 50.00%\n",
      "Epoch [1075/1200], Loss: 3.8592 , Accuracy : 57.50%\n",
      "Epoch [1076/1200], Loss: 0.6024 , Accuracy : 75.00%\n",
      "Epoch [1077/1200], Loss: 0.1271 , Accuracy : 60.00%\n",
      "Epoch [1078/1200], Loss: 0.6447 , Accuracy : 77.50%\n",
      "Epoch [1079/1200], Loss: 1.7516 , Accuracy : 70.00%\n",
      "Epoch [1080/1200], Loss: 2.0778 , Accuracy : 62.50%\n",
      "Epoch [1081/1200], Loss: 1.3035 , Accuracy : 70.00%\n",
      "Epoch [1082/1200], Loss: 0.3341 , Accuracy : 65.00%\n",
      "Epoch [1083/1200], Loss: 1.1919 , Accuracy : 62.50%\n",
      "Epoch [1084/1200], Loss: 0.2752 , Accuracy : 60.00%\n",
      "Epoch [1085/1200], Loss: 1.5507 , Accuracy : 65.00%\n",
      "Epoch [1086/1200], Loss: 0.2861 , Accuracy : 52.50%\n",
      "Epoch [1087/1200], Loss: 0.9212 , Accuracy : 55.00%\n",
      "Epoch [1088/1200], Loss: 0.9547 , Accuracy : 65.00%\n",
      "Epoch [1089/1200], Loss: 1.2813 , Accuracy : 70.00%\n",
      "Epoch [1090/1200], Loss: 1.1594 , Accuracy : 80.00%\n",
      "Epoch [1091/1200], Loss: 1.1946 , Accuracy : 65.00%\n",
      "Epoch [1092/1200], Loss: 1.4236 , Accuracy : 65.00%\n",
      "Epoch [1093/1200], Loss: 0.4703 , Accuracy : 62.50%\n",
      "Epoch [1094/1200], Loss: 1.5189 , Accuracy : 70.00%\n",
      "Epoch [1095/1200], Loss: 1.4979 , Accuracy : 67.50%\n",
      "Epoch [1096/1200], Loss: 0.6866 , Accuracy : 82.50%\n",
      "Epoch [1097/1200], Loss: 0.7868 , Accuracy : 82.50%\n",
      "Epoch [1098/1200], Loss: 2.2842 , Accuracy : 72.50%\n",
      "Epoch [1099/1200], Loss: 1.4183 , Accuracy : 70.00%\n",
      "Epoch [1100/1200], Loss: 0.3790 , Accuracy : 70.00%\n",
      "Epoch [1101/1200], Loss: 0.4451 , Accuracy : 87.50%\n",
      "Epoch [1102/1200], Loss: 1.0613 , Accuracy : 75.00%\n",
      "Epoch [1103/1200], Loss: 0.2418 , Accuracy : 80.00%\n",
      "Epoch [1104/1200], Loss: 0.1165 , Accuracy : 77.50%\n",
      "Epoch [1105/1200], Loss: 1.1536 , Accuracy : 67.50%\n",
      "Epoch [1106/1200], Loss: 1.2648 , Accuracy : 77.50%\n",
      "Epoch [1107/1200], Loss: 0.6052 , Accuracy : 62.50%\n",
      "Epoch [1108/1200], Loss: 0.2513 , Accuracy : 75.00%\n",
      "Epoch [1109/1200], Loss: 0.2566 , Accuracy : 77.50%\n",
      "Epoch [1110/1200], Loss: 0.5397 , Accuracy : 82.50%\n",
      "Epoch [1111/1200], Loss: 0.3970 , Accuracy : 87.50%\n",
      "Epoch [1112/1200], Loss: 0.1135 , Accuracy : 85.00%\n",
      "Epoch [1113/1200], Loss: 0.2201 , Accuracy : 70.00%\n",
      "Epoch [1114/1200], Loss: 0.5188 , Accuracy : 82.50%\n",
      "Epoch [1115/1200], Loss: 0.8138 , Accuracy : 72.50%\n",
      "Epoch [1116/1200], Loss: 0.9144 , Accuracy : 45.00%\n",
      "Epoch [1117/1200], Loss: 1.3885 , Accuracy : 50.00%\n",
      "Epoch [1118/1200], Loss: 2.6971 , Accuracy : 32.50%\n",
      "Epoch [1119/1200], Loss: 0.7237 , Accuracy : 52.50%\n",
      "Epoch [1120/1200], Loss: 2.3876 , Accuracy : 47.50%\n",
      "Epoch [1121/1200], Loss: 0.4968 , Accuracy : 47.50%\n",
      "Epoch [1122/1200], Loss: 3.1895 , Accuracy : 47.50%\n",
      "Epoch [1123/1200], Loss: 0.5756 , Accuracy : 60.00%\n",
      "Epoch [1124/1200], Loss: 1.0121 , Accuracy : 70.00%\n",
      "Epoch [1125/1200], Loss: 0.2275 , Accuracy : 60.00%\n",
      "Epoch [1126/1200], Loss: 0.9333 , Accuracy : 60.00%\n",
      "Epoch [1127/1200], Loss: 1.4088 , Accuracy : 67.50%\n",
      "Epoch [1128/1200], Loss: 1.1003 , Accuracy : 72.50%\n",
      "Epoch [1129/1200], Loss: 0.4190 , Accuracy : 60.00%\n",
      "Epoch [1130/1200], Loss: 0.2557 , Accuracy : 57.50%\n",
      "Epoch [1131/1200], Loss: 0.0850 , Accuracy : 60.00%\n",
      "Epoch [1132/1200], Loss: 1.7143 , Accuracy : 60.00%\n",
      "Epoch [1133/1200], Loss: 0.3879 , Accuracy : 67.50%\n",
      "Epoch [1134/1200], Loss: 0.2542 , Accuracy : 75.00%\n",
      "Epoch [1135/1200], Loss: 0.2960 , Accuracy : 80.00%\n",
      "Epoch [1136/1200], Loss: 1.6634 , Accuracy : 72.50%\n",
      "Epoch [1137/1200], Loss: 1.2319 , Accuracy : 62.50%\n",
      "Epoch [1138/1200], Loss: 0.1664 , Accuracy : 75.00%\n",
      "Epoch [1139/1200], Loss: 0.3864 , Accuracy : 62.50%\n",
      "Epoch [1140/1200], Loss: 0.8929 , Accuracy : 65.00%\n",
      "Epoch [1141/1200], Loss: 0.2344 , Accuracy : 65.00%\n",
      "Epoch [1142/1200], Loss: 0.0644 , Accuracy : 67.50%\n",
      "Epoch [1143/1200], Loss: 1.8633 , Accuracy : 62.50%\n",
      "Epoch [1144/1200], Loss: 0.2744 , Accuracy : 75.00%\n",
      "Epoch [1145/1200], Loss: 0.1451 , Accuracy : 80.00%\n",
      "Epoch [1146/1200], Loss: 1.2160 , Accuracy : 67.50%\n",
      "Epoch [1147/1200], Loss: 0.9245 , Accuracy : 70.00%\n",
      "Epoch [1148/1200], Loss: 0.4737 , Accuracy : 80.00%\n",
      "Epoch [1149/1200], Loss: 1.5412 , Accuracy : 65.00%\n",
      "Epoch [1150/1200], Loss: 2.3993 , Accuracy : 67.50%\n",
      "Epoch [1151/1200], Loss: 1.3148 , Accuracy : 75.00%\n",
      "Epoch [1152/1200], Loss: 2.8072 , Accuracy : 67.50%\n",
      "Epoch [1153/1200], Loss: 1.3846 , Accuracy : 72.50%\n",
      "Epoch [1154/1200], Loss: 0.7803 , Accuracy : 65.00%\n",
      "Epoch [1155/1200], Loss: 0.5882 , Accuracy : 72.50%\n",
      "Epoch [1156/1200], Loss: 0.3581 , Accuracy : 77.50%\n",
      "Epoch [1157/1200], Loss: 1.7784 , Accuracy : 70.00%\n",
      "Epoch [1158/1200], Loss: 1.4218 , Accuracy : 72.50%\n",
      "Epoch [1159/1200], Loss: 1.4961 , Accuracy : 72.50%\n",
      "Epoch [1160/1200], Loss: 1.0444 , Accuracy : 72.50%\n",
      "Epoch [1161/1200], Loss: 0.4975 , Accuracy : 65.00%\n",
      "Epoch [1162/1200], Loss: 0.3304 , Accuracy : 75.00%\n",
      "Epoch [1163/1200], Loss: 0.5334 , Accuracy : 70.00%\n",
      "Epoch [1164/1200], Loss: 1.7240 , Accuracy : 62.50%\n",
      "Epoch [1165/1200], Loss: 0.1387 , Accuracy : 75.00%\n",
      "Epoch [1166/1200], Loss: 0.5502 , Accuracy : 75.00%\n",
      "Epoch [1167/1200], Loss: 0.2054 , Accuracy : 82.50%\n",
      "Epoch [1168/1200], Loss: 1.1578 , Accuracy : 67.50%\n",
      "Epoch [1169/1200], Loss: 0.4862 , Accuracy : 72.50%\n",
      "Epoch [1170/1200], Loss: 1.4851 , Accuracy : 75.00%\n",
      "Epoch [1171/1200], Loss: 0.0774 , Accuracy : 70.00%\n",
      "Epoch [1172/1200], Loss: 0.6832 , Accuracy : 72.50%\n",
      "Epoch [1173/1200], Loss: 0.3567 , Accuracy : 80.00%\n",
      "Epoch [1174/1200], Loss: 0.0573 , Accuracy : 60.00%\n",
      "Epoch [1175/1200], Loss: 0.1220 , Accuracy : 62.50%\n",
      "Epoch [1176/1200], Loss: 0.6255 , Accuracy : 77.50%\n",
      "Epoch [1177/1200], Loss: 2.2800 , Accuracy : 60.00%\n",
      "Epoch [1178/1200], Loss: 0.8737 , Accuracy : 70.00%\n",
      "Epoch [1179/1200], Loss: 1.0543 , Accuracy : 67.50%\n",
      "Epoch [1180/1200], Loss: 0.5871 , Accuracy : 70.00%\n",
      "Epoch [1181/1200], Loss: 0.1133 , Accuracy : 77.50%\n",
      "Epoch [1182/1200], Loss: 0.5372 , Accuracy : 72.50%\n",
      "Epoch [1183/1200], Loss: 0.6470 , Accuracy : 72.50%\n",
      "Epoch [1184/1200], Loss: 0.7126 , Accuracy : 75.00%\n",
      "Epoch [1185/1200], Loss: 0.3241 , Accuracy : 67.50%\n",
      "Epoch [1186/1200], Loss: 0.6410 , Accuracy : 75.00%\n",
      "Epoch [1187/1200], Loss: 1.2138 , Accuracy : 65.00%\n",
      "Epoch [1188/1200], Loss: 0.9200 , Accuracy : 92.50%\n",
      "Epoch [1189/1200], Loss: 0.0964 , Accuracy : 75.00%\n",
      "Epoch [1190/1200], Loss: 1.0267 , Accuracy : 75.00%\n",
      "Epoch [1191/1200], Loss: 1.3476 , Accuracy : 77.50%\n",
      "Epoch [1192/1200], Loss: 0.3752 , Accuracy : 70.00%\n",
      "Epoch [1193/1200], Loss: 0.1292 , Accuracy : 80.00%\n",
      "Epoch [1194/1200], Loss: 2.1779 , Accuracy : 80.00%\n",
      "Epoch [1195/1200], Loss: 0.1530 , Accuracy : 82.50%\n",
      "Epoch [1196/1200], Loss: 0.0521 , Accuracy : 67.50%\n",
      "Epoch [1197/1200], Loss: 0.1896 , Accuracy : 77.50%\n",
      "Epoch [1198/1200], Loss: 1.0661 , Accuracy : 75.00%\n",
      "Epoch [1199/1200], Loss: 0.4140 , Accuracy : 82.50%\n",
      "Epoch [1200/1200], Loss: 1.0649 , Accuracy : 85.00%\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "# References : https://saturncloud.io/blog/calculating-the-accuracy-of-pytorch-models-every-epoch/#:~:text=In%20order%20to%20calculate%20the,tensor%20along%20a%20specified%20dimension\n",
    "num_epochs = 1200\n",
    "for epoch in range(num_epochs):\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    model.train()\n",
    "    for i, (sequences, labels) in enumerate(data_loader):\n",
    "        # Move data to the device\n",
    "        sequences = sequences.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(sequences)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        total_correct += (predicted == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    accuracy = 100 * total_correct /total_samples\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f} , Accuracy : {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save and Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.4916,  0.2518, -1.3187,  ...,  0.5597,  0.2202,  0.0108],\n",
       "         [ 0.4907,  0.2519, -1.3672,  ...,  0.5580,  0.2209,  0.0105],\n",
       "         [ 0.4896,  0.2520, -1.4026,  ...,  0.5580,  0.2210,  0.0110],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.4828,  0.2604, -1.2334,  ...,  0.5483,  0.2258,  0.0073],\n",
       "         [ 0.4816,  0.2606, -1.4555,  ...,  0.5474,  0.2267,  0.0087],\n",
       "         [ 0.4809,  0.2608, -1.4653,  ...,  0.5475,  0.2266,  0.0088],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.5030,  0.2553, -1.1988,  ...,  0.5699,  0.2265,  0.0097],\n",
       "         [ 0.5028,  0.2582, -1.2761,  ...,  0.5689,  0.2266,  0.0109],\n",
       "         [ 0.5028,  0.2605, -1.3315,  ...,  0.5690,  0.2269,  0.0105],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.5122,  0.2456, -1.3706,  ...,  0.5836,  0.2207,  0.0125],\n",
       "         [ 0.5121,  0.2461, -1.4417,  ...,  0.5818,  0.2208,  0.0118],\n",
       "         [ 0.5121,  0.2465, -1.4591,  ...,  0.5815,  0.2204,  0.0118],\n",
       "         ...,\n",
       "         [ 0.5017,  0.2434, -1.4740,  ...,  0.5812,  0.2105,  0.0155],\n",
       "         [ 0.5022,  0.2433, -1.4619,  ...,  0.5818,  0.2102,  0.0157],\n",
       "         [ 0.5032,  0.2431, -1.4609,  ...,  0.5821,  0.2097,  0.0163]]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_sequence(sequences, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 8.6139, -1.0417, -5.6044,  ..., -3.2881,  3.3088, -4.3037],\n",
       "        [-6.4033,  8.9527, -3.1627,  ...,  2.8894, -3.8095, -4.2055],\n",
       "        [-3.5145, -0.6302,  9.2098,  ..., -3.5143, -3.2961,  1.2645],\n",
       "        ...,\n",
       "        [-9.0588, -0.2256, -5.5518,  ..., 10.0945, -7.5426,  1.2404],\n",
       "        [-0.3098, -4.8207, -4.4665,  ..., -5.3419,  8.1656, -2.2520],\n",
       "        [-7.6264, -8.1712, -2.6587,  ...,  1.9282, -2.6411, 11.1228]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Put the model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# No need to track gradients during inference\n",
    "with torch.no_grad():\n",
    "    # Get the model's output (logits)\n",
    "    outputs = model(padded_sequences)\n",
    "\n",
    "# outputs = torch.softmax(outputs, dim=1)\n",
    "# outputs = torch.max(outputs,1)\n",
    "\n",
    "outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.5013,  0.2452, -1.2167,  ...,  0.5663,  0.2188,  0.0098],\n",
       "         [ 0.4997,  0.2482, -1.4690,  ...,  0.5652,  0.2181,  0.0106],\n",
       "         [ 0.4984,  0.2500, -1.4853,  ...,  0.5654,  0.2185,  0.0112],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.4922,  0.2382, -1.2850,  ...,  0.5578,  0.2124,  0.0094],\n",
       "         [ 0.4920,  0.2405, -1.4288,  ...,  0.5571,  0.2116,  0.0099],\n",
       "         [ 0.4920,  0.2409, -1.4093,  ...,  0.5567,  0.2122,  0.0098],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.5049,  0.2371, -1.2115,  ...,  0.5643,  0.2082,  0.0088],\n",
       "         [ 0.5045,  0.2381, -1.1896,  ...,  0.5643,  0.2081,  0.0085],\n",
       "         [ 0.5041,  0.2385, -1.1915,  ...,  0.5643,  0.2080,  0.0089],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.4849,  0.2484, -1.3873,  ...,  0.5543,  0.2162,  0.0108],\n",
       "         [ 0.4846,  0.2500, -1.4881,  ...,  0.5539,  0.2157,  0.0111],\n",
       "         [ 0.4844,  0.2507, -1.4935,  ...,  0.5537,  0.2161,  0.0111],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.5199,  0.2290, -1.2810,  ...,  0.5876,  0.2058,  0.0103],\n",
       "         [ 0.5195,  0.2307, -1.3821,  ...,  0.5873,  0.2059,  0.0106],\n",
       "         [ 0.5193,  0.2327, -1.4100,  ...,  0.5877,  0.2059,  0.0109],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.5005,  0.2439, -1.3629,  ...,  0.5694,  0.2139,  0.0154],\n",
       "         [ 0.5002,  0.2448, -1.5049,  ...,  0.5688,  0.2128,  0.0146],\n",
       "         [ 0.4999,  0.2457, -1.5287,  ...,  0.5683,  0.2134,  0.0148],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = [\"Data for different actions/ไอซ์.mp4/ไอซ์.npy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.5005,  0.2439, -1.3629,  ...,  0.5694,  0.2139,  0.0154],\n",
       "         [ 0.5002,  0.2448, -1.5049,  ...,  0.5688,  0.2128,  0.0146],\n",
       "         [ 0.4999,  0.2457, -1.5287,  ...,  0.5683,  0.2134,  0.0148],\n",
       "         ...,\n",
       "         [ 0.4965,  0.2433, -1.3673,  ...,  0.5670,  0.2114,  0.0169],\n",
       "         [ 0.4960,  0.2433, -1.3676,  ...,  0.5660,  0.2107,  0.0168],\n",
       "         [ 0.4950,  0.2433, -1.3637,  ...,  0.5651,  0.2100,  0.0170]]])"
      ]
     },
     "execution_count": 730,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the sequences\n",
    "import torch\n",
    "sequences = load_keypoint_sequences(file_paths)\n",
    "# Change list to numpy array \n",
    "sequences = np.array(sequences)\n",
    "# Change numpy array to tensor\n",
    "sequences = torch.FloatTensor(sequences)\n",
    "sequences = pad_sequence(sequences, batch_first=True)\n",
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-5.1330, -3.4491,  4.8948,  2.6497, -9.3919, -3.3578, -4.5875, -1.2652,\n",
       "          1.0454,  0.8730,  4.2337,  2.8527, -4.7579, -3.3598,  3.8613, -3.6807,\n",
       "         -0.2372, -7.4923,  2.6996, -3.4138, -3.1389,  0.4774, -5.5571,  2.3744,\n",
       "         -3.7720,  0.5603, -0.7957, -6.6807, -7.6443, -1.8219, -4.7114, -4.6537,\n",
       "         -3.2863, -1.8365,  3.6327, -2.7850, -2.7935, -3.7733, -2.5452,  2.2935]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 731,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model(sequences)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['กฎกระทรวง',\n",
       " 'กฎหมายรัฐธรรมนูญ',\n",
       " 'กรมอนามัย',\n",
       " 'กรรม',\n",
       " 'กรรมสิทธิ์',\n",
       " 'กระโดด',\n",
       " 'กล้วยบวชชี',\n",
       " 'กล้วยเชื่อม',\n",
       " 'กังวล',\n",
       " 'กีฬา',\n",
       " 'น้อง',\n",
       " 'เขิน',\n",
       " 'เขื่อนดิน',\n",
       " 'เขื่อนสิริกิติ์',\n",
       " 'เข้าใจผิด',\n",
       " 'เคย',\n",
       " 'เครียด',\n",
       " 'เครื่องปั่นดิน',\n",
       " 'เครื่องหมายการค้า',\n",
       " 'เจอ',\n",
       " 'เจ้าหนี้',\n",
       " 'เช่าซื้อ',\n",
       " 'เช่าทรัพย์',\n",
       " 'เซอร์เบีย',\n",
       " 'เซเนกัล',\n",
       " 'เซ็ง',\n",
       " 'เดิน',\n",
       " 'เดิมพัน',\n",
       " 'เพลีย',\n",
       " 'เมื่อย',\n",
       " 'เม็กซิโก',\n",
       " 'เฮโรอีน',\n",
       " 'แกมเบีย',\n",
       " 'แซมเบีย',\n",
       " 'โกหก',\n",
       " 'โจทก์',\n",
       " 'โชจู',\n",
       " 'ใกล้',\n",
       " 'ไดโนเสาร์',\n",
       " 'ไอซ์']"
      ]
     },
     "execution_count": 732,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [action.split(\".\")[0] for action in actions]\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change from tensor to numpy arrat\n",
    "outputs = outputs.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.132989  , -3.4491277 ,  4.8947906 ,  2.6497188 , -9.391915  ,\n",
       "        -3.3577971 , -4.587475  , -1.2652152 ,  1.0454049 ,  0.8730298 ,\n",
       "         4.233672  ,  2.8526988 , -4.7579155 , -3.3597836 ,  3.8612597 ,\n",
       "        -3.6806512 , -0.2372104 , -7.4923015 ,  2.6995811 , -3.4138231 ,\n",
       "        -3.1389213 ,  0.47740752, -5.5571103 ,  2.3744497 , -3.7720437 ,\n",
       "         0.5602941 , -0.7957425 , -6.680711  , -7.644286  , -1.8219105 ,\n",
       "        -4.7113743 , -4.6537013 , -3.2863104 , -1.8365319 ,  3.632668  ,\n",
       "        -2.7850468 , -2.7935085 , -3.7733169 , -2.5452118 ,  2.2934556 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 734,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5.132989   -3.4491277   4.8947906   2.6497188  -9.391915   -3.3577971\n",
      " -4.587475   -1.2652152   1.0454049   0.8730298   4.233672    2.8526988\n",
      " -4.7579155  -3.3597836   3.8612597  -3.6806512  -0.2372104  -7.4923015\n",
      "  2.6995811  -3.4138231  -3.1389213   0.47740752 -5.5571103   2.3744497\n",
      " -3.7720437   0.5602941  -0.7957425  -6.680711   -7.644286   -1.8219105\n",
      " -4.7113743  -4.6537013  -3.2863104  -1.8365319   3.632668   -2.7850468\n",
      " -2.7935085  -3.7733169  -2.5452118   2.2934556 ]\n"
     ]
    }
   ],
   "source": [
    "for idx, word in enumerate(outputs):\n",
    "    # max_value = torch.max(outputs)\n",
    "    list_outputs = max(outputs)\n",
    "    print(list_outputs)\n",
    "    # print(max_value)\n",
    "    # print(max_value.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 736,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_max = max(range(len(list_outputs)), key=list_outputs.__getitem__)\n",
    "index_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "กรมอนามัย\n"
     ]
    }
   ],
   "source": [
    "print(labels[index_max])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -------------------------------------------------------------------------------------------------------------------------------------------- ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMModel(\n",
       "  (lstm): LSTM(1662, 128, num_layers=2, batch_first=True)\n",
       "  (fc): Linear(in_features=128, out_features=40, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(loader, model):\n",
    "    if data_loader:\n",
    "        print(\"Checking accuracy on training data\")\n",
    "    else:\n",
    "        print(\"Checking accuracy on test data\")  \n",
    "          \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device)\n",
    "            y = y.to(device=device)\n",
    "            # x = x.reshape(x.shape[0], -1)\n",
    "            \n",
    "            scores = model(x)\n",
    "            _, predictions = scores.max(1)\n",
    "            num_correct += (predictions == y).sum()\n",
    "            num_samples += predictions.size(0)\n",
    "            \n",
    "        print(f\"Got {num_correct} / {num_samples} with accuracy {float(num_correct)/float(num_samples)*100:.2f}\")\n",
    "        \n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on training data\n",
      "Got 32 / 40 with accuracy 80.00\n"
     ]
    }
   ],
   "source": [
    "check_accuracy(data_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
