{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video Classification using LSTM + Attention layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import mediapipe as mp \n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holist = mp.solutions.holistic \n",
    "mp_draw = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_detection(img, model):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img.flags.writeable = False                 \n",
    "    result = model.process(img)                 # Make prediction\n",
    "    img.flags.writeable = True                   \n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR) \n",
    "    return img, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_landmarks(img, result):\n",
    "    mp_draw.draw_landmarks(img, result.face_landmarks, mp_holist.FACEMESH_CONTOURS) # Draw face connections\n",
    "    mp_draw.draw_landmarks(img, result.pose_landmarks, mp_holist.POSE_CONNECTIONS) # Draw pose connections\n",
    "    mp_draw.draw_landmarks(img, result.left_hand_landmarks, mp_holist.HAND_CONNECTIONS) # Draw left hand connections\n",
    "    mp_draw.draw_landmarks(img, result.right_hand_landmarks, mp_holist.HAND_CONNECTIONS) # Draw right hand connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_styled_landmarks(img, result):\n",
    "    mp_draw.draw_landmarks(img, result.face_landmarks, mp_holist.FACEMESH_CONTOURS, \n",
    "                             mp_draw.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1), # color the joint \n",
    "                             mp_draw.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1) #color the connection\n",
    "                             ) \n",
    "    # mp_draw.draw_landmarks(img, result.face_landmarks, mp_holist.FACEMESH_CONTOURS, \n",
    "    #                          mp_draw.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1), # color the joint \n",
    "    #                          mp_draw.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1) #color the connection\n",
    "    #                          ) \n",
    "    \n",
    "    mp_draw.draw_landmarks(img, result.pose_landmarks, mp_holist.POSE_CONNECTIONS,\n",
    "                             mp_draw.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4), \n",
    "                             mp_draw.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                             ) \n",
    "    mp_draw.draw_landmarks(img, result.left_hand_landmarks, mp_holist.HAND_CONNECTIONS, \n",
    "                             mp_draw.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4), \n",
    "                             mp_draw.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                             ) \n",
    "    mp_draw.draw_landmarks(img, result.right_hand_landmarks, mp_holist.HAND_CONNECTIONS, \n",
    "                             mp_draw.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4), \n",
    "                             mp_draw.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                             ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keypoints(results):\n",
    "    pose=np.array([[res.x,res.y,res.z,res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*4)\n",
    "    left_hnd=np.array([[res.x,res.y,res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "    right_hnd=np.array([[res.x,res.y,res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "    face=np.array([[res.x,res.y,res.z] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(468*3)\n",
    "    return np.concatenate([pose,left_hnd,right_hnd,face])\n",
    "# concatenating for the model to detect the sign language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 542,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "video_dir = \"C:/Users/araya/Desktop/keypoints/video_extract\"\n",
    "video_list = []\n",
    "video_list = os.listdir(video_dir)\n",
    "\n",
    "len(video_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['กฎกระทรวง.mp4',\n",
       " 'กฎหมายรัฐธรรมนูญ.mp4',\n",
       " 'กรมอนามัย.mp4',\n",
       " 'กรรม.mp4',\n",
       " 'กรรมสิทธิ์.mp4',\n",
       " 'กระโดด.mp4',\n",
       " 'กล้วยบวชชี.mp4',\n",
       " 'กล้วยเชื่อม.mp4',\n",
       " 'กังวล.mp4',\n",
       " 'กีฬา.mp4',\n",
       " 'น้อง.mp4',\n",
       " 'เขิน.mp4',\n",
       " 'เขื่อนดิน.mp4',\n",
       " 'เขื่อนสิริกิติ์.mp4',\n",
       " 'เข้าใจผิด.mp4',\n",
       " 'เคย.mp4',\n",
       " 'เครียด.mp4',\n",
       " 'เครื่องปั่นดิน.mp4',\n",
       " 'เครื่องหมายการค้า.mp4',\n",
       " 'เจอ.mp4',\n",
       " 'เจ้าหนี้.mp4',\n",
       " 'เช่าซื้อ.mp4',\n",
       " 'เช่าทรัพย์.mp4',\n",
       " 'เซอร์เบีย.mp4',\n",
       " 'เซเนกัล.mp4',\n",
       " 'เซ็ง.mp4',\n",
       " 'เดิน.mp4',\n",
       " 'เดิมพัน.mp4',\n",
       " 'เพลีย.mp4',\n",
       " 'เมื่อย.mp4',\n",
       " 'เม็กซิโก.mp4',\n",
       " 'เฮโรอีน.mp4',\n",
       " 'แกมเบีย.mp4',\n",
       " 'แซมเบีย.mp4',\n",
       " 'โกหก.mp4',\n",
       " 'โจทก์.mp4',\n",
       " 'โชจู.mp4',\n",
       " 'ใกล้.mp4',\n",
       " 'ไดโนเสาร์.mp4',\n",
       " 'ไอซ์.mp4']"
      ]
     },
     "execution_count": 543,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for exported data, numpy arrays\n",
    "Model_Data=os.path.join('Data for different actions')\n",
    "\n",
    "actions = np.array(video_list)\n",
    "\n",
    "no_of_seqs = 1\n",
    "\n",
    "# 30 frames in length\n",
    "seq_length = 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['กฎกระทรวง.mp4', 'กฎหมายรัฐธรรมนูญ.mp4', 'กรมอนามัย.mp4',\n",
       "       'กรรม.mp4', 'กรรมสิทธิ์.mp4', 'กระโดด.mp4', 'กล้วยบวชชี.mp4',\n",
       "       'กล้วยเชื่อม.mp4', 'กังวล.mp4', 'กีฬา.mp4', 'น้อง.mp4', 'เขิน.mp4',\n",
       "       'เขื่อนดิน.mp4', 'เขื่อนสิริกิติ์.mp4', 'เข้าใจผิด.mp4', 'เคย.mp4',\n",
       "       'เครียด.mp4', 'เครื่องปั่นดิน.mp4', 'เครื่องหมายการค้า.mp4',\n",
       "       'เจอ.mp4', 'เจ้าหนี้.mp4', 'เช่าซื้อ.mp4', 'เช่าทรัพย์.mp4',\n",
       "       'เซอร์เบีย.mp4', 'เซเนกัล.mp4', 'เซ็ง.mp4', 'เดิน.mp4',\n",
       "       'เดิมพัน.mp4', 'เพลีย.mp4', 'เมื่อย.mp4', 'เม็กซิโก.mp4',\n",
       "       'เฮโรอีน.mp4', 'แกมเบีย.mp4', 'แซมเบีย.mp4', 'โกหก.mp4',\n",
       "       'โจทก์.mp4', 'โชจู.mp4', 'ใกล้.mp4', 'ไดโนเสาร์.mp4', 'ไอซ์.mp4'],\n",
       "      dtype='<U21')"
      ]
     },
     "execution_count": 545,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collecting keypoint values for Training nd Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory where your videos are stored\n",
    "directory = \"C:/Users/araya/Desktop/keypoints/video_extract\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/araya/Desktop/keypoints/video_extract'"
      ]
     },
     "execution_count": 547,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/araya/Desktop/keypoints/video_extract/กฎกระทรวง.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/กฎหมายรัฐธรรมนูญ.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/กรมอนามัย.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/กรรม.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/กรรมสิทธิ์.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/กระโดด.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/กล้วยบวชชี.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/กล้วยเชื่อม.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/กังวล.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/กีฬา.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/น้อง.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เขิน.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เขื่อนดิน.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เขื่อนสิริกิติ์.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เข้าใจผิด.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เคย.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เครียด.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เครื่องปั่นดิน.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เครื่องหมายการค้า.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เจอ.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เจ้าหนี้.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เช่าซื้อ.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เช่าทรัพย์.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เซอร์เบีย.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เซเนกัล.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เซ็ง.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เดิน.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เดิมพัน.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เพลีย.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เมื่อย.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เม็กซิโก.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/เฮโรอีน.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/แกมเบีย.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/แซมเบีย.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/โกหก.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/โจทก์.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/โชจู.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/ใกล้.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/ไดโนเสาร์.mp4\n",
      "C:/Users/araya/Desktop/keypoints/video_extract/ไอซ์.mp4\n"
     ]
    }
   ],
   "source": [
    "for filename in actions:\n",
    "    print(directory + '/' + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Data for different actions/กฎกระทรวง.mp4/กฎกระทรวง.npy', 'Data for different actions/กฎหมายรัฐธรรมนูญ.mp4/กฎหมายรัฐธรรมนูญ.npy', 'Data for different actions/กรมอนามัย.mp4/กรมอนามัย.npy', 'Data for different actions/กรรม.mp4/กรรม.npy', 'Data for different actions/กรรมสิทธิ์.mp4/กรรมสิทธิ์.npy', 'Data for different actions/กระโดด.mp4/กระโดด.npy', 'Data for different actions/กล้วยบวชชี.mp4/กล้วยบวชชี.npy', 'Data for different actions/กล้วยเชื่อม.mp4/กล้วยเชื่อม.npy', 'Data for different actions/กังวล.mp4/กังวล.npy', 'Data for different actions/กีฬา.mp4/กีฬา.npy', 'Data for different actions/น้อง.mp4/น้อง.npy', 'Data for different actions/เขิน.mp4/เขิน.npy', 'Data for different actions/เขื่อนดิน.mp4/เขื่อนดิน.npy', 'Data for different actions/เขื่อนสิริกิติ์.mp4/เขื่อนสิริกิติ์.npy', 'Data for different actions/เข้าใจผิด.mp4/เข้าใจผิด.npy', 'Data for different actions/เคย.mp4/เคย.npy', 'Data for different actions/เครียด.mp4/เครียด.npy', 'Data for different actions/เครื่องปั่นดิน.mp4/เครื่องปั่นดิน.npy', 'Data for different actions/เครื่องหมายการค้า.mp4/เครื่องหมายการค้า.npy', 'Data for different actions/เจอ.mp4/เจอ.npy', 'Data for different actions/เจ้าหนี้.mp4/เจ้าหนี้.npy', 'Data for different actions/เช่าซื้อ.mp4/เช่าซื้อ.npy', 'Data for different actions/เช่าทรัพย์.mp4/เช่าทรัพย์.npy', 'Data for different actions/เซอร์เบีย.mp4/เซอร์เบีย.npy', 'Data for different actions/เซเนกัล.mp4/เซเนกัล.npy', 'Data for different actions/เซ็ง.mp4/เซ็ง.npy', 'Data for different actions/เดิน.mp4/เดิน.npy', 'Data for different actions/เดิมพัน.mp4/เดิมพัน.npy', 'Data for different actions/เพลีย.mp4/เพลีย.npy', 'Data for different actions/เมื่อย.mp4/เมื่อย.npy', 'Data for different actions/เม็กซิโก.mp4/เม็กซิโก.npy', 'Data for different actions/เฮโรอีน.mp4/เฮโรอีน.npy', 'Data for different actions/แกมเบีย.mp4/แกมเบีย.npy', 'Data for different actions/แซมเบีย.mp4/แซมเบีย.npy', 'Data for different actions/โกหก.mp4/โกหก.npy', 'Data for different actions/โจทก์.mp4/โจทก์.npy', 'Data for different actions/โชจู.mp4/โชจู.npy', 'Data for different actions/ใกล้.mp4/ใกล้.npy', 'Data for different actions/ไดโนเสาร์.mp4/ไดโนเสาร์.npy', 'Data for different actions/ไอซ์.mp4/ไอซ์.npy']\n"
     ]
    }
   ],
   "source": [
    "file_paths = []\n",
    "for action in actions:\n",
    "    video_path = os.path.join('Data for different actions/', action)\n",
    "    # print(video_path)\n",
    "    # print(action)\n",
    "    file_paths.append(video_path + '/' + action.split(\".\")[0] + \".npy\")\n",
    "print(file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_keypoint_sequences(file_paths):\n",
    "    keypoint_sequences = []\n",
    "    for file_path in file_paths:\n",
    "        keypoints = np.load(file_path)\n",
    "        keypoint_sequences.append(torch.tensor(keypoints, dtype=torch.float32))\n",
    "    return keypoint_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 0.5013,  0.2452, -1.2167,  ...,  0.5663,  0.2188,  0.0098],\n",
       "         [ 0.4997,  0.2482, -1.4690,  ...,  0.5652,  0.2181,  0.0106],\n",
       "         [ 0.4984,  0.2500, -1.4853,  ...,  0.5654,  0.2185,  0.0112],\n",
       "         ...,\n",
       "         [ 0.4861,  0.2513, -1.3416,  ...,  0.5572,  0.2177,  0.0091],\n",
       "         [ 0.4873,  0.2514, -1.3574,  ...,  0.5575,  0.2172,  0.0097],\n",
       "         [ 0.4883,  0.2516, -1.3579,  ...,  0.5577,  0.2170,  0.0101]]),\n",
       " tensor([[ 0.4922,  0.2382, -1.2850,  ...,  0.5578,  0.2124,  0.0094],\n",
       "         [ 0.4920,  0.2405, -1.4288,  ...,  0.5571,  0.2116,  0.0099],\n",
       "         [ 0.4920,  0.2409, -1.4093,  ...,  0.5567,  0.2122,  0.0098],\n",
       "         ...,\n",
       "         [ 0.4814,  0.2260, -1.3318,  ...,  0.5503,  0.1923,  0.0123],\n",
       "         [ 0.4815,  0.2257, -1.3351,  ...,  0.5503,  0.1921,  0.0122],\n",
       "         [ 0.4815,  0.2255, -1.3497,  ...,  0.5501,  0.1919,  0.0124]]),\n",
       " tensor([[ 0.5049,  0.2371, -1.2115,  ...,  0.5643,  0.2082,  0.0088],\n",
       "         [ 0.5045,  0.2381, -1.1896,  ...,  0.5643,  0.2081,  0.0085],\n",
       "         [ 0.5041,  0.2385, -1.1915,  ...,  0.5643,  0.2080,  0.0089],\n",
       "         ...,\n",
       "         [ 0.4963,  0.2307, -1.3096,  ...,  0.5624,  0.2043,  0.0127],\n",
       "         [ 0.4965,  0.2308, -1.3085,  ...,  0.5625,  0.2045,  0.0126],\n",
       "         [ 0.4972,  0.2312, -1.3053,  ...,  0.5633,  0.2045,  0.0128]]),\n",
       " tensor([[ 0.5134,  0.2614, -1.4426,  ...,  0.5818,  0.2272,  0.0153],\n",
       "         [ 0.5130,  0.2604, -1.4262,  ...,  0.5810,  0.2273,  0.0147],\n",
       "         [ 0.5126,  0.2599, -1.4278,  ...,  0.5810,  0.2276,  0.0150],\n",
       "         ...,\n",
       "         [ 0.5079,  0.2693, -1.4999,  ...,  0.5780,  0.2349,  0.0115],\n",
       "         [ 0.5090,  0.2688, -1.4936,  ...,  0.5782,  0.2346,  0.0116],\n",
       "         [ 0.5092,  0.2683, -1.4518,  ...,  0.5786,  0.2341,  0.0116]]),\n",
       " tensor([[ 0.4883,  0.2402, -1.1024,  ...,  0.5482,  0.2132,  0.0081],\n",
       "         [ 0.4878,  0.2402, -1.1906,  ...,  0.5469,  0.2135,  0.0083],\n",
       "         [ 0.4863,  0.2402, -1.1774,  ...,  0.5477,  0.2141,  0.0087],\n",
       "         ...,\n",
       "         [ 0.4788,  0.3129, -1.6072,  ...,  0.5349,  0.2531,  0.0022],\n",
       "         [ 0.4782,  0.3129, -1.6350,  ...,  0.5344,  0.2525,  0.0022],\n",
       "         [ 0.4771,  0.3131, -1.6312,  ...,  0.5339,  0.2515,  0.0022]]),\n",
       " tensor([[ 0.4992,  0.1994, -1.1906,  ...,  0.5657,  0.1731,  0.0116],\n",
       "         [ 0.4988,  0.2047, -1.3590,  ...,  0.5663,  0.1723,  0.0123],\n",
       "         [ 0.4982,  0.2082, -1.3140,  ...,  0.5671,  0.1730,  0.0129],\n",
       "         ...,\n",
       "         [ 0.4743,  0.1974, -1.3230,  ...,  0.5475,  0.1620,  0.0155],\n",
       "         [ 0.4732,  0.1974, -1.3174,  ...,  0.5461,  0.1615,  0.0151],\n",
       "         [ 0.4720,  0.1974, -1.3149,  ...,  0.5453,  0.1614,  0.0149]]),\n",
       " tensor([[ 0.5023,  0.2809, -1.6242,  ...,  0.5847,  0.2321,  0.0112],\n",
       "         [ 0.5023,  0.2806, -1.6631,  ...,  0.5840,  0.2322,  0.0130],\n",
       "         [ 0.5022,  0.2805, -1.6912,  ...,  0.5837,  0.2322,  0.0122],\n",
       "         ...,\n",
       "         [ 0.5037,  0.2791, -1.5789,  ...,  0.5834,  0.2224,  0.0129],\n",
       "         [ 0.5044,  0.2774, -1.5686,  ...,  0.5831,  0.2220,  0.0130],\n",
       "         [ 0.5052,  0.2722, -1.5527,  ...,  0.5827,  0.2216,  0.0132]]),\n",
       " tensor([[ 0.4868,  0.2821, -1.4668,  ...,  0.5711,  0.2335,  0.0116],\n",
       "         [ 0.4861,  0.2786, -1.5812,  ...,  0.5702,  0.2334,  0.0129],\n",
       "         [ 0.4856,  0.2769, -1.6059,  ...,  0.5699,  0.2333,  0.0131],\n",
       "         ...,\n",
       "         [ 0.4826,  0.2583, -1.6140,  ...,  0.5606,  0.2261,  0.0154],\n",
       "         [ 0.4820,  0.2583, -1.5231,  ...,  0.5603,  0.2261,  0.0156],\n",
       "         [ 0.4818,  0.2580, -1.5255,  ...,  0.5600,  0.2263,  0.0156]]),\n",
       " tensor([[ 0.5016,  0.2321, -1.1859,  ...,  0.5647,  0.2139,  0.0072],\n",
       "         [ 0.5015,  0.2340, -1.1996,  ...,  0.5645,  0.2135,  0.0076],\n",
       "         [ 0.5016,  0.2346, -1.2272,  ...,  0.5644,  0.2137,  0.0082],\n",
       "         ...,\n",
       "         [ 0.4743,  0.2622, -1.4181,  ...,  0.5499,  0.2133,  0.0080],\n",
       "         [ 0.4763,  0.2599, -1.4742,  ...,  0.5519,  0.2118,  0.0090],\n",
       "         [ 0.4787,  0.2522, -1.6440,  ...,  0.5537,  0.2110,  0.0093]]),\n",
       " tensor([[ 0.4926,  0.1945, -1.2354,  ...,  0.5488,  0.1581,  0.0085],\n",
       "         [ 0.4942,  0.1949, -1.4254,  ...,  0.5481,  0.1576,  0.0085],\n",
       "         [ 0.4948,  0.1960, -1.4483,  ...,  0.5479,  0.1581,  0.0084],\n",
       "         ...,\n",
       "         [ 0.4917,  0.1882, -1.3355,  ...,  0.5458,  0.1536,  0.0126],\n",
       "         [ 0.4918,  0.1885, -1.3154,  ...,  0.5456,  0.1536,  0.0125],\n",
       "         [ 0.4918,  0.1886, -1.3147,  ...,  0.5453,  0.1537,  0.0124]]),\n",
       " tensor([[ 0.4956,  0.2681, -1.1361,  ...,  0.5554,  0.2332,  0.0147],\n",
       "         [ 0.4948,  0.2681, -1.3768,  ...,  0.5540,  0.2333,  0.0116],\n",
       "         [ 0.4943,  0.2681, -1.3754,  ...,  0.5538,  0.2332,  0.0116],\n",
       "         ...,\n",
       "         [ 0.4895,  0.2689, -1.2187,  ...,  0.5513,  0.2276,  0.0135],\n",
       "         [ 0.4889,  0.2688, -1.2198,  ...,  0.5508,  0.2276,  0.0134],\n",
       "         [ 0.4882,  0.2688, -1.2172,  ...,  0.5507,  0.2276,  0.0134]]),\n",
       " tensor([[ 0.5032,  0.2228, -1.1998,  ...,  0.5663,  0.1971,  0.0106],\n",
       "         [ 0.5035,  0.2228, -1.2072,  ...,  0.5662,  0.1969,  0.0106],\n",
       "         [ 0.5035,  0.2230, -1.2082,  ...,  0.5664,  0.1963,  0.0108],\n",
       "         ...,\n",
       "         [ 0.4982,  0.2206, -1.2743,  ...,  0.5578,  0.1892,  0.0092],\n",
       "         [ 0.4983,  0.2178, -1.2380,  ...,  0.5581,  0.1883,  0.0091],\n",
       "         [ 0.4979,  0.2173, -1.2264,  ...,  0.5578,  0.1877,  0.0096]]),\n",
       " tensor([[ 0.5442,  0.2507, -1.4443,  ...,  0.6105,  0.2203,  0.0123],\n",
       "         [ 0.5444,  0.2508, -1.6574,  ...,  0.6094,  0.2198,  0.0134],\n",
       "         [ 0.5445,  0.2510, -1.7250,  ...,  0.6093,  0.2195,  0.0144],\n",
       "         ...,\n",
       "         [ 0.5324,  0.2577, -1.6704,  ...,  0.5975,  0.2210,  0.0145],\n",
       "         [ 0.5323,  0.2560, -1.6673,  ...,  0.5966,  0.2206,  0.0148],\n",
       "         [ 0.5323,  0.2553, -1.6826,  ...,  0.5957,  0.2201,  0.0146]]),\n",
       " tensor([[ 0.5402,  0.2562, -1.5458,  ...,  0.6041,  0.2257,  0.0125],\n",
       "         [ 0.5389,  0.2596, -1.7020,  ...,  0.6031,  0.2264,  0.0130],\n",
       "         [ 0.5379,  0.2616, -1.7134,  ...,  0.6027,  0.2258,  0.0139],\n",
       "         ...,\n",
       "         [ 0.5153,  0.2631, -1.6030,  ...,  0.5956,  0.2125,  0.0142],\n",
       "         [ 0.5176,  0.2626, -1.6101,  ...,  0.5985,  0.2126,  0.0139],\n",
       "         [ 0.5197,  0.2624, -1.5662,  ...,  0.6011,  0.2119,  0.0145]]),\n",
       " tensor([[ 0.5030,  0.2553, -1.1988,  ...,  0.5699,  0.2265,  0.0097],\n",
       "         [ 0.5028,  0.2582, -1.2761,  ...,  0.5689,  0.2266,  0.0109],\n",
       "         [ 0.5028,  0.2605, -1.3315,  ...,  0.5690,  0.2269,  0.0105],\n",
       "         ...,\n",
       "         [ 0.5028,  0.2675, -1.4499,  ...,  0.5672,  0.2323,  0.0110],\n",
       "         [ 0.5007,  0.2672, -1.4234,  ...,  0.5668,  0.2317,  0.0115],\n",
       "         [ 0.4988,  0.2671, -1.4308,  ...,  0.5670,  0.2312,  0.0118]]),\n",
       " tensor([[ 0.5069,  0.2355, -1.3384,  ...,  0.5700,  0.2051,  0.0053],\n",
       "         [ 0.5045,  0.2395, -1.5097,  ...,  0.5699,  0.2043,  0.0064],\n",
       "         [ 0.5028,  0.2420, -1.5081,  ...,  0.5699,  0.2045,  0.0069],\n",
       "         ...,\n",
       "         [ 0.4952,  0.2462, -1.4319,  ...,  0.5658,  0.2015,  0.0122],\n",
       "         [ 0.4952,  0.2448, -1.4781,  ...,  0.5661,  0.2014,  0.0123],\n",
       "         [ 0.4953,  0.2436, -1.4689,  ...,  0.5662,  0.2013,  0.0124]]),\n",
       " tensor([[ 0.5035,  0.2282, -1.1379,  ...,  0.5710,  0.1953,  0.0120],\n",
       "         [ 0.5033,  0.2284, -1.2771,  ...,  0.5713,  0.1954,  0.0123],\n",
       "         [ 0.5032,  0.2286, -1.2743,  ...,  0.5715,  0.1957,  0.0122],\n",
       "         ...,\n",
       "         [ 0.4810,  0.2296, -1.4129,  ...,  0.5542,  0.1897,  0.0133],\n",
       "         [ 0.4812,  0.2296, -1.4275,  ...,  0.5549,  0.1900,  0.0130],\n",
       "         [ 0.4816,  0.2299, -1.4337,  ...,  0.5557,  0.1903,  0.0133]]),\n",
       " tensor([[ 0.5108,  0.2425, -1.1053,  ...,  0.5724,  0.2176,  0.0127],\n",
       "         [ 0.5091,  0.2430, -1.3007,  ...,  0.5713,  0.2177,  0.0129],\n",
       "         [ 0.5080,  0.2432, -1.3035,  ...,  0.5714,  0.2179,  0.0130],\n",
       "         ...,\n",
       "         [ 0.4966,  0.2620, -1.5367,  ...,  0.5653,  0.2259,  0.0082],\n",
       "         [ 0.4968,  0.2621, -1.5419,  ...,  0.5656,  0.2262,  0.0083],\n",
       "         [ 0.4971,  0.2623, -1.5482,  ...,  0.5658,  0.2263,  0.0086]]),\n",
       " tensor([[ 0.4878,  0.2235, -1.2515,  ...,  0.5511,  0.1981,  0.0114],\n",
       "         [ 0.4870,  0.2286, -1.4279,  ...,  0.5506,  0.1977,  0.0105],\n",
       "         [ 0.4865,  0.2315, -1.4431,  ...,  0.5508,  0.1984,  0.0110],\n",
       "         ...,\n",
       "         [ 0.4901,  0.2217, -1.3449,  ...,  0.5576,  0.1888,  0.0156],\n",
       "         [ 0.4898,  0.2224, -1.3780,  ...,  0.5575,  0.1892,  0.0157],\n",
       "         [ 0.4896,  0.2232, -1.4140,  ...,  0.5572,  0.1897,  0.0156]]),\n",
       " tensor([[ 0.5194,  0.2227, -1.3410,  ...,  0.5911,  0.1970,  0.0142],\n",
       "         [ 0.5200,  0.2228, -1.3298,  ...,  0.5912,  0.1965,  0.0131],\n",
       "         [ 0.5202,  0.2230, -1.3074,  ...,  0.5909,  0.1970,  0.0149],\n",
       "         ...,\n",
       "         [ 0.5146,  0.2198, -1.3267,  ...,  0.5821,  0.1907,  0.0159],\n",
       "         [ 0.5141,  0.2205, -1.3207,  ...,  0.5816,  0.1911,  0.0154],\n",
       "         [ 0.5137,  0.2209, -1.3223,  ...,  0.5812,  0.1917,  0.0161]]),\n",
       " tensor([[ 0.5103,  0.2428, -1.1660,  ...,  0.5757,  0.2179,  0.0081],\n",
       "         [ 0.5106,  0.2437, -1.2850,  ...,  0.5751,  0.2183,  0.0099],\n",
       "         [ 0.5112,  0.2443, -1.2880,  ...,  0.5748,  0.2189,  0.0108],\n",
       "         ...,\n",
       "         [ 0.4800,  0.2603, -1.3086,  ...,  0.5532,  0.2237,  0.0069],\n",
       "         [ 0.4807,  0.2604, -1.2544,  ...,  0.5539,  0.2238,  0.0067],\n",
       "         [ 0.4813,  0.2604, -1.2161,  ...,  0.5548,  0.2238,  0.0065]]),\n",
       " tensor([[ 0.4945,  0.2362, -1.1227,  ...,  0.5529,  0.2086,  0.0088],\n",
       "         [ 0.4947,  0.2363, -1.1264,  ...,  0.5528,  0.2094,  0.0088],\n",
       "         [ 0.4951,  0.2364, -1.1371,  ...,  0.5531,  0.2099,  0.0089],\n",
       "         ...,\n",
       "         [ 0.4933,  0.2480, -1.2424,  ...,  0.5563,  0.2184,  0.0091],\n",
       "         [ 0.4933,  0.2480, -1.2443,  ...,  0.5565,  0.2185,  0.0093],\n",
       "         [ 0.4932,  0.2480, -1.2944,  ...,  0.5564,  0.2185,  0.0095]]),\n",
       " tensor([[ 0.5038,  0.2425, -1.1550,  ...,  0.5665,  0.2136,  0.0080],\n",
       "         [ 0.5027,  0.2423, -1.2423,  ...,  0.5653,  0.2133,  0.0092],\n",
       "         [ 0.5018,  0.2423, -1.2565,  ...,  0.5649,  0.2130,  0.0094],\n",
       "         ...,\n",
       "         [ 0.4950,  0.2412, -1.1727,  ...,  0.5624,  0.2175,  0.0087],\n",
       "         [ 0.4951,  0.2412, -1.1690,  ...,  0.5625,  0.2177,  0.0082],\n",
       "         [ 0.4951,  0.2412, -1.1910,  ...,  0.5626,  0.2180,  0.0079]]),\n",
       " tensor([[ 0.4916,  0.2518, -1.3187,  ...,  0.5597,  0.2202,  0.0108],\n",
       "         [ 0.4907,  0.2519, -1.3672,  ...,  0.5580,  0.2209,  0.0105],\n",
       "         [ 0.4896,  0.2520, -1.4026,  ...,  0.5580,  0.2210,  0.0110],\n",
       "         ...,\n",
       "         [ 0.4850,  0.2552, -1.4312,  ...,  0.5509,  0.2199,  0.0138],\n",
       "         [ 0.4839,  0.2550, -1.4298,  ...,  0.5505,  0.2199,  0.0138],\n",
       "         [ 0.4831,  0.2549, -1.4164,  ...,  0.5501,  0.2200,  0.0137]]),\n",
       " tensor([[ 0.5051,  0.2347, -1.4390,  ...,  0.5717,  0.2094,  0.0091],\n",
       "         [ 0.5024,  0.2389, -1.5627,  ...,  0.5707,  0.2087,  0.0090],\n",
       "         [ 0.5005,  0.2417, -1.5896,  ...,  0.5704,  0.2090,  0.0098],\n",
       "         ...,\n",
       "         [ 0.4950,  0.2365, -1.4622,  ...,  0.5663,  0.2072,  0.0114],\n",
       "         [ 0.4950,  0.2366, -1.4772,  ...,  0.5667,  0.2075,  0.0115],\n",
       "         [ 0.4949,  0.2366, -1.4725,  ...,  0.5671,  0.2078,  0.0120]]),\n",
       " tensor([[ 0.5064,  0.2529, -1.3080,  ...,  0.5751,  0.2261,  0.0114],\n",
       "         [ 0.5055,  0.2550, -1.3556,  ...,  0.5752,  0.2257,  0.0106],\n",
       "         [ 0.5048,  0.2568, -1.3925,  ...,  0.5751,  0.2260,  0.0110],\n",
       "         ...,\n",
       "         [ 0.4960,  0.2624, -1.3587,  ...,  0.5642,  0.2311,  0.0101],\n",
       "         [ 0.4961,  0.2619, -1.3373,  ...,  0.5652,  0.2307,  0.0104],\n",
       "         [ 0.4961,  0.2615, -1.3405,  ...,  0.5653,  0.2302,  0.0102]]),\n",
       " tensor([[ 0.5267,  0.2322, -1.2986,  ...,  0.5921,  0.1996,  0.0123],\n",
       "         [ 0.5267,  0.2305, -1.3156,  ...,  0.5925,  0.1999,  0.0112],\n",
       "         [ 0.5266,  0.2296, -1.3147,  ...,  0.5928,  0.1997,  0.0121],\n",
       "         ...,\n",
       "         [ 0.5122,  0.2243, -1.2697,  ...,  0.5819,  0.1855,  0.0147],\n",
       "         [ 0.5114,  0.2239, -1.2687,  ...,  0.5817,  0.1857,  0.0145],\n",
       "         [ 0.5110,  0.2235, -1.2585,  ...,  0.5815,  0.1858,  0.0145]]),\n",
       " tensor([[ 0.5050,  0.2164, -1.1575,  ...,  0.5700,  0.1959,  0.0103],\n",
       "         [ 0.5041,  0.2187, -1.3621,  ...,  0.5689,  0.1959,  0.0100],\n",
       "         [ 0.5031,  0.2218, -1.3920,  ...,  0.5693,  0.1959,  0.0109],\n",
       "         ...,\n",
       "         [ 0.4987,  0.2252, -1.2609,  ...,  0.5655,  0.1932,  0.0101],\n",
       "         [ 0.4982,  0.2238, -1.2657,  ...,  0.5653,  0.1926,  0.0103],\n",
       "         [ 0.4969,  0.2230, -1.2967,  ...,  0.5649,  0.1919,  0.0105]]),\n",
       " tensor([[ 0.5097,  0.2301, -1.2305,  ...,  0.5773,  0.2070,  0.0135],\n",
       "         [ 0.5098,  0.2316, -1.4094,  ...,  0.5762,  0.2072,  0.0130],\n",
       "         [ 0.5099,  0.2328, -1.4219,  ...,  0.5754,  0.2074,  0.0134],\n",
       "         ...,\n",
       "         [ 0.5106,  0.2519, -1.1800,  ...,  0.5731,  0.2204,  0.0132],\n",
       "         [ 0.5082,  0.2514, -1.1958,  ...,  0.5717,  0.2193,  0.0134],\n",
       "         [ 0.5074,  0.2516, -1.2210,  ...,  0.5703,  0.2182,  0.0128]]),\n",
       " tensor([[ 0.5410,  0.2495, -1.3908,  ...,  0.6085,  0.2224,  0.0099],\n",
       "         [ 0.5399,  0.2502, -1.3960,  ...,  0.6066,  0.2219,  0.0111],\n",
       "         [ 0.5390,  0.2511, -1.3861,  ...,  0.6062,  0.2215,  0.0105],\n",
       "         ...,\n",
       "         [ 0.5131,  0.2461, -1.3199,  ...,  0.5857,  0.2158,  0.0118],\n",
       "         [ 0.5137,  0.2459, -1.3370,  ...,  0.5858,  0.2153,  0.0118],\n",
       "         [ 0.5141,  0.2456, -1.3376,  ...,  0.5860,  0.2150,  0.0116]]),\n",
       " tensor([[ 0.4813,  0.2267, -1.2462,  ...,  0.5499,  0.2013,  0.0123],\n",
       "         [ 0.4796,  0.2283, -1.4595,  ...,  0.5479,  0.2026,  0.0127],\n",
       "         [ 0.4786,  0.2300, -1.5108,  ...,  0.5480,  0.2025,  0.0122],\n",
       "         ...,\n",
       "         [ 0.4782,  0.2297, -1.2598,  ...,  0.5464,  0.1965,  0.0150],\n",
       "         [ 0.4781,  0.2300, -1.2686,  ...,  0.5459,  0.1960,  0.0147],\n",
       "         [ 0.4780,  0.2304, -1.2444,  ...,  0.5461,  0.1953,  0.0154]]),\n",
       " tensor([[ 0.5051,  0.2433, -1.3371,  ...,  0.5701,  0.2185,  0.0094],\n",
       "         [ 0.5042,  0.2464, -1.4811,  ...,  0.5696,  0.2193,  0.0109],\n",
       "         [ 0.5039,  0.2479, -1.4928,  ...,  0.5700,  0.2201,  0.0112],\n",
       "         ...,\n",
       "         [ 0.4965,  0.2517, -1.4369,  ...,  0.5645,  0.2217,  0.0130],\n",
       "         [ 0.4956,  0.2516, -1.4394,  ...,  0.5637,  0.2215,  0.0129],\n",
       "         [ 0.4943,  0.2514, -1.4394,  ...,  0.5628,  0.2207,  0.0124]]),\n",
       " tensor([[ 0.5269,  0.2488, -1.5232,  ...,  0.5929,  0.2181,  0.0118],\n",
       "         [ 0.5260,  0.2493, -1.4445,  ...,  0.5918,  0.2172,  0.0111],\n",
       "         [ 0.5250,  0.2497, -1.4588,  ...,  0.5916,  0.2171,  0.0113],\n",
       "         ...,\n",
       "         [ 0.5126,  0.2514, -1.5292,  ...,  0.5827,  0.2212,  0.0138],\n",
       "         [ 0.5125,  0.2512, -1.5273,  ...,  0.5813,  0.2204,  0.0136],\n",
       "         [ 0.5123,  0.2512, -1.5221,  ...,  0.5795,  0.2200,  0.0137]]),\n",
       " tensor([[ 0.5103,  0.2330, -1.4731,  ...,  0.5745,  0.2056,  0.0102],\n",
       "         [ 0.5071,  0.2360, -1.5453,  ...,  0.5731,  0.2055,  0.0103],\n",
       "         [ 0.5052,  0.2381, -1.5650,  ...,  0.5733,  0.2056,  0.0100],\n",
       "         ...,\n",
       "         [ 0.4875,  0.2316, -1.5252,  ...,  0.5606,  0.1993,  0.0132],\n",
       "         [ 0.4872,  0.2318, -1.5227,  ...,  0.5604,  0.1997,  0.0129],\n",
       "         [ 0.4870,  0.2318, -1.5220,  ...,  0.5604,  0.2000,  0.0129]]),\n",
       " tensor([[ 0.4952,  0.2338, -1.3905,  ...,  0.5593,  0.2078,  0.0128],\n",
       "         [ 0.4926,  0.2435, -1.4861,  ...,  0.5600,  0.2072,  0.0117],\n",
       "         [ 0.4916,  0.2483, -1.4905,  ...,  0.5596,  0.2079,  0.0126],\n",
       "         ...,\n",
       "         [ 0.4846,  0.2462, -1.4163,  ...,  0.5649,  0.2045,  0.0151],\n",
       "         [ 0.4852,  0.2450, -1.4038,  ...,  0.5648,  0.2038,  0.0156],\n",
       "         [ 0.4857,  0.2436, -1.3897,  ...,  0.5648,  0.2033,  0.0155]]),\n",
       " tensor([[ 0.4828,  0.2604, -1.2334,  ...,  0.5483,  0.2258,  0.0073],\n",
       "         [ 0.4816,  0.2606, -1.4555,  ...,  0.5474,  0.2267,  0.0087],\n",
       "         [ 0.4809,  0.2608, -1.4653,  ...,  0.5475,  0.2266,  0.0088],\n",
       "         ...,\n",
       "         [ 0.4832,  0.2490, -1.4275,  ...,  0.5557,  0.2156,  0.0123],\n",
       "         [ 0.4845,  0.2491, -1.4277,  ...,  0.5566,  0.2158,  0.0124],\n",
       "         [ 0.4855,  0.2492, -1.4367,  ...,  0.5573,  0.2163,  0.0122]]),\n",
       " tensor([[ 0.5122,  0.2456, -1.3706,  ...,  0.5836,  0.2207,  0.0125],\n",
       "         [ 0.5121,  0.2461, -1.4417,  ...,  0.5818,  0.2208,  0.0118],\n",
       "         [ 0.5121,  0.2465, -1.4591,  ...,  0.5815,  0.2204,  0.0118],\n",
       "         ...,\n",
       "         [ 0.5017,  0.2434, -1.4740,  ...,  0.5812,  0.2105,  0.0155],\n",
       "         [ 0.5022,  0.2433, -1.4619,  ...,  0.5818,  0.2102,  0.0157],\n",
       "         [ 0.5032,  0.2431, -1.4609,  ...,  0.5821,  0.2097,  0.0163]]),\n",
       " tensor([[ 0.4849,  0.2484, -1.3873,  ...,  0.5543,  0.2162,  0.0108],\n",
       "         [ 0.4846,  0.2500, -1.4881,  ...,  0.5539,  0.2157,  0.0111],\n",
       "         [ 0.4844,  0.2507, -1.4935,  ...,  0.5537,  0.2161,  0.0111],\n",
       "         ...,\n",
       "         [ 0.4589,  0.2435, -1.4798,  ...,  0.5299,  0.2058,  0.0120],\n",
       "         [ 0.4586,  0.2436, -1.4788,  ...,  0.5293,  0.2056,  0.0122],\n",
       "         [ 0.4583,  0.2437, -1.4790,  ...,  0.5289,  0.2052,  0.0123]]),\n",
       " tensor([[ 0.5199,  0.2290, -1.2810,  ...,  0.5876,  0.2058,  0.0103],\n",
       "         [ 0.5195,  0.2307, -1.3821,  ...,  0.5873,  0.2059,  0.0106],\n",
       "         [ 0.5193,  0.2327, -1.4100,  ...,  0.5877,  0.2059,  0.0109],\n",
       "         ...,\n",
       "         [ 0.5108,  0.2431, -1.3919,  ...,  0.5781,  0.2077,  0.0105],\n",
       "         [ 0.5093,  0.2422, -1.3894,  ...,  0.5768,  0.2068,  0.0103],\n",
       "         [ 0.5079,  0.2405, -1.3818,  ...,  0.5751,  0.2053,  0.0102]]),\n",
       " tensor([[ 0.5005,  0.2439, -1.3629,  ...,  0.5694,  0.2139,  0.0154],\n",
       "         [ 0.5002,  0.2448, -1.5049,  ...,  0.5688,  0.2128,  0.0146],\n",
       "         [ 0.4999,  0.2457, -1.5287,  ...,  0.5683,  0.2134,  0.0148],\n",
       "         ...,\n",
       "         [ 0.4965,  0.2433, -1.3673,  ...,  0.5670,  0.2114,  0.0169],\n",
       "         [ 0.4960,  0.2433, -1.3676,  ...,  0.5660,  0.2107,  0.0168],\n",
       "         [ 0.4950,  0.2433, -1.3637,  ...,  0.5651,  0.2100,  0.0170]])]"
      ]
     },
     "execution_count": 551,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the sequences\n",
    "import torch\n",
    "sequences = load_keypoint_sequences(file_paths)\n",
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40, 160, 1662])\n"
     ]
    }
   ],
   "source": [
    "# Pad the sequences to the same length\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "padded_sequences = pad_sequence(sequences, batch_first=True)\n",
    "pad_sequence\n",
    "print(padded_sequences.shape) # (batch_size, max_sequence_length, num_keypoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['กฎกระทรวง',\n",
       " 'กฎหมายรัฐธรรมนูญ',\n",
       " 'กรมอนามัย',\n",
       " 'กรรม',\n",
       " 'กรรมสิทธิ์',\n",
       " 'กระโดด',\n",
       " 'กล้วยบวชชี',\n",
       " 'กล้วยเชื่อม',\n",
       " 'กังวล',\n",
       " 'กีฬา',\n",
       " 'น้อง',\n",
       " 'เขิน',\n",
       " 'เขื่อนดิน',\n",
       " 'เขื่อนสิริกิติ์',\n",
       " 'เข้าใจผิด',\n",
       " 'เคย',\n",
       " 'เครียด',\n",
       " 'เครื่องปั่นดิน',\n",
       " 'เครื่องหมายการค้า',\n",
       " 'เจอ',\n",
       " 'เจ้าหนี้',\n",
       " 'เช่าซื้อ',\n",
       " 'เช่าทรัพย์',\n",
       " 'เซอร์เบีย',\n",
       " 'เซเนกัล',\n",
       " 'เซ็ง',\n",
       " 'เดิน',\n",
       " 'เดิมพัน',\n",
       " 'เพลีย',\n",
       " 'เมื่อย',\n",
       " 'เม็กซิโก',\n",
       " 'เฮโรอีน',\n",
       " 'แกมเบีย',\n",
       " 'แซมเบีย',\n",
       " 'โกหก',\n",
       " 'โจทก์',\n",
       " 'โชจู',\n",
       " 'ใกล้',\n",
       " 'ไดโนเสาร์',\n",
       " 'ไอซ์']"
      ]
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [action.split(\".\")[0] for action in actions]\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "       34, 35, 36, 37, 38, 39], dtype=int64)"
      ]
     },
     "execution_count": 554,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "labels = le.fit_transform(labels)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# Create a custom dataset\n",
    "class KeypointDataset(Dataset):\n",
    "    def __init__(self, file_paths, labels):\n",
    "        self.file_paths = file_paths\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        keypoints = np.load(self.file_paths[idx])\n",
    "        label = self.labels[idx]\n",
    "        return torch.tensor(keypoints, dtype=torch.float32), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset\n",
    "dataset = KeypointDataset(file_paths, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Data for different actions/กฎกระทรวง.mp4/กฎกระทรวง.npy', 'Data for different actions/กฎหมายรัฐธรรมนูญ.mp4/กฎหมายรัฐธรรมนูญ.npy', 'Data for different actions/กรมอนามัย.mp4/กรมอนามัย.npy', 'Data for different actions/กรรม.mp4/กรรม.npy', 'Data for different actions/กรรมสิทธิ์.mp4/กรรมสิทธิ์.npy', 'Data for different actions/กระโดด.mp4/กระโดด.npy', 'Data for different actions/กล้วยบวชชี.mp4/กล้วยบวชชี.npy', 'Data for different actions/กล้วยเชื่อม.mp4/กล้วยเชื่อม.npy', 'Data for different actions/กังวล.mp4/กังวล.npy', 'Data for different actions/กีฬา.mp4/กีฬา.npy', 'Data for different actions/น้อง.mp4/น้อง.npy', 'Data for different actions/เขิน.mp4/เขิน.npy', 'Data for different actions/เขื่อนดิน.mp4/เขื่อนดิน.npy', 'Data for different actions/เขื่อนสิริกิติ์.mp4/เขื่อนสิริกิติ์.npy', 'Data for different actions/เข้าใจผิด.mp4/เข้าใจผิด.npy', 'Data for different actions/เคย.mp4/เคย.npy', 'Data for different actions/เครียด.mp4/เครียด.npy', 'Data for different actions/เครื่องปั่นดิน.mp4/เครื่องปั่นดิน.npy', 'Data for different actions/เครื่องหมายการค้า.mp4/เครื่องหมายการค้า.npy', 'Data for different actions/เจอ.mp4/เจอ.npy', 'Data for different actions/เจ้าหนี้.mp4/เจ้าหนี้.npy', 'Data for different actions/เช่าซื้อ.mp4/เช่าซื้อ.npy', 'Data for different actions/เช่าทรัพย์.mp4/เช่าทรัพย์.npy', 'Data for different actions/เซอร์เบีย.mp4/เซอร์เบีย.npy', 'Data for different actions/เซเนกัล.mp4/เซเนกัล.npy', 'Data for different actions/เซ็ง.mp4/เซ็ง.npy', 'Data for different actions/เดิน.mp4/เดิน.npy', 'Data for different actions/เดิมพัน.mp4/เดิมพัน.npy', 'Data for different actions/เพลีย.mp4/เพลีย.npy', 'Data for different actions/เมื่อย.mp4/เมื่อย.npy', 'Data for different actions/เม็กซิโก.mp4/เม็กซิโก.npy', 'Data for different actions/เฮโรอีน.mp4/เฮโรอีน.npy', 'Data for different actions/แกมเบีย.mp4/แกมเบีย.npy', 'Data for different actions/แซมเบีย.mp4/แซมเบีย.npy', 'Data for different actions/โกหก.mp4/โกหก.npy', 'Data for different actions/โจทก์.mp4/โจทก์.npy', 'Data for different actions/โชจู.mp4/โชจู.npy', 'Data for different actions/ใกล้.mp4/ใกล้.npy', 'Data for different actions/ไดโนเสาร์.mp4/ไดโนเสาร์.npy', 'Data for different actions/ไอซ์.mp4/ไอซ์.npy']\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]\n"
     ]
    }
   ],
   "source": [
    "print(dataset.file_paths)\n",
    "print(dataset.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collate function for padding\n",
    "def collate_fn(batch):\n",
    "    sequences, labels = zip(*batch)\n",
    "    padded_sequences = pad_sequence(sequences, batch_first=True)\n",
    "    return padded_sequences, torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x1407ac89e50>"
      ]
     },
     "execution_count": 559,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the DataLoader\n",
    "batch_size = 4\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 560,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set device (use GPU if available)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "class AttentionLayer(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(AttentionLayer, self).__init__()\n",
    "        self.attention_weights = nn.Linear(hidden_size, 1, bias=False)\n",
    "\n",
    "    def forward(self, lstm_output):\n",
    "        # lstm_output: (batch_size, sequence_length, hidden_size)\n",
    "        attention_scores = self.attention_weights(lstm_output)  # (batch_size, sequence_length, 1)\n",
    "        attention_weights = torch.softmax(attention_scores, dim=1)  # (batch_size, sequence_length, 1)\n",
    "        weighted_output = torch.sum(lstm_output * attention_weights, dim=1)  # (batch_size, hidden_size)\n",
    "        return weighted_output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes,dropout):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.pool = nn.MaxPool2d(kernel_size=(2,1), stride=1)\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.attention = AttentionLayer(hidden_size)\n",
    "        self.fc1 = nn.Linear(hidden_size, 256)\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        # c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        \n",
    "        # Apply pooling before LSTM\n",
    "        x = self.pool(x)\n",
    "\n",
    "        # Forward propagate the LSTM\n",
    "        lstm_output, _ = self.lstm(self.dropout(x))\n",
    "\n",
    "        # Apply attention to the LSTM output\n",
    "        attention_output, attention_weights = self.attention(lstm_output)\n",
    "\n",
    "        # Classification based on attention output\n",
    "        out = self.fc1(attention_output)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model, loss function, and optimizer\n",
    "model = LSTMModel(input_size=1662, hidden_size=256, num_layers=2, num_classes=40, dropout=0.5).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()  # For multi-class classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-This Model Has 2568744 (Approximately 2 Million) Parameters!\n"
     ]
    }
   ],
   "source": [
    "# Let's see how many Parameters our Model has!\n",
    "num_model_params = 0\n",
    "for param in model.parameters():\n",
    "    num_model_params += param.flatten().shape[0]\n",
    "\n",
    "print(\"-This Model Has %d (Approximately %d Million) Parameters!\" % (num_model_params, num_model_params//1e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/900], Loss: 3.8469 , Accuracy : 0.00%, F1 Score: 0.00, Recall: 0.00\n",
      "Epoch [2/900], Loss: 3.7933 , Accuracy : 2.50%, F1 Score: 0.00, Recall: 0.01\n",
      "Epoch [3/900], Loss: 3.7144 , Accuracy : 2.50%, F1 Score: 0.00, Recall: 0.02\n",
      "Epoch [4/900], Loss: 3.7006 , Accuracy : 2.50%, F1 Score: 0.00, Recall: 0.02\n",
      "Epoch [5/900], Loss: 3.7025 , Accuracy : 0.00%, F1 Score: 0.00, Recall: 0.01\n",
      "Epoch [6/900], Loss: 3.5913 , Accuracy : 2.50%, F1 Score: 0.01, Recall: 0.02\n",
      "Epoch [7/900], Loss: 3.7733 , Accuracy : 5.00%, F1 Score: 0.01, Recall: 0.02\n",
      "Epoch [8/900], Loss: 4.0240 , Accuracy : 2.50%, F1 Score: 0.01, Recall: 0.02\n",
      "Epoch [9/900], Loss: 3.5889 , Accuracy : 2.50%, F1 Score: 0.01, Recall: 0.02\n",
      "Epoch [10/900], Loss: 3.5410 , Accuracy : 2.50%, F1 Score: 0.01, Recall: 0.02\n",
      "Epoch [11/900], Loss: 2.9606 , Accuracy : 5.00%, F1 Score: 0.01, Recall: 0.03\n",
      "Epoch [12/900], Loss: 3.5367 , Accuracy : 2.50%, F1 Score: 0.01, Recall: 0.03\n",
      "Epoch [13/900], Loss: 3.5849 , Accuracy : 2.50%, F1 Score: 0.01, Recall: 0.03\n",
      "Epoch [14/900], Loss: 3.3053 , Accuracy : 2.50%, F1 Score: 0.01, Recall: 0.03\n",
      "Epoch [15/900], Loss: 3.7452 , Accuracy : 5.00%, F1 Score: 0.01, Recall: 0.03\n",
      "Epoch [16/900], Loss: 3.4142 , Accuracy : 2.50%, F1 Score: 0.01, Recall: 0.03\n",
      "Epoch [17/900], Loss: 3.6353 , Accuracy : 5.00%, F1 Score: 0.01, Recall: 0.03\n",
      "Epoch [18/900], Loss: 3.5609 , Accuracy : 5.00%, F1 Score: 0.01, Recall: 0.03\n",
      "Epoch [19/900], Loss: 3.5933 , Accuracy : 2.50%, F1 Score: 0.01, Recall: 0.03\n",
      "Epoch [20/900], Loss: 3.4830 , Accuracy : 0.00%, F1 Score: 0.01, Recall: 0.03\n",
      "Epoch [21/900], Loss: 3.1570 , Accuracy : 2.50%, F1 Score: 0.01, Recall: 0.03\n",
      "Epoch [22/900], Loss: 3.1816 , Accuracy : 2.50%, F1 Score: 0.01, Recall: 0.03\n",
      "Epoch [23/900], Loss: 3.1798 , Accuracy : 5.00%, F1 Score: 0.01, Recall: 0.03\n",
      "Epoch [24/900], Loss: 3.7656 , Accuracy : 2.50%, F1 Score: 0.02, Recall: 0.03\n",
      "Epoch [25/900], Loss: 4.7324 , Accuracy : 7.50%, F1 Score: 0.02, Recall: 0.03\n",
      "Epoch [26/900], Loss: 3.0261 , Accuracy : 2.50%, F1 Score: 0.02, Recall: 0.03\n",
      "Epoch [27/900], Loss: 3.4467 , Accuracy : 0.00%, F1 Score: 0.02, Recall: 0.03\n",
      "Epoch [28/900], Loss: 2.9404 , Accuracy : 10.00%, F1 Score: 0.02, Recall: 0.03\n",
      "Epoch [29/900], Loss: 2.6627 , Accuracy : 10.00%, F1 Score: 0.02, Recall: 0.03\n",
      "Epoch [30/900], Loss: 3.2587 , Accuracy : 2.50%, F1 Score: 0.02, Recall: 0.03\n",
      "Epoch [31/900], Loss: 2.8490 , Accuracy : 7.50%, F1 Score: 0.02, Recall: 0.03\n",
      "Epoch [32/900], Loss: 3.0645 , Accuracy : 12.50%, F1 Score: 0.03, Recall: 0.04\n",
      "Epoch [33/900], Loss: 2.8861 , Accuracy : 7.50%, F1 Score: 0.03, Recall: 0.04\n",
      "Epoch [34/900], Loss: 3.1027 , Accuracy : 12.50%, F1 Score: 0.03, Recall: 0.04\n",
      "Epoch [35/900], Loss: 2.9250 , Accuracy : 10.00%, F1 Score: 0.03, Recall: 0.04\n",
      "Epoch [36/900], Loss: 2.9870 , Accuracy : 10.00%, F1 Score: 0.03, Recall: 0.04\n",
      "Epoch [37/900], Loss: 2.1085 , Accuracy : 17.50%, F1 Score: 0.04, Recall: 0.05\n",
      "Epoch [38/900], Loss: 4.7920 , Accuracy : 12.50%, F1 Score: 0.04, Recall: 0.05\n",
      "Epoch [39/900], Loss: 2.7619 , Accuracy : 15.00%, F1 Score: 0.04, Recall: 0.05\n",
      "Epoch [40/900], Loss: 2.0347 , Accuracy : 17.50%, F1 Score: 0.05, Recall: 0.06\n",
      "Epoch [41/900], Loss: 4.4256 , Accuracy : 12.50%, F1 Score: 0.05, Recall: 0.06\n",
      "Epoch [42/900], Loss: 2.7554 , Accuracy : 15.00%, F1 Score: 0.05, Recall: 0.06\n",
      "Epoch [43/900], Loss: 2.4749 , Accuracy : 17.50%, F1 Score: 0.05, Recall: 0.06\n",
      "Epoch [44/900], Loss: 2.2349 , Accuracy : 12.50%, F1 Score: 0.06, Recall: 0.06\n",
      "Epoch [45/900], Loss: 2.5311 , Accuracy : 17.50%, F1 Score: 0.06, Recall: 0.07\n",
      "Epoch [46/900], Loss: 2.0605 , Accuracy : 20.00%, F1 Score: 0.06, Recall: 0.07\n",
      "Epoch [47/900], Loss: 2.6183 , Accuracy : 12.50%, F1 Score: 0.06, Recall: 0.07\n",
      "Epoch [48/900], Loss: 2.7594 , Accuracy : 12.50%, F1 Score: 0.06, Recall: 0.07\n",
      "Epoch [49/900], Loss: 2.6603 , Accuracy : 10.00%, F1 Score: 0.06, Recall: 0.07\n",
      "Epoch [50/900], Loss: 3.0700 , Accuracy : 17.50%, F1 Score: 0.06, Recall: 0.07\n",
      "Epoch [51/900], Loss: 2.1894 , Accuracy : 22.50%, F1 Score: 0.07, Recall: 0.08\n",
      "Epoch [52/900], Loss: 3.2231 , Accuracy : 22.50%, F1 Score: 0.07, Recall: 0.08\n",
      "Epoch [53/900], Loss: 2.7080 , Accuracy : 20.00%, F1 Score: 0.07, Recall: 0.08\n",
      "Epoch [54/900], Loss: 2.6268 , Accuracy : 25.00%, F1 Score: 0.07, Recall: 0.09\n",
      "Epoch [55/900], Loss: 2.2027 , Accuracy : 27.50%, F1 Score: 0.08, Recall: 0.09\n",
      "Epoch [56/900], Loss: 2.0503 , Accuracy : 17.50%, F1 Score: 0.08, Recall: 0.09\n",
      "Epoch [57/900], Loss: 2.2553 , Accuracy : 15.00%, F1 Score: 0.08, Recall: 0.09\n",
      "Epoch [58/900], Loss: 2.4506 , Accuracy : 12.50%, F1 Score: 0.08, Recall: 0.09\n",
      "Epoch [59/900], Loss: 2.2421 , Accuracy : 12.50%, F1 Score: 0.08, Recall: 0.09\n",
      "Epoch [60/900], Loss: 1.4520 , Accuracy : 25.00%, F1 Score: 0.08, Recall: 0.10\n",
      "Epoch [61/900], Loss: 2.0395 , Accuracy : 20.00%, F1 Score: 0.08, Recall: 0.10\n",
      "Epoch [62/900], Loss: 2.3417 , Accuracy : 15.00%, F1 Score: 0.09, Recall: 0.10\n",
      "Epoch [63/900], Loss: 2.3552 , Accuracy : 25.00%, F1 Score: 0.09, Recall: 0.10\n",
      "Epoch [64/900], Loss: 2.2074 , Accuracy : 22.50%, F1 Score: 0.09, Recall: 0.10\n",
      "Epoch [65/900], Loss: 2.2606 , Accuracy : 20.00%, F1 Score: 0.09, Recall: 0.10\n",
      "Epoch [66/900], Loss: 2.0076 , Accuracy : 22.50%, F1 Score: 0.09, Recall: 0.11\n",
      "Epoch [67/900], Loss: 2.1541 , Accuracy : 22.50%, F1 Score: 0.09, Recall: 0.11\n",
      "Epoch [68/900], Loss: 1.8852 , Accuracy : 25.00%, F1 Score: 0.10, Recall: 0.11\n",
      "Epoch [69/900], Loss: 4.9888 , Accuracy : 15.00%, F1 Score: 0.10, Recall: 0.11\n",
      "Epoch [70/900], Loss: 1.8873 , Accuracy : 17.50%, F1 Score: 0.10, Recall: 0.11\n",
      "Epoch [71/900], Loss: 1.8628 , Accuracy : 32.50%, F1 Score: 0.10, Recall: 0.11\n",
      "Epoch [72/900], Loss: 1.8238 , Accuracy : 32.50%, F1 Score: 0.10, Recall: 0.12\n",
      "Epoch [73/900], Loss: 2.0179 , Accuracy : 32.50%, F1 Score: 0.11, Recall: 0.12\n",
      "Epoch [74/900], Loss: 2.3714 , Accuracy : 35.00%, F1 Score: 0.11, Recall: 0.12\n",
      "Epoch [75/900], Loss: 3.3634 , Accuracy : 32.50%, F1 Score: 0.11, Recall: 0.13\n",
      "Epoch [76/900], Loss: 1.8703 , Accuracy : 27.50%, F1 Score: 0.11, Recall: 0.13\n",
      "Epoch [77/900], Loss: 2.1075 , Accuracy : 42.50%, F1 Score: 0.12, Recall: 0.13\n",
      "Epoch [78/900], Loss: 1.2145 , Accuracy : 25.00%, F1 Score: 0.12, Recall: 0.13\n",
      "Epoch [79/900], Loss: 1.2822 , Accuracy : 30.00%, F1 Score: 0.12, Recall: 0.13\n",
      "Epoch [80/900], Loss: 2.8718 , Accuracy : 32.50%, F1 Score: 0.12, Recall: 0.14\n",
      "Epoch [81/900], Loss: 1.7148 , Accuracy : 37.50%, F1 Score: 0.13, Recall: 0.14\n",
      "Epoch [82/900], Loss: 2.0528 , Accuracy : 32.50%, F1 Score: 0.13, Recall: 0.14\n",
      "Epoch [83/900], Loss: 1.8182 , Accuracy : 42.50%, F1 Score: 0.13, Recall: 0.15\n",
      "Epoch [84/900], Loss: 2.6615 , Accuracy : 32.50%, F1 Score: 0.13, Recall: 0.15\n",
      "Epoch [85/900], Loss: 2.2225 , Accuracy : 45.00%, F1 Score: 0.14, Recall: 0.15\n",
      "Epoch [86/900], Loss: 2.7553 , Accuracy : 37.50%, F1 Score: 0.14, Recall: 0.15\n",
      "Epoch [87/900], Loss: 1.7570 , Accuracy : 25.00%, F1 Score: 0.14, Recall: 0.16\n",
      "Epoch [88/900], Loss: 1.4543 , Accuracy : 30.00%, F1 Score: 0.14, Recall: 0.16\n",
      "Epoch [89/900], Loss: 1.8381 , Accuracy : 42.50%, F1 Score: 0.15, Recall: 0.16\n",
      "Epoch [90/900], Loss: 1.8104 , Accuracy : 37.50%, F1 Score: 0.15, Recall: 0.16\n",
      "Epoch [91/900], Loss: 1.8374 , Accuracy : 45.00%, F1 Score: 0.15, Recall: 0.17\n",
      "Epoch [92/900], Loss: 1.8317 , Accuracy : 52.50%, F1 Score: 0.16, Recall: 0.17\n",
      "Epoch [93/900], Loss: 1.7513 , Accuracy : 42.50%, F1 Score: 0.16, Recall: 0.17\n",
      "Epoch [94/900], Loss: 1.1010 , Accuracy : 45.00%, F1 Score: 0.16, Recall: 0.17\n",
      "Epoch [95/900], Loss: 1.3135 , Accuracy : 55.00%, F1 Score: 0.17, Recall: 0.18\n",
      "Epoch [96/900], Loss: 1.2840 , Accuracy : 47.50%, F1 Score: 0.17, Recall: 0.18\n",
      "Epoch [97/900], Loss: 1.1696 , Accuracy : 45.00%, F1 Score: 0.17, Recall: 0.18\n",
      "Epoch [98/900], Loss: 1.2777 , Accuracy : 47.50%, F1 Score: 0.17, Recall: 0.19\n",
      "Epoch [99/900], Loss: 1.0692 , Accuracy : 57.50%, F1 Score: 0.18, Recall: 0.19\n",
      "Epoch [100/900], Loss: 1.7544 , Accuracy : 42.50%, F1 Score: 0.18, Recall: 0.19\n",
      "Epoch [101/900], Loss: 1.6273 , Accuracy : 37.50%, F1 Score: 0.18, Recall: 0.20\n",
      "Epoch [102/900], Loss: 1.7577 , Accuracy : 35.00%, F1 Score: 0.18, Recall: 0.20\n",
      "Epoch [103/900], Loss: 2.3851 , Accuracy : 27.50%, F1 Score: 0.19, Recall: 0.20\n",
      "Epoch [104/900], Loss: 1.2904 , Accuracy : 40.00%, F1 Score: 0.19, Recall: 0.20\n",
      "Epoch [105/900], Loss: 1.5206 , Accuracy : 45.00%, F1 Score: 0.19, Recall: 0.20\n",
      "Epoch [106/900], Loss: 1.2868 , Accuracy : 42.50%, F1 Score: 0.19, Recall: 0.20\n",
      "Epoch [107/900], Loss: 2.1955 , Accuracy : 40.00%, F1 Score: 0.19, Recall: 0.21\n",
      "Epoch [108/900], Loss: 1.3813 , Accuracy : 25.00%, F1 Score: 0.19, Recall: 0.21\n",
      "Epoch [109/900], Loss: 2.5491 , Accuracy : 37.50%, F1 Score: 0.20, Recall: 0.21\n",
      "Epoch [110/900], Loss: 2.1316 , Accuracy : 35.00%, F1 Score: 0.20, Recall: 0.21\n",
      "Epoch [111/900], Loss: 1.5328 , Accuracy : 45.00%, F1 Score: 0.20, Recall: 0.21\n",
      "Epoch [112/900], Loss: 1.7733 , Accuracy : 47.50%, F1 Score: 0.20, Recall: 0.21\n",
      "Epoch [113/900], Loss: 1.9034 , Accuracy : 42.50%, F1 Score: 0.20, Recall: 0.22\n",
      "Epoch [114/900], Loss: 1.5137 , Accuracy : 47.50%, F1 Score: 0.20, Recall: 0.22\n",
      "Epoch [115/900], Loss: 2.6196 , Accuracy : 45.00%, F1 Score: 0.21, Recall: 0.22\n",
      "Epoch [116/900], Loss: 1.6295 , Accuracy : 52.50%, F1 Score: 0.21, Recall: 0.22\n",
      "Epoch [117/900], Loss: 3.0074 , Accuracy : 52.50%, F1 Score: 0.21, Recall: 0.23\n",
      "Epoch [118/900], Loss: 1.2650 , Accuracy : 62.50%, F1 Score: 0.21, Recall: 0.23\n",
      "Epoch [119/900], Loss: 1.6460 , Accuracy : 67.50%, F1 Score: 0.22, Recall: 0.23\n",
      "Epoch [120/900], Loss: 1.3235 , Accuracy : 57.50%, F1 Score: 0.22, Recall: 0.24\n",
      "Epoch [121/900], Loss: 2.1307 , Accuracy : 45.00%, F1 Score: 0.22, Recall: 0.24\n",
      "Epoch [122/900], Loss: 1.6515 , Accuracy : 42.50%, F1 Score: 0.23, Recall: 0.24\n",
      "Epoch [123/900], Loss: 0.8547 , Accuracy : 47.50%, F1 Score: 0.23, Recall: 0.24\n",
      "Epoch [124/900], Loss: 1.9268 , Accuracy : 52.50%, F1 Score: 0.23, Recall: 0.24\n",
      "Epoch [125/900], Loss: 1.8319 , Accuracy : 57.50%, F1 Score: 0.23, Recall: 0.25\n",
      "Epoch [126/900], Loss: 1.5324 , Accuracy : 57.50%, F1 Score: 0.23, Recall: 0.25\n",
      "Epoch [127/900], Loss: 1.5879 , Accuracy : 57.50%, F1 Score: 0.24, Recall: 0.25\n",
      "Epoch [128/900], Loss: 1.4371 , Accuracy : 52.50%, F1 Score: 0.24, Recall: 0.25\n",
      "Epoch [129/900], Loss: 1.6695 , Accuracy : 65.00%, F1 Score: 0.24, Recall: 0.26\n",
      "Epoch [130/900], Loss: 1.0574 , Accuracy : 52.50%, F1 Score: 0.24, Recall: 0.26\n",
      "Epoch [131/900], Loss: 0.8853 , Accuracy : 72.50%, F1 Score: 0.25, Recall: 0.26\n",
      "Epoch [132/900], Loss: 0.5541 , Accuracy : 67.50%, F1 Score: 0.25, Recall: 0.26\n",
      "Epoch [133/900], Loss: 0.9697 , Accuracy : 67.50%, F1 Score: 0.26, Recall: 0.27\n",
      "Epoch [134/900], Loss: 1.1489 , Accuracy : 67.50%, F1 Score: 0.26, Recall: 0.27\n",
      "Epoch [135/900], Loss: 1.3600 , Accuracy : 62.50%, F1 Score: 0.26, Recall: 0.27\n",
      "Epoch [136/900], Loss: 2.5823 , Accuracy : 65.00%, F1 Score: 0.26, Recall: 0.28\n",
      "Epoch [137/900], Loss: 1.0449 , Accuracy : 62.50%, F1 Score: 0.27, Recall: 0.28\n",
      "Epoch [138/900], Loss: 1.0209 , Accuracy : 65.00%, F1 Score: 0.27, Recall: 0.28\n",
      "Epoch [139/900], Loss: 1.1033 , Accuracy : 72.50%, F1 Score: 0.27, Recall: 0.28\n",
      "Epoch [140/900], Loss: 1.4055 , Accuracy : 75.00%, F1 Score: 0.28, Recall: 0.29\n",
      "Epoch [141/900], Loss: 1.2136 , Accuracy : 67.50%, F1 Score: 0.28, Recall: 0.29\n",
      "Epoch [142/900], Loss: 1.6751 , Accuracy : 65.00%, F1 Score: 0.28, Recall: 0.29\n",
      "Epoch [143/900], Loss: 0.9092 , Accuracy : 52.50%, F1 Score: 0.28, Recall: 0.29\n",
      "Epoch [144/900], Loss: 1.0806 , Accuracy : 55.00%, F1 Score: 0.29, Recall: 0.30\n",
      "Epoch [145/900], Loss: 1.1031 , Accuracy : 62.50%, F1 Score: 0.29, Recall: 0.30\n",
      "Epoch [146/900], Loss: 1.0839 , Accuracy : 60.00%, F1 Score: 0.29, Recall: 0.30\n",
      "Epoch [147/900], Loss: 1.7965 , Accuracy : 50.00%, F1 Score: 0.29, Recall: 0.30\n",
      "Epoch [148/900], Loss: 1.3007 , Accuracy : 52.50%, F1 Score: 0.29, Recall: 0.30\n",
      "Epoch [149/900], Loss: 0.8194 , Accuracy : 60.00%, F1 Score: 0.29, Recall: 0.31\n",
      "Epoch [150/900], Loss: 1.2706 , Accuracy : 67.50%, F1 Score: 0.30, Recall: 0.31\n",
      "Epoch [151/900], Loss: 1.3772 , Accuracy : 45.00%, F1 Score: 0.30, Recall: 0.31\n",
      "Epoch [152/900], Loss: 1.5707 , Accuracy : 50.00%, F1 Score: 0.30, Recall: 0.31\n",
      "Epoch [153/900], Loss: 1.7394 , Accuracy : 57.50%, F1 Score: 0.30, Recall: 0.31\n",
      "Epoch [154/900], Loss: 0.8437 , Accuracy : 62.50%, F1 Score: 0.30, Recall: 0.31\n",
      "Epoch [155/900], Loss: 1.9135 , Accuracy : 60.00%, F1 Score: 0.31, Recall: 0.32\n",
      "Epoch [156/900], Loss: 0.2799 , Accuracy : 70.00%, F1 Score: 0.31, Recall: 0.32\n",
      "Epoch [157/900], Loss: 0.8826 , Accuracy : 67.50%, F1 Score: 0.31, Recall: 0.32\n",
      "Epoch [158/900], Loss: 2.2248 , Accuracy : 52.50%, F1 Score: 0.31, Recall: 0.32\n",
      "Epoch [159/900], Loss: 1.9378 , Accuracy : 72.50%, F1 Score: 0.31, Recall: 0.32\n",
      "Epoch [160/900], Loss: 0.5459 , Accuracy : 67.50%, F1 Score: 0.32, Recall: 0.33\n",
      "Epoch [161/900], Loss: 0.7874 , Accuracy : 70.00%, F1 Score: 0.32, Recall: 0.33\n",
      "Epoch [162/900], Loss: 1.4044 , Accuracy : 72.50%, F1 Score: 0.32, Recall: 0.33\n",
      "Epoch [163/900], Loss: 0.2828 , Accuracy : 77.50%, F1 Score: 0.32, Recall: 0.33\n",
      "Epoch [164/900], Loss: 0.8348 , Accuracy : 75.00%, F1 Score: 0.33, Recall: 0.34\n",
      "Epoch [165/900], Loss: 1.0149 , Accuracy : 70.00%, F1 Score: 0.33, Recall: 0.34\n",
      "Epoch [166/900], Loss: 1.2846 , Accuracy : 62.50%, F1 Score: 0.33, Recall: 0.34\n",
      "Epoch [167/900], Loss: 0.4777 , Accuracy : 75.00%, F1 Score: 0.33, Recall: 0.34\n",
      "Epoch [168/900], Loss: 1.6676 , Accuracy : 65.00%, F1 Score: 0.34, Recall: 0.35\n",
      "Epoch [169/900], Loss: 1.6450 , Accuracy : 57.50%, F1 Score: 0.34, Recall: 0.35\n",
      "Epoch [170/900], Loss: 1.4982 , Accuracy : 70.00%, F1 Score: 0.34, Recall: 0.35\n",
      "Epoch [171/900], Loss: 0.6833 , Accuracy : 67.50%, F1 Score: 0.34, Recall: 0.35\n",
      "Epoch [172/900], Loss: 1.0995 , Accuracy : 67.50%, F1 Score: 0.34, Recall: 0.35\n",
      "Epoch [173/900], Loss: 0.9544 , Accuracy : 72.50%, F1 Score: 0.35, Recall: 0.35\n",
      "Epoch [174/900], Loss: 0.9113 , Accuracy : 75.00%, F1 Score: 0.35, Recall: 0.36\n",
      "Epoch [175/900], Loss: 0.9603 , Accuracy : 70.00%, F1 Score: 0.35, Recall: 0.36\n",
      "Epoch [176/900], Loss: 0.9176 , Accuracy : 62.50%, F1 Score: 0.35, Recall: 0.36\n",
      "Epoch [177/900], Loss: 1.3869 , Accuracy : 52.50%, F1 Score: 0.35, Recall: 0.36\n",
      "Epoch [178/900], Loss: 0.3864 , Accuracy : 67.50%, F1 Score: 0.35, Recall: 0.36\n",
      "Epoch [179/900], Loss: 0.6011 , Accuracy : 67.50%, F1 Score: 0.36, Recall: 0.36\n",
      "Epoch [180/900], Loss: 1.8579 , Accuracy : 65.00%, F1 Score: 0.36, Recall: 0.37\n",
      "Epoch [181/900], Loss: 0.6851 , Accuracy : 62.50%, F1 Score: 0.36, Recall: 0.37\n",
      "Epoch [182/900], Loss: 0.2136 , Accuracy : 70.00%, F1 Score: 0.36, Recall: 0.37\n",
      "Epoch [183/900], Loss: 1.4656 , Accuracy : 75.00%, F1 Score: 0.36, Recall: 0.37\n",
      "Epoch [184/900], Loss: 1.0103 , Accuracy : 70.00%, F1 Score: 0.36, Recall: 0.37\n",
      "Epoch [185/900], Loss: 0.9815 , Accuracy : 77.50%, F1 Score: 0.37, Recall: 0.38\n",
      "Epoch [186/900], Loss: 0.2359 , Accuracy : 75.00%, F1 Score: 0.37, Recall: 0.38\n",
      "Epoch [187/900], Loss: 1.2094 , Accuracy : 75.00%, F1 Score: 0.37, Recall: 0.38\n",
      "Epoch [188/900], Loss: 1.8713 , Accuracy : 75.00%, F1 Score: 0.37, Recall: 0.38\n",
      "Epoch [189/900], Loss: 0.6686 , Accuracy : 77.50%, F1 Score: 0.38, Recall: 0.38\n",
      "Epoch [190/900], Loss: 0.9415 , Accuracy : 60.00%, F1 Score: 0.38, Recall: 0.38\n",
      "Epoch [191/900], Loss: 0.4821 , Accuracy : 55.00%, F1 Score: 0.38, Recall: 0.39\n",
      "Epoch [192/900], Loss: 3.4821 , Accuracy : 65.00%, F1 Score: 0.38, Recall: 0.39\n",
      "Epoch [193/900], Loss: 0.6581 , Accuracy : 72.50%, F1 Score: 0.38, Recall: 0.39\n",
      "Epoch [194/900], Loss: 0.4798 , Accuracy : 67.50%, F1 Score: 0.38, Recall: 0.39\n",
      "Epoch [195/900], Loss: 1.2370 , Accuracy : 80.00%, F1 Score: 0.38, Recall: 0.39\n",
      "Epoch [196/900], Loss: 0.1648 , Accuracy : 82.50%, F1 Score: 0.39, Recall: 0.39\n",
      "Epoch [197/900], Loss: 0.1428 , Accuracy : 80.00%, F1 Score: 0.39, Recall: 0.40\n",
      "Epoch [198/900], Loss: 1.1356 , Accuracy : 80.00%, F1 Score: 0.39, Recall: 0.40\n",
      "Epoch [199/900], Loss: 2.1417 , Accuracy : 55.00%, F1 Score: 0.39, Recall: 0.40\n",
      "Epoch [200/900], Loss: 3.6040 , Accuracy : 30.00%, F1 Score: 0.39, Recall: 0.40\n",
      "Epoch [201/900], Loss: 2.7189 , Accuracy : 50.00%, F1 Score: 0.39, Recall: 0.40\n",
      "Epoch [202/900], Loss: 1.5063 , Accuracy : 52.50%, F1 Score: 0.39, Recall: 0.40\n",
      "Epoch [203/900], Loss: 0.6251 , Accuracy : 50.00%, F1 Score: 0.39, Recall: 0.40\n",
      "Epoch [204/900], Loss: 1.9058 , Accuracy : 65.00%, F1 Score: 0.39, Recall: 0.40\n",
      "Epoch [205/900], Loss: 0.9596 , Accuracy : 65.00%, F1 Score: 0.40, Recall: 0.40\n",
      "Epoch [206/900], Loss: 0.5634 , Accuracy : 70.00%, F1 Score: 0.40, Recall: 0.40\n",
      "Epoch [207/900], Loss: 0.9734 , Accuracy : 75.00%, F1 Score: 0.40, Recall: 0.41\n",
      "Epoch [208/900], Loss: 1.3366 , Accuracy : 65.00%, F1 Score: 0.40, Recall: 0.41\n",
      "Epoch [209/900], Loss: 0.6784 , Accuracy : 75.00%, F1 Score: 0.40, Recall: 0.41\n",
      "Epoch [210/900], Loss: 1.4181 , Accuracy : 77.50%, F1 Score: 0.40, Recall: 0.41\n",
      "Epoch [211/900], Loss: 0.3062 , Accuracy : 77.50%, F1 Score: 0.40, Recall: 0.41\n",
      "Epoch [212/900], Loss: 1.2760 , Accuracy : 82.50%, F1 Score: 0.41, Recall: 0.41\n",
      "Epoch [213/900], Loss: 0.8125 , Accuracy : 80.00%, F1 Score: 0.41, Recall: 0.42\n",
      "Epoch [214/900], Loss: 0.2825 , Accuracy : 62.50%, F1 Score: 0.41, Recall: 0.42\n",
      "Epoch [215/900], Loss: 1.3502 , Accuracy : 70.00%, F1 Score: 0.41, Recall: 0.42\n",
      "Epoch [216/900], Loss: 0.8556 , Accuracy : 60.00%, F1 Score: 0.41, Recall: 0.42\n",
      "Epoch [217/900], Loss: 0.1325 , Accuracy : 70.00%, F1 Score: 0.41, Recall: 0.42\n",
      "Epoch [218/900], Loss: 0.8010 , Accuracy : 80.00%, F1 Score: 0.41, Recall: 0.42\n",
      "Epoch [219/900], Loss: 0.7966 , Accuracy : 82.50%, F1 Score: 0.42, Recall: 0.42\n",
      "Epoch [220/900], Loss: 0.1289 , Accuracy : 85.00%, F1 Score: 0.42, Recall: 0.43\n",
      "Epoch [221/900], Loss: 1.4752 , Accuracy : 60.00%, F1 Score: 0.42, Recall: 0.43\n",
      "Epoch [222/900], Loss: 0.9142 , Accuracy : 52.50%, F1 Score: 0.42, Recall: 0.43\n",
      "Epoch [223/900], Loss: 1.6327 , Accuracy : 55.00%, F1 Score: 0.42, Recall: 0.43\n",
      "Epoch [224/900], Loss: 1.3095 , Accuracy : 57.50%, F1 Score: 0.42, Recall: 0.43\n",
      "Epoch [225/900], Loss: 1.4013 , Accuracy : 65.00%, F1 Score: 0.42, Recall: 0.43\n",
      "Epoch [226/900], Loss: 0.6823 , Accuracy : 67.50%, F1 Score: 0.42, Recall: 0.43\n",
      "Epoch [227/900], Loss: 1.9724 , Accuracy : 70.00%, F1 Score: 0.42, Recall: 0.43\n",
      "Epoch [228/900], Loss: 0.2611 , Accuracy : 77.50%, F1 Score: 0.43, Recall: 0.43\n",
      "Epoch [229/900], Loss: 0.3254 , Accuracy : 70.00%, F1 Score: 0.43, Recall: 0.43\n",
      "Epoch [230/900], Loss: 0.2227 , Accuracy : 75.00%, F1 Score: 0.43, Recall: 0.44\n",
      "Epoch [231/900], Loss: 0.7492 , Accuracy : 70.00%, F1 Score: 0.43, Recall: 0.44\n",
      "Epoch [232/900], Loss: 0.3618 , Accuracy : 65.00%, F1 Score: 0.43, Recall: 0.44\n",
      "Epoch [233/900], Loss: 13.2496 , Accuracy : 62.50%, F1 Score: 0.43, Recall: 0.44\n",
      "Epoch [234/900], Loss: 11.3591 , Accuracy : 0.00%, F1 Score: 0.43, Recall: 0.44\n",
      "Epoch [235/900], Loss: 1.5257 , Accuracy : 0.00%, F1 Score: 0.43, Recall: 0.43\n",
      "Epoch [236/900], Loss: 3.1523 , Accuracy : 27.50%, F1 Score: 0.43, Recall: 0.43\n",
      "Epoch [237/900], Loss: 2.5760 , Accuracy : 22.50%, F1 Score: 0.43, Recall: 0.43\n",
      "Epoch [238/900], Loss: 2.5231 , Accuracy : 30.00%, F1 Score: 0.43, Recall: 0.43\n",
      "Epoch [239/900], Loss: 1.1479 , Accuracy : 32.50%, F1 Score: 0.42, Recall: 0.43\n",
      "Epoch [240/900], Loss: 2.8526 , Accuracy : 45.00%, F1 Score: 0.42, Recall: 0.43\n",
      "Epoch [241/900], Loss: 1.7317 , Accuracy : 35.00%, F1 Score: 0.42, Recall: 0.43\n",
      "Epoch [242/900], Loss: 1.7242 , Accuracy : 35.00%, F1 Score: 0.42, Recall: 0.43\n",
      "Epoch [243/900], Loss: 1.4171 , Accuracy : 52.50%, F1 Score: 0.42, Recall: 0.43\n",
      "Epoch [244/900], Loss: 0.8740 , Accuracy : 50.00%, F1 Score: 0.42, Recall: 0.43\n",
      "Epoch [245/900], Loss: 1.0184 , Accuracy : 62.50%, F1 Score: 0.43, Recall: 0.43\n",
      "Epoch [246/900], Loss: 1.2821 , Accuracy : 62.50%, F1 Score: 0.43, Recall: 0.43\n",
      "Epoch [247/900], Loss: 1.7150 , Accuracy : 62.50%, F1 Score: 0.43, Recall: 0.43\n",
      "Epoch [248/900], Loss: 1.2550 , Accuracy : 77.50%, F1 Score: 0.43, Recall: 0.44\n",
      "Epoch [249/900], Loss: 0.9211 , Accuracy : 70.00%, F1 Score: 0.43, Recall: 0.44\n",
      "Epoch [250/900], Loss: 1.3518 , Accuracy : 72.50%, F1 Score: 0.43, Recall: 0.44\n",
      "Epoch [251/900], Loss: 0.8656 , Accuracy : 67.50%, F1 Score: 0.43, Recall: 0.44\n",
      "Epoch [252/900], Loss: 0.8556 , Accuracy : 75.00%, F1 Score: 0.43, Recall: 0.44\n",
      "Epoch [253/900], Loss: 1.1385 , Accuracy : 70.00%, F1 Score: 0.43, Recall: 0.44\n",
      "Epoch [254/900], Loss: 1.0608 , Accuracy : 67.50%, F1 Score: 0.43, Recall: 0.44\n",
      "Epoch [255/900], Loss: 0.5261 , Accuracy : 72.50%, F1 Score: 0.44, Recall: 0.44\n",
      "Epoch [256/900], Loss: 1.4442 , Accuracy : 67.50%, F1 Score: 0.44, Recall: 0.44\n",
      "Epoch [257/900], Loss: 1.4208 , Accuracy : 70.00%, F1 Score: 0.44, Recall: 0.45\n",
      "Epoch [258/900], Loss: 1.1846 , Accuracy : 80.00%, F1 Score: 0.44, Recall: 0.45\n",
      "Epoch [259/900], Loss: 0.6232 , Accuracy : 67.50%, F1 Score: 0.44, Recall: 0.45\n",
      "Epoch [260/900], Loss: 1.0211 , Accuracy : 80.00%, F1 Score: 0.44, Recall: 0.45\n",
      "Epoch [261/900], Loss: 0.3939 , Accuracy : 77.50%, F1 Score: 0.44, Recall: 0.45\n",
      "Epoch [262/900], Loss: 0.3990 , Accuracy : 75.00%, F1 Score: 0.44, Recall: 0.45\n",
      "Epoch [263/900], Loss: 0.2541 , Accuracy : 77.50%, F1 Score: 0.44, Recall: 0.45\n",
      "Epoch [264/900], Loss: 1.9711 , Accuracy : 70.00%, F1 Score: 0.45, Recall: 0.45\n",
      "Epoch [265/900], Loss: 0.5622 , Accuracy : 70.00%, F1 Score: 0.45, Recall: 0.45\n",
      "Epoch [266/900], Loss: 1.1204 , Accuracy : 77.50%, F1 Score: 0.45, Recall: 0.46\n",
      "Epoch [267/900], Loss: 0.6412 , Accuracy : 72.50%, F1 Score: 0.45, Recall: 0.46\n",
      "Epoch [268/900], Loss: 0.4750 , Accuracy : 75.00%, F1 Score: 0.45, Recall: 0.46\n",
      "Epoch [269/900], Loss: 0.8149 , Accuracy : 77.50%, F1 Score: 0.45, Recall: 0.46\n",
      "Epoch [270/900], Loss: 0.5974 , Accuracy : 75.00%, F1 Score: 0.45, Recall: 0.46\n",
      "Epoch [271/900], Loss: 1.0037 , Accuracy : 70.00%, F1 Score: 0.45, Recall: 0.46\n",
      "Epoch [272/900], Loss: 2.7958 , Accuracy : 55.00%, F1 Score: 0.45, Recall: 0.46\n",
      "Epoch [273/900], Loss: 1.3544 , Accuracy : 45.00%, F1 Score: 0.45, Recall: 0.46\n",
      "Epoch [274/900], Loss: 0.6503 , Accuracy : 60.00%, F1 Score: 0.45, Recall: 0.46\n",
      "Epoch [275/900], Loss: 4.7024 , Accuracy : 55.00%, F1 Score: 0.45, Recall: 0.46\n",
      "Epoch [276/900], Loss: 0.7476 , Accuracy : 62.50%, F1 Score: 0.45, Recall: 0.46\n",
      "Epoch [277/900], Loss: 1.7165 , Accuracy : 60.00%, F1 Score: 0.46, Recall: 0.46\n",
      "Epoch [278/900], Loss: 1.3927 , Accuracy : 70.00%, F1 Score: 0.46, Recall: 0.46\n",
      "Epoch [279/900], Loss: 0.2953 , Accuracy : 77.50%, F1 Score: 0.46, Recall: 0.47\n",
      "Epoch [280/900], Loss: 0.6110 , Accuracy : 70.00%, F1 Score: 0.46, Recall: 0.47\n",
      "Epoch [281/900], Loss: 0.9909 , Accuracy : 75.00%, F1 Score: 0.46, Recall: 0.47\n",
      "Epoch [282/900], Loss: 1.2947 , Accuracy : 77.50%, F1 Score: 0.46, Recall: 0.47\n",
      "Epoch [283/900], Loss: 0.2643 , Accuracy : 77.50%, F1 Score: 0.46, Recall: 0.47\n",
      "Epoch [284/900], Loss: 0.5143 , Accuracy : 80.00%, F1 Score: 0.46, Recall: 0.47\n",
      "Epoch [285/900], Loss: 0.2330 , Accuracy : 75.00%, F1 Score: 0.46, Recall: 0.47\n",
      "Epoch [286/900], Loss: 0.5529 , Accuracy : 72.50%, F1 Score: 0.46, Recall: 0.47\n",
      "Epoch [287/900], Loss: 0.2011 , Accuracy : 85.00%, F1 Score: 0.47, Recall: 0.47\n",
      "Epoch [288/900], Loss: 0.3971 , Accuracy : 75.00%, F1 Score: 0.47, Recall: 0.47\n",
      "Epoch [289/900], Loss: 0.6597 , Accuracy : 72.50%, F1 Score: 0.47, Recall: 0.48\n",
      "Epoch [290/900], Loss: 0.0901 , Accuracy : 77.50%, F1 Score: 0.47, Recall: 0.48\n",
      "Epoch [291/900], Loss: 1.2756 , Accuracy : 67.50%, F1 Score: 0.47, Recall: 0.48\n",
      "Epoch [292/900], Loss: 0.5009 , Accuracy : 77.50%, F1 Score: 0.47, Recall: 0.48\n",
      "Epoch [293/900], Loss: 0.6856 , Accuracy : 72.50%, F1 Score: 0.47, Recall: 0.48\n",
      "Epoch [294/900], Loss: 0.7110 , Accuracy : 77.50%, F1 Score: 0.47, Recall: 0.48\n",
      "Epoch [295/900], Loss: 1.6288 , Accuracy : 82.50%, F1 Score: 0.47, Recall: 0.48\n",
      "Epoch [296/900], Loss: 1.5530 , Accuracy : 77.50%, F1 Score: 0.47, Recall: 0.48\n",
      "Epoch [297/900], Loss: 0.4029 , Accuracy : 77.50%, F1 Score: 0.48, Recall: 0.48\n",
      "Epoch [298/900], Loss: 0.6237 , Accuracy : 65.00%, F1 Score: 0.48, Recall: 0.48\n",
      "Epoch [299/900], Loss: 0.3756 , Accuracy : 70.00%, F1 Score: 0.48, Recall: 0.48\n",
      "Epoch [300/900], Loss: 1.4011 , Accuracy : 62.50%, F1 Score: 0.48, Recall: 0.48\n",
      "Epoch [301/900], Loss: 0.4306 , Accuracy : 60.00%, F1 Score: 0.48, Recall: 0.49\n",
      "Epoch [302/900], Loss: 1.0157 , Accuracy : 70.00%, F1 Score: 0.48, Recall: 0.49\n",
      "Epoch [303/900], Loss: 1.0369 , Accuracy : 77.50%, F1 Score: 0.48, Recall: 0.49\n",
      "Epoch [304/900], Loss: 0.7984 , Accuracy : 85.00%, F1 Score: 0.48, Recall: 0.49\n",
      "Epoch [305/900], Loss: 1.0779 , Accuracy : 80.00%, F1 Score: 0.48, Recall: 0.49\n",
      "Epoch [306/900], Loss: 0.1990 , Accuracy : 77.50%, F1 Score: 0.48, Recall: 0.49\n",
      "Epoch [307/900], Loss: 0.3972 , Accuracy : 77.50%, F1 Score: 0.48, Recall: 0.49\n",
      "Epoch [308/900], Loss: 0.9939 , Accuracy : 72.50%, F1 Score: 0.48, Recall: 0.49\n",
      "Epoch [309/900], Loss: 0.8698 , Accuracy : 72.50%, F1 Score: 0.49, Recall: 0.49\n",
      "Epoch [310/900], Loss: 0.1220 , Accuracy : 82.50%, F1 Score: 0.49, Recall: 0.49\n",
      "Epoch [311/900], Loss: 0.2990 , Accuracy : 82.50%, F1 Score: 0.49, Recall: 0.49\n",
      "Epoch [312/900], Loss: 0.5034 , Accuracy : 87.50%, F1 Score: 0.49, Recall: 0.50\n",
      "Epoch [313/900], Loss: 0.8902 , Accuracy : 87.50%, F1 Score: 0.49, Recall: 0.50\n",
      "Epoch [314/900], Loss: 0.2417 , Accuracy : 92.50%, F1 Score: 0.49, Recall: 0.50\n",
      "Epoch [315/900], Loss: 0.9328 , Accuracy : 85.00%, F1 Score: 0.49, Recall: 0.50\n",
      "Epoch [316/900], Loss: 0.5824 , Accuracy : 75.00%, F1 Score: 0.49, Recall: 0.50\n",
      "Epoch [317/900], Loss: 0.5100 , Accuracy : 80.00%, F1 Score: 0.49, Recall: 0.50\n",
      "Epoch [318/900], Loss: 1.2709 , Accuracy : 80.00%, F1 Score: 0.50, Recall: 0.50\n",
      "Epoch [319/900], Loss: 0.3377 , Accuracy : 80.00%, F1 Score: 0.50, Recall: 0.50\n",
      "Epoch [320/900], Loss: 0.0341 , Accuracy : 80.00%, F1 Score: 0.50, Recall: 0.50\n",
      "Epoch [321/900], Loss: 0.4818 , Accuracy : 82.50%, F1 Score: 0.50, Recall: 0.51\n",
      "Epoch [322/900], Loss: 0.4790 , Accuracy : 82.50%, F1 Score: 0.50, Recall: 0.51\n",
      "Epoch [323/900], Loss: 0.4760 , Accuracy : 85.00%, F1 Score: 0.50, Recall: 0.51\n",
      "Epoch [324/900], Loss: 0.2563 , Accuracy : 82.50%, F1 Score: 0.50, Recall: 0.51\n",
      "Epoch [325/900], Loss: 0.6252 , Accuracy : 85.00%, F1 Score: 0.50, Recall: 0.51\n",
      "Epoch [326/900], Loss: 0.7201 , Accuracy : 87.50%, F1 Score: 0.50, Recall: 0.51\n",
      "Epoch [327/900], Loss: 2.2310 , Accuracy : 80.00%, F1 Score: 0.50, Recall: 0.51\n",
      "Epoch [328/900], Loss: 1.5588 , Accuracy : 77.50%, F1 Score: 0.51, Recall: 0.51\n",
      "Epoch [329/900], Loss: 0.8877 , Accuracy : 85.00%, F1 Score: 0.51, Recall: 0.51\n",
      "Epoch [330/900], Loss: 0.4798 , Accuracy : 92.50%, F1 Score: 0.51, Recall: 0.51\n",
      "Epoch [331/900], Loss: 0.0195 , Accuracy : 90.00%, F1 Score: 0.51, Recall: 0.52\n",
      "Epoch [332/900], Loss: 0.0815 , Accuracy : 92.50%, F1 Score: 0.51, Recall: 0.52\n",
      "Epoch [333/900], Loss: 0.0394 , Accuracy : 90.00%, F1 Score: 0.51, Recall: 0.52\n",
      "Epoch [334/900], Loss: 0.8076 , Accuracy : 92.50%, F1 Score: 0.51, Recall: 0.52\n",
      "Epoch [335/900], Loss: 0.6685 , Accuracy : 90.00%, F1 Score: 0.51, Recall: 0.52\n",
      "Epoch [336/900], Loss: 0.1416 , Accuracy : 97.50%, F1 Score: 0.52, Recall: 0.52\n",
      "Epoch [337/900], Loss: 0.5502 , Accuracy : 85.00%, F1 Score: 0.52, Recall: 0.52\n",
      "Epoch [338/900], Loss: 0.5891 , Accuracy : 97.50%, F1 Score: 0.52, Recall: 0.52\n",
      "Epoch [339/900], Loss: 0.0200 , Accuracy : 90.00%, F1 Score: 0.52, Recall: 0.52\n",
      "Epoch [340/900], Loss: 0.1667 , Accuracy : 87.50%, F1 Score: 0.52, Recall: 0.53\n",
      "Epoch [341/900], Loss: 0.3766 , Accuracy : 87.50%, F1 Score: 0.52, Recall: 0.53\n",
      "Epoch [342/900], Loss: 0.4405 , Accuracy : 90.00%, F1 Score: 0.52, Recall: 0.53\n",
      "Epoch [343/900], Loss: 0.1218 , Accuracy : 97.50%, F1 Score: 0.52, Recall: 0.53\n",
      "Epoch [344/900], Loss: 0.1472 , Accuracy : 97.50%, F1 Score: 0.52, Recall: 0.53\n",
      "Epoch [345/900], Loss: 0.1065 , Accuracy : 92.50%, F1 Score: 0.53, Recall: 0.53\n",
      "Epoch [346/900], Loss: 0.0317 , Accuracy : 95.00%, F1 Score: 0.53, Recall: 0.53\n",
      "Epoch [347/900], Loss: 0.3064 , Accuracy : 97.50%, F1 Score: 0.53, Recall: 0.53\n",
      "Epoch [348/900], Loss: 0.2690 , Accuracy : 97.50%, F1 Score: 0.53, Recall: 0.54\n",
      "Epoch [349/900], Loss: 0.0292 , Accuracy : 95.00%, F1 Score: 0.53, Recall: 0.54\n",
      "Epoch [350/900], Loss: 0.0233 , Accuracy : 92.50%, F1 Score: 0.53, Recall: 0.54\n",
      "Epoch [351/900], Loss: 0.0697 , Accuracy : 90.00%, F1 Score: 0.53, Recall: 0.54\n",
      "Epoch [352/900], Loss: 0.0877 , Accuracy : 97.50%, F1 Score: 0.53, Recall: 0.54\n",
      "Epoch [353/900], Loss: 0.0532 , Accuracy : 95.00%, F1 Score: 0.54, Recall: 0.54\n",
      "Epoch [354/900], Loss: 0.1918 , Accuracy : 97.50%, F1 Score: 0.54, Recall: 0.54\n",
      "Epoch [355/900], Loss: 0.1439 , Accuracy : 97.50%, F1 Score: 0.54, Recall: 0.54\n",
      "Epoch [356/900], Loss: 0.0101 , Accuracy : 97.50%, F1 Score: 0.54, Recall: 0.54\n",
      "Epoch [357/900], Loss: 0.2174 , Accuracy : 97.50%, F1 Score: 0.54, Recall: 0.55\n",
      "Epoch [358/900], Loss: 0.1871 , Accuracy : 100.00%, F1 Score: 0.54, Recall: 0.55\n",
      "Epoch [359/900], Loss: 0.2204 , Accuracy : 97.50%, F1 Score: 0.54, Recall: 0.55\n",
      "Epoch [360/900], Loss: 0.1416 , Accuracy : 95.00%, F1 Score: 0.54, Recall: 0.55\n",
      "Epoch [361/900], Loss: 1.3809 , Accuracy : 82.50%, F1 Score: 0.55, Recall: 0.55\n",
      "Epoch [362/900], Loss: 0.3781 , Accuracy : 90.00%, F1 Score: 0.55, Recall: 0.55\n",
      "Epoch [363/900], Loss: 0.0130 , Accuracy : 85.00%, F1 Score: 0.55, Recall: 0.55\n",
      "Epoch [364/900], Loss: 1.9778 , Accuracy : 80.00%, F1 Score: 0.55, Recall: 0.55\n",
      "Epoch [365/900], Loss: 0.0972 , Accuracy : 90.00%, F1 Score: 0.55, Recall: 0.55\n",
      "Epoch [366/900], Loss: 1.8011 , Accuracy : 85.00%, F1 Score: 0.55, Recall: 0.55\n",
      "Epoch [367/900], Loss: 0.3940 , Accuracy : 85.00%, F1 Score: 0.55, Recall: 0.56\n",
      "Epoch [368/900], Loss: 0.3922 , Accuracy : 87.50%, F1 Score: 0.55, Recall: 0.56\n",
      "Epoch [369/900], Loss: 0.0360 , Accuracy : 85.00%, F1 Score: 0.55, Recall: 0.56\n",
      "Epoch [370/900], Loss: 0.2018 , Accuracy : 90.00%, F1 Score: 0.55, Recall: 0.56\n",
      "Epoch [371/900], Loss: 0.0442 , Accuracy : 95.00%, F1 Score: 0.55, Recall: 0.56\n",
      "Epoch [372/900], Loss: 0.1570 , Accuracy : 97.50%, F1 Score: 0.56, Recall: 0.56\n",
      "Epoch [373/900], Loss: 0.2185 , Accuracy : 97.50%, F1 Score: 0.56, Recall: 0.56\n",
      "Epoch [374/900], Loss: 0.0745 , Accuracy : 97.50%, F1 Score: 0.56, Recall: 0.56\n",
      "Epoch [375/900], Loss: 0.1292 , Accuracy : 97.50%, F1 Score: 0.56, Recall: 0.56\n",
      "Epoch [376/900], Loss: 0.1606 , Accuracy : 100.00%, F1 Score: 0.56, Recall: 0.56\n",
      "Epoch [377/900], Loss: 0.3709 , Accuracy : 82.50%, F1 Score: 0.56, Recall: 0.57\n",
      "Epoch [378/900], Loss: 0.2949 , Accuracy : 85.00%, F1 Score: 0.56, Recall: 0.57\n",
      "Epoch [379/900], Loss: 0.1357 , Accuracy : 82.50%, F1 Score: 0.56, Recall: 0.57\n",
      "Epoch [380/900], Loss: 0.3134 , Accuracy : 75.00%, F1 Score: 0.56, Recall: 0.57\n",
      "Epoch [381/900], Loss: 0.3121 , Accuracy : 82.50%, F1 Score: 0.56, Recall: 0.57\n",
      "Epoch [382/900], Loss: 0.4446 , Accuracy : 87.50%, F1 Score: 0.56, Recall: 0.57\n",
      "Epoch [383/900], Loss: 0.1554 , Accuracy : 95.00%, F1 Score: 0.57, Recall: 0.57\n",
      "Epoch [384/900], Loss: 0.1418 , Accuracy : 92.50%, F1 Score: 0.57, Recall: 0.57\n",
      "Epoch [385/900], Loss: 0.1392 , Accuracy : 92.50%, F1 Score: 0.57, Recall: 0.57\n",
      "Epoch [386/900], Loss: 0.3388 , Accuracy : 95.00%, F1 Score: 0.57, Recall: 0.57\n",
      "Epoch [387/900], Loss: 0.3385 , Accuracy : 100.00%, F1 Score: 0.57, Recall: 0.57\n",
      "Epoch [388/900], Loss: 0.0148 , Accuracy : 100.00%, F1 Score: 0.57, Recall: 0.57\n",
      "Epoch [389/900], Loss: 0.0352 , Accuracy : 97.50%, F1 Score: 0.57, Recall: 0.58\n",
      "Epoch [390/900], Loss: 0.0898 , Accuracy : 100.00%, F1 Score: 0.57, Recall: 0.58\n",
      "Epoch [391/900], Loss: 0.1122 , Accuracy : 95.00%, F1 Score: 0.57, Recall: 0.58\n",
      "Epoch [392/900], Loss: 0.0567 , Accuracy : 97.50%, F1 Score: 0.57, Recall: 0.58\n",
      "Epoch [393/900], Loss: 0.0102 , Accuracy : 97.50%, F1 Score: 0.58, Recall: 0.58\n",
      "Epoch [394/900], Loss: 0.0557 , Accuracy : 97.50%, F1 Score: 0.58, Recall: 0.58\n",
      "Epoch [395/900], Loss: 0.0737 , Accuracy : 100.00%, F1 Score: 0.58, Recall: 0.58\n",
      "Epoch [396/900], Loss: 0.0443 , Accuracy : 100.00%, F1 Score: 0.58, Recall: 0.58\n",
      "Epoch [397/900], Loss: 0.1182 , Accuracy : 97.50%, F1 Score: 0.58, Recall: 0.58\n",
      "Epoch [398/900], Loss: 0.5906 , Accuracy : 97.50%, F1 Score: 0.58, Recall: 0.59\n",
      "Epoch [399/900], Loss: 0.4964 , Accuracy : 87.50%, F1 Score: 0.58, Recall: 0.59\n",
      "Epoch [400/900], Loss: 0.0264 , Accuracy : 90.00%, F1 Score: 0.58, Recall: 0.59\n",
      "Epoch [401/900], Loss: 0.4431 , Accuracy : 92.50%, F1 Score: 0.58, Recall: 0.59\n",
      "Epoch [402/900], Loss: 0.0166 , Accuracy : 100.00%, F1 Score: 0.58, Recall: 0.59\n",
      "Epoch [403/900], Loss: 0.0075 , Accuracy : 95.00%, F1 Score: 0.59, Recall: 0.59\n",
      "Epoch [404/900], Loss: 0.3038 , Accuracy : 97.50%, F1 Score: 0.59, Recall: 0.59\n",
      "Epoch [405/900], Loss: 0.1438 , Accuracy : 92.50%, F1 Score: 0.59, Recall: 0.59\n",
      "Epoch [406/900], Loss: 0.0208 , Accuracy : 97.50%, F1 Score: 0.59, Recall: 0.59\n",
      "Epoch [407/900], Loss: 0.0564 , Accuracy : 100.00%, F1 Score: 0.59, Recall: 0.59\n",
      "Epoch [408/900], Loss: 0.0373 , Accuracy : 97.50%, F1 Score: 0.59, Recall: 0.59\n",
      "Epoch [409/900], Loss: 0.1932 , Accuracy : 100.00%, F1 Score: 0.59, Recall: 0.59\n",
      "Epoch [410/900], Loss: 0.0728 , Accuracy : 100.00%, F1 Score: 0.59, Recall: 0.60\n",
      "Epoch [411/900], Loss: 0.0408 , Accuracy : 100.00%, F1 Score: 0.59, Recall: 0.60\n",
      "Epoch [412/900], Loss: 0.1338 , Accuracy : 100.00%, F1 Score: 0.59, Recall: 0.60\n",
      "Epoch [413/900], Loss: 0.0205 , Accuracy : 100.00%, F1 Score: 0.60, Recall: 0.60\n",
      "Epoch [414/900], Loss: 0.0197 , Accuracy : 97.50%, F1 Score: 0.60, Recall: 0.60\n",
      "Epoch [415/900], Loss: 0.0173 , Accuracy : 100.00%, F1 Score: 0.60, Recall: 0.60\n",
      "Epoch [416/900], Loss: 0.0181 , Accuracy : 100.00%, F1 Score: 0.60, Recall: 0.60\n",
      "Epoch [417/900], Loss: 0.0290 , Accuracy : 95.00%, F1 Score: 0.60, Recall: 0.60\n",
      "Epoch [418/900], Loss: 0.1937 , Accuracy : 97.50%, F1 Score: 0.60, Recall: 0.60\n",
      "Epoch [419/900], Loss: 0.0240 , Accuracy : 100.00%, F1 Score: 0.60, Recall: 0.60\n",
      "Epoch [420/900], Loss: 0.0460 , Accuracy : 100.00%, F1 Score: 0.60, Recall: 0.61\n",
      "Epoch [421/900], Loss: 0.0229 , Accuracy : 100.00%, F1 Score: 0.60, Recall: 0.61\n",
      "Epoch [422/900], Loss: 0.0085 , Accuracy : 100.00%, F1 Score: 0.60, Recall: 0.61\n",
      "Epoch [423/900], Loss: 0.2670 , Accuracy : 95.00%, F1 Score: 0.60, Recall: 0.61\n",
      "Epoch [424/900], Loss: 0.0432 , Accuracy : 97.50%, F1 Score: 0.61, Recall: 0.61\n",
      "Epoch [425/900], Loss: 0.0274 , Accuracy : 97.50%, F1 Score: 0.61, Recall: 0.61\n",
      "Epoch [426/900], Loss: 0.0169 , Accuracy : 97.50%, F1 Score: 0.61, Recall: 0.61\n",
      "Epoch [427/900], Loss: 1.1314 , Accuracy : 92.50%, F1 Score: 0.61, Recall: 0.61\n",
      "Epoch [428/900], Loss: 0.2722 , Accuracy : 92.50%, F1 Score: 0.61, Recall: 0.61\n",
      "Epoch [429/900], Loss: 0.4583 , Accuracy : 92.50%, F1 Score: 0.61, Recall: 0.61\n",
      "Epoch [430/900], Loss: 0.0346 , Accuracy : 95.00%, F1 Score: 0.61, Recall: 0.61\n",
      "Epoch [431/900], Loss: 1.3064 , Accuracy : 85.00%, F1 Score: 0.61, Recall: 0.61\n",
      "Epoch [432/900], Loss: 1.6262 , Accuracy : 52.50%, F1 Score: 0.61, Recall: 0.61\n",
      "Epoch [433/900], Loss: 0.8790 , Accuracy : 65.00%, F1 Score: 0.61, Recall: 0.61\n",
      "Epoch [434/900], Loss: 1.0375 , Accuracy : 60.00%, F1 Score: 0.61, Recall: 0.61\n",
      "Epoch [435/900], Loss: 0.9132 , Accuracy : 62.50%, F1 Score: 0.61, Recall: 0.61\n",
      "Epoch [436/900], Loss: 0.6452 , Accuracy : 72.50%, F1 Score: 0.61, Recall: 0.61\n",
      "Epoch [437/900], Loss: 0.2586 , Accuracy : 80.00%, F1 Score: 0.61, Recall: 0.61\n",
      "Epoch [438/900], Loss: 0.3969 , Accuracy : 82.50%, F1 Score: 0.61, Recall: 0.62\n",
      "Epoch [439/900], Loss: 0.5217 , Accuracy : 97.50%, F1 Score: 0.61, Recall: 0.62\n",
      "Epoch [440/900], Loss: 0.1537 , Accuracy : 87.50%, F1 Score: 0.61, Recall: 0.62\n",
      "Epoch [441/900], Loss: 0.8373 , Accuracy : 85.00%, F1 Score: 0.61, Recall: 0.62\n",
      "Epoch [442/900], Loss: 0.3417 , Accuracy : 82.50%, F1 Score: 0.61, Recall: 0.62\n",
      "Epoch [443/900], Loss: 0.4214 , Accuracy : 92.50%, F1 Score: 0.62, Recall: 0.62\n",
      "Epoch [444/900], Loss: 0.1190 , Accuracy : 100.00%, F1 Score: 0.62, Recall: 0.62\n",
      "Epoch [445/900], Loss: 0.2200 , Accuracy : 100.00%, F1 Score: 0.62, Recall: 0.62\n",
      "Epoch [446/900], Loss: 0.0624 , Accuracy : 97.50%, F1 Score: 0.62, Recall: 0.62\n",
      "Epoch [447/900], Loss: 0.0261 , Accuracy : 95.00%, F1 Score: 0.62, Recall: 0.62\n",
      "Epoch [448/900], Loss: 0.1763 , Accuracy : 92.50%, F1 Score: 0.62, Recall: 0.62\n",
      "Epoch [449/900], Loss: 0.5613 , Accuracy : 97.50%, F1 Score: 0.62, Recall: 0.62\n",
      "Epoch [450/900], Loss: 0.0890 , Accuracy : 95.00%, F1 Score: 0.62, Recall: 0.62\n",
      "Epoch [451/900], Loss: 0.0150 , Accuracy : 95.00%, F1 Score: 0.62, Recall: 0.62\n",
      "Epoch [452/900], Loss: 0.0428 , Accuracy : 97.50%, F1 Score: 0.62, Recall: 0.63\n",
      "Epoch [453/900], Loss: 0.0681 , Accuracy : 97.50%, F1 Score: 0.62, Recall: 0.63\n",
      "Epoch [454/900], Loss: 0.9212 , Accuracy : 72.50%, F1 Score: 0.62, Recall: 0.63\n",
      "Epoch [455/900], Loss: 2.0011 , Accuracy : 62.50%, F1 Score: 0.62, Recall: 0.63\n",
      "Epoch [456/900], Loss: 2.8153 , Accuracy : 60.00%, F1 Score: 0.62, Recall: 0.63\n",
      "Epoch [457/900], Loss: 1.7524 , Accuracy : 65.00%, F1 Score: 0.62, Recall: 0.63\n",
      "Epoch [458/900], Loss: 0.2357 , Accuracy : 75.00%, F1 Score: 0.62, Recall: 0.63\n",
      "Epoch [459/900], Loss: 1.7558 , Accuracy : 65.00%, F1 Score: 0.62, Recall: 0.63\n",
      "Epoch [460/900], Loss: 0.9250 , Accuracy : 77.50%, F1 Score: 0.62, Recall: 0.63\n",
      "Epoch [461/900], Loss: 0.0265 , Accuracy : 67.50%, F1 Score: 0.62, Recall: 0.63\n",
      "Epoch [462/900], Loss: 0.1430 , Accuracy : 65.00%, F1 Score: 0.62, Recall: 0.63\n",
      "Epoch [463/900], Loss: 0.3515 , Accuracy : 75.00%, F1 Score: 0.62, Recall: 0.63\n",
      "Epoch [464/900], Loss: 0.2673 , Accuracy : 90.00%, F1 Score: 0.62, Recall: 0.63\n",
      "Epoch [465/900], Loss: 0.0252 , Accuracy : 97.50%, F1 Score: 0.63, Recall: 0.63\n",
      "Epoch [466/900], Loss: 0.0727 , Accuracy : 92.50%, F1 Score: 0.63, Recall: 0.63\n",
      "Epoch [467/900], Loss: 3.9189 , Accuracy : 40.00%, F1 Score: 0.63, Recall: 0.63\n",
      "Epoch [468/900], Loss: 5.0040 , Accuracy : 20.00%, F1 Score: 0.62, Recall: 0.63\n",
      "Epoch [469/900], Loss: 1.5052 , Accuracy : 37.50%, F1 Score: 0.62, Recall: 0.63\n",
      "Epoch [470/900], Loss: 0.3178 , Accuracy : 40.00%, F1 Score: 0.62, Recall: 0.63\n",
      "Epoch [471/900], Loss: 0.7441 , Accuracy : 55.00%, F1 Score: 0.62, Recall: 0.63\n",
      "Epoch [472/900], Loss: 1.1111 , Accuracy : 62.50%, F1 Score: 0.62, Recall: 0.63\n",
      "Epoch [473/900], Loss: 0.8522 , Accuracy : 72.50%, F1 Score: 0.62, Recall: 0.63\n",
      "Epoch [474/900], Loss: 1.0664 , Accuracy : 75.00%, F1 Score: 0.62, Recall: 0.63\n",
      "Epoch [475/900], Loss: 2.1567 , Accuracy : 72.50%, F1 Score: 0.62, Recall: 0.63\n",
      "Epoch [476/900], Loss: 0.9290 , Accuracy : 77.50%, F1 Score: 0.62, Recall: 0.63\n",
      "Epoch [477/900], Loss: 0.4053 , Accuracy : 77.50%, F1 Score: 0.62, Recall: 0.63\n",
      "Epoch [478/900], Loss: 1.4555 , Accuracy : 72.50%, F1 Score: 0.62, Recall: 0.63\n",
      "Epoch [479/900], Loss: 1.5418 , Accuracy : 75.00%, F1 Score: 0.63, Recall: 0.63\n",
      "Epoch [480/900], Loss: 0.6563 , Accuracy : 77.50%, F1 Score: 0.63, Recall: 0.63\n",
      "Epoch [481/900], Loss: 0.7853 , Accuracy : 75.00%, F1 Score: 0.63, Recall: 0.63\n",
      "Epoch [482/900], Loss: 1.4850 , Accuracy : 75.00%, F1 Score: 0.63, Recall: 0.63\n",
      "Epoch [483/900], Loss: 0.6029 , Accuracy : 77.50%, F1 Score: 0.63, Recall: 0.63\n",
      "Epoch [484/900], Loss: 1.0298 , Accuracy : 77.50%, F1 Score: 0.63, Recall: 0.63\n",
      "Epoch [485/900], Loss: 2.7238 , Accuracy : 77.50%, F1 Score: 0.63, Recall: 0.63\n",
      "Epoch [486/900], Loss: 0.0300 , Accuracy : 80.00%, F1 Score: 0.63, Recall: 0.63\n",
      "Epoch [487/900], Loss: 0.5042 , Accuracy : 82.50%, F1 Score: 0.63, Recall: 0.63\n",
      "Epoch [488/900], Loss: 0.5707 , Accuracy : 90.00%, F1 Score: 0.63, Recall: 0.63\n",
      "Epoch [489/900], Loss: 0.2203 , Accuracy : 85.00%, F1 Score: 0.63, Recall: 0.63\n",
      "Epoch [490/900], Loss: 0.0707 , Accuracy : 90.00%, F1 Score: 0.63, Recall: 0.63\n",
      "Epoch [491/900], Loss: 0.6628 , Accuracy : 85.00%, F1 Score: 0.63, Recall: 0.63\n",
      "Epoch [492/900], Loss: 0.5195 , Accuracy : 82.50%, F1 Score: 0.63, Recall: 0.63\n",
      "Epoch [493/900], Loss: 0.4438 , Accuracy : 85.00%, F1 Score: 0.63, Recall: 0.63\n",
      "Epoch [494/900], Loss: 0.0879 , Accuracy : 92.50%, F1 Score: 0.63, Recall: 0.63\n",
      "Epoch [495/900], Loss: 0.1850 , Accuracy : 90.00%, F1 Score: 0.63, Recall: 0.63\n",
      "Epoch [496/900], Loss: 0.5781 , Accuracy : 92.50%, F1 Score: 0.63, Recall: 0.64\n",
      "Epoch [497/900], Loss: 0.6458 , Accuracy : 85.00%, F1 Score: 0.63, Recall: 0.64\n",
      "Epoch [498/900], Loss: 0.9268 , Accuracy : 87.50%, F1 Score: 0.63, Recall: 0.64\n",
      "Epoch [499/900], Loss: 0.4990 , Accuracy : 87.50%, F1 Score: 0.63, Recall: 0.64\n",
      "Epoch [500/900], Loss: 0.3514 , Accuracy : 87.50%, F1 Score: 0.63, Recall: 0.64\n",
      "Epoch [501/900], Loss: 0.6064 , Accuracy : 95.00%, F1 Score: 0.63, Recall: 0.64\n",
      "Epoch [502/900], Loss: 0.2602 , Accuracy : 87.50%, F1 Score: 0.64, Recall: 0.64\n",
      "Epoch [503/900], Loss: 0.0700 , Accuracy : 90.00%, F1 Score: 0.64, Recall: 0.64\n",
      "Epoch [504/900], Loss: 0.5263 , Accuracy : 87.50%, F1 Score: 0.64, Recall: 0.64\n",
      "Epoch [505/900], Loss: 0.4143 , Accuracy : 90.00%, F1 Score: 0.64, Recall: 0.64\n",
      "Epoch [506/900], Loss: 0.1197 , Accuracy : 92.50%, F1 Score: 0.64, Recall: 0.64\n",
      "Epoch [507/900], Loss: 0.1659 , Accuracy : 87.50%, F1 Score: 0.64, Recall: 0.64\n",
      "Epoch [508/900], Loss: 0.0285 , Accuracy : 100.00%, F1 Score: 0.64, Recall: 0.64\n",
      "Epoch [509/900], Loss: 0.1417 , Accuracy : 100.00%, F1 Score: 0.64, Recall: 0.64\n",
      "Epoch [510/900], Loss: 0.1394 , Accuracy : 97.50%, F1 Score: 0.64, Recall: 0.64\n",
      "Epoch [511/900], Loss: 0.2695 , Accuracy : 95.00%, F1 Score: 0.64, Recall: 0.64\n",
      "Epoch [512/900], Loss: 0.0720 , Accuracy : 90.00%, F1 Score: 0.64, Recall: 0.64\n",
      "Epoch [513/900], Loss: 0.2650 , Accuracy : 97.50%, F1 Score: 0.64, Recall: 0.64\n",
      "Epoch [514/900], Loss: 0.6391 , Accuracy : 95.00%, F1 Score: 0.64, Recall: 0.65\n",
      "Epoch [515/900], Loss: 0.3604 , Accuracy : 95.00%, F1 Score: 0.64, Recall: 0.65\n",
      "Epoch [516/900], Loss: 0.0456 , Accuracy : 87.50%, F1 Score: 0.64, Recall: 0.65\n",
      "Epoch [517/900], Loss: 0.0130 , Accuracy : 85.00%, F1 Score: 0.64, Recall: 0.65\n",
      "Epoch [518/900], Loss: 0.0206 , Accuracy : 85.00%, F1 Score: 0.64, Recall: 0.65\n",
      "Epoch [519/900], Loss: 0.3625 , Accuracy : 85.00%, F1 Score: 0.64, Recall: 0.65\n",
      "Epoch [520/900], Loss: 0.0248 , Accuracy : 90.00%, F1 Score: 0.65, Recall: 0.65\n",
      "Epoch [521/900], Loss: 1.1451 , Accuracy : 95.00%, F1 Score: 0.65, Recall: 0.65\n",
      "Epoch [522/900], Loss: 0.1500 , Accuracy : 95.00%, F1 Score: 0.65, Recall: 0.65\n",
      "Epoch [523/900], Loss: 0.0760 , Accuracy : 97.50%, F1 Score: 0.65, Recall: 0.65\n",
      "Epoch [524/900], Loss: 0.2886 , Accuracy : 95.00%, F1 Score: 0.65, Recall: 0.65\n",
      "Epoch [525/900], Loss: 0.1151 , Accuracy : 95.00%, F1 Score: 0.65, Recall: 0.65\n",
      "Epoch [526/900], Loss: 0.3237 , Accuracy : 97.50%, F1 Score: 0.65, Recall: 0.65\n",
      "Epoch [527/900], Loss: 0.2226 , Accuracy : 100.00%, F1 Score: 0.65, Recall: 0.65\n",
      "Epoch [528/900], Loss: 0.2144 , Accuracy : 100.00%, F1 Score: 0.65, Recall: 0.65\n",
      "Epoch [529/900], Loss: 0.0076 , Accuracy : 100.00%, F1 Score: 0.65, Recall: 0.65\n",
      "Epoch [530/900], Loss: 0.0081 , Accuracy : 97.50%, F1 Score: 0.65, Recall: 0.65\n",
      "Epoch [531/900], Loss: 0.0534 , Accuracy : 100.00%, F1 Score: 0.65, Recall: 0.65\n",
      "Epoch [532/900], Loss: 0.1699 , Accuracy : 95.00%, F1 Score: 0.65, Recall: 0.66\n",
      "Epoch [533/900], Loss: 0.1850 , Accuracy : 97.50%, F1 Score: 0.65, Recall: 0.66\n",
      "Epoch [534/900], Loss: 0.0173 , Accuracy : 97.50%, F1 Score: 0.65, Recall: 0.66\n",
      "Epoch [535/900], Loss: 0.0681 , Accuracy : 100.00%, F1 Score: 0.65, Recall: 0.66\n",
      "Epoch [536/900], Loss: 0.0654 , Accuracy : 100.00%, F1 Score: 0.66, Recall: 0.66\n",
      "Epoch [537/900], Loss: 0.3086 , Accuracy : 97.50%, F1 Score: 0.66, Recall: 0.66\n",
      "Epoch [538/900], Loss: 0.0110 , Accuracy : 100.00%, F1 Score: 0.66, Recall: 0.66\n",
      "Epoch [539/900], Loss: 0.0451 , Accuracy : 100.00%, F1 Score: 0.66, Recall: 0.66\n",
      "Epoch [540/900], Loss: 0.0688 , Accuracy : 97.50%, F1 Score: 0.66, Recall: 0.66\n",
      "Epoch [541/900], Loss: 1.0639 , Accuracy : 95.00%, F1 Score: 0.66, Recall: 0.66\n",
      "Epoch [542/900], Loss: 0.0459 , Accuracy : 97.50%, F1 Score: 0.66, Recall: 0.66\n",
      "Epoch [543/900], Loss: 0.3420 , Accuracy : 92.50%, F1 Score: 0.66, Recall: 0.66\n",
      "Epoch [544/900], Loss: 1.1562 , Accuracy : 95.00%, F1 Score: 0.66, Recall: 0.66\n",
      "Epoch [545/900], Loss: 0.0357 , Accuracy : 90.00%, F1 Score: 0.66, Recall: 0.66\n",
      "Epoch [546/900], Loss: 0.0270 , Accuracy : 92.50%, F1 Score: 0.66, Recall: 0.66\n",
      "Epoch [547/900], Loss: 0.0387 , Accuracy : 97.50%, F1 Score: 0.66, Recall: 0.66\n",
      "Epoch [548/900], Loss: 0.2839 , Accuracy : 95.00%, F1 Score: 0.66, Recall: 0.66\n",
      "Epoch [549/900], Loss: 0.0156 , Accuracy : 97.50%, F1 Score: 0.66, Recall: 0.66\n",
      "Epoch [550/900], Loss: 3.0755 , Accuracy : 97.50%, F1 Score: 0.66, Recall: 0.67\n",
      "Epoch [551/900], Loss: 0.0255 , Accuracy : 97.50%, F1 Score: 0.66, Recall: 0.67\n",
      "Epoch [552/900], Loss: 0.0461 , Accuracy : 100.00%, F1 Score: 0.66, Recall: 0.67\n",
      "Epoch [553/900], Loss: 0.0167 , Accuracy : 100.00%, F1 Score: 0.66, Recall: 0.67\n",
      "Epoch [554/900], Loss: 0.0106 , Accuracy : 100.00%, F1 Score: 0.67, Recall: 0.67\n",
      "Epoch [555/900], Loss: 0.0293 , Accuracy : 100.00%, F1 Score: 0.67, Recall: 0.67\n",
      "Epoch [556/900], Loss: 0.0158 , Accuracy : 100.00%, F1 Score: 0.67, Recall: 0.67\n",
      "Epoch [557/900], Loss: 0.0329 , Accuracy : 100.00%, F1 Score: 0.67, Recall: 0.67\n",
      "Epoch [558/900], Loss: 0.0421 , Accuracy : 97.50%, F1 Score: 0.67, Recall: 0.67\n",
      "Epoch [559/900], Loss: 0.0089 , Accuracy : 100.00%, F1 Score: 0.67, Recall: 0.67\n",
      "Epoch [560/900], Loss: 0.0053 , Accuracy : 100.00%, F1 Score: 0.67, Recall: 0.67\n",
      "Epoch [561/900], Loss: 0.0092 , Accuracy : 100.00%, F1 Score: 0.67, Recall: 0.67\n",
      "Epoch [562/900], Loss: 0.2004 , Accuracy : 100.00%, F1 Score: 0.67, Recall: 0.67\n",
      "Epoch [563/900], Loss: 0.0941 , Accuracy : 95.00%, F1 Score: 0.67, Recall: 0.67\n",
      "Epoch [564/900], Loss: 0.0683 , Accuracy : 97.50%, F1 Score: 0.67, Recall: 0.67\n",
      "Epoch [565/900], Loss: 0.1104 , Accuracy : 95.00%, F1 Score: 0.67, Recall: 0.67\n",
      "Epoch [566/900], Loss: 0.0238 , Accuracy : 97.50%, F1 Score: 0.67, Recall: 0.67\n",
      "Epoch [567/900], Loss: 0.0233 , Accuracy : 100.00%, F1 Score: 0.67, Recall: 0.68\n",
      "Epoch [568/900], Loss: 0.0061 , Accuracy : 97.50%, F1 Score: 0.67, Recall: 0.68\n",
      "Epoch [569/900], Loss: 2.1024 , Accuracy : 92.50%, F1 Score: 0.67, Recall: 0.68\n",
      "Epoch [570/900], Loss: 0.1363 , Accuracy : 100.00%, F1 Score: 0.67, Recall: 0.68\n",
      "Epoch [571/900], Loss: 0.0156 , Accuracy : 97.50%, F1 Score: 0.67, Recall: 0.68\n",
      "Epoch [572/900], Loss: 0.0099 , Accuracy : 95.00%, F1 Score: 0.68, Recall: 0.68\n",
      "Epoch [573/900], Loss: 0.0121 , Accuracy : 95.00%, F1 Score: 0.68, Recall: 0.68\n",
      "Epoch [574/900], Loss: 0.0495 , Accuracy : 97.50%, F1 Score: 0.68, Recall: 0.68\n",
      "Epoch [575/900], Loss: 0.0689 , Accuracy : 100.00%, F1 Score: 0.68, Recall: 0.68\n",
      "Epoch [576/900], Loss: 0.0053 , Accuracy : 100.00%, F1 Score: 0.68, Recall: 0.68\n",
      "Epoch [577/900], Loss: 0.0283 , Accuracy : 100.00%, F1 Score: 0.68, Recall: 0.68\n",
      "Epoch [578/900], Loss: 0.0033 , Accuracy : 100.00%, F1 Score: 0.68, Recall: 0.68\n",
      "Epoch [579/900], Loss: 0.0093 , Accuracy : 100.00%, F1 Score: 0.68, Recall: 0.68\n",
      "Epoch [580/900], Loss: 0.0025 , Accuracy : 100.00%, F1 Score: 0.68, Recall: 0.68\n",
      "Epoch [581/900], Loss: 0.0173 , Accuracy : 97.50%, F1 Score: 0.68, Recall: 0.68\n",
      "Epoch [582/900], Loss: 0.6831 , Accuracy : 95.00%, F1 Score: 0.68, Recall: 0.68\n",
      "Epoch [583/900], Loss: 0.0098 , Accuracy : 97.50%, F1 Score: 0.68, Recall: 0.68\n",
      "Epoch [584/900], Loss: 0.2293 , Accuracy : 92.50%, F1 Score: 0.68, Recall: 0.68\n",
      "Epoch [585/900], Loss: 0.0027 , Accuracy : 97.50%, F1 Score: 0.68, Recall: 0.68\n",
      "Epoch [586/900], Loss: 0.5771 , Accuracy : 92.50%, F1 Score: 0.68, Recall: 0.68\n",
      "Epoch [587/900], Loss: 0.6280 , Accuracy : 90.00%, F1 Score: 0.68, Recall: 0.69\n",
      "Epoch [588/900], Loss: 0.1342 , Accuracy : 90.00%, F1 Score: 0.68, Recall: 0.69\n",
      "Epoch [589/900], Loss: 0.0282 , Accuracy : 92.50%, F1 Score: 0.68, Recall: 0.69\n",
      "Epoch [590/900], Loss: 0.0399 , Accuracy : 95.00%, F1 Score: 0.68, Recall: 0.69\n",
      "Epoch [591/900], Loss: 0.8574 , Accuracy : 92.50%, F1 Score: 0.68, Recall: 0.69\n",
      "Epoch [592/900], Loss: 0.1891 , Accuracy : 97.50%, F1 Score: 0.69, Recall: 0.69\n",
      "Epoch [593/900], Loss: 0.3277 , Accuracy : 95.00%, F1 Score: 0.69, Recall: 0.69\n",
      "Epoch [594/900], Loss: 0.1395 , Accuracy : 95.00%, F1 Score: 0.69, Recall: 0.69\n",
      "Epoch [595/900], Loss: 0.0303 , Accuracy : 95.00%, F1 Score: 0.69, Recall: 0.69\n",
      "Epoch [596/900], Loss: 0.2366 , Accuracy : 97.50%, F1 Score: 0.69, Recall: 0.69\n",
      "Epoch [597/900], Loss: 0.0416 , Accuracy : 95.00%, F1 Score: 0.69, Recall: 0.69\n",
      "Epoch [598/900], Loss: 0.0112 , Accuracy : 100.00%, F1 Score: 0.69, Recall: 0.69\n",
      "Epoch [599/900], Loss: 0.2491 , Accuracy : 95.00%, F1 Score: 0.69, Recall: 0.69\n",
      "Epoch [600/900], Loss: 0.0059 , Accuracy : 100.00%, F1 Score: 0.69, Recall: 0.69\n",
      "Epoch [601/900], Loss: 0.1019 , Accuracy : 100.00%, F1 Score: 0.69, Recall: 0.69\n",
      "Epoch [602/900], Loss: 0.0076 , Accuracy : 100.00%, F1 Score: 0.69, Recall: 0.69\n",
      "Epoch [603/900], Loss: 0.0137 , Accuracy : 100.00%, F1 Score: 0.69, Recall: 0.69\n",
      "Epoch [604/900], Loss: 0.0381 , Accuracy : 100.00%, F1 Score: 0.69, Recall: 0.69\n",
      "Epoch [605/900], Loss: 0.0125 , Accuracy : 100.00%, F1 Score: 0.69, Recall: 0.69\n",
      "Epoch [606/900], Loss: 0.0083 , Accuracy : 97.50%, F1 Score: 0.69, Recall: 0.69\n",
      "Epoch [607/900], Loss: 0.0079 , Accuracy : 97.50%, F1 Score: 0.69, Recall: 0.69\n",
      "Epoch [608/900], Loss: 0.0966 , Accuracy : 100.00%, F1 Score: 0.69, Recall: 0.69\n",
      "Epoch [609/900], Loss: 0.0128 , Accuracy : 100.00%, F1 Score: 0.69, Recall: 0.70\n",
      "Epoch [610/900], Loss: 0.0227 , Accuracy : 100.00%, F1 Score: 0.69, Recall: 0.70\n",
      "Epoch [611/900], Loss: 0.0325 , Accuracy : 100.00%, F1 Score: 0.69, Recall: 0.70\n",
      "Epoch [612/900], Loss: 0.0207 , Accuracy : 100.00%, F1 Score: 0.70, Recall: 0.70\n",
      "Epoch [613/900], Loss: 0.0085 , Accuracy : 100.00%, F1 Score: 0.70, Recall: 0.70\n",
      "Epoch [614/900], Loss: 0.0240 , Accuracy : 100.00%, F1 Score: 0.70, Recall: 0.70\n",
      "Epoch [615/900], Loss: 0.0129 , Accuracy : 100.00%, F1 Score: 0.70, Recall: 0.70\n",
      "Epoch [616/900], Loss: 0.0432 , Accuracy : 100.00%, F1 Score: 0.70, Recall: 0.70\n",
      "Epoch [617/900], Loss: 0.0044 , Accuracy : 97.50%, F1 Score: 0.70, Recall: 0.70\n",
      "Epoch [618/900], Loss: 0.0188 , Accuracy : 100.00%, F1 Score: 0.70, Recall: 0.70\n",
      "Epoch [619/900], Loss: 0.1281 , Accuracy : 97.50%, F1 Score: 0.70, Recall: 0.70\n",
      "Epoch [620/900], Loss: 0.0233 , Accuracy : 92.50%, F1 Score: 0.70, Recall: 0.70\n",
      "Epoch [621/900], Loss: 0.0269 , Accuracy : 100.00%, F1 Score: 0.70, Recall: 0.70\n",
      "Epoch [622/900], Loss: 0.0206 , Accuracy : 100.00%, F1 Score: 0.70, Recall: 0.70\n",
      "Epoch [623/900], Loss: 0.0107 , Accuracy : 100.00%, F1 Score: 0.70, Recall: 0.70\n",
      "Epoch [624/900], Loss: 0.0057 , Accuracy : 100.00%, F1 Score: 0.70, Recall: 0.70\n",
      "Epoch [625/900], Loss: 0.0128 , Accuracy : 100.00%, F1 Score: 0.70, Recall: 0.70\n",
      "Epoch [626/900], Loss: 0.0032 , Accuracy : 100.00%, F1 Score: 0.70, Recall: 0.70\n",
      "Epoch [627/900], Loss: 0.0496 , Accuracy : 100.00%, F1 Score: 0.70, Recall: 0.70\n",
      "Epoch [628/900], Loss: 0.0044 , Accuracy : 100.00%, F1 Score: 0.70, Recall: 0.70\n",
      "Epoch [629/900], Loss: 0.0214 , Accuracy : 97.50%, F1 Score: 0.70, Recall: 0.70\n",
      "Epoch [630/900], Loss: 0.0233 , Accuracy : 100.00%, F1 Score: 0.70, Recall: 0.71\n",
      "Epoch [631/900], Loss: 0.0028 , Accuracy : 100.00%, F1 Score: 0.70, Recall: 0.71\n",
      "Epoch [632/900], Loss: 0.0159 , Accuracy : 100.00%, F1 Score: 0.70, Recall: 0.71\n",
      "Epoch [633/900], Loss: 0.0100 , Accuracy : 100.00%, F1 Score: 0.71, Recall: 0.71\n",
      "Epoch [634/900], Loss: 0.0112 , Accuracy : 100.00%, F1 Score: 0.71, Recall: 0.71\n",
      "Epoch [635/900], Loss: 0.0031 , Accuracy : 100.00%, F1 Score: 0.71, Recall: 0.71\n",
      "Epoch [636/900], Loss: 0.0130 , Accuracy : 100.00%, F1 Score: 0.71, Recall: 0.71\n",
      "Epoch [637/900], Loss: 0.0039 , Accuracy : 100.00%, F1 Score: 0.71, Recall: 0.71\n",
      "Epoch [638/900], Loss: 0.0142 , Accuracy : 100.00%, F1 Score: 0.71, Recall: 0.71\n",
      "Epoch [639/900], Loss: 0.0112 , Accuracy : 97.50%, F1 Score: 0.71, Recall: 0.71\n",
      "Epoch [640/900], Loss: 0.0051 , Accuracy : 97.50%, F1 Score: 0.71, Recall: 0.71\n",
      "Epoch [641/900], Loss: 0.0041 , Accuracy : 100.00%, F1 Score: 0.71, Recall: 0.71\n",
      "Epoch [642/900], Loss: 0.0011 , Accuracy : 100.00%, F1 Score: 0.71, Recall: 0.71\n",
      "Epoch [643/900], Loss: 0.0019 , Accuracy : 100.00%, F1 Score: 0.71, Recall: 0.71\n",
      "Epoch [644/900], Loss: 0.1300 , Accuracy : 97.50%, F1 Score: 0.71, Recall: 0.71\n",
      "Epoch [645/900], Loss: 0.0047 , Accuracy : 100.00%, F1 Score: 0.71, Recall: 0.71\n",
      "Epoch [646/900], Loss: 0.0081 , Accuracy : 100.00%, F1 Score: 0.71, Recall: 0.71\n",
      "Epoch [647/900], Loss: 0.0107 , Accuracy : 100.00%, F1 Score: 0.71, Recall: 0.71\n",
      "Epoch [648/900], Loss: 0.0029 , Accuracy : 100.00%, F1 Score: 0.71, Recall: 0.71\n",
      "Epoch [649/900], Loss: 0.0048 , Accuracy : 100.00%, F1 Score: 0.71, Recall: 0.71\n",
      "Epoch [650/900], Loss: 0.0090 , Accuracy : 100.00%, F1 Score: 0.71, Recall: 0.71\n",
      "Epoch [651/900], Loss: 0.0067 , Accuracy : 100.00%, F1 Score: 0.71, Recall: 0.71\n",
      "Epoch [652/900], Loss: 0.0433 , Accuracy : 97.50%, F1 Score: 0.71, Recall: 0.72\n",
      "Epoch [653/900], Loss: 0.0036 , Accuracy : 100.00%, F1 Score: 0.71, Recall: 0.72\n",
      "Epoch [654/900], Loss: 0.2591 , Accuracy : 97.50%, F1 Score: 0.71, Recall: 0.72\n",
      "Epoch [655/900], Loss: 0.0163 , Accuracy : 100.00%, F1 Score: 0.71, Recall: 0.72\n",
      "Epoch [656/900], Loss: 0.0012 , Accuracy : 100.00%, F1 Score: 0.72, Recall: 0.72\n",
      "Epoch [657/900], Loss: 0.0075 , Accuracy : 100.00%, F1 Score: 0.72, Recall: 0.72\n",
      "Epoch [658/900], Loss: 0.0116 , Accuracy : 100.00%, F1 Score: 0.72, Recall: 0.72\n",
      "Epoch [659/900], Loss: 0.0286 , Accuracy : 100.00%, F1 Score: 0.72, Recall: 0.72\n",
      "Epoch [660/900], Loss: 0.0005 , Accuracy : 100.00%, F1 Score: 0.72, Recall: 0.72\n",
      "Epoch [661/900], Loss: 0.0507 , Accuracy : 100.00%, F1 Score: 0.72, Recall: 0.72\n",
      "Epoch [662/900], Loss: 0.0074 , Accuracy : 100.00%, F1 Score: 0.72, Recall: 0.72\n",
      "Epoch [663/900], Loss: 0.0018 , Accuracy : 100.00%, F1 Score: 0.72, Recall: 0.72\n",
      "Epoch [664/900], Loss: 0.0041 , Accuracy : 100.00%, F1 Score: 0.72, Recall: 0.72\n",
      "Epoch [665/900], Loss: 0.0037 , Accuracy : 100.00%, F1 Score: 0.72, Recall: 0.72\n",
      "Epoch [666/900], Loss: 0.0081 , Accuracy : 100.00%, F1 Score: 0.72, Recall: 0.72\n",
      "Epoch [667/900], Loss: 0.0065 , Accuracy : 97.50%, F1 Score: 0.72, Recall: 0.72\n",
      "Epoch [668/900], Loss: 0.0329 , Accuracy : 100.00%, F1 Score: 0.72, Recall: 0.72\n",
      "Epoch [669/900], Loss: 0.0016 , Accuracy : 100.00%, F1 Score: 0.72, Recall: 0.72\n",
      "Epoch [670/900], Loss: 0.0030 , Accuracy : 100.00%, F1 Score: 0.72, Recall: 0.72\n",
      "Epoch [671/900], Loss: 0.0315 , Accuracy : 100.00%, F1 Score: 0.72, Recall: 0.72\n",
      "Epoch [672/900], Loss: 0.0037 , Accuracy : 100.00%, F1 Score: 0.72, Recall: 0.72\n",
      "Epoch [673/900], Loss: 0.0017 , Accuracy : 100.00%, F1 Score: 0.72, Recall: 0.72\n",
      "Epoch [674/900], Loss: 0.0040 , Accuracy : 100.00%, F1 Score: 0.72, Recall: 0.72\n",
      "Epoch [675/900], Loss: 0.0021 , Accuracy : 100.00%, F1 Score: 0.72, Recall: 0.72\n",
      "Epoch [676/900], Loss: 0.0019 , Accuracy : 100.00%, F1 Score: 0.72, Recall: 0.73\n",
      "Epoch [677/900], Loss: 0.0162 , Accuracy : 100.00%, F1 Score: 0.72, Recall: 0.73\n",
      "Epoch [678/900], Loss: 0.0112 , Accuracy : 100.00%, F1 Score: 0.72, Recall: 0.73\n",
      "Epoch [679/900], Loss: 0.0036 , Accuracy : 100.00%, F1 Score: 0.72, Recall: 0.73\n",
      "Epoch [680/900], Loss: 0.0038 , Accuracy : 100.00%, F1 Score: 0.73, Recall: 0.73\n",
      "Epoch [681/900], Loss: 0.0020 , Accuracy : 100.00%, F1 Score: 0.73, Recall: 0.73\n",
      "Epoch [682/900], Loss: 0.0027 , Accuracy : 100.00%, F1 Score: 0.73, Recall: 0.73\n",
      "Epoch [683/900], Loss: 0.0013 , Accuracy : 100.00%, F1 Score: 0.73, Recall: 0.73\n",
      "Epoch [684/900], Loss: 0.0014 , Accuracy : 100.00%, F1 Score: 0.73, Recall: 0.73\n",
      "Epoch [685/900], Loss: 0.0029 , Accuracy : 100.00%, F1 Score: 0.73, Recall: 0.73\n",
      "Epoch [686/900], Loss: 0.0021 , Accuracy : 100.00%, F1 Score: 0.73, Recall: 0.73\n",
      "Epoch [687/900], Loss: 0.0043 , Accuracy : 100.00%, F1 Score: 0.73, Recall: 0.73\n",
      "Epoch [688/900], Loss: 0.0025 , Accuracy : 100.00%, F1 Score: 0.73, Recall: 0.73\n",
      "Epoch [689/900], Loss: 0.0025 , Accuracy : 100.00%, F1 Score: 0.73, Recall: 0.73\n",
      "Epoch [690/900], Loss: 0.0050 , Accuracy : 100.00%, F1 Score: 0.73, Recall: 0.73\n",
      "Epoch [691/900], Loss: 0.0005 , Accuracy : 100.00%, F1 Score: 0.73, Recall: 0.73\n",
      "Epoch [692/900], Loss: 0.0015 , Accuracy : 100.00%, F1 Score: 0.73, Recall: 0.73\n",
      "Epoch [693/900], Loss: 0.0020 , Accuracy : 100.00%, F1 Score: 0.73, Recall: 0.73\n",
      "Epoch [694/900], Loss: 0.0014 , Accuracy : 100.00%, F1 Score: 0.73, Recall: 0.73\n",
      "Epoch [695/900], Loss: 0.0007 , Accuracy : 100.00%, F1 Score: 0.73, Recall: 0.73\n",
      "Epoch [696/900], Loss: 0.0185 , Accuracy : 97.50%, F1 Score: 0.73, Recall: 0.73\n",
      "Epoch [697/900], Loss: 0.0018 , Accuracy : 100.00%, F1 Score: 0.73, Recall: 0.73\n",
      "Epoch [698/900], Loss: 0.0437 , Accuracy : 100.00%, F1 Score: 0.73, Recall: 0.73\n",
      "Epoch [699/900], Loss: 0.0035 , Accuracy : 100.00%, F1 Score: 0.73, Recall: 0.73\n",
      "Epoch [700/900], Loss: 0.0015 , Accuracy : 100.00%, F1 Score: 0.73, Recall: 0.73\n",
      "Epoch [701/900], Loss: 0.0031 , Accuracy : 100.00%, F1 Score: 0.73, Recall: 0.73\n",
      "Epoch [702/900], Loss: 0.0010 , Accuracy : 100.00%, F1 Score: 0.73, Recall: 0.74\n",
      "Epoch [703/900], Loss: 0.0012 , Accuracy : 100.00%, F1 Score: 0.73, Recall: 0.74\n",
      "Epoch [704/900], Loss: 0.0041 , Accuracy : 100.00%, F1 Score: 0.73, Recall: 0.74\n",
      "Epoch [705/900], Loss: 0.0013 , Accuracy : 100.00%, F1 Score: 0.74, Recall: 0.74\n",
      "Epoch [706/900], Loss: 0.0036 , Accuracy : 100.00%, F1 Score: 0.74, Recall: 0.74\n",
      "Epoch [707/900], Loss: 0.0047 , Accuracy : 100.00%, F1 Score: 0.74, Recall: 0.74\n",
      "Epoch [708/900], Loss: 0.0030 , Accuracy : 100.00%, F1 Score: 0.74, Recall: 0.74\n",
      "Epoch [709/900], Loss: 0.0032 , Accuracy : 100.00%, F1 Score: 0.74, Recall: 0.74\n",
      "Epoch [710/900], Loss: 0.0021 , Accuracy : 100.00%, F1 Score: 0.74, Recall: 0.74\n",
      "Epoch [711/900], Loss: 0.0041 , Accuracy : 100.00%, F1 Score: 0.74, Recall: 0.74\n",
      "Epoch [712/900], Loss: 0.0064 , Accuracy : 100.00%, F1 Score: 0.74, Recall: 0.74\n",
      "Epoch [713/900], Loss: 0.0025 , Accuracy : 100.00%, F1 Score: 0.74, Recall: 0.74\n",
      "Epoch [714/900], Loss: 0.0008 , Accuracy : 100.00%, F1 Score: 0.74, Recall: 0.74\n",
      "Epoch [715/900], Loss: 0.0034 , Accuracy : 100.00%, F1 Score: 0.74, Recall: 0.74\n",
      "Epoch [716/900], Loss: 0.0017 , Accuracy : 100.00%, F1 Score: 0.74, Recall: 0.74\n",
      "Epoch [717/900], Loss: 0.0008 , Accuracy : 100.00%, F1 Score: 0.74, Recall: 0.74\n",
      "Epoch [718/900], Loss: 0.0036 , Accuracy : 100.00%, F1 Score: 0.74, Recall: 0.74\n",
      "Epoch [719/900], Loss: 0.0002 , Accuracy : 100.00%, F1 Score: 0.74, Recall: 0.74\n",
      "Epoch [720/900], Loss: 0.0012 , Accuracy : 100.00%, F1 Score: 0.74, Recall: 0.74\n",
      "Epoch [721/900], Loss: 0.0025 , Accuracy : 100.00%, F1 Score: 0.74, Recall: 0.74\n",
      "Epoch [722/900], Loss: 0.0031 , Accuracy : 100.00%, F1 Score: 0.74, Recall: 0.74\n",
      "Epoch [723/900], Loss: 0.0031 , Accuracy : 100.00%, F1 Score: 0.74, Recall: 0.74\n",
      "Epoch [724/900], Loss: 0.0010 , Accuracy : 100.00%, F1 Score: 0.74, Recall: 0.74\n",
      "Epoch [725/900], Loss: 0.0012 , Accuracy : 100.00%, F1 Score: 0.74, Recall: 0.74\n",
      "Epoch [726/900], Loss: 0.0016 , Accuracy : 100.00%, F1 Score: 0.74, Recall: 0.74\n",
      "Epoch [727/900], Loss: 0.0066 , Accuracy : 100.00%, F1 Score: 0.74, Recall: 0.74\n",
      "Epoch [728/900], Loss: 0.0025 , Accuracy : 100.00%, F1 Score: 0.74, Recall: 0.74\n",
      "Epoch [729/900], Loss: 0.0006 , Accuracy : 100.00%, F1 Score: 0.74, Recall: 0.75\n",
      "Epoch [730/900], Loss: 0.0146 , Accuracy : 100.00%, F1 Score: 0.74, Recall: 0.75\n",
      "Epoch [731/900], Loss: 0.0013 , Accuracy : 100.00%, F1 Score: 0.74, Recall: 0.75\n",
      "Epoch [732/900], Loss: 0.0005 , Accuracy : 100.00%, F1 Score: 0.74, Recall: 0.75\n",
      "Epoch [733/900], Loss: 0.0038 , Accuracy : 100.00%, F1 Score: 0.75, Recall: 0.75\n",
      "Epoch [734/900], Loss: 0.0027 , Accuracy : 100.00%, F1 Score: 0.75, Recall: 0.75\n",
      "Epoch [735/900], Loss: 0.0014 , Accuracy : 100.00%, F1 Score: 0.75, Recall: 0.75\n",
      "Epoch [736/900], Loss: 0.0016 , Accuracy : 100.00%, F1 Score: 0.75, Recall: 0.75\n",
      "Epoch [737/900], Loss: 0.0004 , Accuracy : 100.00%, F1 Score: 0.75, Recall: 0.75\n",
      "Epoch [738/900], Loss: 0.0018 , Accuracy : 100.00%, F1 Score: 0.75, Recall: 0.75\n",
      "Epoch [739/900], Loss: 0.0030 , Accuracy : 100.00%, F1 Score: 0.75, Recall: 0.75\n",
      "Epoch [740/900], Loss: 0.0002 , Accuracy : 100.00%, F1 Score: 0.75, Recall: 0.75\n",
      "Epoch [741/900], Loss: 0.0017 , Accuracy : 100.00%, F1 Score: 0.75, Recall: 0.75\n",
      "Epoch [742/900], Loss: 0.0014 , Accuracy : 100.00%, F1 Score: 0.75, Recall: 0.75\n",
      "Epoch [743/900], Loss: 0.0009 , Accuracy : 100.00%, F1 Score: 0.75, Recall: 0.75\n",
      "Epoch [744/900], Loss: 0.0019 , Accuracy : 100.00%, F1 Score: 0.75, Recall: 0.75\n",
      "Epoch [745/900], Loss: 0.0012 , Accuracy : 100.00%, F1 Score: 0.75, Recall: 0.75\n",
      "Epoch [746/900], Loss: 0.0032 , Accuracy : 100.00%, F1 Score: 0.75, Recall: 0.75\n",
      "Epoch [747/900], Loss: 0.0027 , Accuracy : 100.00%, F1 Score: 0.75, Recall: 0.75\n",
      "Epoch [748/900], Loss: 0.0008 , Accuracy : 100.00%, F1 Score: 0.75, Recall: 0.75\n",
      "Epoch [749/900], Loss: 0.0019 , Accuracy : 100.00%, F1 Score: 0.75, Recall: 0.75\n",
      "Epoch [750/900], Loss: 0.0030 , Accuracy : 100.00%, F1 Score: 0.75, Recall: 0.75\n",
      "Epoch [751/900], Loss: 0.0002 , Accuracy : 100.00%, F1 Score: 0.75, Recall: 0.75\n",
      "Epoch [752/900], Loss: 0.0005 , Accuracy : 100.00%, F1 Score: 0.75, Recall: 0.75\n",
      "Epoch [753/900], Loss: 0.0008 , Accuracy : 100.00%, F1 Score: 0.75, Recall: 0.75\n",
      "Epoch [754/900], Loss: 0.0009 , Accuracy : 100.00%, F1 Score: 0.75, Recall: 0.75\n",
      "Epoch [755/900], Loss: 0.0016 , Accuracy : 100.00%, F1 Score: 0.75, Recall: 0.75\n",
      "Epoch [756/900], Loss: 0.0006 , Accuracy : 100.00%, F1 Score: 0.75, Recall: 0.75\n",
      "Epoch [757/900], Loss: 0.0016 , Accuracy : 100.00%, F1 Score: 0.75, Recall: 0.75\n",
      "Epoch [758/900], Loss: 0.0058 , Accuracy : 100.00%, F1 Score: 0.75, Recall: 0.75\n",
      "Epoch [759/900], Loss: 0.0010 , Accuracy : 100.00%, F1 Score: 0.75, Recall: 0.76\n",
      "Epoch [760/900], Loss: 0.0010 , Accuracy : 100.00%, F1 Score: 0.75, Recall: 0.76\n",
      "Epoch [761/900], Loss: 0.0003 , Accuracy : 100.00%, F1 Score: 0.75, Recall: 0.76\n",
      "Epoch [762/900], Loss: 0.0004 , Accuracy : 100.00%, F1 Score: 0.76, Recall: 0.76\n",
      "Epoch [763/900], Loss: 0.0014 , Accuracy : 100.00%, F1 Score: 0.76, Recall: 0.76\n",
      "Epoch [764/900], Loss: 0.0010 , Accuracy : 100.00%, F1 Score: 0.76, Recall: 0.76\n",
      "Epoch [765/900], Loss: 0.0025 , Accuracy : 100.00%, F1 Score: 0.76, Recall: 0.76\n",
      "Epoch [766/900], Loss: 0.0018 , Accuracy : 100.00%, F1 Score: 0.76, Recall: 0.76\n",
      "Epoch [767/900], Loss: 0.0013 , Accuracy : 100.00%, F1 Score: 0.76, Recall: 0.76\n",
      "Epoch [768/900], Loss: 0.0013 , Accuracy : 100.00%, F1 Score: 0.76, Recall: 0.76\n",
      "Epoch [769/900], Loss: 0.0019 , Accuracy : 100.00%, F1 Score: 0.76, Recall: 0.76\n",
      "Epoch [770/900], Loss: 0.0012 , Accuracy : 100.00%, F1 Score: 0.76, Recall: 0.76\n",
      "Epoch [771/900], Loss: 0.0022 , Accuracy : 100.00%, F1 Score: 0.76, Recall: 0.76\n",
      "Epoch [772/900], Loss: 0.0004 , Accuracy : 100.00%, F1 Score: 0.76, Recall: 0.76\n",
      "Epoch [773/900], Loss: 0.0017 , Accuracy : 100.00%, F1 Score: 0.76, Recall: 0.76\n",
      "Epoch [774/900], Loss: 0.0007 , Accuracy : 100.00%, F1 Score: 0.76, Recall: 0.76\n",
      "Epoch [775/900], Loss: 0.0028 , Accuracy : 100.00%, F1 Score: 0.76, Recall: 0.76\n",
      "Epoch [776/900], Loss: 0.0015 , Accuracy : 100.00%, F1 Score: 0.76, Recall: 0.76\n",
      "Epoch [777/900], Loss: 0.0002 , Accuracy : 100.00%, F1 Score: 0.76, Recall: 0.76\n",
      "Epoch [778/900], Loss: 0.0011 , Accuracy : 100.00%, F1 Score: 0.76, Recall: 0.76\n",
      "Epoch [779/900], Loss: 0.0010 , Accuracy : 100.00%, F1 Score: 0.76, Recall: 0.76\n",
      "Epoch [780/900], Loss: 0.0010 , Accuracy : 100.00%, F1 Score: 0.76, Recall: 0.76\n",
      "Epoch [781/900], Loss: 0.0103 , Accuracy : 100.00%, F1 Score: 0.76, Recall: 0.76\n",
      "Epoch [782/900], Loss: 0.0005 , Accuracy : 100.00%, F1 Score: 0.76, Recall: 0.76\n",
      "Epoch [783/900], Loss: 0.0028 , Accuracy : 100.00%, F1 Score: 0.76, Recall: 0.76\n",
      "Epoch [784/900], Loss: 0.0005 , Accuracy : 100.00%, F1 Score: 0.76, Recall: 0.76\n",
      "Epoch [785/900], Loss: 0.0011 , Accuracy : 100.00%, F1 Score: 0.76, Recall: 0.76\n",
      "Epoch [786/900], Loss: 0.0007 , Accuracy : 100.00%, F1 Score: 0.76, Recall: 0.76\n",
      "Epoch [787/900], Loss: 0.0015 , Accuracy : 100.00%, F1 Score: 0.76, Recall: 0.76\n",
      "Epoch [788/900], Loss: 0.0005 , Accuracy : 100.00%, F1 Score: 0.76, Recall: 0.76\n",
      "Epoch [789/900], Loss: 0.0012 , Accuracy : 100.00%, F1 Score: 0.76, Recall: 0.76\n",
      "Epoch [790/900], Loss: 0.0030 , Accuracy : 100.00%, F1 Score: 0.76, Recall: 0.76\n",
      "Epoch [791/900], Loss: 0.0013 , Accuracy : 100.00%, F1 Score: 0.76, Recall: 0.77\n",
      "Epoch [792/900], Loss: 0.0005 , Accuracy : 100.00%, F1 Score: 0.76, Recall: 0.77\n",
      "Epoch [793/900], Loss: 0.0012 , Accuracy : 100.00%, F1 Score: 0.76, Recall: 0.77\n",
      "Epoch [794/900], Loss: 0.0006 , Accuracy : 100.00%, F1 Score: 0.76, Recall: 0.77\n",
      "Epoch [795/900], Loss: 0.0010 , Accuracy : 100.00%, F1 Score: 0.77, Recall: 0.77\n",
      "Epoch [796/900], Loss: 0.0012 , Accuracy : 100.00%, F1 Score: 0.77, Recall: 0.77\n",
      "Epoch [797/900], Loss: 0.0005 , Accuracy : 100.00%, F1 Score: 0.77, Recall: 0.77\n",
      "Epoch [798/900], Loss: 0.0012 , Accuracy : 100.00%, F1 Score: 0.77, Recall: 0.77\n",
      "Epoch [799/900], Loss: 0.0007 , Accuracy : 100.00%, F1 Score: 0.77, Recall: 0.77\n",
      "Epoch [800/900], Loss: 0.0005 , Accuracy : 100.00%, F1 Score: 0.77, Recall: 0.77\n",
      "Epoch [801/900], Loss: 0.0013 , Accuracy : 100.00%, F1 Score: 0.77, Recall: 0.77\n",
      "Epoch [802/900], Loss: 0.0010 , Accuracy : 100.00%, F1 Score: 0.77, Recall: 0.77\n",
      "Epoch [803/900], Loss: 0.0008 , Accuracy : 100.00%, F1 Score: 0.77, Recall: 0.77\n",
      "Epoch [804/900], Loss: 1.9832 , Accuracy : 92.50%, F1 Score: 0.77, Recall: 0.77\n",
      "Epoch [805/900], Loss: 3.8288 , Accuracy : 72.50%, F1 Score: 0.77, Recall: 0.77\n",
      "Epoch [806/900], Loss: 2.1017 , Accuracy : 65.00%, F1 Score: 0.77, Recall: 0.77\n",
      "Epoch [807/900], Loss: 6.6962 , Accuracy : 75.00%, F1 Score: 0.77, Recall: 0.77\n",
      "Epoch [808/900], Loss: 0.9566 , Accuracy : 35.00%, F1 Score: 0.77, Recall: 0.77\n",
      "Epoch [809/900], Loss: 1.8611 , Accuracy : 57.50%, F1 Score: 0.77, Recall: 0.77\n",
      "Epoch [810/900], Loss: 0.1332 , Accuracy : 65.00%, F1 Score: 0.77, Recall: 0.77\n",
      "Epoch [811/900], Loss: 2.3178 , Accuracy : 82.50%, F1 Score: 0.77, Recall: 0.77\n",
      "Epoch [812/900], Loss: 0.5348 , Accuracy : 82.50%, F1 Score: 0.77, Recall: 0.77\n",
      "Epoch [813/900], Loss: 1.0610 , Accuracy : 87.50%, F1 Score: 0.77, Recall: 0.77\n",
      "Epoch [814/900], Loss: 0.0631 , Accuracy : 87.50%, F1 Score: 0.77, Recall: 0.77\n",
      "Epoch [815/900], Loss: 0.1407 , Accuracy : 95.00%, F1 Score: 0.77, Recall: 0.77\n",
      "Epoch [816/900], Loss: 0.1221 , Accuracy : 97.50%, F1 Score: 0.77, Recall: 0.77\n",
      "Epoch [817/900], Loss: 0.2041 , Accuracy : 92.50%, F1 Score: 0.77, Recall: 0.77\n",
      "Epoch [818/900], Loss: 0.3901 , Accuracy : 95.00%, F1 Score: 0.77, Recall: 0.77\n",
      "Epoch [819/900], Loss: 0.0462 , Accuracy : 97.50%, F1 Score: 0.77, Recall: 0.77\n",
      "Epoch [820/900], Loss: 0.1015 , Accuracy : 92.50%, F1 Score: 0.77, Recall: 0.77\n",
      "Epoch [821/900], Loss: 0.3943 , Accuracy : 92.50%, F1 Score: 0.77, Recall: 0.77\n",
      "Epoch [822/900], Loss: 0.0722 , Accuracy : 100.00%, F1 Score: 0.77, Recall: 0.77\n",
      "Epoch [823/900], Loss: 0.0593 , Accuracy : 100.00%, F1 Score: 0.77, Recall: 0.77\n",
      "Epoch [824/900], Loss: 0.0360 , Accuracy : 100.00%, F1 Score: 0.77, Recall: 0.77\n",
      "Epoch [825/900], Loss: 0.5168 , Accuracy : 95.00%, F1 Score: 0.77, Recall: 0.77\n",
      "Epoch [826/900], Loss: 1.0570 , Accuracy : 87.50%, F1 Score: 0.77, Recall: 0.77\n",
      "Epoch [827/900], Loss: 0.0130 , Accuracy : 85.00%, F1 Score: 0.77, Recall: 0.77\n",
      "Epoch [828/900], Loss: 0.0723 , Accuracy : 92.50%, F1 Score: 0.77, Recall: 0.77\n",
      "Epoch [829/900], Loss: 0.0909 , Accuracy : 95.00%, F1 Score: 0.77, Recall: 0.77\n",
      "Epoch [830/900], Loss: 0.0086 , Accuracy : 92.50%, F1 Score: 0.77, Recall: 0.77\n",
      "Epoch [831/900], Loss: 0.0236 , Accuracy : 92.50%, F1 Score: 0.77, Recall: 0.77\n",
      "Epoch [832/900], Loss: 0.0287 , Accuracy : 97.50%, F1 Score: 0.77, Recall: 0.77\n",
      "Epoch [833/900], Loss: 0.0114 , Accuracy : 100.00%, F1 Score: 0.77, Recall: 0.77\n",
      "Epoch [834/900], Loss: 0.0260 , Accuracy : 100.00%, F1 Score: 0.77, Recall: 0.77\n",
      "Epoch [835/900], Loss: 0.0112 , Accuracy : 100.00%, F1 Score: 0.77, Recall: 0.77\n",
      "Epoch [836/900], Loss: 0.0091 , Accuracy : 100.00%, F1 Score: 0.77, Recall: 0.77\n",
      "Epoch [837/900], Loss: 0.0110 , Accuracy : 100.00%, F1 Score: 0.77, Recall: 0.77\n",
      "Epoch [838/900], Loss: 0.0260 , Accuracy : 100.00%, F1 Score: 0.77, Recall: 0.77\n",
      "Epoch [839/900], Loss: 0.0029 , Accuracy : 100.00%, F1 Score: 0.77, Recall: 0.77\n",
      "Epoch [840/900], Loss: 0.0160 , Accuracy : 100.00%, F1 Score: 0.77, Recall: 0.77\n",
      "Epoch [841/900], Loss: 0.1105 , Accuracy : 100.00%, F1 Score: 0.77, Recall: 0.77\n",
      "Epoch [842/900], Loss: 0.0152 , Accuracy : 97.50%, F1 Score: 0.77, Recall: 0.77\n",
      "Epoch [843/900], Loss: 0.0087 , Accuracy : 100.00%, F1 Score: 0.77, Recall: 0.77\n",
      "Epoch [844/900], Loss: 0.0295 , Accuracy : 100.00%, F1 Score: 0.77, Recall: 0.78\n",
      "Epoch [845/900], Loss: 0.0094 , Accuracy : 100.00%, F1 Score: 0.77, Recall: 0.78\n",
      "Epoch [846/900], Loss: 0.0055 , Accuracy : 100.00%, F1 Score: 0.77, Recall: 0.78\n",
      "Epoch [847/900], Loss: 0.0060 , Accuracy : 100.00%, F1 Score: 0.78, Recall: 0.78\n",
      "Epoch [848/900], Loss: 0.0150 , Accuracy : 100.00%, F1 Score: 0.78, Recall: 0.78\n",
      "Epoch [849/900], Loss: 0.0194 , Accuracy : 100.00%, F1 Score: 0.78, Recall: 0.78\n",
      "Epoch [850/900], Loss: 0.0061 , Accuracy : 100.00%, F1 Score: 0.78, Recall: 0.78\n",
      "Epoch [851/900], Loss: 0.0111 , Accuracy : 100.00%, F1 Score: 0.78, Recall: 0.78\n",
      "Epoch [852/900], Loss: 0.0075 , Accuracy : 95.00%, F1 Score: 0.78, Recall: 0.78\n",
      "Epoch [853/900], Loss: 0.0223 , Accuracy : 100.00%, F1 Score: 0.78, Recall: 0.78\n",
      "Epoch [854/900], Loss: 0.0110 , Accuracy : 97.50%, F1 Score: 0.78, Recall: 0.78\n",
      "Epoch [855/900], Loss: 0.0488 , Accuracy : 97.50%, F1 Score: 0.78, Recall: 0.78\n",
      "Epoch [856/900], Loss: 0.0035 , Accuracy : 100.00%, F1 Score: 0.78, Recall: 0.78\n",
      "Epoch [857/900], Loss: 0.0152 , Accuracy : 100.00%, F1 Score: 0.78, Recall: 0.78\n",
      "Epoch [858/900], Loss: 0.0249 , Accuracy : 100.00%, F1 Score: 0.78, Recall: 0.78\n",
      "Epoch [859/900], Loss: 0.0138 , Accuracy : 100.00%, F1 Score: 0.78, Recall: 0.78\n",
      "Epoch [860/900], Loss: 0.0076 , Accuracy : 100.00%, F1 Score: 0.78, Recall: 0.78\n",
      "Epoch [861/900], Loss: 0.0029 , Accuracy : 100.00%, F1 Score: 0.78, Recall: 0.78\n",
      "Epoch [862/900], Loss: 0.0075 , Accuracy : 100.00%, F1 Score: 0.78, Recall: 0.78\n",
      "Epoch [863/900], Loss: 0.0074 , Accuracy : 100.00%, F1 Score: 0.78, Recall: 0.78\n",
      "Epoch [864/900], Loss: 0.0038 , Accuracy : 100.00%, F1 Score: 0.78, Recall: 0.78\n",
      "Epoch [865/900], Loss: 0.0055 , Accuracy : 100.00%, F1 Score: 0.78, Recall: 0.78\n",
      "Epoch [866/900], Loss: 0.0019 , Accuracy : 100.00%, F1 Score: 0.78, Recall: 0.78\n",
      "Epoch [867/900], Loss: 0.0052 , Accuracy : 100.00%, F1 Score: 0.78, Recall: 0.78\n",
      "Epoch [868/900], Loss: 0.0056 , Accuracy : 100.00%, F1 Score: 0.78, Recall: 0.78\n",
      "Epoch [869/900], Loss: 0.0049 , Accuracy : 100.00%, F1 Score: 0.78, Recall: 0.78\n",
      "Epoch [870/900], Loss: 0.0098 , Accuracy : 100.00%, F1 Score: 0.78, Recall: 0.78\n",
      "Epoch [871/900], Loss: 0.0057 , Accuracy : 100.00%, F1 Score: 0.78, Recall: 0.78\n",
      "Epoch [872/900], Loss: 0.0026 , Accuracy : 100.00%, F1 Score: 0.78, Recall: 0.78\n",
      "Epoch [873/900], Loss: 0.0042 , Accuracy : 100.00%, F1 Score: 0.78, Recall: 0.78\n",
      "Epoch [874/900], Loss: 0.0024 , Accuracy : 100.00%, F1 Score: 0.78, Recall: 0.78\n",
      "Epoch [875/900], Loss: 0.0014 , Accuracy : 100.00%, F1 Score: 0.78, Recall: 0.78\n",
      "Epoch [876/900], Loss: 0.0174 , Accuracy : 100.00%, F1 Score: 0.78, Recall: 0.78\n",
      "Epoch [877/900], Loss: 0.0023 , Accuracy : 100.00%, F1 Score: 0.78, Recall: 0.78\n",
      "Epoch [878/900], Loss: 0.0065 , Accuracy : 100.00%, F1 Score: 0.78, Recall: 0.78\n",
      "Epoch [879/900], Loss: 0.0051 , Accuracy : 100.00%, F1 Score: 0.78, Recall: 0.78\n",
      "Epoch [880/900], Loss: 0.0011 , Accuracy : 100.00%, F1 Score: 0.78, Recall: 0.78\n",
      "Epoch [881/900], Loss: 0.0062 , Accuracy : 100.00%, F1 Score: 0.78, Recall: 0.78\n",
      "Epoch [882/900], Loss: 0.0114 , Accuracy : 100.00%, F1 Score: 0.78, Recall: 0.78\n",
      "Epoch [883/900], Loss: 0.0081 , Accuracy : 100.00%, F1 Score: 0.78, Recall: 0.78\n",
      "Epoch [884/900], Loss: 0.0030 , Accuracy : 100.00%, F1 Score: 0.78, Recall: 0.79\n",
      "Epoch [885/900], Loss: 0.0053 , Accuracy : 100.00%, F1 Score: 0.78, Recall: 0.79\n",
      "Epoch [886/900], Loss: 0.0063 , Accuracy : 100.00%, F1 Score: 0.78, Recall: 0.79\n",
      "Epoch [887/900], Loss: 0.0022 , Accuracy : 100.00%, F1 Score: 0.79, Recall: 0.79\n",
      "Epoch [888/900], Loss: 0.0092 , Accuracy : 100.00%, F1 Score: 0.79, Recall: 0.79\n",
      "Epoch [889/900], Loss: 0.0087 , Accuracy : 100.00%, F1 Score: 0.79, Recall: 0.79\n",
      "Epoch [890/900], Loss: 0.0069 , Accuracy : 100.00%, F1 Score: 0.79, Recall: 0.79\n",
      "Epoch [891/900], Loss: 0.0070 , Accuracy : 97.50%, F1 Score: 0.79, Recall: 0.79\n",
      "Epoch [892/900], Loss: 0.0682 , Accuracy : 97.50%, F1 Score: 0.79, Recall: 0.79\n",
      "Epoch [893/900], Loss: 0.0119 , Accuracy : 100.00%, F1 Score: 0.79, Recall: 0.79\n",
      "Epoch [894/900], Loss: 0.0015 , Accuracy : 100.00%, F1 Score: 0.79, Recall: 0.79\n",
      "Epoch [895/900], Loss: 0.0955 , Accuracy : 100.00%, F1 Score: 0.79, Recall: 0.79\n",
      "Epoch [896/900], Loss: 0.0007 , Accuracy : 100.00%, F1 Score: 0.79, Recall: 0.79\n",
      "Epoch [897/900], Loss: 0.0081 , Accuracy : 100.00%, F1 Score: 0.79, Recall: 0.79\n",
      "Epoch [898/900], Loss: 0.0017 , Accuracy : 100.00%, F1 Score: 0.79, Recall: 0.79\n",
      "Epoch [899/900], Loss: 0.0030 , Accuracy : 100.00%, F1 Score: 0.79, Recall: 0.79\n",
      "Epoch [900/900], Loss: 0.0096 , Accuracy : 100.00%, F1 Score: 0.79, Recall: 0.79\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "# References : https://saturncloud.io/blog/calculating-the-accuracy-of-pytorch-models-every-epoch/#:~:text=In%20order%20to%20calculate%20the,tensor%20along%20a%20specified%20dimension\n",
    "\n",
    "from sklearn.metrics import f1_score, recall_score\n",
    "\n",
    "num_epochs = 900\n",
    "loss_logger = []\n",
    "accuracy_logger = []\n",
    "f1_logger = []\n",
    "recall_logger = []\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "# n_epochs = []\n",
    "for epoch in range(num_epochs):\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    model.train()\n",
    "    for i, (sequences, labels) in enumerate(data_loader):\n",
    "        # Move data to the device\n",
    "        # labels = labels.type(torch.LongTensor)   # casting to long\n",
    "        sequences = sequences.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(sequences)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        total_correct += (predicted == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "        # Store predictions and labels for calculating metrics\n",
    "        all_preds.extend(predicted.cpu().numpy())  # Store predictions\n",
    "        all_labels.extend(labels.cpu().numpy())    # Store true labels\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # loss_logger.append(loss.item())\n",
    "    loss_logger.append(loss.item())\n",
    "    accuracy = 100 * total_correct /total_samples\n",
    "\n",
    "    # Calculate F1 score and recall\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')  # Weighted average for multi-class\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "    f1_logger.append(f1)\n",
    "    recall_logger.append(recall)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f} , Accuracy : {accuracy:.2f}%, F1 Score: {f1:.2f}, Recall: {recall:.2f}')\n",
    "    accuracy_logger.append(accuracy)\n",
    "    # n_epochs.append(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.8469150066375732,\n",
       " 3.79331111907959,\n",
       " 3.714364528656006,\n",
       " 3.7006430625915527,\n",
       " 3.7024788856506348,\n",
       " 3.591310501098633,\n",
       " 3.773263454437256,\n",
       " 4.024015426635742,\n",
       " 3.588869571685791,\n",
       " 3.5409953594207764,\n",
       " 2.960601568222046,\n",
       " 3.5367186069488525,\n",
       " 3.5848679542541504,\n",
       " 3.3052563667297363,\n",
       " 3.7452399730682373,\n",
       " 3.4141592979431152,\n",
       " 3.635322093963623,\n",
       " 3.5608649253845215,\n",
       " 3.5932888984680176,\n",
       " 3.483013391494751,\n",
       " 3.1570472717285156,\n",
       " 3.1816468238830566,\n",
       " 3.179812431335449,\n",
       " 3.765613079071045,\n",
       " 4.732378005981445,\n",
       " 3.0261032581329346,\n",
       " 3.4467267990112305,\n",
       " 2.940396308898926,\n",
       " 2.6626691818237305,\n",
       " 3.2586610317230225,\n",
       " 2.8489649295806885,\n",
       " 3.064541816711426,\n",
       " 2.886075973510742,\n",
       " 3.10274600982666,\n",
       " 2.9249796867370605,\n",
       " 2.9869651794433594,\n",
       " 2.10847806930542,\n",
       " 4.792024612426758,\n",
       " 2.7618672847747803,\n",
       " 2.0347063541412354,\n",
       " 4.425600051879883,\n",
       " 2.7554287910461426,\n",
       " 2.474928617477417,\n",
       " 2.2349414825439453,\n",
       " 2.5310635566711426,\n",
       " 2.0605032444000244,\n",
       " 2.618326187133789,\n",
       " 2.7594306468963623,\n",
       " 2.6603126525878906,\n",
       " 3.0700483322143555,\n",
       " 2.1893692016601562,\n",
       " 3.223083019256592,\n",
       " 2.707984447479248,\n",
       " 2.6268303394317627,\n",
       " 2.2027275562286377,\n",
       " 2.050292491912842,\n",
       " 2.2553374767303467,\n",
       " 2.4506382942199707,\n",
       " 2.242140531539917,\n",
       " 1.4520081281661987,\n",
       " 2.0394513607025146,\n",
       " 2.3416876792907715,\n",
       " 2.3552019596099854,\n",
       " 2.207401752471924,\n",
       " 2.260560989379883,\n",
       " 2.0075912475585938,\n",
       " 2.1540520191192627,\n",
       " 1.8852380514144897,\n",
       " 4.988792419433594,\n",
       " 1.8872902393341064,\n",
       " 1.8628485202789307,\n",
       " 1.823801875114441,\n",
       " 2.0178539752960205,\n",
       " 2.3714041709899902,\n",
       " 3.3634235858917236,\n",
       " 1.8703022003173828,\n",
       " 2.1074626445770264,\n",
       " 1.2145037651062012,\n",
       " 1.2822108268737793,\n",
       " 2.871767997741699,\n",
       " 1.7147845029830933,\n",
       " 2.052824020385742,\n",
       " 1.8182320594787598,\n",
       " 2.661466360092163,\n",
       " 2.2224767208099365,\n",
       " 2.7553298473358154,\n",
       " 1.757015347480774,\n",
       " 1.454253077507019,\n",
       " 1.8380963802337646,\n",
       " 1.8103634119033813,\n",
       " 1.837364673614502,\n",
       " 1.8316587209701538,\n",
       " 1.751312017440796,\n",
       " 1.1009759902954102,\n",
       " 1.313507318496704,\n",
       " 1.2840166091918945,\n",
       " 1.1695618629455566,\n",
       " 1.2777360677719116,\n",
       " 1.0692272186279297,\n",
       " 1.754360556602478,\n",
       " 1.6272839307785034,\n",
       " 1.757734775543213,\n",
       " 2.3851335048675537,\n",
       " 1.2904345989227295,\n",
       " 1.5206496715545654,\n",
       " 1.286831021308899,\n",
       " 2.195530891418457,\n",
       " 1.3813228607177734,\n",
       " 2.549105644226074,\n",
       " 2.1315622329711914,\n",
       " 1.5328233242034912,\n",
       " 1.7733246088027954,\n",
       " 1.9034230709075928,\n",
       " 1.5136678218841553,\n",
       " 2.619596481323242,\n",
       " 1.6294798851013184,\n",
       " 3.007385492324829,\n",
       " 1.2650073766708374,\n",
       " 1.6460057497024536,\n",
       " 1.3234877586364746,\n",
       " 2.130704402923584,\n",
       " 1.6515135765075684,\n",
       " 0.8547044992446899,\n",
       " 1.9267922639846802,\n",
       " 1.831912875175476,\n",
       " 1.532434344291687,\n",
       " 1.5878971815109253,\n",
       " 1.4371399879455566,\n",
       " 1.6694550514221191,\n",
       " 1.057447075843811,\n",
       " 0.8852578997612,\n",
       " 0.5541158318519592,\n",
       " 0.9697017669677734,\n",
       " 1.1488655805587769,\n",
       " 1.3599522113800049,\n",
       " 2.58231782913208,\n",
       " 1.044924020767212,\n",
       " 1.0208691358566284,\n",
       " 1.1032946109771729,\n",
       " 1.405487060546875,\n",
       " 1.2135846614837646,\n",
       " 1.6751192808151245,\n",
       " 0.9092395305633545,\n",
       " 1.080567479133606,\n",
       " 1.1031129360198975,\n",
       " 1.0838536024093628,\n",
       " 1.7965240478515625,\n",
       " 1.3006610870361328,\n",
       " 0.8193835020065308,\n",
       " 1.270612359046936,\n",
       " 1.3772165775299072,\n",
       " 1.5706983804702759,\n",
       " 1.739391565322876,\n",
       " 0.8437183499336243,\n",
       " 1.9134827852249146,\n",
       " 0.27991703152656555,\n",
       " 0.8826397657394409,\n",
       " 2.2247838973999023,\n",
       " 1.9377772808074951,\n",
       " 0.5459167957305908,\n",
       " 0.7873945832252502,\n",
       " 1.4043916463851929,\n",
       " 0.2827644944190979,\n",
       " 0.8347764611244202,\n",
       " 1.0149073600769043,\n",
       " 1.2845754623413086,\n",
       " 0.4776932895183563,\n",
       " 1.6675879955291748,\n",
       " 1.6450345516204834,\n",
       " 1.498197317123413,\n",
       " 0.6832912564277649,\n",
       " 1.099472999572754,\n",
       " 0.9544356465339661,\n",
       " 0.9113394021987915,\n",
       " 0.9603121876716614,\n",
       " 0.9176335334777832,\n",
       " 1.3868753910064697,\n",
       " 0.3864103853702545,\n",
       " 0.6011320352554321,\n",
       " 1.8579376935958862,\n",
       " 0.6851164698600769,\n",
       " 0.2135944366455078,\n",
       " 1.4656486511230469,\n",
       " 1.0103358030319214,\n",
       " 0.9815276861190796,\n",
       " 0.23594436049461365,\n",
       " 1.2093722820281982,\n",
       " 1.8713057041168213,\n",
       " 0.668573796749115,\n",
       " 0.9415249824523926,\n",
       " 0.482130229473114,\n",
       " 3.482062339782715,\n",
       " 0.6580995321273804,\n",
       " 0.47982627153396606,\n",
       " 1.236985206604004,\n",
       " 0.1648392230272293,\n",
       " 0.14278432726860046,\n",
       " 1.1355750560760498,\n",
       " 2.1416547298431396,\n",
       " 3.6039819717407227,\n",
       " 2.718900442123413,\n",
       " 1.506285309791565,\n",
       " 0.6251476407051086,\n",
       " 1.9057869911193848,\n",
       " 0.9596395492553711,\n",
       " 0.5634422898292542,\n",
       " 0.9734125733375549,\n",
       " 1.336592435836792,\n",
       " 0.6784396171569824,\n",
       " 1.4181238412857056,\n",
       " 0.30623555183410645,\n",
       " 1.275970697402954,\n",
       " 0.8125399947166443,\n",
       " 0.28248992562294006,\n",
       " 1.3501629829406738,\n",
       " 0.855575680732727,\n",
       " 0.13251091539859772,\n",
       " 0.8009851574897766,\n",
       " 0.7966282963752747,\n",
       " 0.1288992315530777,\n",
       " 1.4752391576766968,\n",
       " 0.9142298698425293,\n",
       " 1.6326606273651123,\n",
       " 1.3094863891601562,\n",
       " 1.4012565612792969,\n",
       " 0.6823423504829407,\n",
       " 1.9723916053771973,\n",
       " 0.2611214816570282,\n",
       " 0.3254268765449524,\n",
       " 0.22272080183029175,\n",
       " 0.749193012714386,\n",
       " 0.36176902055740356,\n",
       " 13.249551773071289,\n",
       " 11.359062194824219,\n",
       " 1.525667428970337,\n",
       " 3.152276039123535,\n",
       " 2.5759706497192383,\n",
       " 2.5231220722198486,\n",
       " 1.1479321718215942,\n",
       " 2.8526039123535156,\n",
       " 1.731724500656128,\n",
       " 1.7242070436477661,\n",
       " 1.4170737266540527,\n",
       " 0.8739518523216248,\n",
       " 1.018418312072754,\n",
       " 1.282063603401184,\n",
       " 1.7149603366851807,\n",
       " 1.2550098896026611,\n",
       " 0.9211448431015015,\n",
       " 1.3518378734588623,\n",
       " 0.8655831813812256,\n",
       " 0.8555663824081421,\n",
       " 1.1384731531143188,\n",
       " 1.060831904411316,\n",
       " 0.5261328816413879,\n",
       " 1.4441750049591064,\n",
       " 1.4207650423049927,\n",
       " 1.1846165657043457,\n",
       " 0.6232231855392456,\n",
       " 1.0210528373718262,\n",
       " 0.39393454790115356,\n",
       " 0.3990107476711273,\n",
       " 0.2540670931339264,\n",
       " 1.971098780632019,\n",
       " 0.5622302293777466,\n",
       " 1.1203958988189697,\n",
       " 0.641226053237915,\n",
       " 0.47502434253692627,\n",
       " 0.814910888671875,\n",
       " 0.5974276065826416,\n",
       " 1.0037132501602173,\n",
       " 2.7957797050476074,\n",
       " 1.3544390201568604,\n",
       " 0.6503371000289917,\n",
       " 4.702385425567627,\n",
       " 0.7476476430892944,\n",
       " 1.7165372371673584,\n",
       " 1.3927080631256104,\n",
       " 0.2952704131603241,\n",
       " 0.6110206246376038,\n",
       " 0.9908997416496277,\n",
       " 1.2946888208389282,\n",
       " 0.2643420994281769,\n",
       " 0.5142919421195984,\n",
       " 0.23297439515590668,\n",
       " 0.5529390573501587,\n",
       " 0.20107008516788483,\n",
       " 0.397145539522171,\n",
       " 0.6596620082855225,\n",
       " 0.09005338698625565,\n",
       " 1.275572657585144,\n",
       " 0.500869631767273,\n",
       " 0.6855941414833069,\n",
       " 0.7110002636909485,\n",
       " 1.6287732124328613,\n",
       " 1.55300772190094,\n",
       " 0.4028733968734741,\n",
       " 0.6237096786499023,\n",
       " 0.3755961060523987,\n",
       " 1.4011428356170654,\n",
       " 0.4306305944919586,\n",
       " 1.0157026052474976,\n",
       " 1.0369315147399902,\n",
       " 0.7983613014221191,\n",
       " 1.0778580904006958,\n",
       " 0.1990044116973877,\n",
       " 0.3971894383430481,\n",
       " 0.9938874244689941,\n",
       " 0.86981201171875,\n",
       " 0.12199337035417557,\n",
       " 0.29904627799987793,\n",
       " 0.5034267902374268,\n",
       " 0.89019376039505,\n",
       " 0.2416667342185974,\n",
       " 0.9327524900436401,\n",
       " 0.5823646783828735,\n",
       " 0.5100345611572266,\n",
       " 1.270922303199768,\n",
       " 0.33770835399627686,\n",
       " 0.03406909480690956,\n",
       " 0.4818362295627594,\n",
       " 0.4790481925010681,\n",
       " 0.4759944677352905,\n",
       " 0.2562865912914276,\n",
       " 0.6251693367958069,\n",
       " 0.7201014757156372,\n",
       " 2.230989456176758,\n",
       " 1.5588140487670898,\n",
       " 0.8876795768737793,\n",
       " 0.4797818064689636,\n",
       " 0.019493423402309418,\n",
       " 0.08151661604642868,\n",
       " 0.03943593055009842,\n",
       " 0.8076097965240479,\n",
       " 0.6684994697570801,\n",
       " 0.14158371090888977,\n",
       " 0.550154983997345,\n",
       " 0.5890684723854065,\n",
       " 0.020002946257591248,\n",
       " 0.16671670973300934,\n",
       " 0.3766438066959381,\n",
       " 0.440529465675354,\n",
       " 0.12182129174470901,\n",
       " 0.14721840620040894,\n",
       " 0.10650812089443207,\n",
       " 0.03170831501483917,\n",
       " 0.3063833713531494,\n",
       " 0.2689690887928009,\n",
       " 0.029218651354312897,\n",
       " 0.023342877626419067,\n",
       " 0.06972897052764893,\n",
       " 0.08765195310115814,\n",
       " 0.053187981247901917,\n",
       " 0.19182619452476501,\n",
       " 0.14387854933738708,\n",
       " 0.010075699537992477,\n",
       " 0.2173769772052765,\n",
       " 0.1871446967124939,\n",
       " 0.2204161286354065,\n",
       " 0.14156502485275269,\n",
       " 1.3808693885803223,\n",
       " 0.3781399428844452,\n",
       " 0.013001137413084507,\n",
       " 1.977766513824463,\n",
       " 0.0971570834517479,\n",
       " 1.8011027574539185,\n",
       " 0.39400845766067505,\n",
       " 0.39219263195991516,\n",
       " 0.036008454859256744,\n",
       " 0.20176073908805847,\n",
       " 0.044220857322216034,\n",
       " 0.15698152780532837,\n",
       " 0.21847853064537048,\n",
       " 0.07452739775180817,\n",
       " 0.12915955483913422,\n",
       " 0.16056108474731445,\n",
       " 0.37087738513946533,\n",
       " 0.2948756515979767,\n",
       " 0.13567835092544556,\n",
       " 0.3134194612503052,\n",
       " 0.312086284160614,\n",
       " 0.44462424516677856,\n",
       " 0.15543466806411743,\n",
       " 0.14182314276695251,\n",
       " 0.13921590149402618,\n",
       " 0.33882400393486023,\n",
       " 0.33846110105514526,\n",
       " 0.014830045402050018,\n",
       " 0.035214927047491074,\n",
       " 0.08975952118635178,\n",
       " 0.11220000684261322,\n",
       " 0.05671888589859009,\n",
       " 0.010172784328460693,\n",
       " 0.05571071803569794,\n",
       " 0.0737466812133789,\n",
       " 0.04432372748851776,\n",
       " 0.11815547943115234,\n",
       " 0.5906341671943665,\n",
       " 0.49644407629966736,\n",
       " 0.026402033865451813,\n",
       " 0.4431052505970001,\n",
       " 0.016621848568320274,\n",
       " 0.007490342948585749,\n",
       " 0.3038072884082794,\n",
       " 0.14382867515087128,\n",
       " 0.02082262933254242,\n",
       " 0.05637894943356514,\n",
       " 0.037335481494665146,\n",
       " 0.1932210624217987,\n",
       " 0.0728197693824768,\n",
       " 0.04083458334207535,\n",
       " 0.13381969928741455,\n",
       " 0.020457960665225983,\n",
       " 0.01974882185459137,\n",
       " 0.017309222370386124,\n",
       " 0.018117599189281464,\n",
       " 0.02901275083422661,\n",
       " 0.19366773962974548,\n",
       " 0.024010546505451202,\n",
       " 0.04603862389922142,\n",
       " 0.02292206510901451,\n",
       " 0.00845804251730442,\n",
       " 0.26697060465812683,\n",
       " 0.04317071661353111,\n",
       " 0.02743956819176674,\n",
       " 0.016901953145861626,\n",
       " 1.1313509941101074,\n",
       " 0.27223527431488037,\n",
       " 0.45830535888671875,\n",
       " 0.034645482897758484,\n",
       " 1.3064082860946655,\n",
       " 1.6262176036834717,\n",
       " 0.8790056109428406,\n",
       " 1.037489652633667,\n",
       " 0.9131615161895752,\n",
       " 0.6452125310897827,\n",
       " 0.2586415410041809,\n",
       " 0.39691197872161865,\n",
       " 0.5217339992523193,\n",
       " 0.15367388725280762,\n",
       " 0.8373055458068848,\n",
       " 0.341722309589386,\n",
       " 0.4214474856853485,\n",
       " 0.11896874755620956,\n",
       " 0.2199542224407196,\n",
       " 0.06238347291946411,\n",
       " 0.02608208730816841,\n",
       " 0.1762796938419342,\n",
       " 0.5613215565681458,\n",
       " 0.08902627974748611,\n",
       " 0.01497596874833107,\n",
       " 0.04280829057097435,\n",
       " 0.06812477856874466,\n",
       " 0.9211569428443909,\n",
       " 2.001070976257324,\n",
       " 2.815329074859619,\n",
       " 1.7524266242980957,\n",
       " 0.23566484451293945,\n",
       " 1.7557809352874756,\n",
       " 0.9249744415283203,\n",
       " 0.026548022404313087,\n",
       " 0.14303752779960632,\n",
       " 0.3515029847621918,\n",
       " 0.26729676127433777,\n",
       " 0.025209182873368263,\n",
       " 0.07272075116634369,\n",
       " 3.918911933898926,\n",
       " 5.004027366638184,\n",
       " 1.505176067352295,\n",
       " 0.3178214728832245,\n",
       " 0.7441238760948181,\n",
       " 1.111050009727478,\n",
       " 0.8521881699562073,\n",
       " 1.0664499998092651,\n",
       " 2.1567013263702393,\n",
       " 0.9290280342102051,\n",
       " 0.40530747175216675,\n",
       " 1.4555063247680664,\n",
       " 1.541820764541626,\n",
       " 0.6563080549240112,\n",
       " 0.7853463292121887,\n",
       " 1.4850367307662964,\n",
       " 0.6029135584831238,\n",
       " 1.029798984527588,\n",
       " 2.723750114440918,\n",
       " 0.030013317242264748,\n",
       " 0.5042200684547424,\n",
       " 0.5707334280014038,\n",
       " 0.2203395664691925,\n",
       " 0.0706886574625969,\n",
       " 0.6627804040908813,\n",
       " 0.5194761753082275,\n",
       " 0.4438331425189972,\n",
       " 0.08789347112178802,\n",
       " 0.18498380482196808,\n",
       " 0.5781301856040955,\n",
       " 0.6458303928375244,\n",
       " 0.9267527461051941,\n",
       " 0.4989548921585083,\n",
       " 0.3514171242713928,\n",
       " 0.6064261794090271,\n",
       " 0.26016443967819214,\n",
       " 0.07003526389598846,\n",
       " 0.5262614488601685,\n",
       " 0.4142794609069824,\n",
       " 0.11965107172727585,\n",
       " 0.1659010648727417,\n",
       " 0.02847648411989212,\n",
       " 0.1416587382555008,\n",
       " 0.13937225937843323,\n",
       " 0.2694518268108368,\n",
       " 0.07199978083372116,\n",
       " 0.26503849029541016,\n",
       " 0.6391234993934631,\n",
       " 0.36036404967308044,\n",
       " 0.04558733105659485,\n",
       " 0.013033127412199974,\n",
       " 0.020577838644385338,\n",
       " 0.36249223351478577,\n",
       " 0.02479703724384308,\n",
       " 1.1451140642166138,\n",
       " 0.14995132386684418,\n",
       " 0.07600778341293335,\n",
       " 0.2885836660861969,\n",
       " 0.11506585776805878,\n",
       " 0.3237248957157135,\n",
       " 0.22261378169059753,\n",
       " 0.2144397795200348,\n",
       " 0.007604827638715506,\n",
       " 0.008080409839749336,\n",
       " 0.05343775078654289,\n",
       " 0.16991254687309265,\n",
       " 0.18496176600456238,\n",
       " 0.017251817509531975,\n",
       " 0.06813289225101471,\n",
       " 0.06542596966028214,\n",
       " 0.30864638090133667,\n",
       " 0.011041945777833462,\n",
       " 0.04505252465605736,\n",
       " 0.06880902498960495,\n",
       " 1.0638561248779297,\n",
       " 0.045897193253040314,\n",
       " 0.34195375442504883,\n",
       " 1.1562296152114868,\n",
       " 0.03570801764726639,\n",
       " 0.02703874558210373,\n",
       " 0.0387285090982914,\n",
       " 0.28386470675468445,\n",
       " 0.01560886949300766,\n",
       " 3.075547695159912,\n",
       " 0.0254583191126585,\n",
       " 0.046114638447761536,\n",
       " 0.016662996262311935,\n",
       " 0.010630536824464798,\n",
       " 0.029253099113702774,\n",
       " 0.015787959098815918,\n",
       " 0.03288077563047409,\n",
       " 0.042130813002586365,\n",
       " 0.008855415508151054,\n",
       " 0.005286588333547115,\n",
       " 0.009241703897714615,\n",
       " 0.20043301582336426,\n",
       " 0.09409263730049133,\n",
       " 0.06830562651157379,\n",
       " 0.11035189777612686,\n",
       " 0.023841874673962593,\n",
       " 0.023282930254936218,\n",
       " 0.006135981529951096,\n",
       " 2.1023976802825928,\n",
       " 0.1362849622964859,\n",
       " 0.015552262775599957,\n",
       " 0.009871682152152061,\n",
       " 0.012134919874370098,\n",
       " 0.04945750907063484,\n",
       " 0.0689050555229187,\n",
       " 0.005342393647879362,\n",
       " 0.028294546529650688,\n",
       " 0.003311772830784321,\n",
       " 0.00930771604180336,\n",
       " 0.002450003521516919,\n",
       " 0.01732691377401352,\n",
       " 0.6831012964248657,\n",
       " 0.009764374233782291,\n",
       " 0.22928932309150696,\n",
       " 0.0027003204450011253,\n",
       " 0.5771429538726807,\n",
       " 0.6279964447021484,\n",
       " 0.13419899344444275,\n",
       " 0.028209589421749115,\n",
       " 0.039879634976387024,\n",
       " 0.8573601245880127,\n",
       " 0.1890787035226822,\n",
       " 0.3276848793029785,\n",
       " 0.13950380682945251,\n",
       " 0.03034195862710476,\n",
       " 0.23662219941616058,\n",
       " 0.041579291224479675,\n",
       " 0.01124400831758976,\n",
       " 0.2490711212158203,\n",
       " 0.005857738666236401,\n",
       " 0.10185405611991882,\n",
       " 0.007645635399967432,\n",
       " 0.013735062442719936,\n",
       " 0.038148704916238785,\n",
       " 0.012459022924304008,\n",
       " 0.008343353867530823,\n",
       " 0.007898608222603798,\n",
       " 0.09658284485340118,\n",
       " 0.012754654511809349,\n",
       " 0.022695068269968033,\n",
       " 0.032451655715703964,\n",
       " 0.020710406824946404,\n",
       " 0.008510012179613113,\n",
       " 0.02397868223488331,\n",
       " 0.012851635925471783,\n",
       " 0.04317367449402809,\n",
       " 0.004368622787296772,\n",
       " 0.01881401054561138,\n",
       " 0.12805376946926117,\n",
       " 0.023336000740528107,\n",
       " 0.02694166824221611,\n",
       " 0.020557474344968796,\n",
       " 0.010651940479874611,\n",
       " 0.00567216519266367,\n",
       " 0.012770846486091614,\n",
       " 0.0031667640432715416,\n",
       " 0.04964400827884674,\n",
       " 0.004362247884273529,\n",
       " 0.021415457129478455,\n",
       " 0.023309830576181412,\n",
       " 0.0027937577106058598,\n",
       " 0.01585768535733223,\n",
       " 0.009999412111938,\n",
       " 0.011159390211105347,\n",
       " 0.0030651954002678394,\n",
       " 0.013035515323281288,\n",
       " 0.003934519365429878,\n",
       " 0.014245377853512764,\n",
       " 0.011248139664530754,\n",
       " 0.005101722665131092,\n",
       " 0.004112802911549807,\n",
       " 0.001148413517512381,\n",
       " 0.0018888444174081087,\n",
       " 0.13004472851753235,\n",
       " 0.004700986668467522,\n",
       " 0.008061436004936695,\n",
       " 0.010686264373362064,\n",
       " 0.002902774838730693,\n",
       " 0.004792653955519199,\n",
       " 0.009023543447256088,\n",
       " 0.006702818907797337,\n",
       " 0.043281883001327515,\n",
       " 0.003572785295546055,\n",
       " 0.25906625390052795,\n",
       " 0.016328750178217888,\n",
       " 0.0012471205554902554,\n",
       " 0.007451850920915604,\n",
       " 0.011643292382359505,\n",
       " 0.02862352319061756,\n",
       " 0.0004899307386949658,\n",
       " 0.05074853450059891,\n",
       " 0.007361263036727905,\n",
       " 0.0018371957121416926,\n",
       " 0.004149110987782478,\n",
       " 0.003745900932699442,\n",
       " 0.008091295138001442,\n",
       " 0.006532992236316204,\n",
       " 0.032906677573919296,\n",
       " 0.0016461146296933293,\n",
       " 0.002987128682434559,\n",
       " 0.03151198476552963,\n",
       " 0.0037247580476105213,\n",
       " 0.00174266891553998,\n",
       " 0.0040407986380159855,\n",
       " 0.002122079022228718,\n",
       " 0.0018757053185254335,\n",
       " 0.016227753832936287,\n",
       " 0.011223651468753815,\n",
       " 0.003562005702406168,\n",
       " 0.003778772195801139,\n",
       " 0.002045438624918461,\n",
       " 0.0026719262823462486,\n",
       " 0.0012837575050070882,\n",
       " 0.0013713048538193107,\n",
       " 0.0029455632902681828,\n",
       " 0.0021183015778660774,\n",
       " 0.004279012326151133,\n",
       " 0.0025348891504108906,\n",
       " 0.002537851221859455,\n",
       " 0.004985249601304531,\n",
       " 0.0005440902314148843,\n",
       " 0.0015342148253694177,\n",
       " 0.001984609756618738,\n",
       " 0.0014156796969473362,\n",
       " 0.0007450837874785066,\n",
       " 0.018474368378520012,\n",
       " 0.0018252860754728317,\n",
       " 0.0436580553650856,\n",
       " 0.003467975649982691,\n",
       " 0.001477122656069696,\n",
       " 0.003099955152720213,\n",
       " 0.0009591700509190559,\n",
       " 0.0012305008713155985,\n",
       " 0.004085462540388107,\n",
       " 0.0012822342105209827,\n",
       " 0.0036150943487882614,\n",
       " 0.004673677962273359,\n",
       " 0.002979019656777382,\n",
       " 0.003206032095476985,\n",
       " 0.0021239789202809334,\n",
       " 0.004065488465130329,\n",
       " 0.006386079825460911,\n",
       " 0.0024962141178548336,\n",
       " 0.0007934347959235311,\n",
       " 0.003402195405215025,\n",
       " 0.0017288534436374903,\n",
       " 0.000839010055642575,\n",
       " 0.003622511401772499,\n",
       " 0.00022490567062050104,\n",
       " 0.0011503988644108176,\n",
       " 0.002496243454515934,\n",
       " 0.003052168060094118,\n",
       " 0.0031338557600975037,\n",
       " 0.0009852503426373005,\n",
       " 0.0011771939462050796,\n",
       " 0.0016183346742764115,\n",
       " 0.006563439965248108,\n",
       " 0.0025326991453766823,\n",
       " 0.000594255281612277,\n",
       " 0.014626533724367619,\n",
       " 0.0012595625594258308,\n",
       " 0.0005054272478446364,\n",
       " 0.0037629830185323954,\n",
       " 0.0027462728321552277,\n",
       " 0.0014302378986030817,\n",
       " 0.0015588141977787018,\n",
       " 0.00038203573785722256,\n",
       " 0.0017851025331765413,\n",
       " 0.0030475487001240253,\n",
       " 0.00024764786940068007,\n",
       " 0.001668465556576848,\n",
       " 0.0014105604495853186,\n",
       " 0.000875415513291955,\n",
       " 0.0018719746731221676,\n",
       " 0.001228043343871832,\n",
       " 0.0032141534611582756,\n",
       " 0.0026735735591500998,\n",
       " 0.0007748959469608963,\n",
       " 0.0018600013572722673,\n",
       " 0.003026855643838644,\n",
       " 0.00021835503866896033,\n",
       " 0.0005404097028076649,\n",
       " 0.000835646758787334,\n",
       " 0.0008642362081445754,\n",
       " 0.0015836317325010896,\n",
       " 0.0005858440417796373,\n",
       " 0.0016440756153315306,\n",
       " 0.005804528947919607,\n",
       " 0.0010070930002257228,\n",
       " 0.0010164219420403242,\n",
       " 0.0003190427669323981,\n",
       " 0.0003842035075649619,\n",
       " 0.0014234409900382161,\n",
       " 0.0010320341680198908,\n",
       " 0.002502191811800003,\n",
       " 0.0017675645649433136,\n",
       " 0.0013482053764164448,\n",
       " 0.0013446793891489506,\n",
       " 0.0019168449798598886,\n",
       " 0.00121181586291641,\n",
       " 0.002190524013713002,\n",
       " 0.00036801962414756417,\n",
       " 0.001709016039967537,\n",
       " 0.0007210961193777621,\n",
       " 0.002768556121736765,\n",
       " 0.0015277120983228087,\n",
       " 0.000195321612409316,\n",
       " 0.001146047725342214,\n",
       " 0.0009938612347468734,\n",
       " 0.0009801890701055527,\n",
       " 0.010260273702442646,\n",
       " 0.0005228056106716394,\n",
       " 0.0027587281074374914,\n",
       " 0.0005443172995001078,\n",
       " 0.0011447067372500896,\n",
       " 0.0007236942765302956,\n",
       " 0.0015035909600555897,\n",
       " 0.0005494794459082186,\n",
       " 0.0012120790779590607,\n",
       " 0.0029630297794938087,\n",
       " 0.0012678347993642092,\n",
       " 0.0004984079860150814,\n",
       " 0.001190998824313283,\n",
       " 0.0006407571490854025,\n",
       " 0.00099945068359375,\n",
       " 0.0011529233306646347,\n",
       " 0.0005467931623570621,\n",
       " 0.0012333807535469532,\n",
       " 0.0006797006935812533,\n",
       " 0.00047235016245394945,\n",
       " 0.0012746431166306138,\n",
       " 0.000988034182228148,\n",
       " 0.0007611352484673262,\n",
       " 1.983231544494629,\n",
       " 3.828817844390869,\n",
       " 2.1016769409179688,\n",
       " 6.696244716644287,\n",
       " 0.9565948843955994,\n",
       " 1.861066460609436,\n",
       " 0.13320715725421906,\n",
       " 2.317842483520508,\n",
       " 0.5348383188247681,\n",
       " 1.0610265731811523,\n",
       " 0.06311672180891037,\n",
       " 0.14068827033042908,\n",
       " 0.12213180214166641,\n",
       " 0.20405107736587524,\n",
       " 0.39005306363105774,\n",
       " 0.04619880020618439,\n",
       " 0.10149027407169342,\n",
       " 0.3943192958831787,\n",
       " 0.07224716246128082,\n",
       " 0.05927112698554993,\n",
       " 0.03597044572234154,\n",
       " 0.5168436765670776,\n",
       " 1.0570056438446045,\n",
       " 0.012983988970518112,\n",
       " 0.07228854298591614,\n",
       " 0.09085909277200699,\n",
       " 0.008632998913526535,\n",
       " 0.02355702593922615,\n",
       " 0.02866327203810215,\n",
       " 0.011375270783901215,\n",
       " 0.025952061638236046,\n",
       " 0.011178476735949516,\n",
       " 0.009088438004255295,\n",
       " 0.011016902513802052,\n",
       " 0.025979816913604736,\n",
       " 0.0028752328362315893,\n",
       " 0.015967436134815216,\n",
       " 0.11054027825593948,\n",
       " 0.015159803442656994,\n",
       " 0.008743353188037872,\n",
       " 0.029489345848560333,\n",
       " 0.009432476945221424,\n",
       " 0.005489295814186335,\n",
       " 0.005972931161522865,\n",
       " 0.015009546652436256,\n",
       " 0.019435876980423927,\n",
       " 0.006086512468755245,\n",
       " 0.011141583323478699,\n",
       " 0.007527210749685764,\n",
       " 0.02230105549097061,\n",
       " 0.011003309860825539,\n",
       " 0.04875485226511955,\n",
       " 0.0034677889198064804,\n",
       " 0.015192371793091297,\n",
       " 0.0248868390917778,\n",
       " 0.013812042772769928,\n",
       " 0.007585808169096708,\n",
       " 0.0029014465399086475,\n",
       " 0.007549986243247986,\n",
       " 0.0073866210877895355,\n",
       " 0.003838434349745512,\n",
       " 0.005522110499441624,\n",
       " 0.0019202579278498888,\n",
       " 0.0052393279038369656,\n",
       " 0.00562214944511652,\n",
       " 0.0049210707657039165,\n",
       " 0.009819802828133106,\n",
       " 0.005731154233217239,\n",
       " 0.002607397735118866,\n",
       " 0.004210165701806545,\n",
       " 0.0024257495533674955,\n",
       " 0.0014353180304169655,\n",
       " 0.01735859364271164,\n",
       " 0.0022520015481859446,\n",
       " 0.006470705848187208,\n",
       " 0.005120039451867342,\n",
       " 0.0010976797202602029,\n",
       " 0.006192327011376619,\n",
       " 0.011360283941030502,\n",
       " 0.008105902932584286,\n",
       " 0.0030217193998396397,\n",
       " 0.005281048361212015,\n",
       " 0.006298452615737915,\n",
       " 0.002202992793172598,\n",
       " 0.009229298681020737,\n",
       " 0.0086582712829113,\n",
       " 0.006894605699926615,\n",
       " 0.006968723610043526,\n",
       " 0.06821075826883316,\n",
       " 0.011864406056702137,\n",
       " 0.0014674008125439286,\n",
       " 0.09546820819377899,\n",
       " 0.0006503345211967826,\n",
       " 0.008120221085846424,\n",
       " 0.0017364956438541412,\n",
       " 0.0030371639877557755,\n",
       " 0.009554990567266941]"
      ]
     },
     "execution_count": 567,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.title(\"Loss Curve\")\n",
    "plt.plot(loss_logger, label='train_loss')\n",
    "# plt.plot(accuracy_logger,label='accuracy')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save and Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.5032,  0.2228, -1.1998,  ...,  0.5663,  0.1971,  0.0106],\n",
       "         [ 0.5035,  0.2228, -1.2072,  ...,  0.5662,  0.1969,  0.0106],\n",
       "         [ 0.5035,  0.2230, -1.2082,  ...,  0.5664,  0.1963,  0.0108],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.5005,  0.2439, -1.3629,  ...,  0.5694,  0.2139,  0.0154],\n",
       "         [ 0.5002,  0.2448, -1.5049,  ...,  0.5688,  0.2128,  0.0146],\n",
       "         [ 0.4999,  0.2457, -1.5287,  ...,  0.5683,  0.2134,  0.0148],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.5103,  0.2428, -1.1660,  ...,  0.5757,  0.2179,  0.0081],\n",
       "         [ 0.5106,  0.2437, -1.2850,  ...,  0.5751,  0.2183,  0.0099],\n",
       "         [ 0.5112,  0.2443, -1.2880,  ...,  0.5748,  0.2189,  0.0108],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.4868,  0.2821, -1.4668,  ...,  0.5711,  0.2335,  0.0116],\n",
       "         [ 0.4861,  0.2786, -1.5812,  ...,  0.5702,  0.2334,  0.0129],\n",
       "         [ 0.4856,  0.2769, -1.6059,  ...,  0.5699,  0.2333,  0.0131],\n",
       "         ...,\n",
       "         [ 0.4826,  0.2583, -1.6140,  ...,  0.5606,  0.2261,  0.0154],\n",
       "         [ 0.4820,  0.2583, -1.5231,  ...,  0.5603,  0.2261,  0.0156],\n",
       "         [ 0.4818,  0.2580, -1.5255,  ...,  0.5600,  0.2263,  0.0156]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 573,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_sequence(sequences, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 21.5077,  -1.5351,  -5.1531,  ..., -25.8590,  12.3451, -14.0065],\n",
       "        [ -8.4747,  23.6321, -13.6438,  ...,  13.4433, -13.5173, -17.3546],\n",
       "        [ -3.7024,  11.0017,  43.6401,  ...,  -4.2134,  -1.1009,  -6.5702],\n",
       "        ...,\n",
       "        [-22.7878,  18.8494, -20.9755,  ...,  36.9516, -25.1379,  -8.4389],\n",
       "        [  8.5001,  -1.8790,  -8.7675,  ..., -16.4167,  18.8143,  -6.5828],\n",
       "        [ -6.7226, -23.7696,  -1.6778,  ...,  -6.9594,   2.1646,  22.2828]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 574,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Put the model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# No need to track gradients during inference\n",
    "with torch.no_grad():\n",
    "    # Get the model's output (logits)\n",
    "    outputs = model(padded_sequences.to(device))\n",
    "\n",
    "# outputs = torch.softmax(outputs, dim=1)\n",
    "# outputs = torch.max(outputs,1)\n",
    "\n",
    "outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.5013,  0.2452, -1.2167,  ...,  0.5663,  0.2188,  0.0098],\n",
       "         [ 0.4997,  0.2482, -1.4690,  ...,  0.5652,  0.2181,  0.0106],\n",
       "         [ 0.4984,  0.2500, -1.4853,  ...,  0.5654,  0.2185,  0.0112],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.4922,  0.2382, -1.2850,  ...,  0.5578,  0.2124,  0.0094],\n",
       "         [ 0.4920,  0.2405, -1.4288,  ...,  0.5571,  0.2116,  0.0099],\n",
       "         [ 0.4920,  0.2409, -1.4093,  ...,  0.5567,  0.2122,  0.0098],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.5049,  0.2371, -1.2115,  ...,  0.5643,  0.2082,  0.0088],\n",
       "         [ 0.5045,  0.2381, -1.1896,  ...,  0.5643,  0.2081,  0.0085],\n",
       "         [ 0.5041,  0.2385, -1.1915,  ...,  0.5643,  0.2080,  0.0089],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.4849,  0.2484, -1.3873,  ...,  0.5543,  0.2162,  0.0108],\n",
       "         [ 0.4846,  0.2500, -1.4881,  ...,  0.5539,  0.2157,  0.0111],\n",
       "         [ 0.4844,  0.2507, -1.4935,  ...,  0.5537,  0.2161,  0.0111],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.5199,  0.2290, -1.2810,  ...,  0.5876,  0.2058,  0.0103],\n",
       "         [ 0.5195,  0.2307, -1.3821,  ...,  0.5873,  0.2059,  0.0106],\n",
       "         [ 0.5193,  0.2327, -1.4100,  ...,  0.5877,  0.2059,  0.0109],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.5005,  0.2439, -1.3629,  ...,  0.5694,  0.2139,  0.0154],\n",
       "         [ 0.5002,  0.2448, -1.5049,  ...,  0.5688,  0.2128,  0.0146],\n",
       "         [ 0.4999,  0.2457, -1.5287,  ...,  0.5683,  0.2134,  0.0148],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]])"
      ]
     },
     "execution_count": 575,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = [\"Data for different actions/เขิน_0.mp4/เขิน_0.npy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.4321,  0.2240, -1.4261,  ...,  0.4724,  0.1833,  0.0108],\n",
       "         [ 0.4325,  0.2250, -1.4727,  ...,  0.4722,  0.1847,  0.0102],\n",
       "         [ 0.4330,  0.2258, -1.4930,  ...,  0.4725,  0.1845,  0.0109],\n",
       "         ...,\n",
       "         [ 0.4396,  0.2238, -1.5889,  ...,  0.4802,  0.1780,  0.0139],\n",
       "         [ 0.4395,  0.2238, -1.5796,  ...,  0.4802,  0.1776,  0.0141],\n",
       "         [ 0.4394,  0.2234, -1.5304,  ...,  0.4799,  0.1771,  0.0144]]])"
      ]
     },
     "execution_count": 577,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the sequences\n",
    "import torch\n",
    "sequences = load_keypoint_sequences(file_paths)\n",
    "# Change list to numpy array \n",
    "sequences = np.array(sequences)\n",
    "# Change numpy array to tensor\n",
    "sequences = torch.FloatTensor(sequences)\n",
    "sequences = pad_sequence(sequences, batch_first=True)\n",
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  4.8741,   2.8380, -12.1935,  -9.7840, -21.1354,  -9.6116,  -3.3374,\n",
       "          -1.0576, -13.8072,  -7.2425,   5.3425,   7.9389,   4.0115,  -2.3696,\n",
       "         -16.7757,  -7.0873,  13.8771,  -8.5258, -16.9659,   5.1155, -15.0262,\n",
       "         -14.0276,  -9.7448,  -7.4983,  11.2497,  -2.5736, -13.5570,  -2.3049,\n",
       "          -0.0841,   8.0697,   0.6146,  -0.6261,  11.1816,   6.9605,  -4.4177,\n",
       "           1.9114,   4.5420,  -8.8597,  13.0551,  -8.6640]], device='cuda:0',\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 578,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model(sequences.to(device))\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['กฎกระทรวง',\n",
       " 'กฎหมายรัฐธรรมนูญ',\n",
       " 'กรมอนามัย',\n",
       " 'กรรม',\n",
       " 'กรรมสิทธิ์',\n",
       " 'กระโดด',\n",
       " 'กล้วยบวชชี',\n",
       " 'กล้วยเชื่อม',\n",
       " 'กังวล',\n",
       " 'กีฬา',\n",
       " 'น้อง',\n",
       " 'เขิน',\n",
       " 'เขื่อนดิน',\n",
       " 'เขื่อนสิริกิติ์',\n",
       " 'เข้าใจผิด',\n",
       " 'เคย',\n",
       " 'เครียด',\n",
       " 'เครื่องปั่นดิน',\n",
       " 'เครื่องหมายการค้า',\n",
       " 'เจอ',\n",
       " 'เจ้าหนี้',\n",
       " 'เช่าซื้อ',\n",
       " 'เช่าทรัพย์',\n",
       " 'เซอร์เบีย',\n",
       " 'เซเนกัล',\n",
       " 'เซ็ง',\n",
       " 'เดิน',\n",
       " 'เดิมพัน',\n",
       " 'เพลีย',\n",
       " 'เมื่อย',\n",
       " 'เม็กซิโก',\n",
       " 'เฮโรอีน',\n",
       " 'แกมเบีย',\n",
       " 'แซมเบีย',\n",
       " 'โกหก',\n",
       " 'โจทก์',\n",
       " 'โชจู',\n",
       " 'ใกล้',\n",
       " 'ไดโนเสาร์',\n",
       " 'ไอซ์']"
      ]
     },
     "execution_count": 579,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [action.split(\".\")[0] for action in actions]\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change from tensor to numpy arrat\n",
    "outputs = outputs.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  4.8741097 ,   2.838034  , -12.193487  ,  -9.784008  ,\n",
       "        -21.135399  ,  -9.611589  ,  -3.3373816 ,  -1.0576277 ,\n",
       "        -13.80723   ,  -7.242494  ,   5.342532  ,   7.93888   ,\n",
       "          4.0115466 ,  -2.3695881 , -16.775728  ,  -7.0872507 ,\n",
       "         13.877058  ,  -8.525841  , -16.965889  ,   5.1155214 ,\n",
       "        -15.026201  , -14.027638  ,  -9.744804  ,  -7.4983425 ,\n",
       "         11.249718  ,  -2.5735595 , -13.557028  ,  -2.3049324 ,\n",
       "         -0.08407317,   8.069721  ,   0.6146299 ,  -0.62609255,\n",
       "         11.1815815 ,   6.96048   ,  -4.4176636 ,   1.911376  ,\n",
       "          4.542017  ,  -8.859749  ,  13.055067  ,  -8.663986  ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 581,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  4.8741097    2.838034   -12.193487    -9.784008   -21.135399\n",
      "  -9.611589    -3.3373816   -1.0576277  -13.80723     -7.242494\n",
      "   5.342532     7.93888      4.0115466   -2.3695881  -16.775728\n",
      "  -7.0872507   13.877058    -8.525841   -16.965889     5.1155214\n",
      " -15.026201   -14.027638    -9.744804    -7.4983425   11.249718\n",
      "  -2.5735595  -13.557028    -2.3049324   -0.08407317   8.069721\n",
      "   0.6146299   -0.62609255  11.1815815    6.96048     -4.4176636\n",
      "   1.911376     4.542017    -8.859749    13.055067    -8.663986  ]\n"
     ]
    }
   ],
   "source": [
    "for idx, word in enumerate(outputs):\n",
    "    # max_value = torch.max(outputs)\n",
    "    list_outputs = max(outputs)\n",
    "    print(list_outputs)\n",
    "    # print(max_value)\n",
    "    # print(max_value.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 583,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_max = max(range(len(list_outputs)), key=list_outputs.__getitem__)\n",
    "index_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "เครียด\n"
     ]
    }
   ],
   "source": [
    "print(labels[index_max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input : กฎกระทรวง Predicted : กฎกระทรวง\n",
      "Input : กฎหมายรัฐธรรมนูญ Predicted : กฎหมายรัฐธรรมนูญ\n",
      "Input : กรมอนามัย Predicted : กรมอนามัย\n",
      "Input : กรรม Predicted : กรรม\n",
      "Input : กรรมสิทธิ์ Predicted : กรรมสิทธิ์\n",
      "Input : กระโดด Predicted : กระโดด\n",
      "Input : กล้วยบวชชี Predicted : กล้วยบวชชี\n",
      "Input : กล้วยเชื่อม Predicted : กล้วยเชื่อม\n",
      "Input : กังวล Predicted : กังวล\n",
      "Input : กีฬา Predicted : กีฬา\n",
      "Input : น้อง Predicted : น้อง\n",
      "Input : เขิน Predicted : เขิน\n",
      "Input : เขื่อนดิน Predicted : เขื่อนดิน\n",
      "Input : เขื่อนสิริกิติ์ Predicted : เขื่อนสิริกิติ์\n",
      "Input : เข้าใจผิด Predicted : กังวล\n",
      "Input : เคย Predicted : เคย\n",
      "Input : เครียด Predicted : เครียด\n",
      "Input : เครื่องปั่นดิน Predicted : เครื่องปั่นดิน\n",
      "Input : เครื่องหมายการค้า Predicted : เครื่องหมายการค้า\n",
      "Input : เจอ Predicted : เจอ\n",
      "Input : เจ้าหนี้ Predicted : เจ้าหนี้\n",
      "Input : เช่าซื้อ Predicted : เช่าซื้อ\n",
      "Input : เช่าทรัพย์ Predicted : เช่าทรัพย์\n",
      "Input : เซอร์เบีย Predicted : เมื่อย\n",
      "Input : เซเนกัล Predicted : เซเนกัล\n",
      "Input : เซ็ง Predicted : เซ็ง\n",
      "Input : เดิน Predicted : เดิน\n",
      "Input : เดิมพัน Predicted : เดิมพัน\n",
      "Input : เพลีย Predicted : โจทก์\n",
      "Input : เมื่อย Predicted : เมื่อย\n",
      "Input : เม็กซิโก Predicted : เม็กซิโก\n",
      "Input : เฮโรอีน Predicted : เฮโรอีน\n",
      "Input : แกมเบีย Predicted : แกมเบีย\n",
      "Input : แซมเบีย Predicted : แซมเบีย\n",
      "Input : โกหก Predicted : โกหก\n",
      "Input : โจทก์ Predicted : โจทก์\n",
      "Input : โชจู Predicted : โชจู\n",
      "Input : ใกล้ Predicted : ใกล้\n",
      "Input : ไดโนเสาร์ Predicted : ไดโนเสาร์\n",
      "Input : ไอซ์ Predicted : ไอซ์\n",
      "Correct Predicted on Training set : 37 Corrct percentage : 92.5%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "num_clip = 0\n",
    "for clip in labels:\n",
    "    # print(clip)\n",
    "    file_paths = [f\"Data for different actions/{clip}.mp4/{clip}.npy\"]\n",
    "    # print(file_paths)\n",
    "\n",
    "    sequences = load_keypoint_sequences(file_paths)\n",
    "    # Change list to numpy array \n",
    "    sequences = np.array(sequences)\n",
    "    # Change numpy array to tensor\n",
    "    sequences = torch.FloatTensor(sequences)\n",
    "    sequences = pad_sequence(sequences, batch_first=True)\n",
    "\n",
    "    outputs = model(sequences.to(device))\n",
    "\n",
    "    for idx, word in enumerate(outputs):\n",
    "        # max_value = torch.max(outputs)\n",
    "        list_outputs = max(outputs)\n",
    "\n",
    "    index_max = max(range(len(list_outputs)), key=list_outputs.__getitem__)\n",
    "\n",
    "    print(f\"Input : {clip} Predicted : {labels[index_max]}\")\n",
    "\n",
    "    if clip == labels[index_max]:\n",
    "        correct = correct+1\n",
    "    \n",
    "    num_clip = num_clip + 1 \n",
    "\n",
    "print(f\"Correct Predicted on Training set : {correct} Corrct percentage : {correct*100/num_clip}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['กฎกระทรวง', 'กฎหมายรัฐธรรมนูญ', 'กรมอนามัย', 'กรรม', 'กรรมสิทธิ์', 'กระโดด', 'กล้วยบวชชี', 'กล้วยเชื่อม', 'กังวล', 'กีฬา', 'น้อง', 'เขิน', 'เขื่อนดิน', 'เขื่อนสิริกิติ์', 'เข้าใจผิด', 'เคย', 'เครียด', 'เครื่องปั่นดิน', 'เครื่องหมายการค้า', 'เจอ', 'เจ้าหนี้', 'เช่าซื้อ', 'เช่าทรัพย์', 'เซอร์เบีย', 'เซเนกัล', 'เซ็ง', 'เดิน', 'เดิมพัน', 'เพลีย', 'เมื่อย', 'เม็กซิโก', 'เฮโรอีน', 'แกมเบีย', 'แซมเบีย', 'โกหก', 'โจทก์', 'โชจู', 'ใกล้', 'ไดโนเสาร์', 'ไอซ์']\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 587,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "video_dir = \"C:/Users/araya/Desktop/augments\"\n",
    "video_list = []\n",
    "video_list = os.listdir(video_dir)\n",
    "\n",
    "len(video_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for exported data, numpy arrays\n",
    "Model_Data=os.path.join('../MediaPipe/Test')\n",
    "\n",
    "actions_test = np.array(video_list)\n",
    "\n",
    "no_of_seqs = 1\n",
    "\n",
    "# 30 frames in length\n",
    "seq_length = 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['กฎกระทรวง_0',\n",
       " 'กฎกระทรวง_1',\n",
       " 'กฎหมายรัฐธรรมนูญ_0',\n",
       " 'กฎหมายรัฐธรรมนูญ_1',\n",
       " 'กรมอนามัย_0',\n",
       " 'กรมอนามัย_1',\n",
       " 'กรรม_0',\n",
       " 'กรรม_1',\n",
       " 'กรรมสิทธิ์_0',\n",
       " 'กรรมสิทธิ์_1',\n",
       " 'กระโดด_0',\n",
       " 'กระโดด_1',\n",
       " 'กล้วยบวชชี_0',\n",
       " 'กล้วยบวชชี_1',\n",
       " 'กล้วยเชื่อม_0',\n",
       " 'กล้วยเชื่อม_1',\n",
       " 'กังวล_0',\n",
       " 'กังวล_1',\n",
       " 'กีฬา_0',\n",
       " 'กีฬา_1',\n",
       " 'น้อง_0',\n",
       " 'น้อง_1',\n",
       " 'เขิน_0',\n",
       " 'เขิน_1',\n",
       " 'เขื่อนดิน_0',\n",
       " 'เขื่อนดิน_1',\n",
       " 'เขื่อนสิริกิติ์_0',\n",
       " 'เขื่อนสิริกิติ์_1',\n",
       " 'เข้าใจผิด_0',\n",
       " 'เข้าใจผิด_1',\n",
       " 'เคย_0',\n",
       " 'เคย_1',\n",
       " 'เครียด_0',\n",
       " 'เครียด_1',\n",
       " 'เครื่องปั่นดิน_0',\n",
       " 'เครื่องปั่นดิน_1',\n",
       " 'เครื่องหมายการค้า_0',\n",
       " 'เครื่องหมายการค้า_1',\n",
       " 'เจอ_0',\n",
       " 'เจอ_1',\n",
       " 'เจ้าหนี้_0',\n",
       " 'เจ้าหนี้_1',\n",
       " 'เช่าซื้อ_0',\n",
       " 'เช่าซื้อ_1',\n",
       " 'เช่าทรัพย์_0',\n",
       " 'เช่าทรัพย์_1',\n",
       " 'เซอร์เบีย_0',\n",
       " 'เซอร์เบีย_1',\n",
       " 'เซเนกัล_0',\n",
       " 'เซเนกัล_1',\n",
       " 'เซ็ง_0',\n",
       " 'เซ็ง_1',\n",
       " 'เดิน_0',\n",
       " 'เดิน_1',\n",
       " 'เดิมพัน_0',\n",
       " 'เดิมพัน_1',\n",
       " 'เพลีย_0',\n",
       " 'เพลีย_1',\n",
       " 'เมื่อย_0',\n",
       " 'เมื่อย_1',\n",
       " 'เม็กซิโก_0',\n",
       " 'เม็กซิโก_1',\n",
       " 'เฮโรอีน_0',\n",
       " 'เฮโรอีน_1',\n",
       " 'แกมเบีย_0',\n",
       " 'แกมเบีย_1',\n",
       " 'แซมเบีย_0',\n",
       " 'แซมเบีย_1',\n",
       " 'โกหก_0',\n",
       " 'โกหก_1',\n",
       " 'โจทก์_0',\n",
       " 'โจทก์_1',\n",
       " 'โชจู_0',\n",
       " 'โชจู_1',\n",
       " 'ใกล้_0',\n",
       " 'ใกล้_1',\n",
       " 'ไดโนเสาร์_0',\n",
       " 'ไดโนเสาร์_1',\n",
       " 'ไอซ์_0',\n",
       " 'ไอซ์_1']"
      ]
     },
     "execution_count": 589,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_test = [action.split(\".\")[0] for action in actions_test]\n",
    "labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Test/กฎกระทรวง_0.mp4/กฎกระทรวง_0.npy', 'Test/กฎกระทรวง_1.mp4/กฎกระทรวง_1.npy', 'Test/กฎหมายรัฐธรรมนูญ_0.mp4/กฎหมายรัฐธรรมนูญ_0.npy', 'Test/กฎหมายรัฐธรรมนูญ_1.mp4/กฎหมายรัฐธรรมนูญ_1.npy', 'Test/กรมอนามัย_0.mp4/กรมอนามัย_0.npy', 'Test/กรมอนามัย_1.mp4/กรมอนามัย_1.npy', 'Test/กรรม_0.mp4/กรรม_0.npy', 'Test/กรรม_1.mp4/กรรม_1.npy', 'Test/กรรมสิทธิ์_0.mp4/กรรมสิทธิ์_0.npy', 'Test/กรรมสิทธิ์_1.mp4/กรรมสิทธิ์_1.npy', 'Test/กระโดด_0.mp4/กระโดด_0.npy', 'Test/กระโดด_1.mp4/กระโดด_1.npy', 'Test/กล้วยบวชชี_0.mp4/กล้วยบวชชี_0.npy', 'Test/กล้วยบวชชี_1.mp4/กล้วยบวชชี_1.npy', 'Test/กล้วยเชื่อม_0.mp4/กล้วยเชื่อม_0.npy', 'Test/กล้วยเชื่อม_1.mp4/กล้วยเชื่อม_1.npy', 'Test/กังวล_0.mp4/กังวล_0.npy', 'Test/กังวล_1.mp4/กังวล_1.npy', 'Test/กีฬา_0.mp4/กีฬา_0.npy', 'Test/กีฬา_1.mp4/กีฬา_1.npy', 'Test/น้อง_0.mp4/น้อง_0.npy', 'Test/น้อง_1.mp4/น้อง_1.npy', 'Test/เขิน_0.mp4/เขิน_0.npy', 'Test/เขิน_1.mp4/เขิน_1.npy', 'Test/เขื่อนดิน_0.mp4/เขื่อนดิน_0.npy', 'Test/เขื่อนดิน_1.mp4/เขื่อนดิน_1.npy', 'Test/เขื่อนสิริกิติ์_0.mp4/เขื่อนสิริกิติ์_0.npy', 'Test/เขื่อนสิริกิติ์_1.mp4/เขื่อนสิริกิติ์_1.npy', 'Test/เข้าใจผิด_0.mp4/เข้าใจผิด_0.npy', 'Test/เข้าใจผิด_1.mp4/เข้าใจผิด_1.npy', 'Test/เคย_0.mp4/เคย_0.npy', 'Test/เคย_1.mp4/เคย_1.npy', 'Test/เครียด_0.mp4/เครียด_0.npy', 'Test/เครียด_1.mp4/เครียด_1.npy', 'Test/เครื่องปั่นดิน_0.mp4/เครื่องปั่นดิน_0.npy', 'Test/เครื่องปั่นดิน_1.mp4/เครื่องปั่นดิน_1.npy', 'Test/เครื่องหมายการค้า_0.mp4/เครื่องหมายการค้า_0.npy', 'Test/เครื่องหมายการค้า_1.mp4/เครื่องหมายการค้า_1.npy', 'Test/เจอ_0.mp4/เจอ_0.npy', 'Test/เจอ_1.mp4/เจอ_1.npy', 'Test/เจ้าหนี้_0.mp4/เจ้าหนี้_0.npy', 'Test/เจ้าหนี้_1.mp4/เจ้าหนี้_1.npy', 'Test/เช่าซื้อ_0.mp4/เช่าซื้อ_0.npy', 'Test/เช่าซื้อ_1.mp4/เช่าซื้อ_1.npy', 'Test/เช่าทรัพย์_0.mp4/เช่าทรัพย์_0.npy', 'Test/เช่าทรัพย์_1.mp4/เช่าทรัพย์_1.npy', 'Test/เซอร์เบีย_0.mp4/เซอร์เบีย_0.npy', 'Test/เซอร์เบีย_1.mp4/เซอร์เบีย_1.npy', 'Test/เซเนกัล_0.mp4/เซเนกัล_0.npy', 'Test/เซเนกัล_1.mp4/เซเนกัล_1.npy', 'Test/เซ็ง_0.mp4/เซ็ง_0.npy', 'Test/เซ็ง_1.mp4/เซ็ง_1.npy', 'Test/เดิน_0.mp4/เดิน_0.npy', 'Test/เดิน_1.mp4/เดิน_1.npy', 'Test/เดิมพัน_0.mp4/เดิมพัน_0.npy', 'Test/เดิมพัน_1.mp4/เดิมพัน_1.npy', 'Test/เพลีย_0.mp4/เพลีย_0.npy', 'Test/เพลีย_1.mp4/เพลีย_1.npy', 'Test/เมื่อย_0.mp4/เมื่อย_0.npy', 'Test/เมื่อย_1.mp4/เมื่อย_1.npy', 'Test/เม็กซิโก_0.mp4/เม็กซิโก_0.npy', 'Test/เม็กซิโก_1.mp4/เม็กซิโก_1.npy', 'Test/เฮโรอีน_0.mp4/เฮโรอีน_0.npy', 'Test/เฮโรอีน_1.mp4/เฮโรอีน_1.npy', 'Test/แกมเบีย_0.mp4/แกมเบีย_0.npy', 'Test/แกมเบีย_1.mp4/แกมเบีย_1.npy', 'Test/แซมเบีย_0.mp4/แซมเบีย_0.npy', 'Test/แซมเบีย_1.mp4/แซมเบีย_1.npy', 'Test/โกหก_0.mp4/โกหก_0.npy', 'Test/โกหก_1.mp4/โกหก_1.npy', 'Test/โจทก์_0.mp4/โจทก์_0.npy', 'Test/โจทก์_1.mp4/โจทก์_1.npy', 'Test/โชจู_0.mp4/โชจู_0.npy', 'Test/โชจู_1.mp4/โชจู_1.npy', 'Test/ใกล้_0.mp4/ใกล้_0.npy', 'Test/ใกล้_1.mp4/ใกล้_1.npy', 'Test/ไดโนเสาร์_0.mp4/ไดโนเสาร์_0.npy', 'Test/ไดโนเสาร์_1.mp4/ไดโนเสาร์_1.npy', 'Test/ไอซ์_0.mp4/ไอซ์_0.npy', 'Test/ไอซ์_1.mp4/ไอซ์_1.npy']\n"
     ]
    }
   ],
   "source": [
    "file_paths = []\n",
    "for action in actions_test:\n",
    "    video_path = os.path.join('Test/', action)\n",
    "    # print(video_path)\n",
    "    # print(action)\n",
    "    file_paths.append(video_path + '/' + action.split(\".\")[0] + \".npy\")\n",
    "print(file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input : กฎกระทรวง_0 Predicted : กฎกระทรวง\n",
      "Input : กฎกระทรวง_1 Predicted : กฎกระทรวง\n",
      "Input : กฎหมายรัฐธรรมนูญ_0 Predicted : กฎหมายรัฐธรรมนูญ\n",
      "Input : กฎหมายรัฐธรรมนูญ_1 Predicted : กฎหมายรัฐธรรมนูญ\n",
      "Input : กรมอนามัย_0 Predicted : เขื่อนสิริกิติ์\n",
      "Input : กรมอนามัย_1 Predicted : กรมอนามัย\n",
      "Input : กรรม_0 Predicted : ไดโนเสาร์\n",
      "Input : กรรม_1 Predicted : กรรม\n",
      "Input : กรรมสิทธิ์_0 Predicted : กรรมสิทธิ์\n",
      "Input : กรรมสิทธิ์_1 Predicted : เช่าทรัพย์\n",
      "Input : กระโดด_0 Predicted : เจ้าหนี้\n",
      "Input : กระโดด_1 Predicted : เมื่อย\n",
      "Input : กล้วยบวชชี_0 Predicted : กฎหมายรัฐธรรมนูญ\n",
      "Input : กล้วยบวชชี_1 Predicted : กฎหมายรัฐธรรมนูญ\n",
      "Input : กล้วยเชื่อม_0 Predicted : กล้วยเชื่อม\n",
      "Input : กล้วยเชื่อม_1 Predicted : กล้วยเชื่อม\n",
      "Input : กังวล_0 Predicted : เม็กซิโก\n",
      "Input : กังวล_1 Predicted : กังวล\n",
      "Input : กีฬา_0 Predicted : กรมอนามัย\n",
      "Input : กีฬา_1 Predicted : เครื่องหมายการค้า\n",
      "Input : น้อง_0 Predicted : กล้วยเชื่อม\n",
      "Input : น้อง_1 Predicted : น้อง\n",
      "Input : เขิน_0 Predicted : เครียด\n",
      "Input : เขิน_1 Predicted : เขิน\n",
      "Input : เขื่อนดิน_0 Predicted : เขื่อนดิน\n",
      "Input : เขื่อนดิน_1 Predicted : เขื่อนดิน\n",
      "Input : เขื่อนสิริกิติ์_0 Predicted : กฎกระทรวง\n",
      "Input : เขื่อนสิริกิติ์_1 Predicted : เขื่อนสิริกิติ์\n",
      "Input : เข้าใจผิด_0 Predicted : แกมเบีย\n",
      "Input : เข้าใจผิด_1 Predicted : กังวล\n",
      "Input : เคย_0 Predicted : เคย\n",
      "Input : เคย_1 Predicted : เคย\n",
      "Input : เครียด_0 Predicted : เครียด\n",
      "Input : เครียด_1 Predicted : เครียด\n",
      "Input : เครื่องปั่นดิน_0 Predicted : เขื่อนดิน\n",
      "Input : เครื่องปั่นดิน_1 Predicted : เขื่อนดิน\n",
      "Input : เครื่องหมายการค้า_0 Predicted : เครื่องหมายการค้า\n",
      "Input : เครื่องหมายการค้า_1 Predicted : เครื่องหมายการค้า\n",
      "Input : เจอ_0 Predicted : เจอ\n",
      "Input : เจอ_1 Predicted : เจอ\n",
      "Input : เจ้าหนี้_0 Predicted : เจ้าหนี้\n",
      "Input : เจ้าหนี้_1 Predicted : เจ้าหนี้\n",
      "Input : เช่าซื้อ_0 Predicted : เช่าซื้อ\n",
      "Input : เช่าซื้อ_1 Predicted : เช่าซื้อ\n",
      "Input : เช่าทรัพย์_0 Predicted : เช่าทรัพย์\n",
      "Input : เช่าทรัพย์_1 Predicted : เม็กซิโก\n",
      "Input : เซอร์เบีย_0 Predicted : กฎหมายรัฐธรรมนูญ\n",
      "Input : เซอร์เบีย_1 Predicted : เมื่อย\n",
      "Input : เซเนกัล_0 Predicted : เซเนกัล\n",
      "Input : เซเนกัล_1 Predicted : เซเนกัล\n",
      "Input : เซ็ง_0 Predicted : เมื่อย\n",
      "Input : เซ็ง_1 Predicted : เซ็ง\n",
      "Input : เดิน_0 Predicted : เดิน\n",
      "Input : เดิน_1 Predicted : เดิน\n",
      "Input : เดิมพัน_0 Predicted : เช่าทรัพย์\n",
      "Input : เดิมพัน_1 Predicted : เช่าทรัพย์\n",
      "Input : เพลีย_0 Predicted : โจทก์\n",
      "Input : เพลีย_1 Predicted : กฎกระทรวง\n",
      "Input : เมื่อย_0 Predicted : เมื่อย\n",
      "Input : เมื่อย_1 Predicted : เมื่อย\n",
      "Input : เม็กซิโก_0 Predicted : เม็กซิโก\n",
      "Input : เม็กซิโก_1 Predicted : เม็กซิโก\n",
      "Input : เฮโรอีน_0 Predicted : เฮโรอีน\n",
      "Input : เฮโรอีน_1 Predicted : เฮโรอีน\n",
      "Input : แกมเบีย_0 Predicted : แกมเบีย\n",
      "Input : แกมเบีย_1 Predicted : แกมเบีย\n",
      "Input : แซมเบีย_0 Predicted : แซมเบีย\n",
      "Input : แซมเบีย_1 Predicted : แซมเบีย\n",
      "Input : โกหก_0 Predicted : น้อง\n",
      "Input : โกหก_1 Predicted : โกหก\n",
      "Input : โจทก์_0 Predicted : ไดโนเสาร์\n",
      "Input : โจทก์_1 Predicted : โจทก์\n",
      "Input : โชจู_0 Predicted : เม็กซิโก\n",
      "Input : โชจู_1 Predicted : โชจู\n",
      "Input : ใกล้_0 Predicted : กระโดด\n",
      "Input : ใกล้_1 Predicted : กระโดด\n",
      "Input : ไดโนเสาร์_0 Predicted : เฮโรอีน\n",
      "Input : ไดโนเสาร์_1 Predicted : ไดโนเสาร์\n",
      "Input : ไอซ์_0 Predicted : แกมเบีย\n",
      "Input : ไอซ์_1 Predicted : ไอซ์\n",
      "Correct Predicted on Training set : 0 Corrct percentage : 0.0%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "num_clip = 0\n",
    "for clip in labels_test:\n",
    "    # print(clip)\n",
    "    file_paths = [f\"Test/{clip}.mp4/{clip}.npy\"]\n",
    "    # print(file_paths)\n",
    "\n",
    "    sequences = load_keypoint_sequences(file_paths)\n",
    "    # Change list to numpy array \n",
    "    sequences = np.array(sequences)\n",
    "    # Change numpy array to tensor\n",
    "    sequences = torch.FloatTensor(sequences)\n",
    "    sequences = pad_sequence(sequences, batch_first=True)\n",
    "\n",
    "    outputs = model(sequences.to(device))\n",
    "\n",
    "    for idx, word in enumerate(outputs):\n",
    "        # max_value = torch.max(outputs)\n",
    "        list_outputs = max(outputs)\n",
    "\n",
    "    index_max = max(range(len(list_outputs)), key=list_outputs.__getitem__)\n",
    "\n",
    "    print(f\"Input : {clip} Predicted : {labels[index_max]}\")\n",
    "\n",
    "    if clip == labels[index_max]:\n",
    "        correct = correct+1\n",
    "    \n",
    "    num_clip = num_clip + 1 \n",
    "\n",
    "print(f\"Correct Predicted on Training set : {correct} Corrct percentage : {correct*100/num_clip}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
