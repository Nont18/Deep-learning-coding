{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch\n",
    "\n",
    "is one of the popular deep learning frame work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn # For neural network, optimizer, loss function, layers\n",
    "import torchvision # Computer vision algorithm\n",
    "import torch.nn.functional as F\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = [[1, 1, 1],\n",
    "    [1.5, 1.5, 1.5],\n",
    "    [2, 2, 2]]\n",
    "\n",
    "x = [[6], [7], [8]]\n",
    "\n",
    "b = [[1], [1], [1]]\n",
    "\n",
    "y = [[0], [0], [0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_np = np.array(W)\n",
    "W_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_np = np.array(x)\n",
    "x_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_np = np.ones((3, 1))\n",
    "b_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = np.matmul(W_np, x_np) + b_np\n",
    "print(\"Output : \\n\", output)\n",
    "print(\"Shape : \", output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's Try Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_torch = torch.FloatTensor(W)\n",
    "\n",
    "x_torch = torch.FloatTensor(x)\n",
    "\n",
    "b_torch = torch.ones(3,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "แปลงจาก numpy -> torch : ใช้ฟังก์ชัน torch.FloatTensor()\n",
    "แปลงจาก torch -> numpy : ใช้ฟังก์ชัน .numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_array = np.random.random((3,4))\n",
    "np_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_tensor = torch.FloatTensor(np_array)\n",
    "torch_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_array2 = torch_tensor.numpy()\n",
    "np_array2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.rand(4, 5)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_1 = torch.rand(3,3,3) # first 3 calls batch dimension\n",
    "tensor_2 = torch.rand(3,3,3)\n",
    "\n",
    "add_result = tensor_1 + tensor_2\n",
    "mul_result = tensor_1 * tensor_2\n",
    "\n",
    "print(\"Addition : \\n\", add_result)\n",
    "print(\"Batch Multiplication : \\n\", mul_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_3 = torch.rand(2,4,5) # batch dimension = 2\n",
    "tensor_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_3.transpose(0,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.rand(2,3,1,4)\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor[:, 1, 0, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describing Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.rand(3,5,3,2)\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor.reshape(3,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor.flatten() # We can also use the Flatten method to convert to a 1D Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor.numel() # View the number of elements in total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Squeezing and Unsqueezing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.rand(3, 2)\n",
    "\n",
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor.unsqueeze # Unsqueeze adds an \"empty\" dimension to our Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor.unsqueeze(1).shape # Unsqueeze adds an \"empty\" dimension to pur Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Lets create a 2D Tensor\n",
    "tensor = torch.rand(3,2)\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor.unsqueeze(2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor.unsqueeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets create a 4D Tensor with a few \"empty\" dimensions\n",
    "tensor = torch.rand(1,3,1,2)\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor.squeeze(2).shape # squeeze removes an \"empty\" dimension from our Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor.squeeze(0).shape # squeeze removes an \"empty\" dimension from our Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor.squeeze().shape # If we don't specify a dimension, squeeze will remove ALL empty dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boardcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor1 = torch.rand(1,4,3,1)\n",
    "tensor2 = torch.rand(3,4,1,4)\n",
    "\n",
    "tensor3 = tensor1 + tensor2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.optim as optim \n",
    "import torch.nn.functional as F \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerEncoderLayer(\n",
       "  (self_attn): MultiheadAttention(\n",
       "    (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "  )\n",
       "  (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "  (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  (dropout1): Dropout(p=0.1, inplace=False)\n",
       "  (dropout2): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_layer = nn.TransformerEncoderLayer(d_model=512, nhead=8)\n",
    "encoder_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Windows 10\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TransformerEncoder(\n",
       "  (layers): ModuleList(\n",
       "    (0-5): 6 x TransformerEncoderLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "      (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "      (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (dropout2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=6)\n",
    "transformer_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.7501, 0.9666, 0.0586,  ..., 0.7763, 0.6455, 0.0020],\n",
       "         [0.3634, 0.5891, 0.5072,  ..., 0.3037, 0.0930, 0.8585],\n",
       "         [0.3133, 0.2253, 0.1201,  ..., 0.4338, 0.1026, 0.5115],\n",
       "         ...,\n",
       "         [0.4942, 0.1269, 0.3302,  ..., 0.6041, 0.6952, 0.9387],\n",
       "         [0.1819, 0.9562, 0.2421,  ..., 0.3497, 0.2596, 0.9642],\n",
       "         [0.1399, 0.8375, 0.1582,  ..., 0.1769, 0.2535, 0.0893]],\n",
       "\n",
       "        [[0.3113, 0.3291, 0.6418,  ..., 0.3635, 0.4795, 0.7667],\n",
       "         [0.6885, 0.2902, 0.5716,  ..., 0.4435, 0.9590, 0.3318],\n",
       "         [0.1438, 0.3124, 0.9596,  ..., 0.7508, 0.2811, 0.4790],\n",
       "         ...,\n",
       "         [0.9925, 0.0514, 0.5801,  ..., 0.8119, 0.5110, 0.7906],\n",
       "         [0.1138, 0.3411, 0.1152,  ..., 0.3395, 0.1701, 0.9246],\n",
       "         [0.9142, 0.7350, 0.7266,  ..., 0.8645, 0.0302, 0.4158]],\n",
       "\n",
       "        [[0.3214, 0.0731, 0.1728,  ..., 0.5853, 0.1135, 0.1624],\n",
       "         [0.0599, 0.9215, 0.2395,  ..., 0.4608, 0.2166, 0.1337],\n",
       "         [0.2809, 0.6946, 0.0061,  ..., 0.8518, 0.6025, 0.9332],\n",
       "         ...,\n",
       "         [0.7760, 0.0454, 0.9151,  ..., 0.9541, 0.3892, 0.0988],\n",
       "         [0.7898, 0.9833, 0.4713,  ..., 0.5501, 0.0998, 0.0049],\n",
       "         [0.9338, 0.2653, 0.3922,  ..., 0.3501, 0.5905, 0.5565]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.1236, 0.8566, 0.8979,  ..., 0.9306, 0.1376, 0.8452],\n",
       "         [0.9271, 0.3196, 0.0445,  ..., 0.5153, 0.0029, 0.1643],\n",
       "         [0.4606, 0.6379, 0.7065,  ..., 0.7505, 0.4697, 0.7642],\n",
       "         ...,\n",
       "         [0.9398, 0.8899, 0.7961,  ..., 0.3638, 0.4281, 0.5576],\n",
       "         [0.8798, 0.2739, 0.4306,  ..., 0.1636, 0.8620, 0.3324],\n",
       "         [0.2798, 0.0590, 0.1810,  ..., 0.6239, 0.9835, 0.5482]],\n",
       "\n",
       "        [[0.6944, 0.8405, 0.1341,  ..., 0.3440, 0.2080, 0.6664],\n",
       "         [0.8411, 0.9806, 0.9423,  ..., 0.3468, 0.0800, 0.5714],\n",
       "         [0.7280, 0.3876, 0.6511,  ..., 0.7328, 0.3114, 0.8126],\n",
       "         ...,\n",
       "         [0.0378, 0.3086, 0.4098,  ..., 0.5894, 0.7585, 0.8660],\n",
       "         [0.8031, 0.4119, 0.4881,  ..., 0.9456, 0.0758, 0.9068],\n",
       "         [0.1680, 0.3509, 0.6503,  ..., 0.4951, 0.7062, 0.6672]],\n",
       "\n",
       "        [[0.8801, 0.5495, 0.6669,  ..., 0.4608, 0.6070, 0.7201],\n",
       "         [0.8929, 0.4018, 0.8306,  ..., 0.1306, 0.8349, 0.6965],\n",
       "         [0.9121, 0.4263, 0.0682,  ..., 0.3628, 0.3922, 0.0202],\n",
       "         ...,\n",
       "         [0.1346, 0.0645, 0.2230,  ..., 0.3810, 0.4513, 0.1291],\n",
       "         [0.8498, 0.0890, 0.2073,  ..., 0.7554, 0.8411, 0.9126],\n",
       "         [0.0890, 0.9490, 0.2839,  ..., 0.9348, 0.0429, 0.2256]]])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src = torch.rand(10, 32, 512)\n",
    "src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.4173,  0.5285, -0.4922,  ...,  1.1220,  0.7068,  1.0513],\n",
       "         [ 0.3009,  1.9245,  0.0360,  ...,  1.8044, -0.4298,  1.7677],\n",
       "         [ 0.5797,  1.5567, -1.6801,  ...,  1.4111, -0.4040,  0.9337],\n",
       "         ...,\n",
       "         [ 0.5793,  0.4899, -0.6119,  ...,  1.0848, -0.1130,  2.4516],\n",
       "         [ 0.4736,  2.0445, -0.7715,  ...,  1.9221,  0.2788,  2.0215],\n",
       "         [ 0.2812,  1.5383, -0.9209,  ...,  1.6190, -0.6726,  0.8762]],\n",
       "\n",
       "        [[ 0.2926,  0.8590, -0.9603,  ...,  0.8808, -0.1247,  1.9269],\n",
       "         [ 1.1727,  1.0175,  0.1411,  ...,  1.5764,  0.7284,  0.7808],\n",
       "         [ 0.4388,  0.9928, -0.4929,  ...,  1.3696,  0.0744,  1.4126],\n",
       "         ...,\n",
       "         [ 0.8746,  0.5627, -1.0806,  ...,  1.3645, -0.2224,  1.8059],\n",
       "         [ 0.1838,  1.3060, -0.9096,  ...,  1.1115, -0.1536,  1.7110],\n",
       "         [ 0.8386,  1.3279, -0.1315,  ...,  1.8202, -0.5299,  0.2497]],\n",
       "\n",
       "        [[ 0.5989, -0.0983, -1.2882,  ...,  1.1254, -0.3235,  0.8870],\n",
       "         [ 0.1600,  1.4805, -0.4301,  ...,  1.8629, -0.3025,  1.8343],\n",
       "         [-0.0518,  1.2687, -0.4469,  ...,  0.9345, -0.1137,  2.0111],\n",
       "         ...,\n",
       "         [ 1.0003,  0.3733, -0.9541,  ...,  1.8061, -0.2695,  1.1051],\n",
       "         [ 1.2866,  1.5390, -0.2677,  ...,  1.0965,  0.0784,  1.1563],\n",
       "         [ 0.9547,  1.5445, -0.8788,  ...,  1.4442,  0.2141,  0.7379]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.6236,  1.2407, -0.7597,  ...,  0.7943, -1.0019,  1.0176],\n",
       "         [ 1.6462,  0.9501, -0.6454,  ...,  1.0629, -0.5964,  1.4991],\n",
       "         [ 0.9149,  0.9319, -0.1033,  ...,  0.8512,  0.3892,  1.6597],\n",
       "         ...,\n",
       "         [ 0.6343,  0.9471, -0.6208,  ...,  1.1056,  0.2773,  1.2204],\n",
       "         [ 0.6665,  0.7687, -0.1420,  ...,  0.9313,  0.7977,  1.6158],\n",
       "         [ 0.5078,  1.4360, -0.9204,  ...,  0.8869,  0.4426,  0.3490]],\n",
       "\n",
       "        [[ 0.9885,  1.3558, -1.1083,  ...,  0.5255, -0.9046,  0.7175],\n",
       "         [ 1.2406,  1.9235,  0.1809,  ...,  0.7413,  0.2695,  1.7180],\n",
       "         [ 0.3784,  1.7276, -1.0961,  ...,  1.4454,  0.3374,  1.7873],\n",
       "         ...,\n",
       "         [ 0.5924,  0.5666, -0.6345,  ...,  0.9169,  0.5289,  1.0845],\n",
       "         [ 0.9474,  1.9560, -0.7336,  ...,  1.5401,  0.2848,  2.3783],\n",
       "         [ 0.4499,  1.4949, -0.5379,  ...,  1.6915,  0.5388,  0.5575]],\n",
       "\n",
       "        [[ 0.4301,  1.0400, -0.7407,  ...,  0.8982, -0.1723,  1.5265],\n",
       "         [ 0.6475,  1.2195,  0.4311,  ...,  1.3238,  0.2925,  2.0333],\n",
       "         [ 1.8411,  1.1905, -1.1295,  ...,  0.8782, -0.0374,  1.1962],\n",
       "         ...,\n",
       "         [ 0.2698,  0.4105, -0.5062,  ...,  0.7650, -0.2726,  0.8909],\n",
       "         [ 0.2994,  1.1363, -0.2515,  ...,  1.0447,  0.6250,  1.8989],\n",
       "         [ 0.2174,  2.1452, -0.1576,  ...,  1.0956,  0.1735,  0.8934]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = transformer_encoder(src)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
